{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Draft \u00b6 Draft \u00b6 Draft \u00b6 Draft Draft Draft Draft, Draft , Draft , Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft Draft","title":"Home"},{"location":"#draft","text":"","title":"Draft"},{"location":"#draft_1","text":"","title":"Draft"},{"location":"#draft_2","text":"","title":"Draft"},{"location":"Catalogize/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Intake data-sets from scratch \u00b6 % load_ext lab_black import intake import dask import pandas as pd Open the data sources \u00b6 intake.open_csv reads CSV files into dataframes Parameters are: urlpath : str or iterable, location of data csv_kwargs : dict storage_options : dict path_as_pattern : bool or str, optional csv_kwargs are specific to the plugin. dask.dataframe.read_csv?Signature: dask.dataframe.read_csv( urlpath, blocksize='default', lineterminator=None, compression=None, sample=256000, enforce=False, assume_missing=False, storage_options=None, include_path_column=False, **kwargs, ) src = intake . open_csv ( urlpath = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , csv_kwargs = { \"sep\" : \",\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"departement\" : str , \"jour\" : pd . StringDtype , \"pop\" : pd . StringDtype , \"P\" : pd . StringDtype , \"cl_age90\" : pd . StringDtype , }, }, ) Feed a Catalog \u00b6 A Catalog instance is an object with one or more named entries.The entries might be read: - from a static file (e.g., YAML), - from an Intake server - from any other data service that has a driver. Those are ordinary DataSource classes, except that they have the container type \u201ccatalog\u201d, and do not return data products via the read() method. cat = intake . open_catalog ( name = \"mon catalogue\" ) cat mon catalogue: args: args: null name: mon catalogue description: '' driver: intake.catalog.base.Catalog metadata: {} intake.EntrypointsCatalog? intake.Schema holds details of data description for any type of data-source Subclasses: SQLCatalog from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"source1\" : LocalCatalogEntry ( \"taux\" , description = \"Taux de positivit\u00e9 - quotidien - d\u00e9partement\" , driver = \"csv\" , args = { \"urlpath\" : \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , \"csv_kwargs\" : { \"sep\" : \";\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"dep\" : str , }, }, }, ) } ) print ( mycat [ \"source1\" ] . yaml ()) sources: taux: args: csv_kwargs: blocksize: null dtype: dep: !!python/name:builtins.str '' encoding: iso-8859-1 sep: ; urlpath: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement\" driver: intake.source.csv.CSVSource metadata: catalog_dir: '' mycat . source1 . read () . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour P T cl_age90 0 01 2020-05-13 0 16 9 1 01 2020-05-13 1 17 19 2 01 2020-05-13 0 33 29 3 01 2020-05-13 1 72 39 4 01 2020-05-13 0 54 49 acat = intake . open_catalog ( name = \" catalogue\" ) print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"cato\" : src }, description = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19\" , ) mycat null: args: description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" driver: intake.catalog.base.Catalog metadata: {} type ( mycat ) intake.catalog.base.Catalog mycat . cato csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} type ( src ) intake.source.csv.CSVSource mycat [ \"cato\" ] . description = \"blabla\" mycat . save ( \"aze.yaml\" ) % cat aze . yaml metadata: {} name: null sources: cato: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' parameters: {} urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e src . description src . get () csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . discover () {'datashape': None, 'dtype': {'extract_date': 'object', 'departement': 'object', 'region': 'int64', 'libelle_reg': 'object', 'libelle_dep': 'object', 'tx_incid': 'float64', 'R': 'float64', 'taux_occupation_sae': 'float64', 'tx_pos': 'float64', 'tx_incid_couleur': 'object', 'R_couleur': 'object', 'taux_occupation_sae_couleur': 'object', 'tx_pos_couleur': 'object', 'nb_orange': 'int64', 'nb_rouge': 'int64'}, 'shape': (None, 15), 'npartitions': 1, 'metadata': {}} src . catalog_object src . description = \"AZE\" from pathlib import Path Path ( \"./one.yml\" ) . write_text ( src . yaml ()) 498 print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . shape (None, 15) df = src . read () print ( src . yaml ()) src . urls = dict ( indicateurs = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/\" , titre = \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"indicateurs-covid19-dep\" , delim = \",\" , ), tests_positivite = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed117db6c161bd5baf070be\" , titre = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 SI-DEP\" , file_pattern = \"sp-pos-quot-dep\" , delim = \";\" , ), tests_capacites = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/capacite-analytique-de-tests-virologiques-dans-le-cadre-de-lepidemie-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/0c230dc3-2d51-4f17-be97-aa9938564b39\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed11705afd28672e40fbc2f/\" , titre = \"Capacit\u00e9 analytique de tests virologiques dans le cadre de l'\u00e9pid\u00e9mie COVID-19 SI-DEP\" , file_pattern = \"sp-capa-quot-dep\" , delim = \";\" , ), incidence = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed1175ca00bbe1e4941a46a\" , titre = \"Taux d'incidence de l'\u00e9pid\u00e9mie de COVID-19 SI-DEP\" , file_pattern = \"sp-pe-tb-quot-dep\" , delim = \";\" , ), sursaud = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-des-urgences-hospitalieres-et-de-sos-medecins-relatives-a-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/eceb9fb4-3ebc-4da3-828d-f5939712600a\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5e74ecf52eb7514f2d3b8845\" , titre = \"Donn\u00e9es des urgences hospitali\u00e8res et de SOS m\u00e9decins relatives \u00e0 l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"sursaud-corona-quot-dep\" , delim = \";\" , ), ) import requests req = requests . get ( urls [ \"tests_positivite\" ][ \"url_api\" ]) resp = req . json () resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] import re resources [ 0 ][ \"title\" ] . rstrip ( r \"\\w*\" ) 'sp-pos-quot-dep-2020-09-25-19h15.csv' out = [ { \"args\" : { \"csv_kwargs\" : { \"blocksize\" : \"null\" , \"encoding\" : \"iso-8850-1\" , \"sep\" : \",\" } }, \"description\" : resource . get ( \"description\" , None ), \"metadata\" : { \"title\" : resp . get ( \"title\" , None ), \"uri\" : resp . get ( \"uri\" , None )}, } for resource in resources ] load ( out ) <ipython-input-93-f0a5f1c8081f>:12: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. load(out) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-93-f0a5f1c8081f> in <module> 10 ] 11 ---> 12 load ( out ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/__init__.py in load (stream, Loader) 110 Loader = FullLoader 111 --> 112 loader = Loader ( stream ) 113 try : 114 return loader . get_single_data ( ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/loader.py in __init__ (self, stream) 22 23 def __init__ ( self , stream ) : ---> 24 Reader . __init__ ( self , stream ) 25 Scanner . __init__ ( self ) 26 Parser . __init__ ( self ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in __init__ (self, stream) 83 self . eof = False 84 self . raw_buffer = None ---> 85 self . determine_encoding ( ) 86 87 def peek ( self , index = 0 ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in determine_encoding (self) 122 def determine_encoding ( self ) : 123 while not self . eof and ( self . raw_buffer is None or len ( self . raw_buffer ) < 2 ) : --> 124 self . update_raw ( ) 125 if isinstance ( self . raw_buffer , bytes ) : 126 if self . raw_buffer . startswith ( codecs . BOM_UTF16_LE ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in update_raw (self, size) 176 177 def update_raw ( self , size = 4096 ) : --> 178 data = self . stream . read ( size ) 179 if self . raw_buffer is None : 180 self . raw_buffer = data AttributeError : 'list' object has no attribute 'read' out [{'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - Quotidien.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Description des m\u00e9tadonn\u00e9es.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}] for k in resp : print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resp . get ( k )) ******************************************************************************** acronym -------------------------------------------------------------------------------- SI-DEP ******************************************************************************** archived -------------------------------------------------------------------------------- None ******************************************************************************** badges -------------------------------------------------------------------------------- [] ******************************************************************************** created_at -------------------------------------------------------------------------------- 2020-05-29T16:10:35.407000 ******************************************************************************** deleted -------------------------------------------------------------------------------- None ******************************************************************************** description -------------------------------------------------------------------------------- ### Les actions de Sant\u00e9 publique France Sant\u00e9 publique France a pour mission d'am\u00e9liorer et de prot\u00e9ger la sant\u00e9 des populations. Durant la crise sanitaire li\u00e9e \u00e0 l'\u00e9pid\u00e9mie du COVID-19, Sant\u00e9 publique France se charge de surveiller et comprendre la dynamique de l'\u00e9pid\u00e9mie, d'anticiper les diff\u00e9rents sc\u00e9narii et de mettre en place des actions pour pr\u00e9venir et limiter la transmission de ce virus sur le territoire national. ### Le Syst\u00e8me d\u2019Informations de DEPistage (SI-DEP) Le nouveau syst\u00e8me d\u2019information de d\u00e9pistage (SI-DEP), en d\u00e9ploiement depuis le 13 mai 2020, est une plateforme s\u00e9curis\u00e9e o\u00f9 sont syst\u00e9matiquement enregistr\u00e9s les r\u00e9sultats des laboratoires des tests (RT-PCR) r\u00e9alis\u00e9s par l\u2019ensemble des laboratoires de ville et \u00e9tablissements hospitaliers concernant le SARS-COV2. La cr\u00e9ation de ce syst\u00e8me d'information est autoris\u00e9e pour une dur\u00e9e de 6 mois \u00e0 compter de la fin de l'\u00e9tat d'urgence sanitaire par application du [d\u00e9cret n\u00b0 2020-551 du 12 mai 2020](https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000041869923) relatif aux syst\u00e8mes d\u2019information mentionn\u00e9s \u00e0 l\u2019article 11 de la loi n\u00b0 2020-546 du 11 mai 2020 prorogeant l\u2019\u00e9tat d\u2019urgence sanitaire et compl\u00e9tant ses dispositions. ### Description des donn\u00e9es Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle d\u00e9partementale et r\u00e9gionale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par classe d'\u00e2ge (quotidien et hebdomadaire) ; - le nombre de personnes positives sur 7 jours glissants. Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle nationale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par sexe et classe d'\u00e2ge (quotidien et hebdomadaire). Le taux de positivit\u00e9 correspond au nombre de tests positifs rapport\u00e9s au nombre de tests r\u00e9alis\u00e9s. Il est calcul\u00e9 de la mani\u00e8re suivante : 100*nombre de test positif/ nombre de tests r\u00e9alis\u00e9s **Pr\u00e9cisions** : Si plusieurs pr\u00e9l\u00e8vements sont rapport\u00e9s pour un m\u00eame patient: - S\u00e9lection de la premi\u00e8re date pour les pcr ayant le m\u00eame r\u00e9sultat (par exemple premi\u00e8re date si plusieurs pcr n\u00e9gatives) - Si pcr discordantes chez un m\u00eame patient (N et P), la premi\u00e8re pcr positive est conserv\u00e9e. Exclusion des r\u00e9sultats ininterpr\u00e9tables - A compter du 29/08, les indicateurs issus des donn\u00e9es de laboratoires (SI-DEP) pr\u00e9sentent des taux d\u2019incidence, de positivit\u00e9 et de d\u00e9pistage corrig\u00e9s en fonction des d\u00e9pistages r\u00e9alis\u00e9s dans les a\u00e9roports \u00e0 l\u2019arriv\u00e9e des vols internationaux. La correction s\u2019applique sur l\u2019ensemble des donn\u00e9es post\u00e9rieures \u00e0 la date du 12 ao\u00fbt. **Limites** : - Seuls les tests biologiques des personnes pour lesquelles le d\u00e9partement de r\u00e9sidence a pu \u00eatre localis\u00e9 sont repr\u00e9sent\u00e9s sur les cartes. Les personnes dont le d\u00e9partement n\u2019a pas pu \u00eatre remont\u00e9 dans les donn\u00e9es SIDEP ne sont comptabilis\u00e9es qu'au niveau France enti\u00e8re. De ce fait la somme des tests indiqu\u00e9s dans les d\u00e9partements ou r\u00e9gions est inf\u00e9rieure au nombre de tests indiqu\u00e9 en France. - Le d\u00e9lai de remont\u00e9e des tests peut exc\u00e9der 9 jours dans certains cas. Les indicateurs sont ajust\u00e9s quotidiennement selon la r\u00e9ception des r\u00e9sultats. Pour en savoir plus consultez la note m\u00e9thodologique disponible dans les ressources. ******************************************************************************** extras -------------------------------------------------------------------------------- {'recommendations': [{'id': '5e7de8cf4663c08d4f74ba01', 'score': 89, 'source': 'matomo'}], 'recommendations:sources': ['matomo']} ******************************************************************************** frequency -------------------------------------------------------------------------------- unknown ******************************************************************************** frequency_date -------------------------------------------------------------------------------- None ******************************************************************************** id -------------------------------------------------------------------------------- 5ed117db6c161bd5baf070be ******************************************************************************** last_modified -------------------------------------------------------------------------------- 2020-09-25T19:15:13.847000 ******************************************************************************** last_update -------------------------------------------------------------------------------- 2020-08-27T00:00:00 ******************************************************************************** license -------------------------------------------------------------------------------- fr-lo ******************************************************************************** metrics -------------------------------------------------------------------------------- {'discussions': 21, 'followers': 5, 'issues': 0, 'reuses': 22, 'views': 6112} ******************************************************************************** organization -------------------------------------------------------------------------------- {'acronym': 'SPF', 'class': 'Organization', 'id': '5e721a395d57f93d0bed451f', 'logo': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-original.png', 'logo_thumbnail': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-100.png', 'name': 'Sant\u00e9 publique France', 'page': 'https://www.data.gouv.fr/fr/organizations/sante-publique-france/', 'slug': 'sante-publique-france', 'uri': 'https://www.data.gouv.fr/api/1/organizations/sante-publique-france/'} ******************************************************************************** owner -------------------------------------------------------------------------------- None ******************************************************************************** page -------------------------------------------------------------------------------- https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ ******************************************************************************** private -------------------------------------------------------------------------------- False ******************************************************************************** resources -------------------------------------------------------------------------------- [{'checksum': {'type': 'sha1', 'value': '21b8878f9b8df70e78a5a8ca6d9d28dd4b34a07e'}, 'created_at': '2020-09-01T15:01:03.280000', 'description': 'Note m\u00e9thodologique 27/08', 'extras': {}, 'filesize': 29885, 'filetype': 'file', 'format': 'docx', 'id': 'c98482d3-fba1-4397-99ae-1c958aa629f6', 'last_modified': '2020-09-01T15:04:27.976000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c98482d3-fba1-4397-99ae-1c958aa629f6', 'metrics': {'views': 167}, 'mime': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'preview_url': None, 'published': '2020-08-27T00:00:00', 'schema': None, 'title': 'analyse-de-la-base-sidep-note-methodologique.docx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200901-150103/analyse-de-la-base-sidep-note-methodologique.docx'}, {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'af41c6bc3aff81d2e3ab27e1fd4e85edd12efc77'}, 'created_at': '2020-05-29T18:03:11.045000', 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'extras': {}, 'filesize': 1026513, 'filetype': 'file', 'format': 'csv', 'id': '001aca18-df6a-45c8-89e6-f82d689e6c01', 'last_modified': '2020-09-25T19:15:13.194000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/001aca18-df6a-45c8-89e6-f82d689e6c01', 'metrics': {'views': 828}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:03:11', 'schema': None, 'title': 'sp-pos-quot-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '2879bad07eea8f4420beb68021944ab71af19b87'}, 'created_at': '2020-05-29T18:02:57.551000', 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'extras': {}, 'filesize': 61466, 'filetype': 'file', 'format': 'csv', 'id': 'dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'last_modified': '2020-09-25T19:15:13.762000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'metrics': {'views': 2639}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:57', 'schema': None, 'title': 'sp-pos-quot-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '511d145379f80e1fb1e2fe0bf90cff2d493b5fc5'}, 'created_at': '2020-05-29T18:01:11.291000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'extras': {}, 'filesize': 438028, 'filetype': 'file', 'format': 'csv', 'id': 'dd3ac13c-e87f-4b33-8897-07baff4e1783', 'last_modified': '2020-09-25T19:15:11.314000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd3ac13c-e87f-4b33-8897-07baff4e1783', 'metrics': {'views': 238}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191511%2Fsp-pos-heb-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:11', 'schema': None, 'title': 'sp-pos-heb-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191511/sp-pos-heb-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '59b6f0c920f3aa5a700d1ee1b20fef26b211596a'}, 'created_at': '2020-05-29T18:02:10.342000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'extras': {}, 'filesize': 146314, 'filetype': 'file', 'format': 'csv', 'id': '1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'last_modified': '2020-09-25T19:15:05.806000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'metrics': {'views': 25}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191505%2Fsp-pos-heb-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:10', 'schema': None, 'title': 'sp-pos-heb-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191505/sp-pos-heb-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '27b6ce97a5004564ea5f876f8c8c00f83300a288'}, 'created_at': '2020-05-29T18:01:35.129000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'extras': {}, 'filesize': 9087, 'filetype': 'file', 'format': 'csv', 'id': '2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'last_modified': '2020-09-25T19:15:03.498000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'metrics': {'views': 293}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191503%2Fsp-pos-heb-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:35', 'schema': None, 'title': 'sp-pos-heb-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191503/sp-pos-heb-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '41c46a8b6c450ddffea0845c85815dc42502192b'}, 'created_at': '2020-05-29T18:20:52.321000', 'description': None, 'extras': {}, 'filesize': 215055, 'filetype': 'file', 'format': 'csv', 'id': 'd1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'last_modified': '2020-07-03T19:15:20.039000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/d1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.321000', 'schema': None, 'title': 'sp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-dep-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '215ad0960bbad3719ea13622cbca9b4f15d01332'}, 'created_at': '2020-05-29T18:20:52.324000', 'description': None, 'extras': {}, 'filesize': 52837, 'filetype': 'file', 'format': 'csv', 'id': 'df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'last_modified': '2020-07-03T19:15:20.439000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.324000', 'schema': None, 'title': 'sp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-reg-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '3272b07774ea14ed57c63bb7b9fd26065cf3125d'}, 'created_at': '2020-05-29T18:20:52.318000', 'description': None, 'extras': {}, 'filesize': 2880, 'filetype': 'file', 'format': 'csv', 'id': 'c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'last_modified': '2020-07-03T19:15:19.607000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.318000', 'schema': None, 'title': 'sp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-fra-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'ce0d062e5faa1dcd83616f7bc9f74367b43fb6ff'}, 'created_at': '2020-05-29T17:19:23.764000', 'description': 'Taux de positivit\u00e9 - Quotidien.', 'extras': {}, 'filesize': 1337737, 'filetype': 'file', 'format': 'xlsx', 'id': 'c20aa429-d30b-41d1-8bea-37b106c5f33b', 'last_modified': '2020-07-03T19:15:27.711000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c20aa429-d30b-41d1-8bea-37b106c5f33b', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191527%2Fsp-pos-quot-2020-07-03-19h15.xlsx', 'published': '2020-05-29T17:19:23', 'schema': None, 'title': 'sp-pos-quot-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191527/sp-pos-quot-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '62fb3c2bf176eed6254a72d4067d250bb5414490'}, 'created_at': '2020-05-29T17:17:47.913000', 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'extras': {}, 'filesize': 207005, 'filetype': 'file', 'format': 'xlsx', 'id': 'fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'last_modified': '2020-07-01T19:15:23.424000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200701-191523%2Fsp-pos-heb-2020-07-01-19h15.xlsx', 'published': '2020-05-29T17:17:47', 'schema': None, 'title': 'sp-pos-heb-2020-07-01-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200701-191523/sp-pos-heb-2020-07-01-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': 'f526f981c17773cfc4207320275c2822ce425613'}, 'created_at': '2020-05-29T18:49:52.653000', 'description': None, 'extras': {}, 'filesize': 182582, 'filetype': 'file', 'format': 'xlsx', 'id': '708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'last_modified': '2020-07-03T19:15:20.863000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-2020-07-03-19h15.xlsx', 'published': '2020-05-29T18:49:52.653000', 'schema': None, 'title': 'sp-ti-tp-7j-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '89c55f3a82bb8dcb5f1d1b1f4cb431b798a653ec'}, 'created_at': '2020-05-29T17:00:35.757000', 'description': 'Description des m\u00e9tadonn\u00e9es.', 'extras': {}, 'filesize': 10422, 'filetype': 'file', 'format': 'xlsx', 'id': '39aaad1c-9aac-4be8-96b2-6d001f892b34', 'last_modified': '2020-05-29T17:00:54.313000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/39aaad1c-9aac-4be8-96b2-6d001f892b34', 'metrics': {'views': 321}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Ftaux-de-positivite-aux-tests-virologiques-covid-19%2F20200529-170035%2Fmetadonnees-positivite.xlsx', 'published': '2020-05-29T17:00:35', 'schema': None, 'title': 'metadonnees-positivite.xlsx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/taux-de-positivite-aux-tests-virologiques-covid-19/20200529-170035/metadonnees-positivite.xlsx'}] ******************************************************************************** slug -------------------------------------------------------------------------------- donnees-relatives-aux-resultats-des-tests-virologiques-covid-19 ******************************************************************************** spatial -------------------------------------------------------------------------------- None ******************************************************************************** tags -------------------------------------------------------------------------------- [] ******************************************************************************** temporal_coverage -------------------------------------------------------------------------------- None ******************************************************************************** title -------------------------------------------------------------------------------- Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 ******************************************************************************** uri -------------------------------------------------------------------------------- https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] from yaml import load , dump resources [ 0 ] {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'} print ( dump ( resources [ 0 ])) checksum: type: sha1 value: eb395230851890fe96cbc0618000ae70e302decd created_at: '2020-05-29T18:02:26.703000' description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement .\" extras: {} filesize: 3361733 filetype: file format: csv id: 406c6a23-e283-4300-9484-54e78c8ae675 last_modified: '2020-09-25T19:15:06.758000' latest: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 metrics: views: 8155 mime: text/csv preview_url: /tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv published: '2020-05-29T18:02:26' schema: null title: sp-pos-quot-dep-2020-09-25-19h15.csv type: main url: https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv 'description' , 'latest' , 'title' for k in resources : print ( k [ \"title\" ]) sp-pos-quot-dep-2020-09-25-19h15.csv sp-pos-quot-reg-2020-09-25-19h15.csv sp-pos-quot-fra-2020-09-25-19h15.csv sp-pos-heb-dep-2020-09-25-19h15.csv sp-pos-heb-reg-2020-09-25-19h15.csv sp-pos-heb-fra-2020-09-25-19h15.csv sp-ti-tp-7j-dep-2020-07-03-19h15.csv sp-ti-tp-7j-reg-2020-07-03-19h15.csv sp-ti-tp-7j-fra-2020-07-03-19h15.csv sp-pos-quot-2020-07-03-19h15.xlsx sp-pos-heb-2020-07-01-19h15.xlsx sp-ti-tp-7j-2020-07-03-19h15.xlsx metadonnees-positivite.xlsx for k in resources [ - 1 ]: print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resources [ - 1 ] . get ( k )) src [ \"indicateurs\" ] {'url_web': 'https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/', 'url_stable': 'https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e', 'url_api': 'https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/', 'titre': \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\", 'file_pattern': 'indicateurs-covid19-dep', 'delim': ','}","title":"Catalogize"},{"location":"Catalogize/#intake-data-sets-from-scratch","text":"% load_ext lab_black import intake import dask import pandas as pd","title":"Intake data-sets from scratch"},{"location":"Catalogize/#open-the-data-sources","text":"intake.open_csv reads CSV files into dataframes Parameters are: urlpath : str or iterable, location of data csv_kwargs : dict storage_options : dict path_as_pattern : bool or str, optional csv_kwargs are specific to the plugin. dask.dataframe.read_csv?Signature: dask.dataframe.read_csv( urlpath, blocksize='default', lineterminator=None, compression=None, sample=256000, enforce=False, assume_missing=False, storage_options=None, include_path_column=False, **kwargs, ) src = intake . open_csv ( urlpath = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , csv_kwargs = { \"sep\" : \",\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"departement\" : str , \"jour\" : pd . StringDtype , \"pop\" : pd . StringDtype , \"P\" : pd . StringDtype , \"cl_age90\" : pd . StringDtype , }, }, )","title":"Open the data sources"},{"location":"Catalogize/#feed-a-catalog","text":"A Catalog instance is an object with one or more named entries.The entries might be read: - from a static file (e.g., YAML), - from an Intake server - from any other data service that has a driver. Those are ordinary DataSource classes, except that they have the container type \u201ccatalog\u201d, and do not return data products via the read() method. cat = intake . open_catalog ( name = \"mon catalogue\" ) cat mon catalogue: args: args: null name: mon catalogue description: '' driver: intake.catalog.base.Catalog metadata: {} intake.EntrypointsCatalog? intake.Schema holds details of data description for any type of data-source Subclasses: SQLCatalog from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"source1\" : LocalCatalogEntry ( \"taux\" , description = \"Taux de positivit\u00e9 - quotidien - d\u00e9partement\" , driver = \"csv\" , args = { \"urlpath\" : \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , \"csv_kwargs\" : { \"sep\" : \";\" , \"blocksize\" : None , \"encoding\" : \"iso-8859-1\" , \"dtype\" : { \"dep\" : str , }, }, }, ) } ) print ( mycat [ \"source1\" ] . yaml ()) sources: taux: args: csv_kwargs: blocksize: null dtype: dep: !!python/name:builtins.str '' encoding: iso-8859-1 sep: ; urlpath: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement\" driver: intake.source.csv.CSVSource metadata: catalog_dir: '' mycat . source1 . read () . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour P T cl_age90 0 01 2020-05-13 0 16 9 1 01 2020-05-13 1 17 19 2 01 2020-05-13 0 33 29 3 01 2020-05-13 1 72 39 4 01 2020-05-13 0 54 49 acat = intake . open_catalog ( name = \" catalogue\" ) print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} from intake.catalog import Catalog from intake.catalog.local import LocalCatalogEntry mycat = Catalog . from_dict ( { \"cato\" : src }, description = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19\" , ) mycat null: args: description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" description: \"Donn\\xE9es relatives aux r\\xE9sultats des tests virologiques COVID-19\" driver: intake.catalog.base.Catalog metadata: {} type ( mycat ) intake.catalog.base.Catalog mycat . cato csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} type ( src ) intake.source.csv.CSVSource mycat [ \"cato\" ] . description = \"blabla\" mycat . save ( \"aze.yaml\" ) % cat aze . yaml metadata: {} name: null sources: cato: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' parameters: {} urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e src . description src . get () csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . discover () {'datashape': None, 'dtype': {'extract_date': 'object', 'departement': 'object', 'region': 'int64', 'libelle_reg': 'object', 'libelle_dep': 'object', 'tx_incid': 'float64', 'R': 'float64', 'taux_occupation_sae': 'float64', 'tx_pos': 'float64', 'tx_incid_couleur': 'object', 'R_couleur': 'object', 'taux_occupation_sae_couleur': 'object', 'tx_pos_couleur': 'object', 'nb_orange': 'int64', 'nb_rouge': 'int64'}, 'shape': (None, 15), 'npartitions': 1, 'metadata': {}} src . catalog_object src . description = \"AZE\" from pathlib import Path Path ( \"./one.yml\" ) . write_text ( src . yaml ()) 498 print ( src . yaml ()) sources: csv: args: csv_kwargs: blocksize: null dtype: P: &id001 !!python/name:pandas.core.arrays.string_.StringDtype '' cl_age90: *id001 departement: !!python/name:builtins.str '' jour: *id001 pop: *id001 encoding: iso-8859-1 sep: ',' urlpath: https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e description: '' driver: intake.source.csv.CSVSource metadata: {} src . shape (None, 15) df = src . read () print ( src . yaml ()) src . urls = dict ( indicateurs = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/\" , titre = \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"indicateurs-covid19-dep\" , delim = \",\" , ), tests_positivite = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed117db6c161bd5baf070be\" , titre = \"Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 SI-DEP\" , file_pattern = \"sp-pos-quot-dep\" , delim = \";\" , ), tests_capacites = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/capacite-analytique-de-tests-virologiques-dans-le-cadre-de-lepidemie-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/0c230dc3-2d51-4f17-be97-aa9938564b39\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed11705afd28672e40fbc2f/\" , titre = \"Capacit\u00e9 analytique de tests virologiques dans le cadre de l'\u00e9pid\u00e9mie COVID-19 SI-DEP\" , file_pattern = \"sp-capa-quot-dep\" , delim = \";\" , ), incidence = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5ed1175ca00bbe1e4941a46a\" , titre = \"Taux d'incidence de l'\u00e9pid\u00e9mie de COVID-19 SI-DEP\" , file_pattern = \"sp-pe-tb-quot-dep\" , delim = \";\" , ), sursaud = dict ( url_web = \"https://www.data.gouv.fr/fr/datasets/donnees-des-urgences-hospitalieres-et-de-sos-medecins-relatives-a-lepidemie-de-covid-19/\" , url_stable = \"https://www.data.gouv.fr/fr/datasets/r/eceb9fb4-3ebc-4da3-828d-f5939712600a\" , url_api = \"https://www.data.gouv.fr/api/1/datasets/5e74ecf52eb7514f2d3b8845\" , titre = \"Donn\u00e9es des urgences hospitali\u00e8res et de SOS m\u00e9decins relatives \u00e0 l'\u00e9pid\u00e9mie de COVID-19\" , file_pattern = \"sursaud-corona-quot-dep\" , delim = \";\" , ), ) import requests req = requests . get ( urls [ \"tests_positivite\" ][ \"url_api\" ]) resp = req . json () resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] import re resources [ 0 ][ \"title\" ] . rstrip ( r \"\\w*\" ) 'sp-pos-quot-dep-2020-09-25-19h15.csv' out = [ { \"args\" : { \"csv_kwargs\" : { \"blocksize\" : \"null\" , \"encoding\" : \"iso-8850-1\" , \"sep\" : \",\" } }, \"description\" : resource . get ( \"description\" , None ), \"metadata\" : { \"title\" : resp . get ( \"title\" , None ), \"uri\" : resp . get ( \"uri\" , None )}, } for resource in resources ] load ( out ) <ipython-input-93-f0a5f1c8081f>:12: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. load(out) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-93-f0a5f1c8081f> in <module> 10 ] 11 ---> 12 load ( out ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/__init__.py in load (stream, Loader) 110 Loader = FullLoader 111 --> 112 loader = Loader ( stream ) 113 try : 114 return loader . get_single_data ( ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/loader.py in __init__ (self, stream) 22 23 def __init__ ( self , stream ) : ---> 24 Reader . __init__ ( self , stream ) 25 Scanner . __init__ ( self ) 26 Parser . __init__ ( self ) /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in __init__ (self, stream) 83 self . eof = False 84 self . raw_buffer = None ---> 85 self . determine_encoding ( ) 86 87 def peek ( self , index = 0 ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in determine_encoding (self) 122 def determine_encoding ( self ) : 123 while not self . eof and ( self . raw_buffer is None or len ( self . raw_buffer ) < 2 ) : --> 124 self . update_raw ( ) 125 if isinstance ( self . raw_buffer , bytes ) : 126 if self . raw_buffer . startswith ( codecs . BOM_UTF16_LE ) : /opt/venvs/data_science/lib/python3.8/site-packages/yaml/reader.py in update_raw (self, size) 176 177 def update_raw ( self , size = 4096 ) : --> 178 data = self . stream . read ( size ) 179 if self . raw_buffer is None : 180 self . raw_buffer = data AttributeError : 'list' object has no attribute 'read' out [{'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - Quotidien.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': None, 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}, {'args': {'csv_kwargs': {'blocksize': 'null', 'encoding': 'iso-8850-1', 'sep': ','}}, 'description': 'Description des m\u00e9tadonn\u00e9es.', 'metadata': {'title': 'Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19', 'uri': 'https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/'}}] for k in resp : print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resp . get ( k )) ******************************************************************************** acronym -------------------------------------------------------------------------------- SI-DEP ******************************************************************************** archived -------------------------------------------------------------------------------- None ******************************************************************************** badges -------------------------------------------------------------------------------- [] ******************************************************************************** created_at -------------------------------------------------------------------------------- 2020-05-29T16:10:35.407000 ******************************************************************************** deleted -------------------------------------------------------------------------------- None ******************************************************************************** description -------------------------------------------------------------------------------- ### Les actions de Sant\u00e9 publique France Sant\u00e9 publique France a pour mission d'am\u00e9liorer et de prot\u00e9ger la sant\u00e9 des populations. Durant la crise sanitaire li\u00e9e \u00e0 l'\u00e9pid\u00e9mie du COVID-19, Sant\u00e9 publique France se charge de surveiller et comprendre la dynamique de l'\u00e9pid\u00e9mie, d'anticiper les diff\u00e9rents sc\u00e9narii et de mettre en place des actions pour pr\u00e9venir et limiter la transmission de ce virus sur le territoire national. ### Le Syst\u00e8me d\u2019Informations de DEPistage (SI-DEP) Le nouveau syst\u00e8me d\u2019information de d\u00e9pistage (SI-DEP), en d\u00e9ploiement depuis le 13 mai 2020, est une plateforme s\u00e9curis\u00e9e o\u00f9 sont syst\u00e9matiquement enregistr\u00e9s les r\u00e9sultats des laboratoires des tests (RT-PCR) r\u00e9alis\u00e9s par l\u2019ensemble des laboratoires de ville et \u00e9tablissements hospitaliers concernant le SARS-COV2. La cr\u00e9ation de ce syst\u00e8me d'information est autoris\u00e9e pour une dur\u00e9e de 6 mois \u00e0 compter de la fin de l'\u00e9tat d'urgence sanitaire par application du [d\u00e9cret n\u00b0 2020-551 du 12 mai 2020](https://www.legifrance.gouv.fr/affichTexte.do?cidTexte=JORFTEXT000041869923) relatif aux syst\u00e8mes d\u2019information mentionn\u00e9s \u00e0 l\u2019article 11 de la loi n\u00b0 2020-546 du 11 mai 2020 prorogeant l\u2019\u00e9tat d\u2019urgence sanitaire et compl\u00e9tant ses dispositions. ### Description des donn\u00e9es Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle d\u00e9partementale et r\u00e9gionale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par classe d'\u00e2ge (quotidien et hebdomadaire) ; - le nombre de personnes positives sur 7 jours glissants. Le pr\u00e9sent jeu de donn\u00e9es renseigne \u00e0 l'\u00e9chelle nationale : - le nombre de personnes test\u00e9es et le nombre de personnes d\u00e9clar\u00e9es positives par sexe et classe d'\u00e2ge (quotidien et hebdomadaire). Le taux de positivit\u00e9 correspond au nombre de tests positifs rapport\u00e9s au nombre de tests r\u00e9alis\u00e9s. Il est calcul\u00e9 de la mani\u00e8re suivante : 100*nombre de test positif/ nombre de tests r\u00e9alis\u00e9s **Pr\u00e9cisions** : Si plusieurs pr\u00e9l\u00e8vements sont rapport\u00e9s pour un m\u00eame patient: - S\u00e9lection de la premi\u00e8re date pour les pcr ayant le m\u00eame r\u00e9sultat (par exemple premi\u00e8re date si plusieurs pcr n\u00e9gatives) - Si pcr discordantes chez un m\u00eame patient (N et P), la premi\u00e8re pcr positive est conserv\u00e9e. Exclusion des r\u00e9sultats ininterpr\u00e9tables - A compter du 29/08, les indicateurs issus des donn\u00e9es de laboratoires (SI-DEP) pr\u00e9sentent des taux d\u2019incidence, de positivit\u00e9 et de d\u00e9pistage corrig\u00e9s en fonction des d\u00e9pistages r\u00e9alis\u00e9s dans les a\u00e9roports \u00e0 l\u2019arriv\u00e9e des vols internationaux. La correction s\u2019applique sur l\u2019ensemble des donn\u00e9es post\u00e9rieures \u00e0 la date du 12 ao\u00fbt. **Limites** : - Seuls les tests biologiques des personnes pour lesquelles le d\u00e9partement de r\u00e9sidence a pu \u00eatre localis\u00e9 sont repr\u00e9sent\u00e9s sur les cartes. Les personnes dont le d\u00e9partement n\u2019a pas pu \u00eatre remont\u00e9 dans les donn\u00e9es SIDEP ne sont comptabilis\u00e9es qu'au niveau France enti\u00e8re. De ce fait la somme des tests indiqu\u00e9s dans les d\u00e9partements ou r\u00e9gions est inf\u00e9rieure au nombre de tests indiqu\u00e9 en France. - Le d\u00e9lai de remont\u00e9e des tests peut exc\u00e9der 9 jours dans certains cas. Les indicateurs sont ajust\u00e9s quotidiennement selon la r\u00e9ception des r\u00e9sultats. Pour en savoir plus consultez la note m\u00e9thodologique disponible dans les ressources. ******************************************************************************** extras -------------------------------------------------------------------------------- {'recommendations': [{'id': '5e7de8cf4663c08d4f74ba01', 'score': 89, 'source': 'matomo'}], 'recommendations:sources': ['matomo']} ******************************************************************************** frequency -------------------------------------------------------------------------------- unknown ******************************************************************************** frequency_date -------------------------------------------------------------------------------- None ******************************************************************************** id -------------------------------------------------------------------------------- 5ed117db6c161bd5baf070be ******************************************************************************** last_modified -------------------------------------------------------------------------------- 2020-09-25T19:15:13.847000 ******************************************************************************** last_update -------------------------------------------------------------------------------- 2020-08-27T00:00:00 ******************************************************************************** license -------------------------------------------------------------------------------- fr-lo ******************************************************************************** metrics -------------------------------------------------------------------------------- {'discussions': 21, 'followers': 5, 'issues': 0, 'reuses': 22, 'views': 6112} ******************************************************************************** organization -------------------------------------------------------------------------------- {'acronym': 'SPF', 'class': 'Organization', 'id': '5e721a395d57f93d0bed451f', 'logo': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-original.png', 'logo_thumbnail': 'https://static.data.gouv.fr/avatars/79/7e94cd7a8d43d39544d4018666e646-100.png', 'name': 'Sant\u00e9 publique France', 'page': 'https://www.data.gouv.fr/fr/organizations/sante-publique-france/', 'slug': 'sante-publique-france', 'uri': 'https://www.data.gouv.fr/api/1/organizations/sante-publique-france/'} ******************************************************************************** owner -------------------------------------------------------------------------------- None ******************************************************************************** page -------------------------------------------------------------------------------- https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ ******************************************************************************** private -------------------------------------------------------------------------------- False ******************************************************************************** resources -------------------------------------------------------------------------------- [{'checksum': {'type': 'sha1', 'value': '21b8878f9b8df70e78a5a8ca6d9d28dd4b34a07e'}, 'created_at': '2020-09-01T15:01:03.280000', 'description': 'Note m\u00e9thodologique 27/08', 'extras': {}, 'filesize': 29885, 'filetype': 'file', 'format': 'docx', 'id': 'c98482d3-fba1-4397-99ae-1c958aa629f6', 'last_modified': '2020-09-01T15:04:27.976000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c98482d3-fba1-4397-99ae-1c958aa629f6', 'metrics': {'views': 167}, 'mime': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'preview_url': None, 'published': '2020-08-27T00:00:00', 'schema': None, 'title': 'analyse-de-la-base-sidep-note-methodologique.docx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200901-150103/analyse-de-la-base-sidep-note-methodologique.docx'}, {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'af41c6bc3aff81d2e3ab27e1fd4e85edd12efc77'}, 'created_at': '2020-05-29T18:03:11.045000', 'description': 'Taux de positivit\u00e9 - quotidien - r\u00e9gion.', 'extras': {}, 'filesize': 1026513, 'filetype': 'file', 'format': 'csv', 'id': '001aca18-df6a-45c8-89e6-f82d689e6c01', 'last_modified': '2020-09-25T19:15:13.194000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/001aca18-df6a-45c8-89e6-f82d689e6c01', 'metrics': {'views': 828}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:03:11', 'schema': None, 'title': 'sp-pos-quot-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '2879bad07eea8f4420beb68021944ab71af19b87'}, 'created_at': '2020-05-29T18:02:57.551000', 'description': 'Taux de positivit\u00e9 - quotidien - france.', 'extras': {}, 'filesize': 61466, 'filetype': 'file', 'format': 'csv', 'id': 'dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'last_modified': '2020-09-25T19:15:13.762000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd0de5d9-b5a5-4503-930a-7b08dc0adc7c', 'metrics': {'views': 2639}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191513%2Fsp-pos-quot-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:57', 'schema': None, 'title': 'sp-pos-quot-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191513/sp-pos-quot-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '511d145379f80e1fb1e2fe0bf90cff2d493b5fc5'}, 'created_at': '2020-05-29T18:01:11.291000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - departement.', 'extras': {}, 'filesize': 438028, 'filetype': 'file', 'format': 'csv', 'id': 'dd3ac13c-e87f-4b33-8897-07baff4e1783', 'last_modified': '2020-09-25T19:15:11.314000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/dd3ac13c-e87f-4b33-8897-07baff4e1783', 'metrics': {'views': 238}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191511%2Fsp-pos-heb-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:11', 'schema': None, 'title': 'sp-pos-heb-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191511/sp-pos-heb-dep-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '59b6f0c920f3aa5a700d1ee1b20fef26b211596a'}, 'created_at': '2020-05-29T18:02:10.342000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - r\u00e9gion .', 'extras': {}, 'filesize': 146314, 'filetype': 'file', 'format': 'csv', 'id': '1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'last_modified': '2020-09-25T19:15:05.806000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/1ff7af5f-88d6-44bd-b8b6-16308b046afc', 'metrics': {'views': 25}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191505%2Fsp-pos-heb-reg-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:10', 'schema': None, 'title': 'sp-pos-heb-reg-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191505/sp-pos-heb-reg-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '27b6ce97a5004564ea5f876f8c8c00f83300a288'}, 'created_at': '2020-05-29T18:01:35.129000', 'description': 'Taux de positivit\u00e9 - hebdomadaire - France.', 'extras': {}, 'filesize': 9087, 'filetype': 'file', 'format': 'csv', 'id': '2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'last_modified': '2020-09-25T19:15:03.498000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/2f0f720d-fbd2-41a7-95b4-3a70ff5a9253', 'metrics': {'views': 293}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191503%2Fsp-pos-heb-fra-2020-09-25-19h15.csv', 'published': '2020-05-29T18:01:35', 'schema': None, 'title': 'sp-pos-heb-fra-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191503/sp-pos-heb-fra-2020-09-25-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '41c46a8b6c450ddffea0845c85815dc42502192b'}, 'created_at': '2020-05-29T18:20:52.321000', 'description': None, 'extras': {}, 'filesize': 215055, 'filetype': 'file', 'format': 'csv', 'id': 'd1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'last_modified': '2020-07-03T19:15:20.039000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/d1c1846c-f2d1-43cb-ad84-b46c40d1bec8', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.321000', 'schema': None, 'title': 'sp-ti-tp-7j-dep-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-dep-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '215ad0960bbad3719ea13622cbca9b4f15d01332'}, 'created_at': '2020-05-29T18:20:52.324000', 'description': None, 'extras': {}, 'filesize': 52837, 'filetype': 'file', 'format': 'csv', 'id': 'df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'last_modified': '2020-07-03T19:15:20.439000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/df2f66d3-ef9b-48e0-abdf-f33a6a7ff2fa', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.324000', 'schema': None, 'title': 'sp-ti-tp-7j-reg-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-reg-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': '3272b07774ea14ed57c63bb7b9fd26065cf3125d'}, 'created_at': '2020-05-29T18:20:52.318000', 'description': None, 'extras': {}, 'filesize': 2880, 'filetype': 'file', 'format': 'csv', 'id': 'c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'last_modified': '2020-07-03T19:15:19.607000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c1167c4e-8c89-40f2-adb3-1954f8fedfa7', 'metrics': {}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191519%2Fsp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'published': '2020-05-29T18:20:52.318000', 'schema': None, 'title': 'sp-ti-tp-7j-fra-2020-07-03-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191519/sp-ti-tp-7j-fra-2020-07-03-19h15.csv'}, {'checksum': {'type': 'sha1', 'value': 'ce0d062e5faa1dcd83616f7bc9f74367b43fb6ff'}, 'created_at': '2020-05-29T17:19:23.764000', 'description': 'Taux de positivit\u00e9 - Quotidien.', 'extras': {}, 'filesize': 1337737, 'filetype': 'file', 'format': 'xlsx', 'id': 'c20aa429-d30b-41d1-8bea-37b106c5f33b', 'last_modified': '2020-07-03T19:15:27.711000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/c20aa429-d30b-41d1-8bea-37b106c5f33b', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191527%2Fsp-pos-quot-2020-07-03-19h15.xlsx', 'published': '2020-05-29T17:19:23', 'schema': None, 'title': 'sp-pos-quot-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191527/sp-pos-quot-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '62fb3c2bf176eed6254a72d4067d250bb5414490'}, 'created_at': '2020-05-29T17:17:47.913000', 'description': 'Taux de positivit\u00e9 - hebdomadaire.', 'extras': {}, 'filesize': 207005, 'filetype': 'file', 'format': 'xlsx', 'id': 'fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'last_modified': '2020-07-01T19:15:23.424000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/fc7f9844-05bd-41eb-9d9a-2a4b8010af1d', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200701-191523%2Fsp-pos-heb-2020-07-01-19h15.xlsx', 'published': '2020-05-29T17:17:47', 'schema': None, 'title': 'sp-pos-heb-2020-07-01-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200701-191523/sp-pos-heb-2020-07-01-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': 'f526f981c17773cfc4207320275c2822ce425613'}, 'created_at': '2020-05-29T18:49:52.653000', 'description': None, 'extras': {}, 'filesize': 182582, 'filetype': 'file', 'format': 'xlsx', 'id': '708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'last_modified': '2020-07-03T19:15:20.863000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/708eb9ee-d8e8-4008-ac2d-0827acd95ba7', 'metrics': {}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200703-191520%2Fsp-ti-tp-7j-2020-07-03-19h15.xlsx', 'published': '2020-05-29T18:49:52.653000', 'schema': None, 'title': 'sp-ti-tp-7j-2020-07-03-19h15.xlsx', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200703-191520/sp-ti-tp-7j-2020-07-03-19h15.xlsx'}, {'checksum': {'type': 'sha1', 'value': '89c55f3a82bb8dcb5f1d1b1f4cb431b798a653ec'}, 'created_at': '2020-05-29T17:00:35.757000', 'description': 'Description des m\u00e9tadonn\u00e9es.', 'extras': {}, 'filesize': 10422, 'filetype': 'file', 'format': 'xlsx', 'id': '39aaad1c-9aac-4be8-96b2-6d001f892b34', 'last_modified': '2020-05-29T17:00:54.313000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/39aaad1c-9aac-4be8-96b2-6d001f892b34', 'metrics': {'views': 321}, 'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Ftaux-de-positivite-aux-tests-virologiques-covid-19%2F20200529-170035%2Fmetadonnees-positivite.xlsx', 'published': '2020-05-29T17:00:35', 'schema': None, 'title': 'metadonnees-positivite.xlsx', 'type': 'documentation', 'url': 'https://static.data.gouv.fr/resources/taux-de-positivite-aux-tests-virologiques-covid-19/20200529-170035/metadonnees-positivite.xlsx'}] ******************************************************************************** slug -------------------------------------------------------------------------------- donnees-relatives-aux-resultats-des-tests-virologiques-covid-19 ******************************************************************************** spatial -------------------------------------------------------------------------------- None ******************************************************************************** tags -------------------------------------------------------------------------------- [] ******************************************************************************** temporal_coverage -------------------------------------------------------------------------------- None ******************************************************************************** title -------------------------------------------------------------------------------- Donn\u00e9es relatives aux r\u00e9sultats des tests virologiques COVID-19 ******************************************************************************** uri -------------------------------------------------------------------------------- https://www.data.gouv.fr/api/1/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/ resources = [ r for r in resp [ \"resources\" ] if \"wordprocessingml\" not in r [ \"mime\" ]] from yaml import load , dump resources [ 0 ] {'checksum': {'type': 'sha1', 'value': 'eb395230851890fe96cbc0618000ae70e302decd'}, 'created_at': '2020-05-29T18:02:26.703000', 'description': 'Taux de positivit\u00e9 - quotidien - d\u00e9partement .', 'extras': {}, 'filesize': 3361733, 'filetype': 'file', 'format': 'csv', 'id': '406c6a23-e283-4300-9484-54e78c8ae675', 'last_modified': '2020-09-25T19:15:06.758000', 'latest': 'https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675', 'metrics': {'views': 8155}, 'mime': 'text/csv', 'preview_url': '/tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv', 'published': '2020-05-29T18:02:26', 'schema': None, 'title': 'sp-pos-quot-dep-2020-09-25-19h15.csv', 'type': 'main', 'url': 'https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv'} print ( dump ( resources [ 0 ])) checksum: type: sha1 value: eb395230851890fe96cbc0618000ae70e302decd created_at: '2020-05-29T18:02:26.703000' description: \"Taux de positivit\\xE9 - quotidien - d\\xE9partement .\" extras: {} filesize: 3361733 filetype: file format: csv id: 406c6a23-e283-4300-9484-54e78c8ae675 last_modified: '2020-09-25T19:15:06.758000' latest: https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675 metrics: views: 8155 mime: text/csv preview_url: /tabular/preview/?url=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-relatives-aux-resultats-des-tests-virologiques-covid-19%2F20200925-191506%2Fsp-pos-quot-dep-2020-09-25-19h15.csv published: '2020-05-29T18:02:26' schema: null title: sp-pos-quot-dep-2020-09-25-19h15.csv type: main url: https://static.data.gouv.fr/resources/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/20200925-191506/sp-pos-quot-dep-2020-09-25-19h15.csv 'description' , 'latest' , 'title' for k in resources : print ( k [ \"title\" ]) sp-pos-quot-dep-2020-09-25-19h15.csv sp-pos-quot-reg-2020-09-25-19h15.csv sp-pos-quot-fra-2020-09-25-19h15.csv sp-pos-heb-dep-2020-09-25-19h15.csv sp-pos-heb-reg-2020-09-25-19h15.csv sp-pos-heb-fra-2020-09-25-19h15.csv sp-ti-tp-7j-dep-2020-07-03-19h15.csv sp-ti-tp-7j-reg-2020-07-03-19h15.csv sp-ti-tp-7j-fra-2020-07-03-19h15.csv sp-pos-quot-2020-07-03-19h15.xlsx sp-pos-heb-2020-07-01-19h15.xlsx sp-ti-tp-7j-2020-07-03-19h15.xlsx metadonnees-positivite.xlsx for k in resources [ - 1 ]: print ( \"*\" * 80 ) print ( k ) print ( \"-\" * 80 ) print ( resources [ - 1 ] . get ( k )) src [ \"indicateurs\" ] {'url_web': 'https://www.data.gouv.fr/fr/datasets/indicateurs-de-suivi-de-lepidemie-de-covid-19/', 'url_stable': 'https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e', 'url_api': 'https://www.data.gouv.fr/api/1/datasets/5ee9df5003284f565d561278/', 'titre': \"Indicateurs de suivi de l'\u00e9pid\u00e9mie de COVID-19\", 'file_pattern': 'indicateurs-covid19-dep', 'delim': ','}","title":"Feed a Catalog"},{"location":"Covid/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Covid19 \u00b6 % load_ext lab_black import intake import pandas as pd Metadata \u00b6 url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1 Donn\u00e9es \u00b6 https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 987 0 --:--:-- --:--:-- --:--:-- 987 100 3761k 100 3761k 0 0 240k 0 0:00:15 0:00:15 --:--:-- 259k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fd6c0060430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 152152 entries, 0 to 152151 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 152152 non-null object 1 jour 152152 non-null datetime64[ns] 2 pop 152152 non-null float64 3 P 152152 non-null int32 4 cl_age90 152152 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) def plot_incidence ( dpt : int ): gp = dfpa . where ( dfpa . dep == dpt ) . groupby ( \"jour\" ) gp . P . sum () . plot () gp . P . sum () . rolling ( 7 ) . mean () . plot () plot_incidence ( \"43\" ) import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Covid"},{"location":"Covid/#covid19","text":"% load_ext lab_black import intake import pandas as pd","title":"Covid19"},{"location":"Covid/#metadata","text":"url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1","title":"Metadata"},{"location":"Covid/#donnees","text":"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 987 0 --:--:-- --:--:-- --:--:-- 987 100 3761k 100 3761k 0 0 240k 0 0:00:15 0:00:15 --:--:-- 259k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fd6c0060430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 152152 entries, 0 to 152151 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 152152 non-null object 1 jour 152152 non-null datetime64[ns] 2 pop 152152 non-null float64 3 P 152152 non-null int32 4 cl_age90 152152 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) def plot_incidence ( dpt : int ): gp = dfpa . where ( dfpa . dep == dpt ) . groupby ( \"jour\" ) gp . P . sum () . plot () gp . P . sum () . rolling ( 7 ) . mean () . plot () plot_incidence ( \"43\" ) import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Donn\u00e9es"},{"location":"WebDev/Intro/","text":"Web Developpment \u00b6 HTML and DOM specifications are issued from 2 main organisms, W3C and WHATWG 1 : WHATWG maintains the HTML and DOM Living Standards W3C bridges communities, develop use cases, fill issues, write tests, mediate issue resolution HTML semantic elements \u00b6 Elements, attributes, and attribute values in HTML are defined (by this specification) to have certain meanings (semantics). For example, the ol element represents an ordered list, and the lang attribute represents the language of the content. These definitions allow HTML processors, such as Web browsers or search engines, to present and use documents and applications in a wide variety of contexts that the author might not have considered. 2 Kind of content \u00b6 article aside nav section Heading content h1 h2 h3 h4 h5 h6 hgroup Web components \u00b6 JavaScript file defines a class called PopUpInfo , which extends HTMLElement . Inside the constructor, all the functionality the element will have when an instance of it is instantiated. Example Create a badge similar to the one at the top of the page: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class DocBadge extends HTMLElement { constructor () { // Always call super first in constructor super (); // Create a documentation badge var shadow = this . attachShadow ({ mode : 'open' }); var wrapper = document . createElement ( 'span' ); wrapper . setAttribute ( 'class' , 'myBadge' ); var href = this . hasAttribute ( 'href' ) ? this . getAttribute ( 'href' ) : 'img/default.png' ; var alt = this . hasAttribute ( 'alt' ) ? this . getAttribute ( 'alt' ) : 'Documentation' ; var label = this . hasAttribute ( 'label' ) ? this . getAttribute ( 'label' ) : 'docs' ; var message = this . hasAttribute ( 'message' ) ? this . getAttribute ( 'message' ) : 'stable' ; var color = this . hasAttribute ( 'color' ) ? this . getAttribute ( 'color' ) : 'brightgreen' ; var logo = this . hasAttribute ( 'logo' ) ? this . getAttribute ( 'logo' ) : 'Read-the-docs' ; var src = `https://img.shields.io/badge/ ${ label } - ${ message } - ${ color } ?style=flat&logo= ${ logo } ` ; var link = document . createElement ( 'a' ); link . setAttribute ( 'target' , '_blank' ); link . setAttribute ( 'href' , href ); var img = document . createElement ( 'img' ); img . setAttribute ( 'src' , src ); img . setAttribute ( 'alt' , alt ); shadow . appendChild ( wrapper ); wrapper . appendChild ( link ); link . appendChild ( img ); } } // register it customElements . define ( 'badge-doc' , DocBadge ); Usage: < badge-doc href = \"https://developer.mozilla.org/en-US/docs/Web/Web_Components\" message = \"MDN\" color = \"lightgrey\" ></ badge-doc > Resources \u00b6 Shield badges Simple icons W3C and WHATWG to work together to advance the open Web platform \u21a9 WHATWG spec \u21a9","title":"Intro"},{"location":"WebDev/Intro/#web-developpment","text":"HTML and DOM specifications are issued from 2 main organisms, W3C and WHATWG 1 : WHATWG maintains the HTML and DOM Living Standards W3C bridges communities, develop use cases, fill issues, write tests, mediate issue resolution","title":"Web Developpment"},{"location":"WebDev/Intro/#html-semantic-elements","text":"Elements, attributes, and attribute values in HTML are defined (by this specification) to have certain meanings (semantics). For example, the ol element represents an ordered list, and the lang attribute represents the language of the content. These definitions allow HTML processors, such as Web browsers or search engines, to present and use documents and applications in a wide variety of contexts that the author might not have considered. 2","title":"HTML semantic elements"},{"location":"WebDev/Intro/#kind-of-content","text":"article aside nav section Heading content h1 h2 h3 h4 h5 h6 hgroup","title":"Kind of content"},{"location":"WebDev/Intro/#web-components","text":"JavaScript file defines a class called PopUpInfo , which extends HTMLElement . Inside the constructor, all the functionality the element will have when an instance of it is instantiated. Example Create a badge similar to the one at the top of the page: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class DocBadge extends HTMLElement { constructor () { // Always call super first in constructor super (); // Create a documentation badge var shadow = this . attachShadow ({ mode : 'open' }); var wrapper = document . createElement ( 'span' ); wrapper . setAttribute ( 'class' , 'myBadge' ); var href = this . hasAttribute ( 'href' ) ? this . getAttribute ( 'href' ) : 'img/default.png' ; var alt = this . hasAttribute ( 'alt' ) ? this . getAttribute ( 'alt' ) : 'Documentation' ; var label = this . hasAttribute ( 'label' ) ? this . getAttribute ( 'label' ) : 'docs' ; var message = this . hasAttribute ( 'message' ) ? this . getAttribute ( 'message' ) : 'stable' ; var color = this . hasAttribute ( 'color' ) ? this . getAttribute ( 'color' ) : 'brightgreen' ; var logo = this . hasAttribute ( 'logo' ) ? this . getAttribute ( 'logo' ) : 'Read-the-docs' ; var src = `https://img.shields.io/badge/ ${ label } - ${ message } - ${ color } ?style=flat&logo= ${ logo } ` ; var link = document . createElement ( 'a' ); link . setAttribute ( 'target' , '_blank' ); link . setAttribute ( 'href' , href ); var img = document . createElement ( 'img' ); img . setAttribute ( 'src' , src ); img . setAttribute ( 'alt' , alt ); shadow . appendChild ( wrapper ); wrapper . appendChild ( link ); link . appendChild ( img ); } } // register it customElements . define ( 'badge-doc' , DocBadge ); Usage: < badge-doc href = \"https://developer.mozilla.org/en-US/docs/Web/Web_Components\" message = \"MDN\" color = \"lightgrey\" ></ badge-doc >","title":"Web components"},{"location":"WebDev/Intro/#resources","text":"Shield badges Simple icons W3C and WHATWG to work together to advance the open Web platform \u21a9 WHATWG spec \u21a9","title":"Resources"},{"location":"WebDev/REACT/","text":"REACT \u00b6 Synthetic events Theme \u00b6 material UI Forms \u00b6 See formik https://jaredpalmer.com/formik/docs/overview Hooks \u00b6 Introducing hooks Books \u00b6 Learning react by Kirupa Chinnathambi azeaze qsd Eloquent JavaScript by Marijn Haverbeke Read favorite Eloquent JavaScript by Marijn Haverbeke Read favorite Open \u00b6 Styled components make use of","title":"REACT"},{"location":"WebDev/REACT/#react","text":"Synthetic events","title":"REACT"},{"location":"WebDev/REACT/#theme","text":"material UI","title":"Theme"},{"location":"WebDev/REACT/#forms","text":"See formik https://jaredpalmer.com/formik/docs/overview","title":"Forms"},{"location":"WebDev/REACT/#hooks","text":"Introducing hooks","title":"Hooks"},{"location":"WebDev/REACT/#books","text":"","title":"Books"},{"location":"WebDev/REACT/#open","text":"Styled components make use of","title":"Open"},{"location":"WebDev/cors/","text":"Cross-Origin Resource Sharing - CORS \u00b6 is a mechanism that uses additional HTTP headers to tell browsers to give a web application running at one origin, access to selected resources from a different origin.","title":"CORS"},{"location":"WebDev/cors/#cross-origin-resource-sharing-cors","text":"is a mechanism that uses additional HTTP headers to tell browsers to give a web application running at one origin, access to selected resources from a different origin.","title":"Cross-Origin Resource Sharing - CORS"},{"location":"WebDev/css/","text":"CSS \u00b6 Element size \u00b6 Width [ <length> | <percentage> ] && [ border-box | content-box ]? | available | min-content | max-content | fit-content | auto Flex box \u00b6 Initialisation \u00b6 display: flex; or display: inline-flex; Properties that apply to the parent \u00b6 Ordering and Orientation Property Value Comment flex-direction row | row-reverse | column | column-reverse Ex. : div { flex-direction: row; } flex-wrap nowrap | wrap | wrap-reverse Ex. : div { flex-direction: column; flex-wrap: wrap; } flex-flow see individual properties Shorthand for flex-direction and flex-wrap Ex. : div { felx-flow: row-reverse wrap-reverse; } 1 2 3 4 1 2 3 4 Ordering justify-content align-items align-content Property Value Comment justify-content flex-start | flex-end | center | space-between | space-around align-items flex-start | flex-end | center | baseline | stretch align-content flex-start | flex-end | center | space-between | space-around | stretch Properties that apply to the child elements \u00b6 Ordering order : flex flow direction Property Value order <integer> Flexibility Property Value flex-grow <number> flex-shrink <number> flex-basis content | <width>","title":"CSS"},{"location":"WebDev/css/#css","text":"","title":"CSS"},{"location":"WebDev/css/#element-size","text":"Width [ <length> | <percentage> ] && [ border-box | content-box ]? | available | min-content | max-content | fit-content | auto","title":"Element size"},{"location":"WebDev/css/#flex-box","text":"","title":"Flex box"},{"location":"WebDev/css/#initialisation","text":"display: flex; or display: inline-flex;","title":"Initialisation"},{"location":"WebDev/css/#properties-that-apply-to-the-parent","text":"","title":"Properties that apply to the parent"},{"location":"WebDev/css/#properties-that-apply-to-the-child-elements","text":"Ordering order : flex flow direction Property Value order <integer> Flexibility Property Value flex-grow <number> flex-shrink <number> flex-basis content | <width>","title":"Properties that apply to the child elements"},{"location":"WebDev/node/","text":"Node.js \u00b6 List packages and version from package-lock.json using jq cat package-lock.json | jq '[.dependencies | to_entries[] | {\"key\": .key, \"value\": .value.version}] | from_entries'","title":"node"},{"location":"WebDev/node/#nodejs","text":"List packages and version from package-lock.json using jq cat package-lock.json | jq '[.dependencies | to_entries[] | {\"key\": .key, \"value\": .value.version}] | from_entries'","title":"Node.js"},{"location":"cloud/cloudlandscape/","text":"","title":"Cloud landscape"},{"location":"cloud/cloudnative/","text":"Cloud native \u00b6 Definition \u00b6 CNCF Coud Native Definition v1.0 English Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach. These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone. Fran\u00e7ais Les technologies nativement cloud permettent aux entreprises de construire et d'exploiter des applications \u00e9lastiques dans des environnements modernes et dynamiques comme des clouds publics, priv\u00e9s ou bien hybrides. Les conteneurs, les services maill\u00e9s, les micro services, les infrastructures immuables et les API d\u00e9claratives illustrent cette approche. Ces techniques permettent la mise en \u0153uvre de syst\u00e8mes faiblement coupl\u00e9s, \u00e0 la fois r\u00e9sistants, pilotables et observables. Combin\u00e9s \u00e0 un robuste syst\u00e8me d'automatisation, ils permettent aux ing\u00e9nieurs de proc\u00e9der \u00e0 des modifications impactantes, fr\u00e9quemment et de fa\u00e7on pr\u00e9visible avec un minimum de travail. La Cloud Native Computing Foundation cherche \u00e0 favoriser l'adoption de ce paradigme en encourageant et en soutenant un \u00e9cosyst\u00e8me de projets \"opensource\" et ind\u00e9pendants. Nous d\u00e9mocratisons l'\u00e9tat de l'art des pratiques afin de rendre l'innovation accessible \u00e0 tous. Deutsch Cloud native Technologien erm\u00f6glichen es Unternehmen, skalierbare Anwendungen in modernen, dynamischen Umgebungen zu implementieren und zu betreiben. Dies k\u00f6nnen \u00f6ffentliche, private und Hybrid-Clouds sein. Best-Practises, wie Container, Service-Meshs, Microservices, immutable Infrastruktur und deklarative APIs, unterst\u00fctzen diesen Ansatz. Die zugrundeliegenden Techniken erm\u00f6glichen die Umsetzung von entkoppelten Systemen, die belastbar, handhabbar und beobachtbar sind. Kombiniert mit einer robusten Automatisierung k\u00f6nnen Softwareentwickler mit geringem Aufwand flexibel und schnell auf \u00c4nderungen reagieren. Die Cloud Native Computing Foundation f\u00f6rdert die Akzeptanz dieser Paradigmen durch die Ausgestaltung eines Open Source \u00d6kosystems aus herstellerneutralen Projekten. Wir demokratisieren modernste und innovative Softwareentwicklungs-Patterns, um diese Innovationen f\u00fcr alle zug\u00e4nglich zu machen. Microservices \u00b6 Status: Application where all configuration, and config run on a guest OS in a VM. For scaling, a new VM must be set up. Containers: Application run in containers with config, binarires and libraries. Abstraction over operating system. Elements of orchestration: Kubernetes Serverless vs containers: \u00b6 Abstraction of servers Event driven/event scale Micro-billing Cloud native uses DevOps Develop, Deliver, Operate, Security Pattern \u00b6 Fallacies of distributed computing are a set of assertions made by L Peter Deutsch and others at Sun Microsystems describing false assumptions that programmers new to distributed applications invariably make: The network is reliable; Latency is zero; Bandwidth is infinite; The network is secure; Topology doesn't change; There is one administrator; Transport cost is zero; The network is homogeneous. Retry Pattern \u00b6 On failure, an application retries to connect the server Circuit Breaker Pattern \u00b6 If a service is not available, the user can become quicker information on the failure. Kind of proxy. Made through a State machine: Open Closed: a timer will be increased. Over a threshold, no requests any more Half-Open: an amount of requests are satisfied; Over a threshold, goes in closed Pub & Sub \u00b6 A sender can reach several consumer without to know which part is interesting for the consumer Message Broker: from an input channel, fills output channels that can be consummed by consumers. Work at scale \u00b6 vertical scaling k horizontal scaling involves service instances, e.g. load balancer in K8s","title":"Cloud native"},{"location":"cloud/cloudnative/#cloud-native","text":"","title":"Cloud native"},{"location":"cloud/cloudnative/#definition","text":"CNCF Coud Native Definition v1.0 English Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach. These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone. Fran\u00e7ais Les technologies nativement cloud permettent aux entreprises de construire et d'exploiter des applications \u00e9lastiques dans des environnements modernes et dynamiques comme des clouds publics, priv\u00e9s ou bien hybrides. Les conteneurs, les services maill\u00e9s, les micro services, les infrastructures immuables et les API d\u00e9claratives illustrent cette approche. Ces techniques permettent la mise en \u0153uvre de syst\u00e8mes faiblement coupl\u00e9s, \u00e0 la fois r\u00e9sistants, pilotables et observables. Combin\u00e9s \u00e0 un robuste syst\u00e8me d'automatisation, ils permettent aux ing\u00e9nieurs de proc\u00e9der \u00e0 des modifications impactantes, fr\u00e9quemment et de fa\u00e7on pr\u00e9visible avec un minimum de travail. La Cloud Native Computing Foundation cherche \u00e0 favoriser l'adoption de ce paradigme en encourageant et en soutenant un \u00e9cosyst\u00e8me de projets \"opensource\" et ind\u00e9pendants. Nous d\u00e9mocratisons l'\u00e9tat de l'art des pratiques afin de rendre l'innovation accessible \u00e0 tous. Deutsch Cloud native Technologien erm\u00f6glichen es Unternehmen, skalierbare Anwendungen in modernen, dynamischen Umgebungen zu implementieren und zu betreiben. Dies k\u00f6nnen \u00f6ffentliche, private und Hybrid-Clouds sein. Best-Practises, wie Container, Service-Meshs, Microservices, immutable Infrastruktur und deklarative APIs, unterst\u00fctzen diesen Ansatz. Die zugrundeliegenden Techniken erm\u00f6glichen die Umsetzung von entkoppelten Systemen, die belastbar, handhabbar und beobachtbar sind. Kombiniert mit einer robusten Automatisierung k\u00f6nnen Softwareentwickler mit geringem Aufwand flexibel und schnell auf \u00c4nderungen reagieren. Die Cloud Native Computing Foundation f\u00f6rdert die Akzeptanz dieser Paradigmen durch die Ausgestaltung eines Open Source \u00d6kosystems aus herstellerneutralen Projekten. Wir demokratisieren modernste und innovative Softwareentwicklungs-Patterns, um diese Innovationen f\u00fcr alle zug\u00e4nglich zu machen.","title":"Definition"},{"location":"cloud/cloudnative/#microservices","text":"Status: Application where all configuration, and config run on a guest OS in a VM. For scaling, a new VM must be set up. Containers: Application run in containers with config, binarires and libraries. Abstraction over operating system. Elements of orchestration: Kubernetes","title":"Microservices"},{"location":"cloud/cloudnative/#serverless-vs-containers","text":"Abstraction of servers Event driven/event scale Micro-billing Cloud native uses DevOps Develop, Deliver, Operate, Security","title":"Serverless vs containers:"},{"location":"cloud/cloudnative/#pattern","text":"Fallacies of distributed computing are a set of assertions made by L Peter Deutsch and others at Sun Microsystems describing false assumptions that programmers new to distributed applications invariably make: The network is reliable; Latency is zero; Bandwidth is infinite; The network is secure; Topology doesn't change; There is one administrator; Transport cost is zero; The network is homogeneous.","title":"Pattern"},{"location":"cloud/cloudnative/#retry-pattern","text":"On failure, an application retries to connect the server","title":"Retry Pattern"},{"location":"cloud/cloudnative/#circuit-breaker-pattern","text":"If a service is not available, the user can become quicker information on the failure. Kind of proxy. Made through a State machine: Open Closed: a timer will be increased. Over a threshold, no requests any more Half-Open: an amount of requests are satisfied; Over a threshold, goes in closed","title":"Circuit Breaker Pattern"},{"location":"cloud/cloudnative/#pub-sub","text":"A sender can reach several consumer without to know which part is interesting for the consumer Message Broker: from an input channel, fills output channels that can be consummed by consumers.","title":"Pub &amp; Sub"},{"location":"cloud/cloudnative/#work-at-scale","text":"vertical scaling k horizontal scaling involves service instances, e.g. load balancer in K8s","title":"Work at scale"},{"location":"data/Covid/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Covid19 \u00b6 % load_ext lab_black import intake import pandas as pd Metadata \u00b6 url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1 Donn\u00e9es \u00b6 https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 1017 0 --:--:-- --:--:-- --:--:-- 1017 100 3790k 100 3790k 0 0 208k 0 0:00:18 0:00:18 --:--:-- 220k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fcfcbfab430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 153296 entries, 0 to 153295 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 153296 non-null object 1 jour 153296 non-null datetime64[ns] 2 pop 153296 non-null float64 3 P 153296 non-null int32 4 cl_age90 153296 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) from matplotlib.axis import Axis dfpa [ \"pop\" ] 0 83001.00000 1 84665.00000 2 65496.00000 3 85588.00000 4 89678.00000 ... 153291 2878.06000 153292 1097.68600 153293 296.76760 153294 66.59655 153295 35746.00000 Name: pop, Length: 153296, dtype: float64 df2 = dfpa [ dfpa . cl_age90 == 0 ] df2 . groupby ( \"jour\" ) <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fcf683c6d00> def plot_incidence ( dpt : int , ax : Axis = None ): _df = dfpa . copy () _df [ \"P_pro_100k\" ] = dfpa . P / dfpa [ \"pop\" ] * 100_000 gp = _df . where ( _df . dep == dpt ) . groupby ( \"jour\" ) ( gp . P_pro_100k . sum () / 2 ) . plot ( ax = ax ) ( gp . P_pro_100k . sum () / 2 ) . rolling ( 7 ) . mean () . plot ( ax = ax ) plot_incidence ( \"43\" ) import matplotlib.pyplot as plt with plt . style . context ( \"ggplot\" ): fig , axs = plt . subplots ( 2 , 3 , figsize = ( 22 , 10 ), sharex = True ) depts = [ 43 , 63 , 42 , 15 , 69 , \"07\" ] for ax , dept in zip ( axs . ravel (), depts ): plot_incidence ( str ( dept ), ax ) ax . set_title ( dept ) plt . tight_layout () import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Covid"},{"location":"data/Covid/#covid19","text":"% load_ext lab_black import intake import pandas as pd","title":"Covid19"},{"location":"data/Covid/#metadata","text":"url_metadata = ( \"https://www.data.gouv.fr/fr/datasets/r/a8b5931a-3aa7-4aec-a81b-8b3de628cf63\" ) ! mkdir - p data / covid ; curl - s - o data / covid / metadata . xlsx - L $ url_metadata pd . read_excel ( \"data/covid/metadata.xlsx\" ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colonne Type Description_FR Description_EN Exemple 0 dep String Departement State 01 1 reg String Region region 2 2 fra String France France FR 3 jour Date Jour Day 2020-05-13 4 week Date Semaine Week 2020-S21 5 pop integer Population de reference (du departement, de la... Reference population (department, region, nati... 656955 6 t integer Nombre de test r\u00e9alis\u00e9s Number of tests performed 2141 7 cl_age90 integer Classe d'age Age class 09 8 p integer Nombre de test positifs Number of positive tests 34 9 p_h integer Nombre de test positif chez les hommes Number of positive test in men 1688 10 t_h integer Nombre de test effectu\u00e9s chez les hommes Number of tests performed on men 93639 11 p_f integer Nombre de test positif chez les femmes Number of positive test in women 2415 12 t_f integer Nombre de test effectu\u00e9s chez les femmes Number of tests performed on women 122725 13 tx_std integer Taux d'incidence standardis\u00e9 (100000 * nombre ... Standardized incidence rate 1","title":"Metadata"},{"location":"data/Covid/#donnees","text":"https://www.data.gouv.fr/fr/datasets/taux-dincidence-de-lepidemie-de-covid-19/ url = \"https://www.data.gouv.fr/fr/datasets/r/19a91d64-3cd3-42fc-9943-d635491a4d76\" ! curl - LO $ url % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 473 100 473 0 0 1017 0 --:--:-- --:--:-- --:--:-- 1017 100 3790k 100 3790k 0 0 208k 0 0:00:18 0:00:18 --:--:-- 220k import pyarrow.csv as csv import pyarrow as pa csv . ParseOptions ( delimiter = \";\" ) <pyarrow._csv.ParseOptions at 0x7fcfcbfab430> schema = pa . schema ( { \"dep\" : pa . string (), \"jour\" : pa . string (), \"pop\" : pa . float64 (), \"P\" : pa . int32 (), \"cl_age90\" : pa . int8 (), } ) table = csv . read_csv ( \"19a91d64-3cd3-42fc-9943-d635491a4d76\" , parse_options = csv . ParseOptions ( delimiter = \";\" ), convert_options = csv . ConvertOptions ( column_types = schema ), ) dfpa = table . to_pandas () . astype ({ \"jour\" : \"datetime64[ns]\" }) dfpa . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dep jour pop P cl_age90 0 01 2020-05-13 83001.0 0 9 1 01 2020-05-13 84665.0 1 19 2 01 2020-05-13 65496.0 0 29 3 01 2020-05-13 85588.0 1 39 4 01 2020-05-13 89678.0 0 49 dfpa . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 153296 entries, 0 to 153295 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 dep 153296 non-null object 1 jour 153296 non-null datetime64[ns] 2 pop 153296 non-null float64 3 P 153296 non-null int32 4 cl_age90 153296 non-null int8 dtypes: datetime64[ns](1), float64(1), int32(1), int8(1), object(1) memory usage: 4.2+ MB df = pd.read_csv(\"19a91d64-3cd3-42fc-9943-d635491a4d76\", sep=\";\", parse_dates=[\"jour\"]) from matplotlib.axis import Axis dfpa [ \"pop\" ] 0 83001.00000 1 84665.00000 2 65496.00000 3 85588.00000 4 89678.00000 ... 153291 2878.06000 153292 1097.68600 153293 296.76760 153294 66.59655 153295 35746.00000 Name: pop, Length: 153296, dtype: float64 df2 = dfpa [ dfpa . cl_age90 == 0 ] df2 . groupby ( \"jour\" ) <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fcf683c6d00> def plot_incidence ( dpt : int , ax : Axis = None ): _df = dfpa . copy () _df [ \"P_pro_100k\" ] = dfpa . P / dfpa [ \"pop\" ] * 100_000 gp = _df . where ( _df . dep == dpt ) . groupby ( \"jour\" ) ( gp . P_pro_100k . sum () / 2 ) . plot ( ax = ax ) ( gp . P_pro_100k . sum () / 2 ) . rolling ( 7 ) . mean () . plot ( ax = ax ) plot_incidence ( \"43\" ) import matplotlib.pyplot as plt with plt . style . context ( \"ggplot\" ): fig , axs = plt . subplots ( 2 , 3 , figsize = ( 22 , 10 ), sharex = True ) depts = [ 43 , 63 , 42 , 15 , 69 , \"07\" ] for ax , dept in zip ( axs . ravel (), depts ): plot_incidence ( str ( dept ), ax ) ax . set_title ( dept ) plt . tight_layout () import numpy as np today = np . sort ( df . jour . unique ())[ - 1 ] today - np . timedelta64 ( 7 , 'D' ) numpy.datetime64('2020-09-15T00:00:00.000000000') import matplotlib.pyplot as plt df [ 'P_normed' ] = df . P / df [ 'pop' ] * 100_000 df_today = df [ df . jour >= today - np . timedelta64 ( 7 , 'D' )] gp_today_dep = df_today . groupby ( 'dep' ) ( gp_today_dep . sum () . P_normed / 2 / 7 ) . sort_values () . plot . bar ( figsize = ( 22 , 9 )) plt . axhline ( 50 , c = 'red' ) <matplotlib.lines.Line2D at 0x7f4cea8f1c70> plot_incidence ( '43' ) url_indic = ( \"https://www.data.gouv.fr/fr/datasets/r/4acad602-d8b1-4516-bc71-7d5574d5f33e\" ) ! curl - LO $ url_indic % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 461 100 461 0 0 1546 0 --:--:-- --:--:-- --:--:-- 0-:--:-- --:--:-- 1546 100 1916k 100 1916k 0 0 236k 0 0:00:08 0:00:08 --:--:-- 259k ! head \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" \"extract_date\",\"departement\",\"region\",\"libelle_reg\",\"libelle_dep\",\"tx_incid\",\"R\",\"taux_occupation_sae\",\"tx_pos\",\"tx_incid_couleur\",\"R_couleur\",\"taux_occupation_sae_couleur\",\"tx_pos_couleur\",\"nb_orange\",\"nb_rouge\" \"2020-04-04\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,134,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-07\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,135.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-08\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,131.7,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-05\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,139.4,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-06\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,140.1,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-15\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,114.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-16\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,112.3,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-17\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,107.5,NA,\"\",\"\",\"rouge\",\"\",0,1 \"2020-04-18\",\"01\",84,\"Auvergne Rh\ufffdne Alpes\",\"Ain\",NA,NA,103.4,NA,\"\",\"\",\"rouge\",\"\",0,1 df_indic = pd . read_csv ( \"4acad602-d8b1-4516-bc71-7d5574d5f33e\" , sep = \",\" , encoding = \"ISO-8859-1\" ) df_indic . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 18988 entries, 0 to 18987 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 extract_date 18988 non-null object 1 departement 18988 non-null object 2 region 18988 non-null int64 3 libelle_reg 18988 non-null object 4 libelle_dep 18988 non-null object 5 tx_incid 13029 non-null float64 6 R 2746 non-null float64 7 taux_occupation_sae 18988 non-null float64 8 tx_pos 13029 non-null float64 9 tx_incid_couleur 13029 non-null object 10 R_couleur 2746 non-null object 11 taux_occupation_sae_couleur 18988 non-null object 12 tx_pos_couleur 13029 non-null object 13 nb_orange 18988 non-null int64 14 nb_rouge 18988 non-null int64 dtypes: float64(4), int64(3), object(8) memory usage: 2.2+ MB df_indic [ df_indic . departement == \"43\" ] . tx_incid . plot . bar () <AxesSubplot:> df_indic [ df_indic . departement == \"43\" ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } extract_date departement region libelle_reg libelle_dep tx_incid R taux_occupation_sae tx_pos tx_incid_couleur R_couleur taux_occupation_sae_couleur tx_pos_couleur nb_orange nb_rouge 1316 2020-03-19 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 14.1 NaN NaN NaN vert NaN 0 0 1317 2020-03-20 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 15.6 NaN NaN NaN vert NaN 0 0 1318 2020-03-18 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 6.3 NaN NaN NaN vert NaN 0 0 1319 2020-04-01 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 120.2 NaN NaN NaN rouge NaN 0 1 1320 2020-04-02 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire NaN NaN 125.2 NaN NaN NaN rouge NaN 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1499 2020-08-08 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.378788 vert NaN vert vert 0 0 1500 2020-08-09 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 1.32 NaN 3.4 0.377358 vert NaN vert vert 0 0 1501 2020-08-06 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 0.88 NaN 3.2 0.232558 vert NaN vert vert 0 0 1502 2020-08-11 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 1.17 3.0 1.003764 vert orange vert vert 1 0 1503 2020-08-10 43 84 Auvergne Rh\u00f4ne Alpes Haute-Loire 3.53 NaN 3.4 1.021711 vert NaN vert vert 0 0 188 rows \u00d7 15 columns","title":"Donn\u00e9es"},{"location":"data/crisp-dm/","text":"CRISP-DM - Cross Industry Standard Process for Data Mining \u00b6","title":"CRISP-DM"},{"location":"data/crisp-dm/#crisp-dm-cross-industry-standard-process-for-data-mining","text":"","title":"CRISP-DM - Cross Industry Standard Process for Data Mining"},{"location":"data/spark/","text":"SparkSession Main entry point for DataFrame and SQL functionality. DataFrame A distributed collection of data grouped into named columns. Column A column expression in a DataFrame. Row A row of data in a DataFrame. GroupedData Aggregation methods, returned by DataFrame.groupBy(). DataFrameNaFunctions Methods for handling missing data (null values). DataFrameStatFunctions Methods for statistics functionality. functions List of built-in functions available for DataFrame. types List of data types available. Window For working with window functions.","title":"Spark"},{"location":"data/db/intro/","text":"Database \u00b6 Language statements \u00b6 DDL - Data Definition Language \u00b6 in impala DML - Data Manipulation Language \u00b6 in impala Data types \u00b6 Large objects, generaly up to 4Gb, and not supported universaly, e.g. not in Impala: BLOB : binary large objects CLOB character large object Entity Relationship Diagram (ERD) \u00b6 Type of data modeling representing objects or concepts within an information system or organization and their relation to one other. EdgeDB Framework \u00b6 Ibis \u00b6 Data catalog \u00b6 Intake \u00b6 Persisting data","title":"intro"},{"location":"data/db/intro/#database","text":"","title":"Database"},{"location":"data/db/intro/#language-statements","text":"","title":"Language statements"},{"location":"data/db/intro/#ddl-data-definition-language","text":"in impala","title":"DDL - Data Definition Language"},{"location":"data/db/intro/#dml-data-manipulation-language","text":"in impala","title":"DML - Data Manipulation Language"},{"location":"data/db/intro/#data-types","text":"Large objects, generaly up to 4Gb, and not supported universaly, e.g. not in Impala: BLOB : binary large objects CLOB character large object","title":"Data types"},{"location":"data/db/intro/#entity-relationship-diagram-erd","text":"Type of data modeling representing objects or concepts within an information system or organization and their relation to one other. EdgeDB","title":"Entity Relationship Diagram (ERD)"},{"location":"data/db/intro/#framework","text":"","title":"Framework"},{"location":"data/db/intro/#ibis","text":"","title":"Ibis"},{"location":"data/db/intro/#data-catalog","text":"","title":"Data catalog"},{"location":"data/db/intro/#intake","text":"Persisting data","title":"Intake"},{"location":"data/db/S3/_intro/","text":"Object Store (S3) \u00b6 MinIO \u00b6 https://docs.min.io/docs/minio-multi-user-quickstart-guide.html S3 API: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html","title":"Intro"},{"location":"data/db/S3/_intro/#object-store-s3","text":"","title":"Object Store (S3)"},{"location":"data/db/S3/_intro/#minio","text":"https://docs.min.io/docs/minio-multi-user-quickstart-guide.html S3 API: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html","title":"MinIO"},{"location":"data/db/SQL/_intro/","text":"SQL - Structured Query Language \u00b6 Command types \u00b6 Name Description sample DML - Data Manipulation Language used to retrieve and manipulate data in a relational DB SELECT...INTO , INSERT INTO... VALUES... SQL within Python \u00b6 For sql like data access, SQLAlchemy consists of two distinct components, known as the Core (abstraction toolkit) and an optional but convenient ORM (Object Relational Mapper). For analytics, Pandas provides facili tes and loads the data into the memory of the local host, Ibis leaves the data in its storage, and performs the computations there For SQL command in jupyter, see the SQL jupyter magic and a notebook example Sort order \u00b6 Collation \u00b6 String sorting is done on a character-by-character basis but custom alphanumeric values is possible . A DBMS uses a collating sequence, or collation, to determine the order in which characters are sorted. The collation defines the order of precedence for every character in your character set. Your character set depends on the language that you\u2019re using\u2014European languages (a Latin character set), Hebrew (the Hebrew alphabet), or Chinese (ideographs), for example. The collation also determines case sensitivity (is \u2018A\u2019 < \u2018a\u2019?), accent sensitivity (is \u2018A\u2019 < \u2018\u00c0\u2019 ?), width sensitivity (for multibyte or Unicode characters), and other factors such as linguistic practices. The SQL standard doesn\u2019t define particular collations and character sets, so each DBMS uses its own sorting strategy and default collation\u2026 Search your DBMS documentation for collation or sort order. Source: Fehily, Chris - SQL VIsual QuickStart Guide, 3 rd Edition . Missing values \u00b6 NULL values are handled differently on SQL engine, e.g.: Impala handles NULL as top values Hive and MySQL handles NULL as lower values. To override such a behavior, NULLS FIST or NULL LAST can be specified. This is not supported by all engines. Impala, Hive and PostgreSQL does when MySQL does not. Another possibility to achieve this is to double the sort operation: -- SQL will fist sort by 'col2 IS NULL' which is a boolean, then by 'col2' SELECT col , col2 FROM table1 ORDER BY col2 IS NULL ASC , col2 Engines limitations \u00b6 Selection must sometimes include the column on which the is done. Example -- This will not work in Hive SELECT col1 , col2 FROM table1 ORDER BY col3 -- Nor this SELECT col1 , col2 FROM table1 ORDER BY col3 * col4 -- This will be ok SELECT col1 , col2 , col3 , col4 FROM table1 ORDER BY col3 * col4 -- and this SELECT col1 , col2 , col3 * col4 AS muliplication FROM table1 ORDER BY multiplication Limit \u00b6 For pagination, sql specific implementations: -- For Impala and PostgreSQL LIMIT < limit > OFFSET < offset > -- For Hive Limit < offset > , < limit > -- MySQL supports both -- some use SKIP Danger Without ORDER BY , order is not deterministic: some row could be displayed multiple times or missing as selection is arbitrary. Impala require ORDER BY when using OFFSET Select \u00b6 Syntaxic order SELECT, FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT Execution order (in general) FROM, WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT Shortcut \u00b6 Order by position It is possible in some engine to specify the position or the column to apply the order on. This is not supported by every engine and will not raise an error. -- This will order by the 3rd column SELECT col1 , col2 , col3 FROM table1 ORDER BY 3","title":"Intro"},{"location":"data/db/SQL/_intro/#sql-structured-query-language","text":"","title":"SQL - Structured Query Language"},{"location":"data/db/SQL/_intro/#command-types","text":"Name Description sample DML - Data Manipulation Language used to retrieve and manipulate data in a relational DB SELECT...INTO , INSERT INTO... VALUES...","title":"Command types"},{"location":"data/db/SQL/_intro/#sql-within-python","text":"For sql like data access, SQLAlchemy consists of two distinct components, known as the Core (abstraction toolkit) and an optional but convenient ORM (Object Relational Mapper). For analytics, Pandas provides facili tes and loads the data into the memory of the local host, Ibis leaves the data in its storage, and performs the computations there For SQL command in jupyter, see the SQL jupyter magic and a notebook example","title":"SQL within Python"},{"location":"data/db/SQL/_intro/#sort-order","text":"","title":"Sort order"},{"location":"data/db/SQL/_intro/#collation","text":"String sorting is done on a character-by-character basis but custom alphanumeric values is possible . A DBMS uses a collating sequence, or collation, to determine the order in which characters are sorted. The collation defines the order of precedence for every character in your character set. Your character set depends on the language that you\u2019re using\u2014European languages (a Latin character set), Hebrew (the Hebrew alphabet), or Chinese (ideographs), for example. The collation also determines case sensitivity (is \u2018A\u2019 < \u2018a\u2019?), accent sensitivity (is \u2018A\u2019 < \u2018\u00c0\u2019 ?), width sensitivity (for multibyte or Unicode characters), and other factors such as linguistic practices. The SQL standard doesn\u2019t define particular collations and character sets, so each DBMS uses its own sorting strategy and default collation\u2026 Search your DBMS documentation for collation or sort order. Source: Fehily, Chris - SQL VIsual QuickStart Guide, 3 rd Edition .","title":"Collation"},{"location":"data/db/SQL/_intro/#missing-values","text":"NULL values are handled differently on SQL engine, e.g.: Impala handles NULL as top values Hive and MySQL handles NULL as lower values. To override such a behavior, NULLS FIST or NULL LAST can be specified. This is not supported by all engines. Impala, Hive and PostgreSQL does when MySQL does not. Another possibility to achieve this is to double the sort operation: -- SQL will fist sort by 'col2 IS NULL' which is a boolean, then by 'col2' SELECT col , col2 FROM table1 ORDER BY col2 IS NULL ASC , col2","title":"Missing values"},{"location":"data/db/SQL/_intro/#engines-limitations","text":"Selection must sometimes include the column on which the is done. Example -- This will not work in Hive SELECT col1 , col2 FROM table1 ORDER BY col3 -- Nor this SELECT col1 , col2 FROM table1 ORDER BY col3 * col4 -- This will be ok SELECT col1 , col2 , col3 , col4 FROM table1 ORDER BY col3 * col4 -- and this SELECT col1 , col2 , col3 * col4 AS muliplication FROM table1 ORDER BY multiplication","title":"Engines limitations"},{"location":"data/db/SQL/_intro/#limit","text":"For pagination, sql specific implementations: -- For Impala and PostgreSQL LIMIT < limit > OFFSET < offset > -- For Hive Limit < offset > , < limit > -- MySQL supports both -- some use SKIP Danger Without ORDER BY , order is not deterministic: some row could be displayed multiple times or missing as selection is arbitrary. Impala require ORDER BY when using OFFSET","title":"Limit"},{"location":"data/db/SQL/_intro/#select","text":"Syntaxic order SELECT, FROM, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT Execution order (in general) FROM, WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT","title":"Select"},{"location":"data/db/SQL/_intro/#shortcut","text":"Order by position It is possible in some engine to specify the position or the column to apply the order on. This is not supported by every engine and will not raise an error. -- This will order by the 3rd column SELECT col1 , col2 , col3 FROM table1 ORDER BY 3","title":"Shortcut"},{"location":"data/db/SQL/impala/","text":"Impala \u00b6 Impala shell \u00b6 The impala-shell can be used for: ad hoc queries and exploration as a REPL process single statement with the -q flag or scripts with the -f flag Note The impala-shell uses readline .inputrc in your home direc","title":"Impala"},{"location":"data/db/SQL/impala/#impala","text":"","title":"Impala"},{"location":"data/db/SQL/impala/#impala-shell","text":"The impala-shell can be used for: ad hoc queries and exploration as a REPL process single statement with the -q flag or scripts with the -f flag Note The impala-shell uses readline .inputrc in your home direc","title":"Impala shell"},{"location":"data/db/SQL/postgres/","text":"PostgreSQL \u00b6 Connect From Your Local Machine to a PostgreSQL Database in Docker https://medium.com/better-programming/connect-from-local-machine-to-postgresql-docker-container-f785f00461a7 Linux downloads (Ubuntu) https://www.postgresql.org/download/linux/ubuntu/ http://zetcode.com/db/postgresqlc/ Docker \u00b6","title":"PostgreSQL"},{"location":"data/db/SQL/postgres/#postgresql","text":"Connect From Your Local Machine to a PostgreSQL Database in Docker https://medium.com/better-programming/connect-from-local-machine-to-postgresql-docker-container-f785f00461a7 Linux downloads (Ubuntu) https://www.postgresql.org/download/linux/ubuntu/ http://zetcode.com/db/postgresqlc/","title":"PostgreSQL"},{"location":"data/db/SQL/postgres/#docker","text":"","title":"Docker"},{"location":"data/db/mongoDB/Aggregation/","text":"Aggregation framework \u00b6 Aggregation structure and basic syntax rules: pipelines are always an array of one or more stages. stages are composed of one or more operators/expressions. expressions may take a single/an array of arguments. Code { $ match : { < query > } } Selection stage \u00b6 $match - filtering documents \u00b6 a $match may contain a $text query operator, but it must be the first in the pipeline $match should come early in the pipeline $where can not be used with $match $match uses the same syntax as find() $project - shaping document (projection) \u00b6 { $project: { } } specify fields to be retained _id must be explicitly removed let add new fields or reassign values can be used as many times as required in an aggregation pipeline $addFields : add transformation fields in the document \u00b6 $geoNear : filtering documents \u00b6 must be the first stage in the pipeline is a collection with only one geo index Example $geoNear: { near: <Point>, distanceField: \"<key>\", ... } Cursor-like stages \u00b6 $limit : limit \u00b6 $skip : limit \u00b6 $count : limit \u00b6 $sort : limit \u00b6 $sample : limit \u00b6 Group stage \u00b6 $group : limit \u00b6","title":"Aggregation framework"},{"location":"data/db/mongoDB/Aggregation/#aggregation-framework","text":"Aggregation structure and basic syntax rules: pipelines are always an array of one or more stages. stages are composed of one or more operators/expressions. expressions may take a single/an array of arguments. Code { $ match : { < query > } }","title":"Aggregation framework"},{"location":"data/db/mongoDB/Aggregation/#selection-stage","text":"","title":"Selection stage"},{"location":"data/db/mongoDB/Aggregation/#match-filtering-documents","text":"a $match may contain a $text query operator, but it must be the first in the pipeline $match should come early in the pipeline $where can not be used with $match $match uses the same syntax as find()","title":"$match - filtering documents"},{"location":"data/db/mongoDB/Aggregation/#project-shaping-document-projection","text":"{ $project: { } } specify fields to be retained _id must be explicitly removed let add new fields or reassign values can be used as many times as required in an aggregation pipeline","title":"$project - shaping document (projection)"},{"location":"data/db/mongoDB/Aggregation/#addfields-add-transformation-fields-in-the-document","text":"","title":"$addFields: add transformation fields in the document"},{"location":"data/db/mongoDB/Aggregation/#geonear-filtering-documents","text":"must be the first stage in the pipeline is a collection with only one geo index Example $geoNear: { near: <Point>, distanceField: \"<key>\", ... }","title":"$geoNear: filtering    documents"},{"location":"data/db/mongoDB/Aggregation/#cursor-like-stages","text":"","title":"Cursor-like stages"},{"location":"data/db/mongoDB/Aggregation/#limit-limit","text":"","title":"$limit: limit"},{"location":"data/db/mongoDB/Aggregation/#skip-limit","text":"","title":"$skip: limit"},{"location":"data/db/mongoDB/Aggregation/#count-limit","text":"","title":"$count: limit"},{"location":"data/db/mongoDB/Aggregation/#sort-limit","text":"","title":"$sort: limit"},{"location":"data/db/mongoDB/Aggregation/#sample-limit","text":"","title":"$sample: limit"},{"location":"data/db/mongoDB/Aggregation/#group-stage","text":"","title":"Group stage"},{"location":"data/db/mongoDB/Aggregation/#group-limit","text":"","title":"$group: limit"},{"location":"data/db/mongoDB/_intro/","text":"MongoDB \u00b6 Notation: field path: $fieldName system variable: $$UPPERCASE user variable: $$foo Jupyter kernel imongo \u00b6 imongo ipython wrapper kernel Jupyter messenging doc http://zguide.zeromq.org/page:all","title":"Intro"},{"location":"data/db/mongoDB/_intro/#mongodb","text":"Notation: field path: $fieldName system variable: $$UPPERCASE user variable: $$foo","title":"MongoDB"},{"location":"data/db/mongoDB/_intro/#jupyter-kernel-imongo","text":"imongo ipython wrapper kernel Jupyter messenging doc http://zguide.zeromq.org/page:all","title":"Jupyter kernel imongo"},{"location":"data/db/mongoDB/docker/","text":"MongoDB docker image \u00b6 Environment variables / startup scripts \u00b6 Danger Any pre-existing DB will be left untouched, so env. var. have no effect MONGO_INITDB_ROOT_USERNAME MONGO_INITDB_ROOT_PASSWORD , when used with ..._USERNAME , creates user in the admin auth DB with root role MONGO_INITDB_DATABASE specify the name of a DB used in initialization scripts Info Files can be passed for sensitive informatin by appending _FILE a env. var., e.g.: MONGO_INITB_ROOT_PASSWORD_FILE='/var/mongodb_root_secret' Initialization \u00b6 optional and used for more complex setup all files located at /dock-entrypoint-initdb.d/ with extension .js and .sh will be executed. execution in alphabetical order .js files will be executed by mongo using MONGO_INIT_DATABASE otherwise 'test'","title":"Docker Image"},{"location":"data/db/mongoDB/docker/#mongodb-docker-image","text":"","title":"MongoDB docker image"},{"location":"data/db/mongoDB/docker/#environment-variables-startup-scripts","text":"Danger Any pre-existing DB will be left untouched, so env. var. have no effect MONGO_INITDB_ROOT_USERNAME MONGO_INITDB_ROOT_PASSWORD , when used with ..._USERNAME , creates user in the admin auth DB with root role MONGO_INITDB_DATABASE specify the name of a DB used in initialization scripts Info Files can be passed for sensitive informatin by appending _FILE a env. var., e.g.: MONGO_INITB_ROOT_PASSWORD_FILE='/var/mongodb_root_secret'","title":"Environment variables / startup scripts"},{"location":"data/db/mongoDB/docker/#initialization","text":"optional and used for more complex setup all files located at /dock-entrypoint-initdb.d/ with extension .js and .sh will be executed. execution in alphabetical order .js files will be executed by mongo using MONGO_INIT_DATABASE otherwise 'test'","title":"Initialization"},{"location":"data/pipelines/luigi/","text":"Luigi \u00b6 2 fundamentals buidling blocks, both abstract classes: Tasks defines three methods: run() , output() and requires() . Target , resource generated by a Task defines one method that must be overridden: exists , returns a boolean. corresponds to a file on a disk, a file on HDFS or some kind of a checkpoint, like an entry in a database, already defined LocalTarget and HdfsTarget , and from luigi.contribi : s3.S3Target , ssh.RemoteTarget , ftp.RemoteTarget , mysqldb.MySqlTarget , ... filesystem like targets implement the open() method returning s stream object whose mode can be specified, e.g. mode='w' Gzip support by providing format=format.Gzip Parameter Source: https://luigi.readthedocs.io","title":"Luigi"},{"location":"data/pipelines/luigi/#luigi","text":"2 fundamentals buidling blocks, both abstract classes: Tasks defines three methods: run() , output() and requires() . Target , resource generated by a Task defines one method that must be overridden: exists , returns a boolean. corresponds to a file on a disk, a file on HDFS or some kind of a checkpoint, like an entry in a database, already defined LocalTarget and HdfsTarget , and from luigi.contribi : s3.S3Target , ssh.RemoteTarget , ftp.RemoteTarget , mysqldb.MySqlTarget , ... filesystem like targets implement the open() method returning s stream object whose mode can be specified, e.g. mode='w' Gzip support by providing format=format.Gzip Parameter Source: https://luigi.readthedocs.io","title":"Luigi"},{"location":"data/pipelines/prefect/","text":"Prefect \u00b6","title":"prefect"},{"location":"data/pipelines/prefect/#prefect","text":"","title":"Prefect"},{"location":"data/viz/matplotlib/","text":"Matplotlib \u00b6 verything in matplotlib is organized in a hierarchy: at the top of the hierarchy is the matplotlib \"state-machine environment\" which is provided by the matplotlib.pyplot module. At this level, simple functions are used to add plot elements (lines, images, text, etc.) to the current axes in the current figure. https://dev.to/skotaro/artist-in-matplotlib---something-i-wanted-to-know-before-spending-tremendous-hours-on-googling-how-tos--31oo Anatomy of a figure \u00b6 https://matplotlib.org/tutorials/intermediate/artists.html Axis \u00b6 Accessor method Description get_scale The scale of the axis, e.g., 'log' or 'linear' get_view_interval The interval instance of the axis view limits get_data_interval The interval instance of the axis data limits get_gridlines A list of grid lines for the Axis get_label The axis label - a Text instance get_ticklabels A list of Text instances - keyword minor-True get_ticklines A list of Line2D instances - keyword minor-True get_ticklocs A list of Tick locations - keyword minor-True get_major_locator The matplotlib.ticker.Locator instance for major ticks get_major_formatter The matplotlib.ticker.Formatter instance for major ticks get_minor_locator The matplotlib.ticker.Locator instance for minor ticks get_minor_formatter The matplotlib.ticker.Formatter instance for minor ticks get_major_ticks A list of Tick instances for major ticks get_minor_ticks A list of Tick instances for minor ticks grid Turn the grid on or off for the major or minor ticks Spines \u00b6","title":"Matplolib"},{"location":"data/viz/matplotlib/#matplotlib","text":"verything in matplotlib is organized in a hierarchy: at the top of the hierarchy is the matplotlib \"state-machine environment\" which is provided by the matplotlib.pyplot module. At this level, simple functions are used to add plot elements (lines, images, text, etc.) to the current axes in the current figure. https://dev.to/skotaro/artist-in-matplotlib---something-i-wanted-to-know-before-spending-tremendous-hours-on-googling-how-tos--31oo","title":"Matplotlib"},{"location":"data/viz/matplotlib/#anatomy-of-a-figure","text":"https://matplotlib.org/tutorials/intermediate/artists.html","title":"Anatomy of a figure"},{"location":"data/viz/matplotlib/#axis","text":"Accessor method Description get_scale The scale of the axis, e.g., 'log' or 'linear' get_view_interval The interval instance of the axis view limits get_data_interval The interval instance of the axis data limits get_gridlines A list of grid lines for the Axis get_label The axis label - a Text instance get_ticklabels A list of Text instances - keyword minor-True get_ticklines A list of Line2D instances - keyword minor-True get_ticklocs A list of Tick locations - keyword minor-True get_major_locator The matplotlib.ticker.Locator instance for major ticks get_major_formatter The matplotlib.ticker.Formatter instance for major ticks get_minor_locator The matplotlib.ticker.Locator instance for minor ticks get_minor_formatter The matplotlib.ticker.Formatter instance for minor ticks get_major_ticks A list of Tick instances for major ticks get_minor_ticks A list of Tick instances for minor ticks grid Turn the grid on or off for the major or minor ticks","title":"Axis"},{"location":"data/viz/matplotlib/#spines","text":"","title":"Spines"},{"location":"doc/md/","text":"usage and plugins \u00b6 mkdocs mkdocs-material Github guide Comments \u00b6 [comment]: <> (This is a comment, it will not be included) [//]: <> (This is also a comment.) [//]: # (This may be the most platform independent comment) Source: Stack Overflow 4823469 Extensions \u00b6 PyMdown extensions \u00b6 Collection of extensions for Python Markdown. Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with MathJax. p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} . Admonition \u00b6 Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content Note !!! note For fixed block Note ??? note For collapsible block Supported types: note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error Bug Example quote, cite Content tab \u00b6 Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Keys \u00b6 ++ctrl+alt+del++ ++ctrl+C++","title":"Help"},{"location":"doc/md/#usage-and-plugins","text":"mkdocs mkdocs-material Github guide","title":"usage and plugins"},{"location":"doc/md/#comments","text":"[comment]: <> (This is a comment, it will not be included) [//]: <> (This is also a comment.) [//]: # (This may be the most platform independent comment) Source: Stack Overflow 4823469","title":"Comments"},{"location":"doc/md/#extensions","text":"","title":"Extensions"},{"location":"doc/md/#pymdown-extensions","text":"Collection of extensions for Python Markdown. Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with MathJax. p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} .","title":"PyMdown extensions  "},{"location":"doc/md/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content Note !!! note For fixed block Note ??? note For collapsible block Supported types: note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error Bug Example quote, cite","title":"Admonition"},{"location":"doc/md/#content-tab","text":"Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Content tab"},{"location":"doc/md/#keys","text":"++ctrl+alt+del++ ++ctrl+C++","title":"Keys"},{"location":"go/concurency/","text":"Go concurency \u00b6 Do not communicate by sharing memory; instead, share memory by communicating. 1 Context \u00b6 Context pkg defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes. Notes: \u00b6 https://golang.org/doc/effective_go.html#concurrency \u21a9","title":"Concurency"},{"location":"go/concurency/#go-concurency","text":"Do not communicate by sharing memory; instead, share memory by communicating. 1","title":"Go concurency"},{"location":"go/concurency/#context","text":"Context pkg defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes.","title":"Context"},{"location":"go/concurency/#notes","text":"https://golang.org/doc/effective_go.html#concurrency \u21a9","title":"Notes:"},{"location":"go/distributed/","text":"Distributed \u00b6 RAFT algorithm \u00b6 Blog post Used in Kubernets etcd distributed key-value store.","title":"Distributed"},{"location":"go/distributed/#distributed","text":"","title":"Distributed"},{"location":"go/distributed/#raft-algorithm","text":"Blog post Used in Kubernets etcd distributed key-value store.","title":"RAFT algorithm"},{"location":"go/intro/","text":"Go lang \u00b6 In Go, when you call a function or a method the arguments are copied. High performance go by Dave Cheney (Paris 2019)","title":"Go lang"},{"location":"go/intro/#go-lang","text":"In Go, when you call a function or a method the arguments are copied. High performance go by Dave Cheney (Paris 2019)","title":"Go lang"},{"location":"infrastructure/ldap/","text":"Lightweight Directory Access Protocol (LDAP) \u00b6 Implementations \u00b6 Python \u00b6 Python ldap provides an interface to LDAP v3. Base objects are: ldap provides access to OpenLDAP's C API.","title":"Lightweight Directory Access Protocol (LDAP)"},{"location":"infrastructure/ldap/#lightweight-directory-access-protocol-ldap","text":"","title":"Lightweight Directory Access Protocol (LDAP)"},{"location":"infrastructure/ldap/#implementations","text":"","title":"Implementations"},{"location":"infrastructure/ldap/#python","text":"Python ldap provides an interface to LDAP v3. Base objects are: ldap provides access to OpenLDAP's C API.","title":"Python"},{"location":"infrastructure/vm/","text":"VM \u00b6 Wikipedia VirtualBox \u00b6 VirtualBox is a general-purpose full virtualizer for x86 hardware, targeted at server, desktop and embedded use. Installation \u00b6 Binaries, extension and source code can be installed from the wiki . A handy feature is the ability to run common commands for managing VM from the cli after installing the extension pack Basic command for running VM \u00b6 The extension pack cli entry point VBoxManage can be aliased as: alias vbm = VBoxManage List VM's: vbm list vms # List running vms vbm list runningvms Change the name of a VM: vbm modifyvm \"VirtualMachine provided for test purpose\" --name \"MyVM\" Start a VM in headless mode: vbm startvm \"MyVM\" --type headless Once started, a VM in headless mode can be controlled (pause/resume/poweroff): vbm controlvm \"MyVM\" pause --type headless vbm controlvm \"MyVM\" resume --type headless vbm controlvm \"MyVM\" poweroff --type headless View VM properties with vboxmanage guestproperty # Enumerate all properties of the VM named MyVM vbm guestproperty enumerate MyVM # Get the IP address of the VM named Cloudera vbm guestproperty get Cloudera /VirtualBox/GuestInfo/Net/0/V4/IP Vagrant \u00b6 Installation on Debian based systems \u00b6 deb package can be found at download curl -LO https://releases.hashicorp.com/vagrant/2.2.9/vagrant_2.2.9_x86_64.deb sudo apt install ./vagrant_2.2.9_x86_64.deb # or dpkg -i Customizing Vagrant VMware Fusion Virtual Machines with VMX Parameters How to create a Vagrant Box running Red Hat Enterprise Linux Troubleshooting on hosts with secure mode enabled \u00b6 UEFI[^1] Secure Boot[^2] (SB) is a verification mechanism for ensuring that code launched by a computer's UEFI firmware is trusted. Unsigned drivers are therefor not allowed to load. 2 kernels modules are compiled at installation time and must be loaded. If the host provides the proper kernel headers and gcc, these two modules will be built silently. The progress is logged into /tmp/vmware-root/vmware-PID.log[^3]. On error type like: Cannot open /dev/vmmon : No such file or directory. Please make sure that the kernel module vmmon is loaded The modules must be signed and the keys added to a database recognised by the first stage of the bootloader, the Machine Owner Key # Modules must be signed by a CA ( Certificate Authority ) , here self-signed openssl req -new -x509 -newkey rsa:2048 -keyout <MOK.priv> -outform DER -out <MOK.der> -nodes -days 36500 -subj \"/CN=VMware/\" sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmmon) sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmnet) sudo mokutil --test-key <MOK.der> # cert should not be currently enrolled sudo mokutil --import <MOK.der> # mokutil should request pwd sudo mokutil --test-key <MOK.der> # cert should be enrolled now sudo mokutil --list-new # your cert should be displayed reboot Links \u00b6 [^1] Unified Extensible Firmware Interface - https://wiki.debian.org/UEFI [^2] Debian secure boot documentation page [^3] VMware knowledge base","title":"VM"},{"location":"infrastructure/vm/#vm","text":"Wikipedia","title":"VM"},{"location":"infrastructure/vm/#virtualbox","text":"VirtualBox is a general-purpose full virtualizer for x86 hardware, targeted at server, desktop and embedded use.","title":"VirtualBox"},{"location":"infrastructure/vm/#installation","text":"Binaries, extension and source code can be installed from the wiki . A handy feature is the ability to run common commands for managing VM from the cli after installing the extension pack","title":"Installation"},{"location":"infrastructure/vm/#basic-command-for-running-vm","text":"The extension pack cli entry point VBoxManage can be aliased as: alias vbm = VBoxManage List VM's: vbm list vms # List running vms vbm list runningvms Change the name of a VM: vbm modifyvm \"VirtualMachine provided for test purpose\" --name \"MyVM\" Start a VM in headless mode: vbm startvm \"MyVM\" --type headless Once started, a VM in headless mode can be controlled (pause/resume/poweroff): vbm controlvm \"MyVM\" pause --type headless vbm controlvm \"MyVM\" resume --type headless vbm controlvm \"MyVM\" poweroff --type headless View VM properties with vboxmanage guestproperty # Enumerate all properties of the VM named MyVM vbm guestproperty enumerate MyVM # Get the IP address of the VM named Cloudera vbm guestproperty get Cloudera /VirtualBox/GuestInfo/Net/0/V4/IP","title":"Basic command for running VM"},{"location":"infrastructure/vm/#vagrant","text":"","title":"Vagrant"},{"location":"infrastructure/vm/#installation-on-debian-based-systems","text":"deb package can be found at download curl -LO https://releases.hashicorp.com/vagrant/2.2.9/vagrant_2.2.9_x86_64.deb sudo apt install ./vagrant_2.2.9_x86_64.deb # or dpkg -i Customizing Vagrant VMware Fusion Virtual Machines with VMX Parameters How to create a Vagrant Box running Red Hat Enterprise Linux","title":"Installation on Debian based systems"},{"location":"infrastructure/vm/#troubleshooting-on-hosts-with-secure-mode-enabled","text":"UEFI[^1] Secure Boot[^2] (SB) is a verification mechanism for ensuring that code launched by a computer's UEFI firmware is trusted. Unsigned drivers are therefor not allowed to load. 2 kernels modules are compiled at installation time and must be loaded. If the host provides the proper kernel headers and gcc, these two modules will be built silently. The progress is logged into /tmp/vmware-root/vmware-PID.log[^3]. On error type like: Cannot open /dev/vmmon : No such file or directory. Please make sure that the kernel module vmmon is loaded The modules must be signed and the keys added to a database recognised by the first stage of the bootloader, the Machine Owner Key # Modules must be signed by a CA ( Certificate Authority ) , here self-signed openssl req -new -x509 -newkey rsa:2048 -keyout <MOK.priv> -outform DER -out <MOK.der> -nodes -days 36500 -subj \"/CN=VMware/\" sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmmon) sudo /usr/src/linux-headers-``uname -r``/scripts/sign-file sha256 <MOK.priv> <MOK.der> $(modinfo -n vmnet) sudo mokutil --test-key <MOK.der> # cert should not be currently enrolled sudo mokutil --import <MOK.der> # mokutil should request pwd sudo mokutil --test-key <MOK.der> # cert should be enrolled now sudo mokutil --list-new # your cert should be displayed reboot","title":"Troubleshooting on hosts with secure mode enabled"},{"location":"infrastructure/vm/#links","text":"[^1] Unified Extensible Firmware Interface - https://wiki.debian.org/UEFI [^2] Debian secure boot documentation page [^3] VMware knowledge base","title":"Links"},{"location":"infrastructure/containerization/cli/","text":"","title":"Docker CLI"},{"location":"infrastructure/containerization/containerd/","text":"Docker \u00b6 Containerd \u00b6 A \u201ccontainer runtime\u201d layer located between platforms (Docker, Kubernetes) and lower level runtimes (runc, Kata, Firecracker, gVisor) a resource manager for container processes, image artifacts, filesystem snapshots, metadata and dependencies Originally built up alongside Docker, the project was nor forked nor inherited but grew in scope from a container supervisor to full runtime. Completely new interfaces for managing containers and images were created. Source: https://static.sched.com/hosted_files/kccnceu20/99/2020%20-%20Kubecon%20EU%20Introduction-containerd.pdf https://youtube.com/watch?v=aVReM1D82iY https://static.sched.com/hosted_files/kccnceu20/c1/containerd-deep-dive.pdf https://youtube.com/c/cloudnativef","title":"Containerd"},{"location":"infrastructure/containerization/containerd/#docker","text":"","title":"Docker"},{"location":"infrastructure/containerization/containerd/#containerd","text":"A \u201ccontainer runtime\u201d layer located between platforms (Docker, Kubernetes) and lower level runtimes (runc, Kata, Firecracker, gVisor) a resource manager for container processes, image artifacts, filesystem snapshots, metadata and dependencies Originally built up alongside Docker, the project was nor forked nor inherited but grew in scope from a container supervisor to full runtime. Completely new interfaces for managing containers and images were created. Source: https://static.sched.com/hosted_files/kccnceu20/99/2020%20-%20Kubecon%20EU%20Introduction-containerd.pdf https://youtube.com/watch?v=aVReM1D82iY https://static.sched.com/hosted_files/kccnceu20/c1/containerd-deep-dive.pdf https://youtube.com/c/cloudnativef","title":"Containerd"},{"location":"infrastructure/containerization/intro/","text":"Docker \u00b6 Containers and virtual machines have similar resource isolation and allocation benefits, but function differently because containers virtualize the operating system instead of hardware. Containers are more portable and efficient. Source: http://docker.com Tools \u00b6 container-diff is a tool for analyzing and comparing container images along several different criteria, e.g. Docker Image History, image file system andsize, Apt, RPM, pip and npm packages. Dive is a tool for exploring each layer in a docker image. DockerSlim minify docker image and Generate Security Profiles.","title":"Docker"},{"location":"infrastructure/containerization/intro/#docker","text":"Containers and virtual machines have similar resource isolation and allocation benefits, but function differently because containers virtualize the operating system instead of hardware. Containers are more portable and efficient. Source: http://docker.com","title":"Docker"},{"location":"infrastructure/containerization/intro/#tools","text":"container-diff is a tool for analyzing and comparing container images along several different criteria, e.g. Docker Image History, image file system andsize, Apt, RPM, pip and npm packages. Dive is a tool for exploring each layer in a docker image. DockerSlim minify docker image and Generate Security Profiles.","title":"Tools"},{"location":"infrastructure/devops/ansible/","text":"Ansible \u00b6 Mac setup and configuration from Jeff Gerling github repo < Cowsay and Ansible > \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || || Keywords \u00b6 Templates \u00b6 Tutorial Testing \u00b6 Molecule \u00b6","title":"Ansible"},{"location":"infrastructure/devops/ansible/#ansible","text":"Mac setup and configuration from Jeff Gerling github repo < Cowsay and Ansible > \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || ||","title":"Ansible"},{"location":"infrastructure/devops/ansible/#keywords","text":"","title":"Keywords"},{"location":"infrastructure/devops/ansible/#templates","text":"Tutorial","title":"Templates"},{"location":"infrastructure/devops/ansible/#testing","text":"","title":"Testing"},{"location":"infrastructure/devops/ansible/#molecule","text":"","title":"Molecule"},{"location":"infrastructure/orchestration/cli/","text":"CLI \u00b6 helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources. kustomize lets you customize raw, template-free YAML files for multiple purposes, leaving the original YAML untouched and usable as is. kustomize build system has been included in kubectl. helm convert let you convert existing charts into Kustomize compatible package. kubectl \u00b6 helm \u00b6 kustomize \u00b6","title":"kubectl"},{"location":"infrastructure/orchestration/cli/#cli","text":"helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources. kustomize lets you customize raw, template-free YAML files for multiple purposes, leaving the original YAML untouched and usable as is. kustomize build system has been included in kubectl. helm convert let you convert existing charts into Kustomize compatible package.","title":"CLI"},{"location":"infrastructure/orchestration/cli/#kubectl","text":"","title":"kubectl"},{"location":"infrastructure/orchestration/cli/#helm","text":"","title":"helm"},{"location":"infrastructure/orchestration/cli/#kustomize","text":"","title":"kustomize"},{"location":"infrastructure/orchestration/intro/","text":"Kubernetes \u00b6 K8S components \u00b6 Brendan Burns Elements of orchestration \u00b6 Orchestrator role: get a status defined declarativly by the prgrammer. Control Plane Components \u00b6 kube-apiserver exposes K8S API. etcd is distributed key-value store used to store all cluster data. kube-scheduler watches and decide on why node to run newly created pods. kube-controller-manager Node controller : notices and responds when nodes go down. Replication controller : maintains the correct number of pods for every replication controller object Endpoints controller : populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : creates default accounts and API access tokens. cloud-controller-manager embeds cloud-specific control logic, e.g.: Node controller : checks the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : sets up routes Service controller : creates, updates and deletes cloud provider load balancers Node Components \u00b6 kubelet is an agent running on each node that starts and monitor the container runtime workloads. kube-proxy routes inter-pod and internet requests. Container runtime is responsible for running containers (usually Docker). Objects \u00b6 Pods Set of containers, all containers inside a port share a port-space. An appliciation-specfic \"logical host\". A pod is started on a node: containers in the pod can communicate over localhost. Deployments and ReplicaSets \u00b6 Desired state definition for pods. Deployment strategies on Kubernetes Kubernetes Examples Strategies Kubernetes deployment strategies explained Strategy ZERO DOWNTIME REAL TRAFFIC TESTING TARGETED USER CLOUD COST ROLLBACK DURATION NEGATIVE IMPACT ON USER COMPLEXITY OF SETUP RECREATE Version A is terminated then version B is rolled out \u2717 \u2717 \u2717 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b \u2b1b\u2b1b\u2b1b \u2b1c\u2b1c\u2b1c RAMPED Version B is slowly rolled out and replacing version A \u2713 \u2717 \u2717 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c BLUE/GREEN version A and B are released alongside, then traffic switched to B \u2713 \u2717 \u2717 \u2b1b\u2b1b\u2b1b \u2b1c\u2b1c\u2b1c \u2b1b\u2b1b\u2b1c \u2b1b\u2b1b\u2b1c CANARY version B is released to a subset of users before full rollout \u2713 \u2713 \u2717 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1c A/B TESTING version B is released to a subset of users under specific conditions \u2713 \u2713 \u2713 \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b SHADOW version B receives seal world traffic alongside version A and doesn't impact the responce \u2713 \u2713 \u2717 \u2b1b\u2b1b\u2b1b \u2b1c\u2b1c\u2b1c \u2b1c\u2b1c\u2b1c \u2b1b\u2b1b\u2b1b Source Bridge to Kubernetes \u00b6 On Azure Dev Spaces tooling AZDS Connect , repo to extension Outer loop Networking \u00b6 Ingress and Egress flows \u00b6 Ingress enables traffic from outside the cluster. A LoadBalancer service provides the routing to the pod. CNI: Container Network Interface 2 options: - in cluster Ingress Controller - External Ingress Controller Nginx Kong Azure AppGW .. Azure: AGIC (Application Gateway Ingress Controller) DNS operator allow for dynamic configuraiton of DNS records Kubernetes network policy \u00b6 kind: NetworkPolicy (networking.k8s.io/v1) Only ingress controlle is public namespaces for different workloads DMS names automatically maintained by opertaurs network policies for isolatind workloards against each other Securing your identities and secrets \u00b6 identities on Azure: aad-pod-identiy secrets on Azure: kubernetes-keyvault-flextool (today) -> secrets-store-csi-driver (soon) Azure Securtiy Center on AKS: - continuoous discovery of managed AKS instances - actionable recommendations... - ... Policies \u00b6 prevent any publics ips on the load balancer no image from repo xyz ... No native kubernetes solution for this. Giant swarm \u00b6 Cloud native for entreprise Day 2 operation \u00b6 try to ensure everything is: - immutable - automated - declarative - operated Testing \u00b6 conftest helps defining tests against structured configuration data for Kubernetes configuration, Tekton pipeline definitions, Terraform code, Serverless configs or any other config files. Tools \u00b6 GitOps \u00b6 flux2 is constructed with the GitOps Toolkit and is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy. Tracing \u00b6 applicaton Insights (Azure) OpenCensus / OpenTelemetry Zipkin (java) Jaeger (go) Others \u00b6 dapr.io is a portable, event-driven, runtime for building distributed applications across cloud and edge. Service invocation over API State management: key/value Publish and subscribe v1.0/publish/","title":"Intro"},{"location":"infrastructure/orchestration/intro/#kubernetes","text":"","title":"Kubernetes"},{"location":"infrastructure/orchestration/intro/#k8s-components","text":"Brendan Burns","title":"K8S components"},{"location":"infrastructure/orchestration/intro/#elements-of-orchestration","text":"Orchestrator role: get a status defined declarativly by the prgrammer.","title":"Elements of orchestration"},{"location":"infrastructure/orchestration/intro/#control-plane-components","text":"kube-apiserver exposes K8S API. etcd is distributed key-value store used to store all cluster data. kube-scheduler watches and decide on why node to run newly created pods. kube-controller-manager Node controller : notices and responds when nodes go down. Replication controller : maintains the correct number of pods for every replication controller object Endpoints controller : populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : creates default accounts and API access tokens. cloud-controller-manager embeds cloud-specific control logic, e.g.: Node controller : checks the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : sets up routes Service controller : creates, updates and deletes cloud provider load balancers","title":"Control Plane Components"},{"location":"infrastructure/orchestration/intro/#node-components","text":"kubelet is an agent running on each node that starts and monitor the container runtime workloads. kube-proxy routes inter-pod and internet requests. Container runtime is responsible for running containers (usually Docker).","title":"Node Components"},{"location":"infrastructure/orchestration/intro/#objects","text":"","title":"Objects"},{"location":"infrastructure/orchestration/intro/#deployments-and-replicasets","text":"Desired state definition for pods. Deployment strategies on Kubernetes Kubernetes Examples","title":"Deployments and ReplicaSets"},{"location":"infrastructure/orchestration/intro/#bridge-to-kubernetes","text":"On Azure Dev Spaces tooling AZDS Connect , repo to extension Outer loop","title":"Bridge to Kubernetes"},{"location":"infrastructure/orchestration/intro/#networking","text":"","title":"Networking"},{"location":"infrastructure/orchestration/intro/#ingress-and-egress-flows","text":"Ingress enables traffic from outside the cluster. A LoadBalancer service provides the routing to the pod. CNI: Container Network Interface 2 options: - in cluster Ingress Controller - External Ingress Controller Nginx Kong Azure AppGW .. Azure: AGIC (Application Gateway Ingress Controller) DNS operator allow for dynamic configuraiton of DNS records","title":"Ingress and Egress flows"},{"location":"infrastructure/orchestration/intro/#kubernetes-network-policy","text":"kind: NetworkPolicy (networking.k8s.io/v1) Only ingress controlle is public namespaces for different workloads DMS names automatically maintained by opertaurs network policies for isolatind workloards against each other","title":"Kubernetes network policy"},{"location":"infrastructure/orchestration/intro/#securing-your-identities-and-secrets","text":"identities on Azure: aad-pod-identiy secrets on Azure: kubernetes-keyvault-flextool (today) -> secrets-store-csi-driver (soon) Azure Securtiy Center on AKS: - continuoous discovery of managed AKS instances - actionable recommendations... - ...","title":"Securing  your identities and secrets"},{"location":"infrastructure/orchestration/intro/#policies","text":"prevent any publics ips on the load balancer no image from repo xyz ... No native kubernetes solution for this.","title":"Policies"},{"location":"infrastructure/orchestration/intro/#giant-swarm","text":"Cloud native for entreprise","title":"Giant swarm"},{"location":"infrastructure/orchestration/intro/#day-2-operation","text":"try to ensure everything is: - immutable - automated - declarative - operated","title":"Day 2 operation"},{"location":"infrastructure/orchestration/intro/#testing","text":"conftest helps defining tests against structured configuration data for Kubernetes configuration, Tekton pipeline definitions, Terraform code, Serverless configs or any other config files.","title":"Testing"},{"location":"infrastructure/orchestration/intro/#tools","text":"","title":"Tools"},{"location":"infrastructure/orchestration/intro/#gitops","text":"flux2 is constructed with the GitOps Toolkit and is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy.","title":"GitOps"},{"location":"infrastructure/orchestration/intro/#tracing","text":"applicaton Insights (Azure) OpenCensus / OpenTelemetry Zipkin (java) Jaeger (go)","title":"Tracing"},{"location":"infrastructure/orchestration/intro/#others","text":"dapr.io is a portable, event-driven, runtime for building distributed applications across cloud and edge. Service invocation over API State management: key/value Publish and subscribe v1.0/publish/","title":"Others"},{"location":"infrastructure/orchestration/k8sdist/","text":"Kubernetes distribution \u00b6 Minikube \u00b6 Minikube installs a local kubernetes cluster. Installation \u00b6 Direct download via: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube Driver: \u00b6 The vmware driver supports virtualization across all VMware based hypervisors. r = https://api.github.com/repos/machine-drivers/docker-machine-driver-vmware curl -LO $( curl -s $r /releases/latest | grep -o 'http.*darwin_amd64' | head -n1 ) \\ && install docker-machine-driver-vmware_darwin_amd64 \\ /usr/local/bin/docker-machine-driver-vmware OpenShift \u00b6 Service accounts \u00b6 List service accounts: oc get serviceaccounts Service accounts can be created with oc create sa <ACCOUNTNAME> , the informations relative to this account can be displayed with oc describe sa <ACCOUNTNAME> . Namespace, labels, annotations, secrets, tokens and events can de parsed, e.g. for a secret cert: oc get secret <ACCOUNTNAME>-token-<RANDOM> -o \"jsonpath={.data['service-ca\\.crt']}\" | base64 -d Resources \u00b6 Quota can be visualized per namespace with oc describe quota Usage can be visualized for resources images , imagestreams , node and pods with oc adm top <RESOURCE> . This one is a built on kubectl top <RESOURCE> . Minishift \u00b6 Minishift is a tool that helps run OpenShift locally by running a single-node OpenShift cluster inside a VM. Note: Install minikube \u21a9","title":"K8S distributions"},{"location":"infrastructure/orchestration/k8sdist/#kubernetes-distribution","text":"","title":"Kubernetes distribution"},{"location":"infrastructure/orchestration/k8sdist/#minikube","text":"Minikube installs a local kubernetes cluster.","title":"Minikube"},{"location":"infrastructure/orchestration/k8sdist/#installation","text":"Direct download via: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube","title":"Installation"},{"location":"infrastructure/orchestration/k8sdist/#driver","text":"The vmware driver supports virtualization across all VMware based hypervisors. r = https://api.github.com/repos/machine-drivers/docker-machine-driver-vmware curl -LO $( curl -s $r /releases/latest | grep -o 'http.*darwin_amd64' | head -n1 ) \\ && install docker-machine-driver-vmware_darwin_amd64 \\ /usr/local/bin/docker-machine-driver-vmware","title":"Driver:"},{"location":"infrastructure/orchestration/k8sdist/#openshift","text":"","title":"OpenShift"},{"location":"infrastructure/orchestration/k8sdist/#service-accounts","text":"List service accounts: oc get serviceaccounts Service accounts can be created with oc create sa <ACCOUNTNAME> , the informations relative to this account can be displayed with oc describe sa <ACCOUNTNAME> . Namespace, labels, annotations, secrets, tokens and events can de parsed, e.g. for a secret cert: oc get secret <ACCOUNTNAME>-token-<RANDOM> -o \"jsonpath={.data['service-ca\\.crt']}\" | base64 -d","title":"Service accounts"},{"location":"infrastructure/orchestration/k8sdist/#resources","text":"Quota can be visualized per namespace with oc describe quota Usage can be visualized for resources images , imagestreams , node and pods with oc adm top <RESOURCE> . This one is a built on kubectl top <RESOURCE> .","title":"Resources"},{"location":"infrastructure/orchestration/k8sdist/#minishift","text":"Minishift is a tool that helps run OpenShift locally by running a single-node OpenShift cluster inside a VM. Note: Install minikube \u21a9","title":"Minishift"},{"location":"linux/freedesktop/","text":"FreeDesktop \u00b6 https://www.freedesktop.org Specification \u00b6 Basedir specification Base directories, decreasing precedence: $XDG_DATA_HOME : base directory relative to which user specific data files should be stored. Default: $HOME/.local/share should be used. $XDG_CONFIG_HOME : base directory relative to which user specific configuration files should be stored. Default: $HOME/.config should be used. $XDG_DATA_DIRS : preference-ordered set of base directories to search for data files in addition to the $XDG_DATA_HOME base directory. Directories should be seperated with a colon : . Default to /usr/local/share/:/usr/share/ should be used. $XDG_CONFIG_DIRS : preference-ordered set of base directories to search for configuration files in addition to the $XDG_CONFIG_HOME base directory. Directories in should be seperated with a colon : . Default to /etc/xdg should be used. $XDG_CACHE_HOME : base directory relative to which user specific non-essential data files should be stored. Default equal to $HOME/.cache should be used. $XDG_RUNTIME_DIR : defines the base directory relative to which user-specific non-essential runtime files and other file objects (such as sockets, named pipes, ...) should be stored. More information on this on freedesktop home page.","title":"freedesktop"},{"location":"linux/freedesktop/#freedesktop","text":"https://www.freedesktop.org","title":"FreeDesktop"},{"location":"linux/freedesktop/#specification","text":"Basedir specification Base directories, decreasing precedence: $XDG_DATA_HOME : base directory relative to which user specific data files should be stored. Default: $HOME/.local/share should be used. $XDG_CONFIG_HOME : base directory relative to which user specific configuration files should be stored. Default: $HOME/.config should be used. $XDG_DATA_DIRS : preference-ordered set of base directories to search for data files in addition to the $XDG_DATA_HOME base directory. Directories should be seperated with a colon : . Default to /usr/local/share/:/usr/share/ should be used. $XDG_CONFIG_DIRS : preference-ordered set of base directories to search for configuration files in addition to the $XDG_CONFIG_HOME base directory. Directories in should be seperated with a colon : . Default to /etc/xdg should be used. $XDG_CACHE_HOME : base directory relative to which user specific non-essential data files should be stored. Default equal to $HOME/.cache should be used. $XDG_RUNTIME_DIR : defines the base directory relative to which user-specific non-essential runtime files and other file objects (such as sockets, named pipes, ...) should be stored. More information on this on freedesktop home page.","title":"Specification"},{"location":"linux/network/","text":"Network \u00b6 Basics \u00b6 The OSI (Open Systems Interconnection) uses seven layers, - physical layer (layer 1) - network layer (layer 3) - transport layer (layer 4) - application layer (layer 7) SASL/GSSAPI \u00b6 SASL: Simple Authentification and Security Layer Framework authentication and data security in Internet protocols. It decouples authentication mechanisms from application protocols: developpers can implement different authentication mechanisms clients and servers can negociate a mutulaly acceptable exchange mechanism GSSAPI: Generic Secutrity Services Application Program Interface Kerberos \u00b6 From Wikipedia and some python notes : After login on the client machine, the client transform the password into the key of a symmetric cipher The AS becomes the request and uses the password to decrypt the request: the user is verified . User Client-based Login The client authenticates itself to the Authentication Server (AS) : Client sends an unauthenticated request to the server Server sends back a 401 response with a WWW-Authenticate: Negotiate header with no authentication details Client Authentication which forwards the username to a key distribution center (KDC) . The KDC issues a ticket-granting ticket (TGT) , which is time stamped and encrypts it using the ticket-granting service's (TGS) secret key and returns the encrypted result to the user's workstation. The Ticket Granting Ticket (TGT) encrypted with another secret key - Client Authentication Client sends a new request with an Authorization: Negotiate header Server checks the Authorization header against the Kerberos infrastructure and either allows or denies access accordingly. If access is allowed, it should include a WWW-Authenticate: Negotiate header with authentication details in the reply. Client checks the authentication details in the reply to ensure that the request came from the server kinit and klist Utils \u00b6 mtr determines the address of each network hop between the machines, it sends a sequence of ICMP ECHO requests to each one to determine the quality of the link to each machine. Resources \u00b6 Displaying IP address on eth0 interface ifconfig eth0 | grep \"inet ad\" | cut -d ':' -f 2 | cut -d ' ' -f 1 18 commands to monitor network bandwith on Linux server Red Hat blog: Introduction to Linux interfaces for virtual networking","title":"network"},{"location":"linux/network/#network","text":"","title":"Network"},{"location":"linux/network/#basics","text":"The OSI (Open Systems Interconnection) uses seven layers, - physical layer (layer 1) - network layer (layer 3) - transport layer (layer 4) - application layer (layer 7)","title":"Basics"},{"location":"linux/network/#saslgssapi","text":"","title":"SASL/GSSAPI"},{"location":"linux/network/#kerberos","text":"From Wikipedia and some python notes : After login on the client machine, the client transform the password into the key of a symmetric cipher The AS becomes the request and uses the password to decrypt the request: the user is verified . User Client-based Login The client authenticates itself to the Authentication Server (AS) : Client sends an unauthenticated request to the server Server sends back a 401 response with a WWW-Authenticate: Negotiate header with no authentication details Client Authentication which forwards the username to a key distribution center (KDC) . The KDC issues a ticket-granting ticket (TGT) , which is time stamped and encrypts it using the ticket-granting service's (TGS) secret key and returns the encrypted result to the user's workstation. The Ticket Granting Ticket (TGT) encrypted with another secret key - Client Authentication Client sends a new request with an Authorization: Negotiate header Server checks the Authorization header against the Kerberos infrastructure and either allows or denies access accordingly. If access is allowed, it should include a WWW-Authenticate: Negotiate header with authentication details in the reply. Client checks the authentication details in the reply to ensure that the request came from the server","title":"Kerberos"},{"location":"linux/network/#utils","text":"mtr determines the address of each network hop between the machines, it sends a sequence of ICMP ECHO requests to each one to determine the quality of the link to each machine.","title":"Utils"},{"location":"linux/network/#resources","text":"Displaying IP address on eth0 interface ifconfig eth0 | grep \"inet ad\" | cut -d ':' -f 2 | cut -d ' ' -f 1 18 commands to monitor network bandwith on Linux server Red Hat blog: Introduction to Linux interfaces for virtual networking","title":"Resources"},{"location":"linux/services/","text":"Services \u00b6 Init Unix System V - Slackware: init proche de Unix BSD - Ubuntu: upstart until 14.04 then systemd systemd \u00b6 systemctl list-unit-files --type service -all enabled, disabled, masked (inactive until mask is unset), static and generatedl init \u00b6","title":"Services"},{"location":"linux/services/#services","text":"Init Unix System V - Slackware: init proche de Unix BSD - Ubuntu: upstart until 14.04 then systemd","title":"Services"},{"location":"linux/services/#systemd","text":"systemctl list-unit-files --type service -all enabled, disabled, masked (inactive until mask is unset), static and generatedl","title":"systemd"},{"location":"linux/services/#init","text":"","title":"init"},{"location":"linux/ssh/","text":"SSH (OpenSSH) \u00b6 Configuration \u00b6 SSH banner / MOTD \u00b6 The banner is configurable per user. Activation is one by setting Banner in /etc/ssh/sshd_config . MOTD - Message Of The Day - is a text printed on an interactive terminal whereas the banner is sent aas a packet ( SSH2_MSG_USERAUTH_BANNER ). In OpenSSH, option PrintMotd in /etc/ssh/sshd_config . On Debian system, the MOTD is displayed via pam and the configuration is done in /etc/pam.d/sshd . Dynamic MOTD can be configured in /etc/update-motd/","title":"SSH (OpenSSH)"},{"location":"linux/ssh/#ssh-openssh","text":"","title":"SSH (OpenSSH)"},{"location":"linux/ssh/#configuration","text":"","title":"Configuration"},{"location":"linux/ssh/#ssh-banner-motd","text":"The banner is configurable per user. Activation is one by setting Banner in /etc/ssh/sshd_config . MOTD - Message Of The Day - is a text printed on an interactive terminal whereas the banner is sent aas a packet ( SSH2_MSG_USERAUTH_BANNER ). In OpenSSH, option PrintMotd in /etc/ssh/sshd_config . On Debian system, the MOTD is displayed via pam and the configuration is done in /etc/pam.d/sshd . Dynamic MOTD can be configured in /etc/update-motd/","title":"SSH banner / MOTD"},{"location":"linux/terminal/","text":"Terminal \u00b6 Terminal capabilities \u00b6 Terminfo (formerly Termcap) is a database of terminal capabilities and more. For every (well almost) model of terminal it tells application programs what the terminal is capable of doing. Links An introduction to termcap and terminfo in french.","title":"terminal"},{"location":"linux/terminal/#terminal","text":"","title":"Terminal"},{"location":"linux/terminal/#terminal-capabilities","text":"Terminfo (formerly Termcap) is a database of terminal capabilities and more. For every (well almost) model of terminal it tells application programs what the terminal is capable of doing. Links An introduction to termcap and terminfo in french.","title":"Terminal capabilities"},{"location":"linux/pkg_mgt/apk/","text":"Alpine linux \u00b6 CMD Description add Add new packages or upgrade packages to the running system del Delete packages from the running system fix Attempt to repair or upgrade an installed package update Update the index of available packages info Prints information about installed or available packages search Search for packages or descriptions with wildcard patterns upgrade Upgrade the currently installed packages cache Maintenance operations for locally cached package repository version Compare version differences between installed and available packages index create a repository index from a list of packages fetch download (but not install) packages audit List changes to the file system from pristine package install state verify Verify a package signature dot Create a graphviz graph description for a given package policy Display the repository that updates a given package, plus repositories that also offer the package stats Display statistics, including number of packages installed and available, number of directories and files, etc.","title":"Alpine linux"},{"location":"linux/pkg_mgt/apk/#alpine-linux","text":"CMD Description add Add new packages or upgrade packages to the running system del Delete packages from the running system fix Attempt to repair or upgrade an installed package update Update the index of available packages info Prints information about installed or available packages search Search for packages or descriptions with wildcard patterns upgrade Upgrade the currently installed packages cache Maintenance operations for locally cached package repository version Compare version differences between installed and available packages index create a repository index from a list of packages fetch download (but not install) packages audit List changes to the file system from pristine package install state verify Verify a package signature dot Create a graphviz graph description for a given package policy Display the repository that updates a given package, plus repositories that also offer the package stats Display statistics, including number of packages installed and available, number of directories and files, etc.","title":"Alpine linux"},{"location":"ml/bayesianinference/","text":"Bayesian inference \u00b6 Basics \u00b6 Short def. (Wikipedia) The marginal probability is the probability of a single event occurring, independent of other events. \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] The conditional probability is a measure of the probability of an event occurring given that another event has (by assumption, presumption, assertion or evidence) occurred. \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} Given random variables \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots , that are defined on a probability space, the joint probability for \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots is a probability distribution that gives the probability that each of \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots falls in any particular range or discrete set of values specified for that variable. \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)} \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)}","title":"Bayesian inference"},{"location":"ml/bayesianinference/#bayesian-inference","text":"","title":"Bayesian inference"},{"location":"ml/bayesianinference/#basics","text":"Short def. (Wikipedia) The marginal probability is the probability of a single event occurring, independent of other events. \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] \\displaystyle p_{X}(x)=\\operatorname {E} _{Y}[p_{X\\mid Y}(x\\mid y)] The conditional probability is a measure of the probability of an event occurring given that another event has (by assumption, presumption, assertion or evidence) occurred. \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} \\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\\frac {P(X=x,Y=y)}{P_{X}(x)}} Given random variables \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots , that are defined on a probability space, the joint probability for \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots is a probability distribution that gives the probability that each of \\displaystyle X,Y,\\ldots \\displaystyle X,Y,\\ldots falls in any particular range or discrete set of values specified for that variable. \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)} \u2200 A \u2208 C \\quad P(A/B) = \\frac{P(A \u2229 B)}{P(B)}","title":"Basics"},{"location":"ml/data/","text":"Apache Arrow \u00b6","title":"Intro"},{"location":"ml/data/#apache-arrow","text":"","title":"Apache Arrow"},{"location":"ml/descriptivestatistics/","text":"Descriptive statistics \u00b6 Basics: mean, median, mode and quantiles \u00b6 The Arithmetic mean is the sum of a collection of numbers divided by the count of numbers in the collection \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} The Median M_e M_e is a value separating the higher half from the lower half of a data sample, a population or a probability distribution. \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) The Mode M_0 M_0 of a set of data values is the value that appears most often. Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. Application: box-plot Standardized way of displaying the dataset based on a five-number summary: Median (Q2 / 50 th percentile) : the middle value of the dataset. First quartile (Q1 / 25 th percentile) : or lower quartile qn(0.25), is the median of the lower half of the dataset. Third quartile (Q3 / 75 th percentile) : or upper quartile qn(0.75), is the median of the upper half of the dataset. Interquartile range (IQR) : is the distance between the upper and lower quartiles. \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) Minimum : the lowest data point with or wo. any outliers. Maximum : the largest data point with or wo. any outliers. The whiskers can represent several possible alternative values, among them: the minimum and maximum of all of the data (as in figure 2) one standard deviation above and below the mean of the data the 9 th percentile and the 91 st percentile the 2 nd percentile and the 98 th percentile. Example with wiskers with maximum 1.5 IQR: Moment \u00b6 The moment of order r\u2009\u2208\u2009\u2115 is a random variable X, an indicator of the spread of this variable. Raw, central, normalised moment \u00b6 X X is a random variable and \\mathbb{E} \\mathbb{E} the expectation operator. The raw, central and normalised moments are defined if the following exist: \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} Some moments are commonly used to characterize a random variable X X : the expected value aka the mean, moment of first order: \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) The second central moment is the variance : \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] The positive square root of the variance is the standard deviation: \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} The third central moment is the measure of the lopsidedness of the distribution: Skewness \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] The fourth central moment is a measure of the heaviness of the tail of the distribution, compared to the normal distribution of the same variance: Kurtosis \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right] \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right]","title":"Descriptive statistics"},{"location":"ml/descriptivestatistics/#descriptive-statistics","text":"","title":"Descriptive statistics"},{"location":"ml/descriptivestatistics/#basics-mean-median-mode-and-quantiles","text":"The Arithmetic mean is the sum of a collection of numbers divided by the count of numbers in the collection \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} \\displaystyle {\\overline {x}}={\\frac {1}{n}}\\sum _{i=1}^{n}{x_{i}} The Median M_e M_e is a value separating the higher half from the lower half of a data sample, a population or a probability distribution. \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) \\displaystyle \\mathrm {median} (x)={\\frac {1}{2}}(x_{\\lfloor (n+1)/2\\rfloor }+x_{\\lceil (n+)/2\\rceil }) The Mode M_0 M_0 of a set of data values is the value that appears most often. Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities, or dividing the observations in a sample in the same way. Application: box-plot Standardized way of displaying the dataset based on a five-number summary: Median (Q2 / 50 th percentile) : the middle value of the dataset. First quartile (Q1 / 25 th percentile) : or lower quartile qn(0.25), is the median of the lower half of the dataset. Third quartile (Q3 / 75 th percentile) : or upper quartile qn(0.75), is the median of the upper half of the dataset. Interquartile range (IQR) : is the distance between the upper and lower quartiles. \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) \\displaystyle {\\text{IQR}}=Q_{3}-Q_{1}=q_{n}(0.75)-q_{n}(0.25) Minimum : the lowest data point with or wo. any outliers. Maximum : the largest data point with or wo. any outliers. The whiskers can represent several possible alternative values, among them: the minimum and maximum of all of the data (as in figure 2) one standard deviation above and below the mean of the data the 9 th percentile and the 91 st percentile the 2 nd percentile and the 98 th percentile. Example with wiskers with maximum 1.5 IQR:","title":"Basics: mean, median, mode and quantiles"},{"location":"ml/descriptivestatistics/#moment","text":"The moment of order r\u2009\u2208\u2009\u2115 is a random variable X, an indicator of the spread of this variable.","title":"Moment"},{"location":"ml/descriptivestatistics/#raw-central-normalised-moment","text":"X X is a random variable and \\mathbb{E} \\mathbb{E} the expectation operator. The raw, central and normalised moments are defined if the following exist: \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} \\begin{align} m_{r} & \\triangleq {\\mathbb {E}}(X^{r}) \\\\ \\mu_r & \\triangleq \\mathbb{E}([X - \\mathbb{E}(X)]^r) \\\\ \\beta_{r-2} & \\triangleq \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right )^r \\right ] \\end{align} Some moments are commonly used to characterize a random variable X X : the expected value aka the mean, moment of first order: \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) \\displaystyle \\mu \\triangleq m_{1}=\\mathbb {E} (X) The second central moment is the variance : \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] \\operatorname {V}(X)\\triangleq {\\mu}_{2}={\\mathbb {E}}[(X-\\mu )^{2}] The positive square root of the variance is the standard deviation: \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} \\displaystyle \\sigma \\triangleq {\\sqrt {\\operatorname {V} (X)}}={\\sqrt {\\mu_{2}}} The third central moment is the measure of the lopsidedness of the distribution: Skewness \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] \\displaystyle {\\gamma}_{1}\\triangleq {\\beta}_{1}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{3}\\right] The fourth central moment is a measure of the heaviness of the tail of the distribution, compared to the normal distribution of the same variance: Kurtosis \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right] \\displaystyle \\beta_{2}=\\mathbb {E} \\left[\\left({\\frac {X-\\mu }{\\sigma }}\\right)^{4}\\right]","title":"Raw, central, normalised moment"},{"location":"ml/features/","text":"Features \u00b6 Featuretools is a python library for automated feature engineering tsfresh automatically calculates a large number of time series characteristics, the so called features. 1D convolutional neural network \u00b6 Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences A Visual Introduction to Machine Learning and AI 1D ConvolutionalNeural Networks andApplications\u2013A Survey Signal Status Recognition Based on 1DCNN and Its Feature Extraction Mechanism Analysis Working with 1D convonlutional neural network in Keras \u00b6 https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/ Example \u00b6","title":"Features"},{"location":"ml/features/#features","text":"Featuretools is a python library for automated feature engineering tsfresh automatically calculates a large number of time series characteristics, the so called features.","title":"Features"},{"location":"ml/features/#1d-convolutional-neural-network","text":"Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences A Visual Introduction to Machine Learning and AI 1D ConvolutionalNeural Networks andApplications\u2013A Survey Signal Status Recognition Based on 1DCNN and Its Feature Extraction Mechanism Analysis","title":"1D convolutional neural network"},{"location":"ml/features/#working-with-1d-convonlutional-neural-network-in-keras","text":"https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/","title":"Working with 1D convonlutional neural network in Keras"},{"location":"ml/features/#example","text":"","title":"Example"},{"location":"ml/pipelines/","text":"Pipelines \u00b6 Pipeline stages \u00b6 Note Scikit-learn A Spark-ml A DVC A Imputation \u00b6 The impute module provides classes for completing missing values. SimpleInputer performs imputation based on missing_values (number, string, np.nan (default) or None), and a strategy (mean, median, most_frequent, constant). Further parameters fill_value for constant strategy and add_indicator that add a MissingIndicator Modules \u00b6 tpot \u00b6 A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. Source: https://scikit-learn.org","title":"Pipelining"},{"location":"ml/pipelines/#pipelines","text":"","title":"Pipelines"},{"location":"ml/pipelines/#pipeline-stages","text":"Note Scikit-learn A Spark-ml A DVC A","title":"Pipeline stages"},{"location":"ml/pipelines/#imputation","text":"The impute module provides classes for completing missing values. SimpleInputer performs imputation based on missing_values (number, string, np.nan (default) or None), and a strategy (mean, median, most_frequent, constant). Further parameters fill_value for constant strategy and add_indicator that add a MissingIndicator","title":"Imputation"},{"location":"ml/pipelines/#modules","text":"","title":"Modules"},{"location":"ml/pipelines/#tpot","text":"A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. Source: https://scikit-learn.org","title":"tpot"},{"location":"ml/regression/","text":"Multi linear regression: identify the strength of the effect that the independent variables have on the dependent variable predict the impact of changes, that is, to understand how the dependent variable changes when we change the independent variables","title":"Regression"},{"location":"ml/windowing/","text":"Windowing \u00b6 Machine learning and data exploring: the potential of windowing","title":"Windowing"},{"location":"ml/windowing/#windowing","text":"Machine learning and data exploring: the potential of windowing","title":"Windowing"},{"location":"ml/ndarray/intro/","text":"ND-array \u00b6 The N-dimensional array (ndarray) \u00b6 contiguous one-dimensional segment of computer memory NumPy ndarray internals can be read in source code typedef struct tagPyArrayObject_fields { PyObject_HEAD /* Pointer to the raw data buffer */ char * data ; /* The number of dimensions, also called 'ndim' */ int nd ; /* The size in each dimension, also called 'shape' */ npy_intp * dimensions ; /* * Number of bytes to jump to get to the * next element in each dimension */ npy_intp * strides ; /* * This object is decref'd upon * deletion of array. Except in the * case of WRITEBACKIFCOPY which has * special handling. * * For views it points to the original * array, collapsed so no chains of * views occur. * * For creation from buffer object it * points to an object that should be * decref'd on deletion * * For WRITEBACKIFCOPY flag this is an * array to-be-updated upon calling * PyArray_ResolveWritebackIfCopy */ PyObject * base ; /* Pointer to type structure */ PyArray_Descr * descr ; /* Flags describing array -- see below */ int flags ; /* For weak references */ PyObject * weakreflist ; } PyArrayObject_fields ; Papers: https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html NumPy documentation https://github.com/numpy/numpy/blob/b7c27bd2a3817f59c84b004b87bba5db57d9a9b0/numpy/core/include/numpy/ndarraytypes.h#L1343 ndarray.flags Information about the memory layout of the array. ndarray.shape Tuple of array dimensions. ndarray.strides Tuple of bytes to step in each dimension when traversing an array. ndarray.ndim Number of array dimensions. ndarray.data Python buffer object pointing to the start of the array\u2019s data. ndarray.size Number of elements in the array. ndarray.itemsize Length of one array element in bytes. ndarray.nbytes Total bytes consumed by the elements of the array. ndarray.base Base object if memory is from some other object.","title":"Intro"},{"location":"ml/ndarray/intro/#nd-array","text":"","title":"ND-array"},{"location":"ml/ndarray/intro/#the-n-dimensional-array-ndarray","text":"contiguous one-dimensional segment of computer memory NumPy ndarray internals can be read in source code typedef struct tagPyArrayObject_fields { PyObject_HEAD /* Pointer to the raw data buffer */ char * data ; /* The number of dimensions, also called 'ndim' */ int nd ; /* The size in each dimension, also called 'shape' */ npy_intp * dimensions ; /* * Number of bytes to jump to get to the * next element in each dimension */ npy_intp * strides ; /* * This object is decref'd upon * deletion of array. Except in the * case of WRITEBACKIFCOPY which has * special handling. * * For views it points to the original * array, collapsed so no chains of * views occur. * * For creation from buffer object it * points to an object that should be * decref'd on deletion * * For WRITEBACKIFCOPY flag this is an * array to-be-updated upon calling * PyArray_ResolveWritebackIfCopy */ PyObject * base ; /* Pointer to type structure */ PyArray_Descr * descr ; /* Flags describing array -- see below */ int flags ; /* For weak references */ PyObject * weakreflist ; } PyArrayObject_fields ; Papers: https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html NumPy documentation https://github.com/numpy/numpy/blob/b7c27bd2a3817f59c84b004b87bba5db57d9a9b0/numpy/core/include/numpy/ndarraytypes.h#L1343 ndarray.flags Information about the memory layout of the array. ndarray.shape Tuple of array dimensions. ndarray.strides Tuple of bytes to step in each dimension when traversing an array. ndarray.ndim Number of array dimensions. ndarray.data Python buffer object pointing to the start of the array\u2019s data. ndarray.size Number of elements in the array. ndarray.itemsize Length of one array element in bytes. ndarray.nbytes Total bytes consumed by the elements of the array. ndarray.base Base object if memory is from some other object.","title":"The N-dimensional array (ndarray)"},{"location":"ml/timeseries/_intro/","text":"Time series \u00b6 http://www.timeseriesclassification.com","title":"Intro"},{"location":"ml/timeseries/_intro/#time-series","text":"http://www.timeseriesclassification.com","title":"Time series"},{"location":"ml/timeseries/matrixprofile/","text":"Matrix profile \u00b6 Papers: Efficient Matrix Profile Computation Using DifferentDistance Functions Matrix Profile I: All Pairs Similarity Joins for Time Series:A Unifying View that Includes Motifs, Discords and Shapelets Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred MillionBarrierfor Time Series Motifs and Joins Stumpy \u00b6 Quote At its core, the STUMPY library efficiently computes something called a matrix profile , a vector that stores the z-normalized Euclidean distance between any subsequence within a time series and its nearest neigbor.","title":"Matrix profile"},{"location":"ml/timeseries/matrixprofile/#matrix-profile","text":"Papers: Efficient Matrix Profile Computation Using DifferentDistance Functions Matrix Profile I: All Pairs Similarity Joins for Time Series:A Unifying View that Includes Motifs, Discords and Shapelets Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred MillionBarrierfor Time Series Motifs and Joins","title":"Matrix profile"},{"location":"ml/timeseries/matrixprofile/#stumpy","text":"Quote At its core, the STUMPY library efficiently computes something called a matrix profile , a vector that stores the z-normalized Euclidean distance between any subsequence within a time series and its nearest neigbor.","title":"Stumpy "},{"location":"shell/intro/","text":"Shell \u00b6 Configuration \u00b6 Line edition and keybindings \u00b6 GNU Readline is a software library that provides line-editing and history capabilities for interactive programs with a command-line interface. Bash typically uses this library (same original author ). Emacs-like keybindings are default but readline enables configuration files at /etc/inputrc or ~/.inputrc . A lot of program not specifically written in C rely on readline , e.g. the impala-shell through python's readline module . Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo . LS_COLORS \u00b6 vivid is a generator for the LS_COLORS environment variable export LS_COLORS = \" $( vivid generate molokai ) \" GNU Stow \u00b6 GNU Stow is a symlink farm manager which takes distinct packages of software and/or data located in separate directories on the filesystem, and makes them appear to be installed in the same place. The software can be used to manage dotfiles. GNU envsubst (Gettext package) \u00b6 GNU envsubst substitutes the values of environment variables. Autojump \u00b6 These utilities give the most visited directory for the shortest search term typed. jump is written in go. autojump is written in python. zoxide is written in rust. zsh-z is a native zsh port of z.sh Finding files \u00b6 nnn is another vi-inspired filemanager for the console, lightweight, written in C. Ranger , vim-inspired filemanager for the console, written in python. Install with pipx install ranger-fm exa is a replacement for ls written in Rust. Directory content \u00b6 dust is a rust application printing a similar output to du with additional bar chart. fuzzy finder \u00b6 fzf is a go fuzzy finder Search syntax Token Match type Description sbtrkt fuzzy-match Items that match sbtrkt 'wild exact-match (quoted) Items that include wild ^music prefix-exact-match Items that start with music .mp3$ suffix-exact-match Items that end with .mp3 !fire inverse-exact-match Items that do not include fire !^music inverse-prefix-exact-match Items that do not start with music !.mp3$ inverse-suffix-exact-match Items that do not end with .mp3 fzf provides bindings : Ctrl T paste the selected files and directories onto the command-line Ctrl R paste the selected command from history onto the command-line. A second press on Ctrl R sorts relevant entries in chronological order Alt C cd into the selected directory fuzzy competion is activated with ** , e.g. vim **<TAB> completes all files in the cwd. fzy is written in C File content search \u00b6 Search can be efficiently performed by the silver search ( ag ) and ripgrep ( rg ) , written resp. in C and rust. rg tends to be one of the quickest. Ripgrep Usage rg [ OPTIONS ] PATTERN [ PATH ... ] rg [ OPTIONS ] [ -e PATTERN ... ] [ -f PATTERNFILE ... ] [ PATH ... ] rg [ OPTIONS ] --files [ PATH ... ] rg [ OPTIONS ] --type-list command | rg [ OPTIONS ] PATTERN --type <TYPE> where <TYPE> is part of the registered types, can be displayed with rg --list-types Search with substitution \u00b6 In respect of DOTADIW , rg does not support natively search and replacement. This can be achieved with a pipe. Prepare cookiecutter templates from molecule init outputs rg ROLE --files-with-matches | xargs sed -e \"s/ROLE/\\{\\{ cookiecutter.role_name \\}\\}/g\" Link: https://learnbyexample.github.io/substitution-with-ripgrep/ Manual filtering: globs \u00b6 Exclude path 'pack' from search rg -g '!/pack/**' g:ale Working with structured data \u00b6 JSON \u00b6 jq JQ cheatsheet Prepare cookiecutter templates from molecule init outputs bash URL=$(you-get --json \"https://www.youtube.com/watch?v=ZzfHjytDceU\" | jq -s 'sort_by(.streams.__default__.size) | reverse | .[0].streams.__default__.src[0]' | sed -e s/\\\"//g) YAML \u00b6 yq Makefile \u00b6 Wildcard characters \u00b6 * , ? and [...] Automatic variables \u00b6 $^ list all the prerequisites of the rule $< list the first prerequisite $? list all the prerequisites newer than the target $@ is the target Splitting Recipe Lines https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html Makefile tutorial https://makefiletutorial.com/ Introduction \u00e0 Makefile https://gl.developpez.com/tutoriel/outil/makefile/ Workflows \u00b6 desk makes it easy to flip back and forth between different project contexts in your favorite shell. Change directory, activate a virtualenv or rvm, load in domain-specific aliases, environment variables, functions, arbitrary shell files, all in a single command. direnv augments existing shells with a new feature that can load and unload environment variables depending on the current directory. Modules is a tool that simplify shell initialization and lets users easily modify their environment during the session with modulefiles. zsh-autoenv automatically sources (known/whitelisted) .autoenv.zsh files, handles \"enter\" and leave\" events, nesting, and stashing of variables (overwriting and restoring). asdf manage multiple runtime versions with a single CLI tool, extendable via plugins. Others \u00b6 nutshell is a new kind of shell, currently under heavy development.","title":"shell"},{"location":"shell/intro/#shell","text":"","title":"Shell"},{"location":"shell/intro/#configuration","text":"","title":"Configuration"},{"location":"shell/intro/#line-edition-and-keybindings","text":"GNU Readline is a software library that provides line-editing and history capabilities for interactive programs with a command-line interface. Bash typically uses this library (same original author ). Emacs-like keybindings are default but readline enables configuration files at /etc/inputrc or ~/.inputrc . A lot of program not specifically written in C rely on readline , e.g. the impala-shell through python's readline module . Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo .","title":"Line edition and keybindings"},{"location":"shell/intro/#ls_colors","text":"vivid is a generator for the LS_COLORS environment variable export LS_COLORS = \" $( vivid generate molokai ) \"","title":"LS_COLORS"},{"location":"shell/intro/#gnu-stow","text":"GNU Stow is a symlink farm manager which takes distinct packages of software and/or data located in separate directories on the filesystem, and makes them appear to be installed in the same place. The software can be used to manage dotfiles.","title":"GNU Stow"},{"location":"shell/intro/#gnu-envsubst-gettext-package","text":"GNU envsubst substitutes the values of environment variables.","title":"GNU envsubst (Gettext package)"},{"location":"shell/intro/#autojump","text":"These utilities give the most visited directory for the shortest search term typed. jump is written in go. autojump is written in python. zoxide is written in rust. zsh-z is a native zsh port of z.sh","title":"Autojump"},{"location":"shell/intro/#finding-files","text":"nnn is another vi-inspired filemanager for the console, lightweight, written in C. Ranger , vim-inspired filemanager for the console, written in python. Install with pipx install ranger-fm exa is a replacement for ls written in Rust.","title":"Finding files"},{"location":"shell/intro/#directory-content","text":"dust is a rust application printing a similar output to du with additional bar chart.","title":"Directory content"},{"location":"shell/intro/#fuzzy-finder","text":"fzf is a go fuzzy finder Search syntax Token Match type Description sbtrkt fuzzy-match Items that match sbtrkt 'wild exact-match (quoted) Items that include wild ^music prefix-exact-match Items that start with music .mp3$ suffix-exact-match Items that end with .mp3 !fire inverse-exact-match Items that do not include fire !^music inverse-prefix-exact-match Items that do not start with music !.mp3$ inverse-suffix-exact-match Items that do not end with .mp3 fzf provides bindings : Ctrl T paste the selected files and directories onto the command-line Ctrl R paste the selected command from history onto the command-line. A second press on Ctrl R sorts relevant entries in chronological order Alt C cd into the selected directory fuzzy competion is activated with ** , e.g. vim **<TAB> completes all files in the cwd. fzy is written in C","title":"fuzzy finder"},{"location":"shell/intro/#file-content-search","text":"Search can be efficiently performed by the silver search ( ag ) and ripgrep ( rg ) , written resp. in C and rust. rg tends to be one of the quickest. Ripgrep Usage rg [ OPTIONS ] PATTERN [ PATH ... ] rg [ OPTIONS ] [ -e PATTERN ... ] [ -f PATTERNFILE ... ] [ PATH ... ] rg [ OPTIONS ] --files [ PATH ... ] rg [ OPTIONS ] --type-list command | rg [ OPTIONS ] PATTERN --type <TYPE> where <TYPE> is part of the registered types, can be displayed with rg --list-types","title":"File content search"},{"location":"shell/intro/#search-with-substitution","text":"In respect of DOTADIW , rg does not support natively search and replacement. This can be achieved with a pipe. Prepare cookiecutter templates from molecule init outputs rg ROLE --files-with-matches | xargs sed -e \"s/ROLE/\\{\\{ cookiecutter.role_name \\}\\}/g\" Link: https://learnbyexample.github.io/substitution-with-ripgrep/","title":"Search with substitution"},{"location":"shell/intro/#manual-filtering-globs","text":"Exclude path 'pack' from search rg -g '!/pack/**' g:ale","title":"Manual filtering: globs"},{"location":"shell/intro/#working-with-structured-data","text":"","title":"Working with structured data"},{"location":"shell/intro/#json","text":"jq JQ cheatsheet Prepare cookiecutter templates from molecule init outputs bash URL=$(you-get --json \"https://www.youtube.com/watch?v=ZzfHjytDceU\" | jq -s 'sort_by(.streams.__default__.size) | reverse | .[0].streams.__default__.src[0]' | sed -e s/\\\"//g)","title":"JSON"},{"location":"shell/intro/#yaml","text":"yq","title":"YAML"},{"location":"shell/intro/#makefile","text":"","title":"Makefile"},{"location":"shell/intro/#wildcard-characters","text":"* , ? and [...]","title":"Wildcard characters"},{"location":"shell/intro/#automatic-variables","text":"$^ list all the prerequisites of the rule $< list the first prerequisite $? list all the prerequisites newer than the target $@ is the target Splitting Recipe Lines https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html Makefile tutorial https://makefiletutorial.com/ Introduction \u00e0 Makefile https://gl.developpez.com/tutoriel/outil/makefile/","title":"Automatic variables"},{"location":"shell/intro/#workflows","text":"desk makes it easy to flip back and forth between different project contexts in your favorite shell. Change directory, activate a virtualenv or rvm, load in domain-specific aliases, environment variables, functions, arbitrary shell files, all in a single command. direnv augments existing shells with a new feature that can load and unload environment variables depending on the current directory. Modules is a tool that simplify shell initialization and lets users easily modify their environment during the session with modulefiles. zsh-autoenv automatically sources (known/whitelisted) .autoenv.zsh files, handles \"enter\" and leave\" events, nesting, and stashing of variables (overwriting and restoring). asdf manage multiple runtime versions with a single CLI tool, extendable via plugins.","title":"Workflows"},{"location":"shell/intro/#others","text":"nutshell is a new kind of shell, currently under heavy development.","title":"Others"},{"location":"shell/tmux/","text":"tmux \u00b6 Panes \u00b6 Layout \u00b6 Change layout : select-layout has five predefined layouts : even-horizontal , even-vertical , main-horizontal , main-vertical , or tiled . Move panes move-pane [-t dst-pane] Plugins \u00b6 tpm Installation if \"test ! -d ~/.tmux/plugins/tpm\" \\ \"run 'git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm && ~/.tmux/plugins/tpm/bin/install_plugins'\" tpm tpm tpm tpm","title":"tmux"},{"location":"shell/tmux/#tmux","text":"","title":"tmux"},{"location":"shell/tmux/#panes","text":"","title":"Panes"},{"location":"shell/tmux/#layout","text":"Change layout : select-layout has five predefined layouts : even-horizontal , even-vertical , main-horizontal , main-vertical , or tiled . Move panes move-pane [-t dst-pane]","title":"Layout"},{"location":"shell/tmux/#plugins","text":"tpm Installation if \"test ! -d ~/.tmux/plugins/tpm\" \\ \"run 'git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm && ~/.tmux/plugins/tpm/bin/install_plugins'\" tpm tpm tpm tpm","title":"Plugins"},{"location":"shell/version_manager/","text":"Version manager \u00b6 Bash: C:","title":"Version manager"},{"location":"shell/version_manager/#version-manager","text":"Bash: C:","title":"Version manager"},{"location":"shell/zsh/","text":"Zsh \u00b6 The Z-shell Initialisation \u00b6 Shell initilization performs operations depending on the execution context, these operations can be mainly separated on login and interactive property. An short summary can be found at pyenv wiki . Basically: login : e.g. when user logs in to a system with non-graphical interface or via SSH; interactive : shell that has a prompt and whose standard input and error are both connected to terminals. If $ZDOTDIR , $RCS or $GLOABL_RCS are not set, Zsh performs initialiation in the following order: /etc/zsh/zshenv ~/.zshenv login mode: /etc/zsh/zprofile ~/.zprofile interactive: /etc/zsh/zshrc ~/.zshrc login mode: /etc/zsh/login ~/.zlogin .zlogout and /etc/zsh/zshlogout are called when exiting, not when opening. See this post for a complementary information. Readline capability: ZLE \u00b6 Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo . All actions in the editor are performed by widgets . Bindings are affected to keymaps . The current used keymap is main . Initially, there are eight keymaps: emacs EMACS emulation viins vi emulation - insert mode vicmd vi emulation - command mode viopp vi emulation - operator pending visual vi emulation - selection active isearch incremental search mode command read a command name .safe fallback keymap These keymaps can be accessed l Keymap can be created and must be affected to main to be in use: bindkey -N mymap viins bindkey -A mymap main New bindings are affected to the current ( main ) keymap . bindkey -lL shows which keymap is linked to `main'. zle -la list all existing keymap names in the form of bindkey commands to create or link the keymaps. Links an intro on widgets Prompt \u00b6 Prompt sequences undergo a special form of expansion . Some modules make it easier to personalize the prompt. The prompt system must be loaded (performed by extensions): autoload -U promptinit; promptinit . A theme can be applied with the prompt cmd. \u276f prompt <TAB> -- prompt theme -- adam1 bigfade elite fire pure restore zefram adam2 clint elite2 off pws suse bart default fade oliver redhat walters Third party modules: spaceshift is a pure zsh prompt providing VCS integration, language version, job indicator and more. starshift is a port of spaceshift in rust. pure is a lighweight prompt in pure zsh. Parameters \u00b6 Parameters set by the shell Parameter Description ! The process ID of the last command started in the background with &, put into the background with the bg builtin, or spawned with coproc. # The number of positional parameters in decimal. Note that some confusion may occur with the syntax $#param which substitutes the length of param. Use ${#} to resolve ambiguities. In particular, the sequence \u2018$#-...\u2019 in an arithmetic expression is interpreted as the length of the parameter -, q.v. ARGC Same as #. $ The process ID of this shell. Note that this indicates the original shell started by invoking zsh; all processes forked from the shells without executing a new program, such as subshells started by (...), substitute the same value. - Flags supplied to the shell on invocation or by the set or setopt commands. * An array containing the positional parameters. argv Same as *. Assigning to argv changes the local positional parameters, but argv is not itself a local parameter. Deleting argv with unset in any function deletes it everywhere, although only the innermost positional parameter array is deleted (so * and @ in other scopes are not affected). @ Same as argv[@], even when argv is not set. ? The exit status returned by the last command. 0 The name used to invoke the current shell, or as set by the -c command line option upon invocation. If the FUNCTION_ARGZERO option is set, $0 is set upon entry to a shell function to the name of the function, and upon entry to a sourced script to the name of the script, and reset to its previous value when the function or script returns. status Same as ?. pipestatus An array containing the exit statuses returned by all commands in the last pipeline. _ The last argument of the previous command. Also, this parameter is set in the environment of every command executed to the full pathname of the command. CPUTYPE The machine type (microprocessor class or machine model), as determined at run time. EGID The effective group ID of the shell process. If you have sufficient privileges, you may change the effective group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective group ID by \u2018(EGID=gid; command)\u2019 EUID The effective user ID of the shell process. If you have sufficient privileges, you may change the effective user ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective user ID by \u2018(EUID=uid; command)\u2019 ERRNO The value of errno (see man page errno(3)) as set by the most recently failed system call. This value is system dependent and is intended for debugging purposes. It is also useful with the zsh/system module which allows the number to be turned into a name or message. FUNCNEST Integer. If greater than or equal to zero, the maximum nesting depth of shell functions. When it is exceeded, an error is raised at the point where a function is called. The default value is determined when the shell is configured, but is typically 500. Increasing the value increases the danger of a runaway function recursion causing the shell to crash. Setting a negative value turns off the check. GID The real group ID of the shell process. If you have sufficient privileges, you may change the group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different group ID by \u2018(GID=gid; command)\u2019 HISTCMD The current history event number in an interactive shell, in other words the event number for the command that caused $HISTCMD to be read. If the current history event modifies the history, HISTCMD changes to the new maximum history event number. HOST The current hostname. LINENO The line number of the current line within the current script, sourced file, or shell function being executed, whichever was started most recently. Note that in the case of shell functions the line number refers to the function as it appeared in the original definition, not necessarily as displayed by the functions builtin. LOGNAME If the corresponding variable is not set in the environment of the shell, it is initialized to the login name corresponding to the current login session. This parameter is exported by default but this can be disabled using the typeset builtin. The value is set to the string returned by the man page getlogin(3) system call if that is available. MACHTYPE The machine type (microprocessor class or machine model), as determined at compile time. OLDPWD The previous working directory. This is set when the shell initializes and whenever the directory changes. OPTARG The value of the last option argument processed by the getopts command. OPTIND The index of the last option argument processed by the getopts command. OSTYPE The operating system, as determined at compile time. PPID The process ID of the parent of the shell. PWD The present working directory. This is set when the shell initializes and whenever the directory changes. RANDOM A pseudo-random integer from 0 to 32767. SECONDS The number of seconds since shell invocation. SHLVL Incremented by one each time a new shell is started. signals An array containing the names of the signals. TRY_BLOCK_ERROR In an always block, indicates whether the preceding list of code caused an error. The value is 1 to indicate an error, 0 otherwise. It may be reset, clearing the error condition. See Complex Commands TRY_BLOCK_INTERRUPT This variable works in a similar way to TRY_BLOCK_ERROR , but represents the status of an interrupt from the signal SIGINT, which typically comes from the keyboard when the user types ^C. If set to 0, any such interrupt will be reset; otherwise, the interrupt is propagated after the always block. TTY The name of the tty associated with the shell, if any. TTYIDLE The idle time of the tty associated with the shell in seconds or -1 if there is no such tty. UID <S> The real user ID of the shell process. USERNAME The username corresponding to the real user ID of the shell process. If you have sufficient privileges, you may change the username (and also the user ID and group ID) of the shell by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different username (and user ID and group ID) by \u2018(USERNAME=username; command)\u2019 VENDOR The vendor, as determined at compile time. zsh_eval_context ( ZSH_EVAL_CONTEXT ) An array (colon-separated list) indicating the context of shell code that is being run. See documentation for details. ZSH_ARGZERO If zsh was invoked to run a script, this is the name of the script. Otherwise, it is the name used to invoke the current shell. This is the same as the value of $0 when the POSIX_ARGZERO option is set, but is always available. ZSH_EXECUTION_STRING If the shell was started with the option -c, this contains the argument passed to the option. Otherwise it is not set. ZSH_NAME Expands to the basename of the command used to invoke this instance of zsh. ZSH_PATCHLEVEL The output of \u2018git describe \u2013tags \u2013long\u2019 for the zsh repository used to build the shell. This is most useful in order to keep track of versions of the shell during development between releases; hence most users should not use it and should instead rely on $ZSH_VERSION. zsh_scheduled_events See The zsh/sched Module. ZSH_SCRIPT If zsh was invoked to run a script, this is the name of the script, otherwise it is unset. ZSH_SUBSHELL Readonly integer. Initially zero, incremented each time the shell forks to create a subshell for executing code. Hence \u2018(print $ZSH_SUBSHELL)\u2019 and \u2018print $(print $ZSH_SUBSHELL)\u2019 output 1, while \u2018( (print $ZSH_SUBSHELL) )\u2019 outputs 2. ZSH_VERSION The version number of the release of zsh. Data structures \u00b6 Associative arrays \u00b6 Declared with declare -A <ARRAY> or typeset -A <ARRAY> Associative arrays can not be nested Functions \u00b6 Hook functions \u00b6 It is possible to define an array that has the same name as the function with _functions appended. Any element in such an array is taken as the name of a function to execute; it is executed in the same context and with the same arguments as the basic function. Example \u276f echo $precmd_functions _zsh_autosuggest_start _zsh_highlight_main__precmd_hook _zshz_precmd prompt_pure_precmd # Show the definition of a function: # it is possible to use `which` or nearly identical to bash `type -f` \u276f whence -f _zsh_autosuggest_start chpwd : executed whenever the current working directory is changed. periodic : if the parameter PERIOD is set, this function is executed every $PERIOD seconds, just before a prompt. precmd : executed before each prompt. preexec : executed just after a command has been read and is about to be executed. zshaddhistory : executed when a history line has been read interactively, but before it is executed. zshexit : executed at the point where the main shell is about to exit normally. Display user configuration of hooks functions Expansion \u00b6 This section is a cheatsheet on expansion, based on the manual and reads, especially this blog post . The examples hereunder are taken from the latest and to be run, interactive comments must be enabled in zsh ( setopt interactive_comments ). The following types of expansions are performed in the indicated order in five steps: History Expansion is performed only in interactive shells. Alias Expansion Aliases are expanded immediately. Process Substitution , Parameter Expansion , Command Substitution , Arithmetic Expansion , Brace Expansion These five are performed in left-to-right fashion. On each argument, any of the five steps that are needed are performed one after the other. Hence, for example, all the parts of parameter expansion are completed before command substitution is started. After these expansions, all unquoted occurrences of the characters \u2018\\\u2019,\u2018\u2019\u2019 and \u2018\"\u2019 are removed. Filename Expansion If the SH_FILE_EXPANSION option is set, the order of expansion is modified for compatibility with sh and ksh: filename expansion is performed immediately after alias expansion. Filename Generation , commonly referred to as globbing, always done last. Filename generation (globbing) \u00b6 glob operators * matches any string, including the null string. ? matches any character. [...] matches any of the enclosed characters: ranges of characters can be specified by separating two characters by a - or classes as [:alnum:] , [:alpha:] , [:ascii:] , ..., [:xdigit:] ! or ^ negates the class <[x]-[y]> matches any number in the range x to y, inclusive. (...) matches the enclosed pattern. x|y matches either x or y. ^x matches anything except the pattern x. Requires EXTENDED_GLOB to be set. x~y match anything that matches the pattern x but does not match y. Requires EXTENDED_GLOB to be set. x# Matches zero or more occurrences of the pattern x. Requires EXTENDED_GLOB to be set. x## Matches one or more occurrences of the pattern x. Requires EXTENDED_GLOB to be set. The precedence of the operators given above is (highest) \u2018^\u2019, \u2018/\u2019, \u2018~\u2019, \u2018|\u2019 (lowest) # list text files that end in a number from 1 to 10 \u276f ls -l zsh_demo/**/*< 1 -10>.txt # list text files that start with the letter a \u276f ls -l zsh_demo/**/ [ a ] *.txt # list text files that start with either ab or bc \u276f ls -l zsh_demo/**/ ( ab | bc ) *.txt # list text files that don't start with a lower or uppercase c \u276f ls -l zsh_demo/**/ [ ^cC ] *.txt # Remove all but go.mod \u276f setopt extended_glob \u276f rm -Rf -- ^go.mod glob flag i case insensitive. l lower case characters in the pattern match upper or lower case characters. Upper case characters behvior unchanged. I case sensitive: locally negates the effect of i or l from that point on. ... glob qualifiers Furthers qualifiers Qualifiers Scope / directories F \u2018full\u2019 (i.e. non-empty) directories. . plain files @ symbolic links = sockets p named pipes (FIFOs) * executable plain files (0100 or 0010 or 0001) % device files (character or block special) %b block special files %c character special files r owner-readable files (0400) w owner-writable files (0200) x owner-executable files (0100) A group-readable files (0040) I group-writable files (0020) E group-executable files (0010) R world-readable files (0004) W world-writable files (0002) X world-executable files (0001) s setuid files (04000) S setgid files (02000) t files with the sticky bit (01000) fspec files with access rights matching spec. estring +cmd The string will be executed as shell code. ddev files on the device dev l[-|+]ct files having a link count less than ct (-), greater than ct (+), or equal to ct U files owned by the effective user ID G files owned by the effective group ID uid files owned by user ID id if that is a number. gid like uid but with group IDs or names a[Mwhms][-|+]n files accessed exactly n days ago. m[Mwhms][-|+]n like the file access qualifier, except that it uses the file modification time. c[Mwhms][-|+]n like the file access qualifier, except that it uses the file inode change time. L[+|-]n files less than n bytes (-), more than n bytes (+), or exactly n bytes in length. ^ negates all qualifiers following it - toggles between making the qualifiers work on symbolic links (the default) and the files they point to M sets the MARK_DIRS option for the current pattern T appends a trailing qualifier mark to the filenames, analogous to the LIST_TYPES option, for the current pattern (overrides M) N sets the NULL_GLOB option for the current pattern D sets the GLOB_DOTS option for the current pattern n sets the NUMERIC_GLOB_SORT option for the current pattern Yn enables short-circuit mode: the pattern will expand to at most n filenames. # show only directories \u276f print -l zsh_demo/**/* ( / ) # because the expression is expanded, # can be used with editors, e.g. vim # will open a lot of files (36) \u276f vim zsh_demo/**/* ( . ) # show empty files \u276f ls -l zsh_demo/**/* ( L0 ) # show files greater than 3 KB \u276f ls -l zsh_demo/**/* ( Lk+3 ) # show files modified in the last hour \u276f print -l zsh_demo/**/* ( mh-1 ) # sort files from most to least recently modified and show the last 3 \u276f ls -l zsh_demo/**/* ( om [ 1 ,3 ]) # keep it simple \u276f ls -l zsh_demo/**/* ( .Lm-2mh-1om [ 1 ,3 ]) Completion \u00b6 Initialization \u00b6 # menu-select widget, part of the zsh/complist module # must be loaded before the call to compinit zmodload -i zsh/complist # Use modern completion system autoload -U compinit compinit Behind the hood Completion is provided by files named as the command name prefixed by an underscore: _cmd contains the completion logic for cmd . The location of this file must be in $fpath . Addition of a path can be done with fpath+=<PATH TO COMPLETION FILE> . When compinit is run, the first line of accessible files in $fpath is read. Those containing one of the tags #compdef or #autoload will be autoloaded. The declaration can be done for multiple commands, function aliases can be referenced too, e.g. slogin to ssh hereunder: #compdef ssh slogin=ssh scp ssh-add ssh-agent ssh-copy-id ssh-keygen ssh-keyscan sftp As an alternative, compdef may be called directly Configuration \u00b6 \ud83d\udd17 User defined completion \u00b6 Some utility functions Sources: zsh-completion how to: \ud83d\udd17 Modules \u00b6 Modules are loaded with zmodload ZSH modules ZSH modules are loaded with the prefix zsh/ , e.g. for net/tcl \u276f zmodload zsh/net/tcp Modules Description attr Builtins for manipulating extended attributes (xattr). cap Builtins for manipulating POSIX.1e (POSIX.6) capability (privilege) sets. clone A builtin that can clone a running shell onto another terminal. compctl The compctl builtin for controlling completion. complete The basic completion code. complist Completion listing extensions. computil A module with utility builtins needed for the shell function based completion system. curses curses windowing commands datetime Some date/time commands and parameters. deltochar A ZLE function duplicating EMACS' zap-to-char. example An example of how to write a module. files Some basic file manipulation commands as builtins. mapfile Access to external files via a special associative array. mathfunc Standard scientific functions for use in mathematical evaluations. net/socket Manipulation of Unix domain sockets net/tcp Manipulation of TCP sockets newuser Arrange for files for new users to be installed. parameter Access to internal hash tables via special associative arrays. pcre Interface to the PCRE library. regex Interface to the POSIX regex library. sched A builtin that provides a timed execution facility within the shell. stat A builtin command interface to the stat system call. system A builtin interface to various low-level system features. termcap Interface to the termcap database. terminfo Interface to the terminfo database. zftp A builtin FTP client. zle The Zsh Line Editor, including the bindkey and vared builtins. zleparameter Access to internals of the Zsh Line Editor via parameters. zprof A module allowing profiling for shell functions. zpty A builtin for starting a command in a pseudo-terminal. zselect Block and return when file descriptors are ready. zutil Some utility builtins, e.g. the one for supporting configuration via styles. zsh/zutil \u00b6 The zsh/zutil module adds some builtins: zstyle is used to define and lookup styles. zformat provides two different forms of formatting. zregexparse implements some internals of the _regex_arguments function zparseopts simplifies the parsing of options in positional parameters zsh/net/tcp \u00b6 # list all open file descriptors ($$ refers to the current process) \u276f ls -la /proc/ $$ /fd \u276f ztcp File descriptors Wikipedia: \ud83d\udd17 Send to stdout of the current terminal echo \"hello\" >> /proc/ $$ /fd/2 Plugins \u00b6 zsh-z Jump quickly to directories that you have visited \"frecently.\" zsh-autosuggestions Fish-like autosuggestions for zsh Other links \u00b6 Adding Vi to your Zsh Moving to Zsh Introduction \u00e0 la programmation parall\u00e8le avec Open MPI et Open MP: \ud83d\udd17","title":"zsh"},{"location":"shell/zsh/#zsh","text":"The Z-shell","title":"Zsh"},{"location":"shell/zsh/#initialisation","text":"Shell initilization performs operations depending on the execution context, these operations can be mainly separated on login and interactive property. An short summary can be found at pyenv wiki . Basically: login : e.g. when user logs in to a system with non-graphical interface or via SSH; interactive : shell that has a prompt and whose standard input and error are both connected to terminals. If $ZDOTDIR , $RCS or $GLOABL_RCS are not set, Zsh performs initialiation in the following order: /etc/zsh/zshenv ~/.zshenv login mode: /etc/zsh/zprofile ~/.zprofile interactive: /etc/zsh/zshrc ~/.zshrc login mode: /etc/zsh/login ~/.zlogin .zlogout and /etc/zsh/zshlogout are called when exiting, not when opening. See this post for a complementary information.","title":"Initialisation"},{"location":"shell/zsh/#readline-capability-zle","text":"Zsh does not use readline, instead uses an own development Zsh Line Editor (ZLE) . Keybindings in inputrc are not read, rely instead on an internal command bindkey that can be coupled to terminfo . All actions in the editor are performed by widgets . Bindings are affected to keymaps . The current used keymap is main . Initially, there are eight keymaps: emacs EMACS emulation viins vi emulation - insert mode vicmd vi emulation - command mode viopp vi emulation - operator pending visual vi emulation - selection active isearch incremental search mode command read a command name .safe fallback keymap These keymaps can be accessed l Keymap can be created and must be affected to main to be in use: bindkey -N mymap viins bindkey -A mymap main New bindings are affected to the current ( main ) keymap . bindkey -lL shows which keymap is linked to `main'. zle -la list all existing keymap names in the form of bindkey commands to create or link the keymaps. Links an intro on widgets","title":"Readline capability: ZLE"},{"location":"shell/zsh/#prompt","text":"Prompt sequences undergo a special form of expansion . Some modules make it easier to personalize the prompt. The prompt system must be loaded (performed by extensions): autoload -U promptinit; promptinit . A theme can be applied with the prompt cmd. \u276f prompt <TAB> -- prompt theme -- adam1 bigfade elite fire pure restore zefram adam2 clint elite2 off pws suse bart default fade oliver redhat walters Third party modules: spaceshift is a pure zsh prompt providing VCS integration, language version, job indicator and more. starshift is a port of spaceshift in rust. pure is a lighweight prompt in pure zsh.","title":"Prompt"},{"location":"shell/zsh/#parameters","text":"Parameters set by the shell Parameter Description ! The process ID of the last command started in the background with &, put into the background with the bg builtin, or spawned with coproc. # The number of positional parameters in decimal. Note that some confusion may occur with the syntax $#param which substitutes the length of param. Use ${#} to resolve ambiguities. In particular, the sequence \u2018$#-...\u2019 in an arithmetic expression is interpreted as the length of the parameter -, q.v. ARGC Same as #. $ The process ID of this shell. Note that this indicates the original shell started by invoking zsh; all processes forked from the shells without executing a new program, such as subshells started by (...), substitute the same value. - Flags supplied to the shell on invocation or by the set or setopt commands. * An array containing the positional parameters. argv Same as *. Assigning to argv changes the local positional parameters, but argv is not itself a local parameter. Deleting argv with unset in any function deletes it everywhere, although only the innermost positional parameter array is deleted (so * and @ in other scopes are not affected). @ Same as argv[@], even when argv is not set. ? The exit status returned by the last command. 0 The name used to invoke the current shell, or as set by the -c command line option upon invocation. If the FUNCTION_ARGZERO option is set, $0 is set upon entry to a shell function to the name of the function, and upon entry to a sourced script to the name of the script, and reset to its previous value when the function or script returns. status Same as ?. pipestatus An array containing the exit statuses returned by all commands in the last pipeline. _ The last argument of the previous command. Also, this parameter is set in the environment of every command executed to the full pathname of the command. CPUTYPE The machine type (microprocessor class or machine model), as determined at run time. EGID The effective group ID of the shell process. If you have sufficient privileges, you may change the effective group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective group ID by \u2018(EGID=gid; command)\u2019 EUID The effective user ID of the shell process. If you have sufficient privileges, you may change the effective user ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command with a different effective user ID by \u2018(EUID=uid; command)\u2019 ERRNO The value of errno (see man page errno(3)) as set by the most recently failed system call. This value is system dependent and is intended for debugging purposes. It is also useful with the zsh/system module which allows the number to be turned into a name or message. FUNCNEST Integer. If greater than or equal to zero, the maximum nesting depth of shell functions. When it is exceeded, an error is raised at the point where a function is called. The default value is determined when the shell is configured, but is typically 500. Increasing the value increases the danger of a runaway function recursion causing the shell to crash. Setting a negative value turns off the check. GID The real group ID of the shell process. If you have sufficient privileges, you may change the group ID of the shell process by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different group ID by \u2018(GID=gid; command)\u2019 HISTCMD The current history event number in an interactive shell, in other words the event number for the command that caused $HISTCMD to be read. If the current history event modifies the history, HISTCMD changes to the new maximum history event number. HOST The current hostname. LINENO The line number of the current line within the current script, sourced file, or shell function being executed, whichever was started most recently. Note that in the case of shell functions the line number refers to the function as it appeared in the original definition, not necessarily as displayed by the functions builtin. LOGNAME If the corresponding variable is not set in the environment of the shell, it is initialized to the login name corresponding to the current login session. This parameter is exported by default but this can be disabled using the typeset builtin. The value is set to the string returned by the man page getlogin(3) system call if that is available. MACHTYPE The machine type (microprocessor class or machine model), as determined at compile time. OLDPWD The previous working directory. This is set when the shell initializes and whenever the directory changes. OPTARG The value of the last option argument processed by the getopts command. OPTIND The index of the last option argument processed by the getopts command. OSTYPE The operating system, as determined at compile time. PPID The process ID of the parent of the shell. PWD The present working directory. This is set when the shell initializes and whenever the directory changes. RANDOM A pseudo-random integer from 0 to 32767. SECONDS The number of seconds since shell invocation. SHLVL Incremented by one each time a new shell is started. signals An array containing the names of the signals. TRY_BLOCK_ERROR In an always block, indicates whether the preceding list of code caused an error. The value is 1 to indicate an error, 0 otherwise. It may be reset, clearing the error condition. See Complex Commands TRY_BLOCK_INTERRUPT This variable works in a similar way to TRY_BLOCK_ERROR , but represents the status of an interrupt from the signal SIGINT, which typically comes from the keyboard when the user types ^C. If set to 0, any such interrupt will be reset; otherwise, the interrupt is propagated after the always block. TTY The name of the tty associated with the shell, if any. TTYIDLE The idle time of the tty associated with the shell in seconds or -1 if there is no such tty. UID <S> The real user ID of the shell process. USERNAME The username corresponding to the real user ID of the shell process. If you have sufficient privileges, you may change the username (and also the user ID and group ID) of the shell by assigning to this parameter. Also (assuming sufficient privileges), you may start a single command under a different username (and user ID and group ID) by \u2018(USERNAME=username; command)\u2019 VENDOR The vendor, as determined at compile time. zsh_eval_context ( ZSH_EVAL_CONTEXT ) An array (colon-separated list) indicating the context of shell code that is being run. See documentation for details. ZSH_ARGZERO If zsh was invoked to run a script, this is the name of the script. Otherwise, it is the name used to invoke the current shell. This is the same as the value of $0 when the POSIX_ARGZERO option is set, but is always available. ZSH_EXECUTION_STRING If the shell was started with the option -c, this contains the argument passed to the option. Otherwise it is not set. ZSH_NAME Expands to the basename of the command used to invoke this instance of zsh. ZSH_PATCHLEVEL The output of \u2018git describe \u2013tags \u2013long\u2019 for the zsh repository used to build the shell. This is most useful in order to keep track of versions of the shell during development between releases; hence most users should not use it and should instead rely on $ZSH_VERSION. zsh_scheduled_events See The zsh/sched Module. ZSH_SCRIPT If zsh was invoked to run a script, this is the name of the script, otherwise it is unset. ZSH_SUBSHELL Readonly integer. Initially zero, incremented each time the shell forks to create a subshell for executing code. Hence \u2018(print $ZSH_SUBSHELL)\u2019 and \u2018print $(print $ZSH_SUBSHELL)\u2019 output 1, while \u2018( (print $ZSH_SUBSHELL) )\u2019 outputs 2. ZSH_VERSION The version number of the release of zsh.","title":"Parameters"},{"location":"shell/zsh/#data-structures","text":"","title":"Data structures"},{"location":"shell/zsh/#associative-arrays","text":"Declared with declare -A <ARRAY> or typeset -A <ARRAY> Associative arrays can not be nested","title":"Associative arrays"},{"location":"shell/zsh/#functions","text":"","title":"Functions"},{"location":"shell/zsh/#hook-functions","text":"It is possible to define an array that has the same name as the function with _functions appended. Any element in such an array is taken as the name of a function to execute; it is executed in the same context and with the same arguments as the basic function. Example \u276f echo $precmd_functions _zsh_autosuggest_start _zsh_highlight_main__precmd_hook _zshz_precmd prompt_pure_precmd # Show the definition of a function: # it is possible to use `which` or nearly identical to bash `type -f` \u276f whence -f _zsh_autosuggest_start chpwd : executed whenever the current working directory is changed. periodic : if the parameter PERIOD is set, this function is executed every $PERIOD seconds, just before a prompt. precmd : executed before each prompt. preexec : executed just after a command has been read and is about to be executed. zshaddhistory : executed when a history line has been read interactively, but before it is executed. zshexit : executed at the point where the main shell is about to exit normally. Display user configuration of hooks functions","title":"Hook functions "},{"location":"shell/zsh/#expansion","text":"This section is a cheatsheet on expansion, based on the manual and reads, especially this blog post . The examples hereunder are taken from the latest and to be run, interactive comments must be enabled in zsh ( setopt interactive_comments ). The following types of expansions are performed in the indicated order in five steps: History Expansion is performed only in interactive shells. Alias Expansion Aliases are expanded immediately. Process Substitution , Parameter Expansion , Command Substitution , Arithmetic Expansion , Brace Expansion These five are performed in left-to-right fashion. On each argument, any of the five steps that are needed are performed one after the other. Hence, for example, all the parts of parameter expansion are completed before command substitution is started. After these expansions, all unquoted occurrences of the characters \u2018\\\u2019,\u2018\u2019\u2019 and \u2018\"\u2019 are removed. Filename Expansion If the SH_FILE_EXPANSION option is set, the order of expansion is modified for compatibility with sh and ksh: filename expansion is performed immediately after alias expansion. Filename Generation , commonly referred to as globbing, always done last.","title":"Expansion"},{"location":"shell/zsh/#filename-generation-globbing","text":"","title":"Filename generation (globbing)"},{"location":"shell/zsh/#completion","text":"","title":"Completion"},{"location":"shell/zsh/#initialization","text":"# menu-select widget, part of the zsh/complist module # must be loaded before the call to compinit zmodload -i zsh/complist # Use modern completion system autoload -U compinit compinit","title":"Initialization"},{"location":"shell/zsh/#configuration","text":"\ud83d\udd17","title":"Configuration"},{"location":"shell/zsh/#user-defined-completion","text":"Some utility functions","title":"User defined completion"},{"location":"shell/zsh/#modules","text":"Modules are loaded with zmodload ZSH modules ZSH modules are loaded with the prefix zsh/ , e.g. for net/tcl \u276f zmodload zsh/net/tcp Modules Description attr Builtins for manipulating extended attributes (xattr). cap Builtins for manipulating POSIX.1e (POSIX.6) capability (privilege) sets. clone A builtin that can clone a running shell onto another terminal. compctl The compctl builtin for controlling completion. complete The basic completion code. complist Completion listing extensions. computil A module with utility builtins needed for the shell function based completion system. curses curses windowing commands datetime Some date/time commands and parameters. deltochar A ZLE function duplicating EMACS' zap-to-char. example An example of how to write a module. files Some basic file manipulation commands as builtins. mapfile Access to external files via a special associative array. mathfunc Standard scientific functions for use in mathematical evaluations. net/socket Manipulation of Unix domain sockets net/tcp Manipulation of TCP sockets newuser Arrange for files for new users to be installed. parameter Access to internal hash tables via special associative arrays. pcre Interface to the PCRE library. regex Interface to the POSIX regex library. sched A builtin that provides a timed execution facility within the shell. stat A builtin command interface to the stat system call. system A builtin interface to various low-level system features. termcap Interface to the termcap database. terminfo Interface to the terminfo database. zftp A builtin FTP client. zle The Zsh Line Editor, including the bindkey and vared builtins. zleparameter Access to internals of the Zsh Line Editor via parameters. zprof A module allowing profiling for shell functions. zpty A builtin for starting a command in a pseudo-terminal. zselect Block and return when file descriptors are ready. zutil Some utility builtins, e.g. the one for supporting configuration via styles.","title":"Modules"},{"location":"shell/zsh/#zshzutil","text":"The zsh/zutil module adds some builtins: zstyle is used to define and lookup styles. zformat provides two different forms of formatting. zregexparse implements some internals of the _regex_arguments function zparseopts simplifies the parsing of options in positional parameters","title":"zsh/zutil"},{"location":"shell/zsh/#zshnettcp","text":"# list all open file descriptors ($$ refers to the current process) \u276f ls -la /proc/ $$ /fd \u276f ztcp File descriptors Wikipedia: \ud83d\udd17 Send to stdout of the current terminal echo \"hello\" >> /proc/ $$ /fd/2","title":"zsh/net/tcp"},{"location":"shell/zsh/#plugins","text":"zsh-z Jump quickly to directories that you have visited \"frecently.\" zsh-autosuggestions Fish-like autosuggestions for zsh","title":"Plugins"},{"location":"shell/zsh/#other-links","text":"Adding Vi to your Zsh Moving to Zsh Introduction \u00e0 la programmation parall\u00e8le avec Open MPI et Open MP: \ud83d\udd17","title":"Other links"},{"location":"shell/Ubuntu/configuration/","text":"Configuration \u00b6 Environment variables \u00b6 https://help.ubuntu.com/community/EnvironmentVariables LVM \u00b6 https://doc.ubuntu-fr.org/lvm Partitioning: https://www.cyberciti.biz/tips/fdisk-unable-to-create-partition-greater-2tb.html Touchpad \u00b6 libinput \u00b6 See https://wayland.freedesktop.org/libinput/doc/latest/index.html libinput-gesture fusuma","title":"Configuration"},{"location":"shell/Ubuntu/configuration/#configuration","text":"","title":"Configuration"},{"location":"shell/Ubuntu/configuration/#environment-variables","text":"https://help.ubuntu.com/community/EnvironmentVariables","title":"Environment variables"},{"location":"shell/Ubuntu/configuration/#lvm","text":"https://doc.ubuntu-fr.org/lvm Partitioning: https://www.cyberciti.biz/tips/fdisk-unable-to-create-partition-greater-2tb.html","title":"LVM"},{"location":"shell/Ubuntu/configuration/#touchpad","text":"","title":"Touchpad"},{"location":"shell/Ubuntu/configuration/#libinput","text":"See https://wayland.freedesktop.org/libinput/doc/latest/index.html libinput-gesture fusuma","title":"libinput"},{"location":"sw_dvpt/git/","text":"GIT \u00b6 Configuration \u00b6 The configuration is made out of four files : $(prefix)/etc/gitconfig $XDG_CONFIG_HOME/git/config ~/.gitconfig $GIT_DIR/config Add credential cache (timed out daemon) when not using ssh authentication: git config --global credential.helper cache # Set the timeout to 300s instead 900s (defaut) git config --global credential.helper 'cache --timeout=300' # To explicitly exits the daemon git credential-cache exit Revision selection \u00b6 Individual commit selection \u00b6 SHA1 selection Git allows selection of a single commit by its full 40 char. SHA1-hash. git log <OPTIONS> to display and locate commits. Ouptut format can be heavily customized. git reflog show local editions git show <COMMIT> to inspect a specific commit, for reflog specific entries, @{<n>} can be used to display history, e.g. git show HEAD@{5} will show the fifth entry of your reflog git rev-parse <OPTIONS> , belonging to plumbing tools can be used to investigate revisons at a lower lever Ancestry selection An ancestry can be selected by adding a ^ (caret) at the end of a reference, e.g. HEAD^ to select the element's parent. Several carets can be used to select the parent in direct line or ~ (tilde). A parent sibling branch is selected by using a number next to the caret. Range selection \u00b6 Double dot Enable to see commits between two history points that can be on different branches, e.g.: # Show what is beeing pulled (what's between HEAD and origin/master) git log --pretty = oneline -n 10 HEAD..origin/master # Show a branch history (master to parent's commit o new_branch) git log master..new_branch^ Exclude reachable commit \u00b6 This can be done with ^ before the commit or branch or by using thee --not syntax. e.g. to see all commits reachable from refA and refB but not refC : # Usage are equivalent git log revA revB ^revC git log revA revB --not revC # Usage are equivalent git log revA..revB git log ^revA revB git log rebB --not revA Mutualy exclution: triple dot \u00b6 Specify commits that are reachabel either by both references Examples \u00b6 Loeliger notation G H I J \\ / \\ / D E F \\ | / \\ \\ | / | \\|/ | B C \\ / \\ / A Ancestry selection G H I J | A = = A^0 \\ / \\ / | B = A^ = A^1 = A~1 D E F | C = A^2 = A^2 \\ | / \\ | D = A^^ = A^1^1 = A~2 \\ | / | | E = B^2 = A^^2 \\|/ | | F = B^3 = A^^3 B C | G = A^^^ = A^1^1^1 = A~3 \\ / | H = D^2 = B^^2 = A^^^2 = A~2^2 \\ / | I = F^ = B^3^ = A^^3^ A | J = F^2 = B^3^2 = A^^3^2 Extended selection G H I J | Args | Expanded arguments | Selected commits \\ / \\ / | ----------|----------------------|------------------ D E F | D | | G H D \\ | / \\ | D F | | G H I J D F \\ | / | | ^G D | | H D \\|/ | | ^D B | | E I J F B B C | ^D B C | | E I J F B C \\ / | C | | I J F C \\ / | B..C | = ^B C | C A | B...C | = B ^F C | G H D E B C | B^- | = B^..B | | | = ^B^1 B | E I J F B | C^@ | = C^1 | | | = F | I J F | B^@ | = B^1 B^2 B^3 | | | = D E F | D G H E F I J | C^! | = C ^C^@ | | | = C ^C^1 | | | = C ^F | C | B^! | = B ^B^@ | | | = B ^B^1 ^B^2 ^B^3 | | | = B ^D ^E ^F | B | F^! D | = F ^I ^J D | G H D F Submodules \u00b6 Commands \u00b6 status prints the SHA1 status of checked submodules. Prefixed with: - if the submodule is not initialized + in case of conflicts between current subdmodule and the index of the containing directory U in case of merge conflicts Remove a submodule \u00b6 A submodule can be deleted by running git rm <submodule path> && git commit . $GIT_DIR/modules/<name> delete the submodule completly. Util then, deletion can be undone using git revert . Alternative method: Remove the submodule entry from .git/config git submodule deinit -f path/to/submodule Remove the submodule directory from the superproject's .git/modules directory rm -rf .git/modules/path/to/submodule Commit the changes git commit-m \"Removed submodule \" Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule git rm -f path/to/submodule Updating submodule url and branch \u00b6 The submodule configuration can be displayed with git config : git config -l A specific config file can be given to git config with the --file flag : git config -l --file=.gitmodules Url, branch and other parameters can be configured via git config git config --file=.gitmodules submodule.<submodule_name>.url <git@github.com:username/repository.git> git config --file=.gitmodules submodule.<submodule_name>.branch <branch_name> Synchronization adn update of the submodules are done with: git submodule sync git submodule update --init --recursive --remote --merge # ! If --merge option is missing, HEAD will be detached Tags \u00b6 Get the most recent tag: git describe --tags --abbrev=0 Hooks \u00b6 Hooks are executable scripts, generaly located in .git/hooks . They can be devided into two groups: client-side server-side Client side \u00b6 Hook Run description post-checkout after a successful git checkout pre-commit before commiting message, general checks like linting prepare-commit-msg before the commit message editor is fired up but after the default message is created, good for commits where the default message is auto-generated commit-msg validate project state or commit message pre-rebase before you rebase anything pre-push during git push , after the remote refs have been updated but before any objects have been transferred post-rewrite triggered by commands that replace commits, such as git commit --amend and git rebase post-merge after a successful merge command post-commit once eveything coompleted. There are other hooks, invoked by specific commands: pre-auto-gc by invoking garbage collection git gc --auto applypatch-msg , pre-applypatch and post-applypatch all invoked by git am for an email-based workflow. Server side \u00b6 Hook Run description pre-receive first script to run when handling a push from a client. Runs only once. post-receive run once for each branch the pusher is trying to update update after the entire process is completed and can be used to update other services or notify users Installation must be performed on the server, see e.g. for gitlab . If no admin rights are available, some alternatives: webhooks github / gitlab CI/CD pipeline github gitlab push rules gitlab Cherry pick from another repository \u00b6 First the other repository source must be added to the remote list git remote add other https://other.url/repository.git git fetch other Then use git cherry-pick Others \u00b6 conform is a tool for enforcing policies on your build pipelines. Conventional commits Conventional Commits 1.0.0 \u00b6 Summary \u00b6 The Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of. This convention dovetails with SemVer , by describing the features, fixes, and breaking changes made in commit messages. The commit message should be structured as follows: <type>[optional scope]: <description> [optional body] [optional footer(s)] \u00b6 The commit contains the following structural elements, to communicate intent to the consumers of your library: fix: a commit of the type fix patches a bug in your codebase (this correlates with PATCH in semantic versioning). feat: a commit of the type feat introduces a new feature to the codebase (this correlates with MINOR in semantic versioning). BREAKING CHANGE: a commit that has a footer BREAKING CHANGE: , or appends a ! after the type/scope, introduces a breaking API change (correlating with MAJOR in semantic versioning). A BREAKING CHANGE can be part of commits of any type . types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the the Angular convention ) recommends build: , chore: , ci: , docs: , style: , refactor: , perf: , test: , and others. footers other than BREAKING CHANGE: <description> may be provided and follow a convention similar to git trailer format . Additional types are not mandated by the Conventional Commits specification, and have no implicit effect in semantic versioning (unless they include a BREAKING CHANGE). A scope may be provided to a commit's type, to provide additional contextual information and is contained within parenthesis, e.g., feat(parser): add ability to parse arrays . Examples \u00b6 Commit message with description and breaking change footer \u00b6 feat: allow provided config object to extend other configs BREAKING CHANGE: `extends` key in config file is now used for extending other config files Commit message with ! to draw attention to breaking change \u00b6 refactor!: drop support for Node 6 Commit message with both ! and BREAKING CHANGE footer \u00b6 refactor!: drop support for Node 6 BREAKING CHANGE: refactor to use JavaScript features not available in Node 6. Commit message with no body \u00b6 docs: correct spelling of CHANGELOG Commit message with scope \u00b6 feat(lang): add polish language Commit message with multi-paragraph body and multiple footers \u00b6 fix: correct minor typos in code see the issue for details on typos fixed. Reviewed-by: Z Refs #133 Specification \u00b6 The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 . Commits MUST be prefixed with a type, which consists of a noun, feat , fix , etc., followed by the OPTIONAL scope, OPTIONAL ! , and REQUIRED terminal colon and space. The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MAY be provided after a type. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): A description MUST immediately follow the colon and space after the type/scope prefix. The description is a short summary of the code changes, e.g., fix: array parsing issue when multiple spaces were contained in string . A longer commit body MAY be provided after the short description, providing additional contextual information about the code changes. The body MUST begin one blank line after the description. A commit body is free-form and MAY consist of any number of newline separated paragraphs. One or more footers MAY be provided one blank line after the body. Each footer MUST consist of a word token, followed by either a :<space> or <space># separator, followed by a string value (this is inspired by the git trailer convention ). A footer's token MUST use - in place of whitespace characters, e.g., Acked-by (this helps differentiate the footer section from a multi-paragraph body). An exception is made for BREAKING CHANGE , which MAY also be used as a token. A footer's value MAY contain spaces and newlines, and parsing MUST terminate when the next valid footer token/separator pair is observed. Breaking changes MUST be indicated in the type/scope prefix of a commit, or as an entry in the footer. If included as a footer, a breaking change MUST consist of the uppercase text BREAKING CHANGE, followed by a colon, space, and description, e.g., BREAKING CHANGE: environment variables now take precedence over config files . If included in the type/scope prefix, breaking changes MUST be indicated by a ! immediately before the : . If ! is used, BREAKING CHANGE: MAY be omitted from the footer section, and the commit description SHALL be used to describe the breaking change. Types other than feat and fix MAY be used in your commit messages, e.g., docs: updated ref docs. The units of information that make up Conventional Commits MUST NOT be treated as case sensitive by implementors, with the exception of BREAKING CHANGE which MUST be uppercase. BREAKING-CHANGE MUST be synonymous with BREAKING CHANGE, when used as a token in a footer. ghq provides a way to organize remote repository clones, like go get does. Git flow \u00b6 From Scott Chacon blog : To work on something new, create a descriptively named branch off of master Commit to that branch locally and regularly push your work to the same named branch on the server When you need feedback or help, or you think the branch is ready for merging, open a pull request After someone else has reviewed and signed off on the feature, you can merge it into master Pull request \u00b6 https://github.blog/2015-01-21-how-to-write-the-perfect-pull-request/ https://stackoverflow.com/questions/14680711 https://stackoverflow.com/questions/29049650 Switch branches or restore working tree files git checkout master git checkout -b mybranch git remote manage the set of repositories (\"remotes\") whose branches you track. git remote -v # If upstream is not configured, add the upstream route git remote add upstream /url/original/repo git fetch upstream # reset master to upstream/master git checkout master git reset --hard upstream/master git push --force y--y--y (mybranch) / z--z--z (master, upstream/master, origin/master) # replay the patches (even they are rejected for now) on top of master git checkout mybranch git rebase master git push -u origin mybranch y'--y'--y' (mybranch, origin/mybranch) / z--z--z (master, upstream/master, origin/master) Platform specific \u00b6 Github \u00b6 cli is github official cli tool. Change the repository language detection .gitattributes s used for the files you want to override using the linguist-documentation , linguist-language , linguist-vendored , linguist-generated and linguist-detectable attributes. Installation is performed with gem: gem install github-linguist Github action act run GitHub Actions locally. Git diff \u00b6 Git diff can be displayed side by side with delta as a pager [core] pager = delta","title":"git"},{"location":"sw_dvpt/git/#git","text":"","title":"GIT"},{"location":"sw_dvpt/git/#configuration","text":"The configuration is made out of four files : $(prefix)/etc/gitconfig $XDG_CONFIG_HOME/git/config ~/.gitconfig $GIT_DIR/config Add credential cache (timed out daemon) when not using ssh authentication: git config --global credential.helper cache # Set the timeout to 300s instead 900s (defaut) git config --global credential.helper 'cache --timeout=300' # To explicitly exits the daemon git credential-cache exit","title":"Configuration"},{"location":"sw_dvpt/git/#revision-selection","text":"","title":"Revision selection"},{"location":"sw_dvpt/git/#individual-commit-selection","text":"","title":"Individual commit selection"},{"location":"sw_dvpt/git/#range-selection","text":"","title":"Range selection"},{"location":"sw_dvpt/git/#exclude-reachable-commit","text":"This can be done with ^ before the commit or branch or by using thee --not syntax. e.g. to see all commits reachable from refA and refB but not refC : # Usage are equivalent git log revA revB ^revC git log revA revB --not revC # Usage are equivalent git log revA..revB git log ^revA revB git log rebB --not revA","title":"Exclude reachable commit"},{"location":"sw_dvpt/git/#mutualy-exclution-triple-dot","text":"Specify commits that are reachabel either by both references","title":"Mutualy exclution: triple dot"},{"location":"sw_dvpt/git/#examples","text":"Loeliger notation G H I J \\ / \\ / D E F \\ | / \\ \\ | / | \\|/ | B C \\ / \\ / A Ancestry selection G H I J | A = = A^0 \\ / \\ / | B = A^ = A^1 = A~1 D E F | C = A^2 = A^2 \\ | / \\ | D = A^^ = A^1^1 = A~2 \\ | / | | E = B^2 = A^^2 \\|/ | | F = B^3 = A^^3 B C | G = A^^^ = A^1^1^1 = A~3 \\ / | H = D^2 = B^^2 = A^^^2 = A~2^2 \\ / | I = F^ = B^3^ = A^^3^ A | J = F^2 = B^3^2 = A^^3^2 Extended selection G H I J | Args | Expanded arguments | Selected commits \\ / \\ / | ----------|----------------------|------------------ D E F | D | | G H D \\ | / \\ | D F | | G H I J D F \\ | / | | ^G D | | H D \\|/ | | ^D B | | E I J F B B C | ^D B C | | E I J F B C \\ / | C | | I J F C \\ / | B..C | = ^B C | C A | B...C | = B ^F C | G H D E B C | B^- | = B^..B | | | = ^B^1 B | E I J F B | C^@ | = C^1 | | | = F | I J F | B^@ | = B^1 B^2 B^3 | | | = D E F | D G H E F I J | C^! | = C ^C^@ | | | = C ^C^1 | | | = C ^F | C | B^! | = B ^B^@ | | | = B ^B^1 ^B^2 ^B^3 | | | = B ^D ^E ^F | B | F^! D | = F ^I ^J D | G H D F","title":"Examples"},{"location":"sw_dvpt/git/#submodules","text":"","title":"Submodules"},{"location":"sw_dvpt/git/#commands","text":"status prints the SHA1 status of checked submodules. Prefixed with: - if the submodule is not initialized + in case of conflicts between current subdmodule and the index of the containing directory U in case of merge conflicts","title":"Commands"},{"location":"sw_dvpt/git/#remove-a-submodule","text":"A submodule can be deleted by running git rm <submodule path> && git commit . $GIT_DIR/modules/<name> delete the submodule completly. Util then, deletion can be undone using git revert . Alternative method: Remove the submodule entry from .git/config git submodule deinit -f path/to/submodule Remove the submodule directory from the superproject's .git/modules directory rm -rf .git/modules/path/to/submodule Commit the changes git commit-m \"Removed submodule \" Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule git rm -f path/to/submodule","title":"Remove a submodule"},{"location":"sw_dvpt/git/#updating-submodule-url-and-branch","text":"The submodule configuration can be displayed with git config : git config -l A specific config file can be given to git config with the --file flag : git config -l --file=.gitmodules Url, branch and other parameters can be configured via git config git config --file=.gitmodules submodule.<submodule_name>.url <git@github.com:username/repository.git> git config --file=.gitmodules submodule.<submodule_name>.branch <branch_name> Synchronization adn update of the submodules are done with: git submodule sync git submodule update --init --recursive --remote --merge # ! If --merge option is missing, HEAD will be detached","title":"Updating submodule url and branch"},{"location":"sw_dvpt/git/#tags","text":"Get the most recent tag: git describe --tags --abbrev=0","title":"Tags"},{"location":"sw_dvpt/git/#hooks","text":"Hooks are executable scripts, generaly located in .git/hooks . They can be devided into two groups: client-side server-side","title":"Hooks"},{"location":"sw_dvpt/git/#client-side","text":"Hook Run description post-checkout after a successful git checkout pre-commit before commiting message, general checks like linting prepare-commit-msg before the commit message editor is fired up but after the default message is created, good for commits where the default message is auto-generated commit-msg validate project state or commit message pre-rebase before you rebase anything pre-push during git push , after the remote refs have been updated but before any objects have been transferred post-rewrite triggered by commands that replace commits, such as git commit --amend and git rebase post-merge after a successful merge command post-commit once eveything coompleted. There are other hooks, invoked by specific commands: pre-auto-gc by invoking garbage collection git gc --auto applypatch-msg , pre-applypatch and post-applypatch all invoked by git am for an email-based workflow.","title":"Client side"},{"location":"sw_dvpt/git/#server-side","text":"Hook Run description pre-receive first script to run when handling a push from a client. Runs only once. post-receive run once for each branch the pusher is trying to update update after the entire process is completed and can be used to update other services or notify users Installation must be performed on the server, see e.g. for gitlab . If no admin rights are available, some alternatives: webhooks github / gitlab CI/CD pipeline github gitlab push rules gitlab","title":"Server side"},{"location":"sw_dvpt/git/#cherry-pick-from-another-repository","text":"First the other repository source must be added to the remote list git remote add other https://other.url/repository.git git fetch other Then use git cherry-pick","title":"Cherry pick from another repository"},{"location":"sw_dvpt/git/#others","text":"conform is a tool for enforcing policies on your build pipelines. Conventional commits","title":"Others"},{"location":"sw_dvpt/git/#conventional-commits-100","text":"","title":"Conventional Commits 1.0.0"},{"location":"sw_dvpt/git/#summary","text":"The Conventional Commits specification is a lightweight convention on top of commit messages. It provides an easy set of rules for creating an explicit commit history; which makes it easier to write automated tools on top of. This convention dovetails with SemVer , by describing the features, fixes, and breaking changes made in commit messages. The commit message should be structured as follows:","title":"Summary"},{"location":"sw_dvpt/git/#typeoptional-scope-description-optional-body-optional-footers","text":"The commit contains the following structural elements, to communicate intent to the consumers of your library: fix: a commit of the type fix patches a bug in your codebase (this correlates with PATCH in semantic versioning). feat: a commit of the type feat introduces a new feature to the codebase (this correlates with MINOR in semantic versioning). BREAKING CHANGE: a commit that has a footer BREAKING CHANGE: , or appends a ! after the type/scope, introduces a breaking API change (correlating with MAJOR in semantic versioning). A BREAKING CHANGE can be part of commits of any type . types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the the Angular convention ) recommends build: , chore: , ci: , docs: , style: , refactor: , perf: , test: , and others. footers other than BREAKING CHANGE: <description> may be provided and follow a convention similar to git trailer format . Additional types are not mandated by the Conventional Commits specification, and have no implicit effect in semantic versioning (unless they include a BREAKING CHANGE). A scope may be provided to a commit's type, to provide additional contextual information and is contained within parenthesis, e.g., feat(parser): add ability to parse arrays .","title":"&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n"},{"location":"sw_dvpt/git/#examples_1","text":"","title":"Examples"},{"location":"sw_dvpt/git/#commit-message-with-description-and-breaking-change-footer","text":"feat: allow provided config object to extend other configs BREAKING CHANGE: `extends` key in config file is now used for extending other config files","title":"Commit message with description and breaking change footer"},{"location":"sw_dvpt/git/#commit-message-with-to-draw-attention-to-breaking-change","text":"refactor!: drop support for Node 6","title":"Commit message with ! to draw attention to breaking change"},{"location":"sw_dvpt/git/#commit-message-with-both-and-breaking-change-footer","text":"refactor!: drop support for Node 6 BREAKING CHANGE: refactor to use JavaScript features not available in Node 6.","title":"Commit message with both ! and BREAKING CHANGE footer"},{"location":"sw_dvpt/git/#commit-message-with-no-body","text":"docs: correct spelling of CHANGELOG","title":"Commit message with no body"},{"location":"sw_dvpt/git/#commit-message-with-scope","text":"feat(lang): add polish language","title":"Commit message with scope"},{"location":"sw_dvpt/git/#commit-message-with-multi-paragraph-body-and-multiple-footers","text":"fix: correct minor typos in code see the issue for details on typos fixed. Reviewed-by: Z Refs #133","title":"Commit message with multi-paragraph body and multiple footers"},{"location":"sw_dvpt/git/#specification","text":"The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD NOT\u201d, \u201cRECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be interpreted as described in RFC 2119 . Commits MUST be prefixed with a type, which consists of a noun, feat , fix , etc., followed by the OPTIONAL scope, OPTIONAL ! , and REQUIRED terminal colon and space. The type feat MUST be used when a commit adds a new feature to your application or library. The type fix MUST be used when a commit represents a bug fix for your application. A scope MAY be provided after a type. A scope MUST consist of a noun describing a section of the codebase surrounded by parenthesis, e.g., fix(parser): A description MUST immediately follow the colon and space after the type/scope prefix. The description is a short summary of the code changes, e.g., fix: array parsing issue when multiple spaces were contained in string . A longer commit body MAY be provided after the short description, providing additional contextual information about the code changes. The body MUST begin one blank line after the description. A commit body is free-form and MAY consist of any number of newline separated paragraphs. One or more footers MAY be provided one blank line after the body. Each footer MUST consist of a word token, followed by either a :<space> or <space># separator, followed by a string value (this is inspired by the git trailer convention ). A footer's token MUST use - in place of whitespace characters, e.g., Acked-by (this helps differentiate the footer section from a multi-paragraph body). An exception is made for BREAKING CHANGE , which MAY also be used as a token. A footer's value MAY contain spaces and newlines, and parsing MUST terminate when the next valid footer token/separator pair is observed. Breaking changes MUST be indicated in the type/scope prefix of a commit, or as an entry in the footer. If included as a footer, a breaking change MUST consist of the uppercase text BREAKING CHANGE, followed by a colon, space, and description, e.g., BREAKING CHANGE: environment variables now take precedence over config files . If included in the type/scope prefix, breaking changes MUST be indicated by a ! immediately before the : . If ! is used, BREAKING CHANGE: MAY be omitted from the footer section, and the commit description SHALL be used to describe the breaking change. Types other than feat and fix MAY be used in your commit messages, e.g., docs: updated ref docs. The units of information that make up Conventional Commits MUST NOT be treated as case sensitive by implementors, with the exception of BREAKING CHANGE which MUST be uppercase. BREAKING-CHANGE MUST be synonymous with BREAKING CHANGE, when used as a token in a footer. ghq provides a way to organize remote repository clones, like go get does.","title":"Specification"},{"location":"sw_dvpt/git/#git-flow","text":"From Scott Chacon blog : To work on something new, create a descriptively named branch off of master Commit to that branch locally and regularly push your work to the same named branch on the server When you need feedback or help, or you think the branch is ready for merging, open a pull request After someone else has reviewed and signed off on the feature, you can merge it into master","title":"Git flow"},{"location":"sw_dvpt/git/#pull-request","text":"https://github.blog/2015-01-21-how-to-write-the-perfect-pull-request/ https://stackoverflow.com/questions/14680711 https://stackoverflow.com/questions/29049650 Switch branches or restore working tree files git checkout master git checkout -b mybranch git remote manage the set of repositories (\"remotes\") whose branches you track. git remote -v # If upstream is not configured, add the upstream route git remote add upstream /url/original/repo git fetch upstream # reset master to upstream/master git checkout master git reset --hard upstream/master git push --force y--y--y (mybranch) / z--z--z (master, upstream/master, origin/master) # replay the patches (even they are rejected for now) on top of master git checkout mybranch git rebase master git push -u origin mybranch y'--y'--y' (mybranch, origin/mybranch) / z--z--z (master, upstream/master, origin/master)","title":"Pull request"},{"location":"sw_dvpt/git/#platform-specific","text":"","title":"Platform specific"},{"location":"sw_dvpt/git/#github","text":"cli is github official cli tool.","title":"Github"},{"location":"sw_dvpt/git/#git-diff","text":"Git diff can be displayed side by side with delta as a pager [core] pager = delta","title":"Git diff"},{"location":"sw_dvpt/make/","text":"Make \u00b6 Variables \u00b6 variables defined with \u2018=\u2019 are recursively expanded. variables defined with \u2018:=\u2019 or \u2018::=\u2019 are simply expanded variable names may contain function and variable references, which are expanded when the line is read to find the actual variable name to use. Automatic variables \u00b6 @ | The file name of the target of the rule. If the target is an archive member, then \u2018 @ | The file name of the target of the rule. If the target is an archive member, then \u2018 @\u2019 is the name of the archive file. In a pattern rule that has multiple targets (see Introduction to Pattern Rules), \u2018$@\u2019 is the name of whichever target caused the rule\u2019s recipe to be run. | % | The target member name, when the target is an archive member. See Archives. For example, if the target is foo.a(bar.o) then \u2018 % | The target member name, when the target is an archive member. See Archives. For example, if the target is foo.a(bar.o) then \u2018 %\u2019 is bar.o and \u2018 @\u2019 is foo.a. \u2018 @\u2019 is foo.a. \u2018 %\u2019 is empty when the target is not an archive member. | $< The name of the first prerequisite. If the target got its recipe from an implicit rule, this will be the first prerequisite added by the implicit rule (see Implicit Rules). $? The names of all the prerequisites that are newer than the target, with spaces between them. If the target does not exist, all prerequisites will be included. For prerequisites which are archive members, only the named member is used (see Archives). $^ The names of all the prerequisites, with spaces between them. For prerequisites which are archive members, only the named member is used (see Archives). A target has only one prerequisite on each other file it depends on, no matter how many times each file is listed as a prerequisite. So if you list a prerequisite more than once for a target, the value of $^ contains just one copy of the name. This list does not contain any of the order-only prerequisites; for those see the \u2018$|\u2019 variable, below. $+ This is like \u2018$^\u2019, but prerequisites listed more than once are duplicated in the order they were listed in the makefile. This is primarily useful for use in linking commands where it is meaningful to repeat library file names in a particular order. $| The names of all the order-only prerequisites, with spaces between them. $* The stem with which an implicit rule matches (see How Patterns Match). If the target is dir/a.foo.b and the target pattern is a.%.b then the stem is dir/foo. The stem is useful for constructing names of related files. In a static pattern rule, the stem is part of the file name that matched the \u2018%\u2019 in the target pattern. In an explicit rule, there is no stem; so \u2018$*\u2019 cannot be determined in that way. Instead, if the target name ends with a recognized suffix (see Old-Fashioned Suffix Rules), \u2018$*\u2019 is set to the target name minus the suffix. For example, if the target name is \u2018foo.c\u2019, then \u2018$*\u2019 is set to \u2018foo\u2019, since \u2018.c\u2019 is a suffix. GNU make does this bizarre thing only for compatibility with other implementations of make. You should generally avoid using \u2018$*\u2019 except in implicit rules or static pattern rules. If the target name in an explicit rule does not end with a recognized suffix, \u2018$*\u2019 is set to the empty string for that rule. \u2018$?\u2019 is useful even in explicit rules when you wish to operate on only the prerequisites that have changed. For example, suppose that an archive named lib is supposed to contain copies of several object files. This rule copies just the changed object files into the archive: lib: foo.o bar.o lose.o win.o ar r lib $? Of the variables listed above, four have values that are single file names, and three have values that are lists of file names. These seven have variants that get just the file\u2019s directory name or just the file name within the directory. The variant variables\u2019 names are formed by appending \u2018D\u2019 or \u2018F\u2019, respectively. The functions dir and notdir can be used to obtain a similar effect (see Functions for File Names). Note, however, that the \u2018D\u2019 variants all omit the trailing slash which always appears in the output of the dir function. Here is a table of the variants: \u2018$(@D)\u2019 The directory part of the file name of the target, with the trailing slash removed. If the value of \u2018$@\u2019 is dir/foo.o then \u2018$(@D)\u2019 is dir. This value is . if \u2018$@\u2019 does not contain a slash. \u2018$(@F)\u2019 The file-within-directory part of the file name of the target. If the value of \u2018$@\u2019 is dir/foo.o then \u2018$(@F)\u2019 is foo.o. \u2018$(@F)\u2019 is equivalent to \u2018$(notdir $@)\u2019. \u2018 (*D)\u2019 \u2018 (*D)\u2019 \u2018 (*F)\u2019 The directory part and the file-within-directory part of the stem; dir and foo in this example. \u2018 (%D)\u2019 \u2018 (%D)\u2019 \u2018 (%F)\u2019 The directory part and the file-within-directory part of the target archive member name. This makes sense only for archive member targets of the form archive(member) and is useful only when member may contain a directory name. (See Archive Members as Targets.) \u2018 (<D)\u2019 \u2018 (<D)\u2019 \u2018 (<F)\u2019 The directory part and the file-within-directory part of the first prerequisite. \u2018 (^D)\u2019 \u2018 (^D)\u2019 \u2018 (^F)\u2019 Lists of the directory parts and the file-within-directory parts of all prerequisites. \u2018 (+D)\u2019 \u2018 (+D)\u2019 \u2018 (+F)\u2019 Lists of the directory parts and the file-within-directory parts of all prerequisites, including multiple instances of duplicated prerequisites. \u2018 (?D)\u2019 \u2018 (?D)\u2019 \u2018 (?F)\u2019 Lists of the directory parts and the file-within-directory parts of all prerequisites that are newer than the target.","title":"Make"},{"location":"sw_dvpt/make/#make","text":"","title":"Make"},{"location":"sw_dvpt/make/#variables","text":"variables defined with \u2018=\u2019 are recursively expanded. variables defined with \u2018:=\u2019 or \u2018::=\u2019 are simply expanded variable names may contain function and variable references, which are expanded when the line is read to find the actual variable name to use.","title":"Variables"},{"location":"sw_dvpt/make/#automatic-variables","text":"@ | The file name of the target of the rule. If the target is an archive member, then \u2018 @ | The file name of the target of the rule. If the target is an archive member, then \u2018 @\u2019 is the name of the archive file. In a pattern rule that has multiple targets (see Introduction to Pattern Rules), \u2018$@\u2019 is the name of whichever target caused the rule\u2019s recipe to be run. | % | The target member name, when the target is an archive member. See Archives. For example, if the target is foo.a(bar.o) then \u2018 % | The target member name, when the target is an archive member. See Archives. For example, if the target is foo.a(bar.o) then \u2018 %\u2019 is bar.o and \u2018 @\u2019 is foo.a. \u2018 @\u2019 is foo.a. \u2018 %\u2019 is empty when the target is not an archive member. | $< The name of the first prerequisite. If the target got its recipe from an implicit rule, this will be the first prerequisite added by the implicit rule (see Implicit Rules). $? The names of all the prerequisites that are newer than the target, with spaces between them. If the target does not exist, all prerequisites will be included. For prerequisites which are archive members, only the named member is used (see Archives). $^ The names of all the prerequisites, with spaces between them. For prerequisites which are archive members, only the named member is used (see Archives). A target has only one prerequisite on each other file it depends on, no matter how many times each file is listed as a prerequisite. So if you list a prerequisite more than once for a target, the value of $^ contains just one copy of the name. This list does not contain any of the order-only prerequisites; for those see the \u2018$|\u2019 variable, below. $+ This is like \u2018$^\u2019, but prerequisites listed more than once are duplicated in the order they were listed in the makefile. This is primarily useful for use in linking commands where it is meaningful to repeat library file names in a particular order. $| The names of all the order-only prerequisites, with spaces between them. $* The stem with which an implicit rule matches (see How Patterns Match). If the target is dir/a.foo.b and the target pattern is a.%.b then the stem is dir/foo. The stem is useful for constructing names of related files. In a static pattern rule, the stem is part of the file name that matched the \u2018%\u2019 in the target pattern. In an explicit rule, there is no stem; so \u2018$*\u2019 cannot be determined in that way. Instead, if the target name ends with a recognized suffix (see Old-Fashioned Suffix Rules), \u2018$*\u2019 is set to the target name minus the suffix. For example, if the target name is \u2018foo.c\u2019, then \u2018$*\u2019 is set to \u2018foo\u2019, since \u2018.c\u2019 is a suffix. GNU make does this bizarre thing only for compatibility with other implementations of make. You should generally avoid using \u2018$*\u2019 except in implicit rules or static pattern rules. If the target name in an explicit rule does not end with a recognized suffix, \u2018$*\u2019 is set to the empty string for that rule. \u2018$?\u2019 is useful even in explicit rules when you wish to operate on only the prerequisites that have changed. For example, suppose that an archive named lib is supposed to contain copies of several object files. This rule copies just the changed object files into the archive: lib: foo.o bar.o lose.o win.o ar r lib $? Of the variables listed above, four have values that are single file names, and three have values that are lists of file names. These seven have variants that get just the file\u2019s directory name or just the file name within the directory. The variant variables\u2019 names are formed by appending \u2018D\u2019 or \u2018F\u2019, respectively. The functions dir and notdir can be used to obtain a similar effect (see Functions for File Names). Note, however, that the \u2018D\u2019 variants all omit the trailing slash which always appears in the output of the dir function. Here is a table of the variants: \u2018$(@D)\u2019 The directory part of the file name of the target, with the trailing slash removed. If the value of \u2018$@\u2019 is dir/foo.o then \u2018$(@D)\u2019 is dir. This value is . if \u2018$@\u2019 does not contain a slash. \u2018$(@F)\u2019 The file-within-directory part of the file name of the target. If the value of \u2018$@\u2019 is dir/foo.o then \u2018$(@F)\u2019 is foo.o. \u2018$(@F)\u2019 is equivalent to \u2018$(notdir $@)\u2019. \u2018 (*D)\u2019 \u2018 (*D)\u2019 \u2018 (*F)\u2019 The directory part and the file-within-directory part of the stem; dir and foo in this example. \u2018 (%D)\u2019 \u2018 (%D)\u2019 \u2018 (%F)\u2019 The directory part and the file-within-directory part of the target archive member name. This makes sense only for archive member targets of the form archive(member) and is useful only when member may contain a directory name. (See Archive Members as Targets.) \u2018 (<D)\u2019 \u2018 (<D)\u2019 \u2018 (<F)\u2019 The directory part and the file-within-directory part of the first prerequisite. \u2018 (^D)\u2019 \u2018 (^D)\u2019 \u2018 (^F)\u2019 Lists of the directory parts and the file-within-directory parts of all prerequisites. \u2018 (+D)\u2019 \u2018 (+D)\u2019 \u2018 (+F)\u2019 Lists of the directory parts and the file-within-directory parts of all prerequisites, including multiple instances of duplicated prerequisites. \u2018 (?D)\u2019 \u2018 (?D)\u2019 \u2018 (?F)\u2019 Lists of the directory parts and the file-within-directory parts of all prerequisites that are newer than the target.","title":"Automatic variables"},{"location":"sw_dvpt/patterns/","text":"Design patterns \u00b6 Dependency injection \u00b6 Examples: Pytest fixtures AngularJS","title":"Design patterns"},{"location":"sw_dvpt/patterns/#design-patterns","text":"","title":"Design patterns"},{"location":"sw_dvpt/patterns/#dependency-injection","text":"Examples: Pytest fixtures AngularJS","title":"Dependency injection"},{"location":"sw_dvpt/version_manager/","text":"Version managers \u00b6 These tools help managing developping environements for","title":"Version managers"},{"location":"sw_dvpt/version_manager/#version-managers","text":"These tools help managing developping environements for","title":"Version managers"},{"location":"sw_dvpt/ci_cd/cicd/","text":"CI/CD \u00b6 Continuous Integration ensure an application build and test triggered by defined changes. Continuous Integration/Delivery with pre-commmit \u00b6 is a command line utility - pre-commit aliased pc - that can be used for automation of the creation of git pre-commit hook . What is a git pre-commit hook? It's used to inspect the snapshot that\u2019s about to be committed, to see if you\u2019ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. Exiting non-zero from this hook aborts the commit. pre-commmit stores its config in a yaml file .pre-commit-config.yaml whose root value is repos . A template can be generated with: pre-commit sample-config > .pre-commit-config.yaml and the script is installed with: pre-commit install Some hooks are available for various purpose: General \u00b6 Some \"built-in\" hooks are provided with pre-commit. Example - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.4.0 hooks : - id : end-of-file-fixer - id : trailing-whitespace Code style \u00b6 Isort Example - repo : https://github.com/psf/black rev : v3.3.0 hooks : - id : isort Black Example - repo : https://github.com/psf/black rev : v3.3.0 hooks : - id : black Lint \u00b6 yamllint Example - repo : https://github.com/adrienverge/yamllint rev : v1.25.0 hooks : - id : yamllint flake8 Example - repo : https://gitlab.com/pycqa/flake8 rev : 3.8.1 hooks : - id : flake8 additional_dependencies : [ flake8-bugbear ] Code checker \u00b6 MyPy \u00b6 Example - repo : https://github.com/pre-commit/mirrors-mypy rev : v0.770 hooks : - id : mypy exclude : ^docs/conf.py","title":"Intro"},{"location":"sw_dvpt/ci_cd/cicd/#cicd","text":"Continuous Integration ensure an application build and test triggered by defined changes. Continuous Integration/Delivery","title":"CI/CD"},{"location":"sw_dvpt/ci_cd/cicd/#with-pre-commmit","text":"is a command line utility - pre-commit aliased pc - that can be used for automation of the creation of git pre-commit hook . What is a git pre-commit hook? It's used to inspect the snapshot that\u2019s about to be committed, to see if you\u2019ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. Exiting non-zero from this hook aborts the commit. pre-commmit stores its config in a yaml file .pre-commit-config.yaml whose root value is repos . A template can be generated with: pre-commit sample-config > .pre-commit-config.yaml and the script is installed with: pre-commit install Some hooks are available for various purpose:","title":"with pre-commmit"},{"location":"sw_dvpt/ci_cd/cicd/#general","text":"Some \"built-in\" hooks are provided with pre-commit. Example - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.4.0 hooks : - id : end-of-file-fixer - id : trailing-whitespace","title":"General"},{"location":"sw_dvpt/ci_cd/cicd/#code-style","text":"","title":"Code style"},{"location":"sw_dvpt/ci_cd/cicd/#lint","text":"","title":"Lint"},{"location":"sw_dvpt/ci_cd/cicd/#code-checker","text":"","title":"Code checker"},{"location":"sw_dvpt/ci_cd/cicd/#mypy","text":"Example - repo : https://github.com/pre-commit/mirrors-mypy rev : v0.770 hooks : - id : mypy exclude : ^docs/conf.py","title":"MyPy"},{"location":"sw_dvpt/ci_cd/codecov/","text":"Code coverage \u00b6 In computer science, test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs. Coverage criteria \u00b6 There are a number of coverage criteria, the main ones being: Function coverage has each function (or subroutine) in the program been called? Statement coverage has each statement in the program been executed? Edge coverage has every edge in the Control flow graph been executed? Branch coverage has each branch (also called DD-path) of each control structure (such as in if and case statements) been executed? For example, given an if statement, have both the true and false branches been executed? This is a subset of edge coverage. Condition coverage (or predicate coverage) has each Boolean sub-expression evaluated both to true and false? https://codecov.io/","title":"Code coverage"},{"location":"sw_dvpt/ci_cd/codecov/#code-coverage","text":"In computer science, test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs.","title":"Code coverage"},{"location":"sw_dvpt/ci_cd/codecov/#coverage-criteria","text":"There are a number of coverage criteria, the main ones being: Function coverage has each function (or subroutine) in the program been called? Statement coverage has each statement in the program been executed? Edge coverage has every edge in the Control flow graph been executed? Branch coverage has each branch (also called DD-path) of each control structure (such as in if and case statements) been executed? For example, given an if statement, have both the true and false branches been executed? This is a subset of edge coverage. Condition coverage (or predicate coverage) has each Boolean sub-expression evaluated both to true and false? https://codecov.io/","title":"Coverage criteria"},{"location":"sw_dvpt/protocols/ssh/","text":"SSH \u00b6 Seure shell is a protocol to safely administrying remote servers. Underlying entcryption techniques used: symmetrical encryption: type of entcryption where one key can be used to entcrypt messages to the opposite party, also to decrypt the messages received from the other participant. Also called shared secret or secret key encryption, typically one single key for all operations, or a pair of keys.","title":"SSH"},{"location":"sw_dvpt/protocols/ssh/#ssh","text":"Seure shell is a protocol to safely administrying remote servers. Underlying entcryption techniques used: symmetrical encryption: type of entcryption where one key can be used to entcrypt messages to the opposite party, also to decrypt the messages received from the other participant. Also called shared secret or secret key encryption, typically one single key for all operations, or a pair of keys.","title":"SSH"},{"location":"sw_dvpt/protocols/ssl/","text":"TLS / SSL \u00b6 Transport Layer Security (TLS), and its now-deprecated predecessor, Secure Sockets Layer (SSL), are cryptographic protocols designed to provide communications security over a computer network","title":"TLS / SSL"},{"location":"sw_dvpt/protocols/ssl/#tls-ssl","text":"Transport Layer Security (TLS), and its now-deprecated predecessor, Secure Sockets Layer (SSL), are cryptographic protocols designed to provide communications security over a computer network","title":"TLS / SSL"},{"location":"vim/edition/","text":"Editing \u00b6 Operation ...entire line ...to eol entire word ...to eow ... to begin of next word Change cc C ( or c$ ) ciw / caw cw (or ce ) Delete dd D ( or d$ ) diw / daw de dw Registers \u00b6 There are 10 types of :h registers : The unnamed register \"\" 10 numbered registers \"0 to \"9 filled with text from the last 10 yank and delete commands. The small delete register \"- from commands that delete less than a line. 26 named registers \"a to \"z or \"A to \"Z Three read-only registers: \": , most recent command, \". , \"% , name of the current file) Alternate buffer register \"# The expression register \"= : The selection and drop registers (: \"* , contains the PRIMARY selection which is available on Linux when users select some data. \"+ , contains the CLIPBOARD select, available on active requests of copy. To use the PRIMARY selection too, set clipboard^=unnamed,unnamedplus \"~ registers the dropped text from the last drag'n'drop operation. The black hole register \"_ Last search pattern register \"/ Insertion of register in command mode in triggerd by C-r . Selection \u00b6 :h text-objects or operate in visual mode and consists ot two characters: i and a and correspond to an inner resp. outer selection. Comment \u00b6 Comment line (via plugin vim-commentary): gcc in normal mode, gc in visual mode Surroung element while editing Completion \u00b6 complete \u00b6 Completion is set up by the complete options, a list of location used for completion lookup. The default is \".,w,b,u,t,i\", which means to scan: 1. the current buffer 2. buffers in other windows 3. other loaded buffers 4. unloaded buffers 5. tags 6. included files See h: 535 completeopt \u00b6 The completion menu appearance is controlled by completeopt ( ofu ) ins-completion \u00b6 Completion in insert mode h: ins-completion is activated with C-x and triggers a sub-mode h: i_CTRL-X . |-----|--------------------------------------------|-------------------| | | Desc | Key | |-----|--------------------------------------------|-------------------| | 1. | Whole lines | CTRL-L | | 2. | keywords in the current file | CTRL-N | | 3. | keywords in 'dictionary' | CTRL-K | | 4. | keywords in 'thesaurus', thesaurus-style | CTRL-T | | 5. | keywords in the current and included files | CTRL-I | | 6. | tags | CTRL-] | | 7. | file names | CTRL-F | | 8. | definitions or macros | CTRL-D | | 9. | Vim command-line | CTRL-V | | 10. | User defined completion | CTRL-U | | 11. | omni completion | CTRL-O | | 12. | Spelling suggestions | s | | 13. | keywords in 'complete' | CTRL-N / CTRL-P | omnifunc \u00b6 Omni completion supports filetype-specific completion. Ex: omnifunc=htmlcomplete#CompleteTags function! InputTarget() let c = getchar() echo c endfunction function! Codify() let selection = getpos('.') echo string(selection) . \"Yo\" \" Get selection \" Length == 1 (normal mode) \" -> expand selection to zone delimited by space \" Length >= 1 (visual mode) \" -> get selection and introduce ` around selection endfunction Folding \u00b6 Types of Folding : Type Description manual folds are created manually and remain in RAM indent lines with equal indent form a fold expr vim scripts give identation of a line marker based on specific characters syntax syntax highlightung items specify folds diff fold test that is not changed The command zc will close a fold (if the cursor is in an open fold), and zo will open a fold (if the cursor is in a closed fold). It's easier to just use za which will toggle the current fold (close it if it was open, or open it if it was closed). The commands zc (close), zo (open), and za (toggle) operate on one level of folding, at the cursor. The commands zC, zO and zA are similar, but operate on all folding levels (for example, the cursor line may be in an open fold, which is inside another open fold; typing zC would close all folds at the cursor). The command zr reduces folding by opening one more level of folds throughout the whole buffer (the cursor position is not relevant). Use zR to open all folds. The command zm gives more folding by closing one more level of folds throughout the whole buffer. Use zM to close all folds. Source: https://vim.fandom.com/wiki/Folding Folding principel: folds at defined per level: :set foldlevel=<LEVEL> and adjacent lines are fold grouped by level value to fold level at start :set foldlevelstart=<LEVEL> Macros \u00b6 Editing a macro \u00b6 From vim.fandom.com : Type :let @a='i Press Ctrl-R Ctrl-R a to insert the current contents of register a (type Ctrl-R twice to insert the register exactly). Edit the text as required. Append an apostrophe ' to finish the command, and press Enter. Enter :reg a to view the new value in the register. Type @a to execute the contents of register a . Note the caveat above about macros which end in <CR> or <NL> . Linting \u00b6 ale","title":"Edition"},{"location":"vim/edition/#editing","text":"Operation ...entire line ...to eol entire word ...to eow ... to begin of next word Change cc C ( or c$ ) ciw / caw cw (or ce ) Delete dd D ( or d$ ) diw / daw de dw","title":"Editing"},{"location":"vim/edition/#registers","text":"There are 10 types of :h registers : The unnamed register \"\" 10 numbered registers \"0 to \"9 filled with text from the last 10 yank and delete commands. The small delete register \"- from commands that delete less than a line. 26 named registers \"a to \"z or \"A to \"Z Three read-only registers: \": , most recent command, \". , \"% , name of the current file) Alternate buffer register \"# The expression register \"= : The selection and drop registers (: \"* , contains the PRIMARY selection which is available on Linux when users select some data. \"+ , contains the CLIPBOARD select, available on active requests of copy. To use the PRIMARY selection too, set clipboard^=unnamed,unnamedplus \"~ registers the dropped text from the last drag'n'drop operation. The black hole register \"_ Last search pattern register \"/ Insertion of register in command mode in triggerd by C-r .","title":"Registers"},{"location":"vim/edition/#selection","text":":h text-objects or operate in visual mode and consists ot two characters: i and a and correspond to an inner resp. outer selection.","title":"Selection"},{"location":"vim/edition/#comment","text":"Comment line (via plugin vim-commentary): gcc in normal mode, gc in visual mode Surroung element while editing","title":"Comment"},{"location":"vim/edition/#completion","text":"","title":"Completion"},{"location":"vim/edition/#complete","text":"Completion is set up by the complete options, a list of location used for completion lookup. The default is \".,w,b,u,t,i\", which means to scan: 1. the current buffer 2. buffers in other windows 3. other loaded buffers 4. unloaded buffers 5. tags 6. included files See h: 535","title":"complete"},{"location":"vim/edition/#completeopt","text":"The completion menu appearance is controlled by completeopt ( ofu )","title":"completeopt"},{"location":"vim/edition/#ins-completion","text":"Completion in insert mode h: ins-completion is activated with C-x and triggers a sub-mode h: i_CTRL-X . |-----|--------------------------------------------|-------------------| | | Desc | Key | |-----|--------------------------------------------|-------------------| | 1. | Whole lines | CTRL-L | | 2. | keywords in the current file | CTRL-N | | 3. | keywords in 'dictionary' | CTRL-K | | 4. | keywords in 'thesaurus', thesaurus-style | CTRL-T | | 5. | keywords in the current and included files | CTRL-I | | 6. | tags | CTRL-] | | 7. | file names | CTRL-F | | 8. | definitions or macros | CTRL-D | | 9. | Vim command-line | CTRL-V | | 10. | User defined completion | CTRL-U | | 11. | omni completion | CTRL-O | | 12. | Spelling suggestions | s | | 13. | keywords in 'complete' | CTRL-N / CTRL-P |","title":"ins-completion"},{"location":"vim/edition/#omnifunc","text":"Omni completion supports filetype-specific completion. Ex: omnifunc=htmlcomplete#CompleteTags function! InputTarget() let c = getchar() echo c endfunction function! Codify() let selection = getpos('.') echo string(selection) . \"Yo\" \" Get selection \" Length == 1 (normal mode) \" -> expand selection to zone delimited by space \" Length >= 1 (visual mode) \" -> get selection and introduce ` around selection endfunction","title":"omnifunc"},{"location":"vim/edition/#folding","text":"Types of Folding : Type Description manual folds are created manually and remain in RAM indent lines with equal indent form a fold expr vim scripts give identation of a line marker based on specific characters syntax syntax highlightung items specify folds diff fold test that is not changed The command zc will close a fold (if the cursor is in an open fold), and zo will open a fold (if the cursor is in a closed fold). It's easier to just use za which will toggle the current fold (close it if it was open, or open it if it was closed). The commands zc (close), zo (open), and za (toggle) operate on one level of folding, at the cursor. The commands zC, zO and zA are similar, but operate on all folding levels (for example, the cursor line may be in an open fold, which is inside another open fold; typing zC would close all folds at the cursor). The command zr reduces folding by opening one more level of folds throughout the whole buffer (the cursor position is not relevant). Use zR to open all folds. The command zm gives more folding by closing one more level of folds throughout the whole buffer. Use zM to close all folds. Source: https://vim.fandom.com/wiki/Folding Folding principel: folds at defined per level: :set foldlevel=<LEVEL> and adjacent lines are fold grouped by level value to fold level at start :set foldlevelstart=<LEVEL>","title":"Folding"},{"location":"vim/edition/#macros","text":"","title":"Macros"},{"location":"vim/edition/#editing-a-macro","text":"From vim.fandom.com : Type :let @a='i Press Ctrl-R Ctrl-R a to insert the current contents of register a (type Ctrl-R twice to insert the register exactly). Edit the text as required. Append an apostrophe ' to finish the command, and press Enter. Enter :reg a to view the new value in the register. Type @a to execute the contents of register a . Note the caveat above about macros which end in <CR> or <NL> .","title":"Editing a macro"},{"location":"vim/edition/#linting","text":"ale","title":"Linting"},{"location":"vim/intro/","text":"Vim \u00b6 Cheatsheet Initialisation \u00b6 :h init or At startup, Vim checks environment variables and files and sets values in this order: Set the 'shell' and 'term' option Process the arguments Execute Ex commands, from environment variables and/or files Load the plugin scripts. Set 'shellpipe' and 'shellredir' Set various less used initialization until windows open (see doc) Execute startup commands Configuration \u00b6 Vim has a number of internal variables and switches: options description of all options map key mapping and abbreviations autocmd automatically executing commands on an event fold hide (fold) ranges of lines When starting, vim will look in the runtimepath and underlying directories for runtime files. Basicaly on unix like systems: $HOME/.vim, $VIM/vimfiles, $VIMRUNTIME, $VIM/vimfiles/after, $HOME/.vim/after This is a list of some directories which will be searched for runtime files: File Description filetype.vim filetypes by file name new-filetype scripts.vim filetypes by file contents new-filetype-scripts autoload/ automatically loaded scripts autoload-functions colors/ color scheme files compiler/ compiler files ftplugin/ filetype plugins write-filetype-plugin import/ files that are found by :import indent/ indent scripts indent-expression pack/ packages :packadd plugin/ plugin scripts write-plugin syntax/ syntax files mysyntaxfile ~/.vim/syntax contains Packages (Plugins) \u00b6 :h packages' Links \u00b6 Learn vim script the hard way VIM cheatsheet VIM script cheatsheet","title":"Intro"},{"location":"vim/intro/#vim","text":"Cheatsheet","title":"Vim"},{"location":"vim/intro/#initialisation","text":":h init or At startup, Vim checks environment variables and files and sets values in this order: Set the 'shell' and 'term' option Process the arguments Execute Ex commands, from environment variables and/or files Load the plugin scripts. Set 'shellpipe' and 'shellredir' Set various less used initialization until windows open (see doc) Execute startup commands","title":"Initialisation"},{"location":"vim/intro/#configuration","text":"Vim has a number of internal variables and switches: options description of all options map key mapping and abbreviations autocmd automatically executing commands on an event fold hide (fold) ranges of lines When starting, vim will look in the runtimepath and underlying directories for runtime files. Basicaly on unix like systems: $HOME/.vim, $VIM/vimfiles, $VIMRUNTIME, $VIM/vimfiles/after, $HOME/.vim/after This is a list of some directories which will be searched for runtime files: File Description filetype.vim filetypes by file name new-filetype scripts.vim filetypes by file contents new-filetype-scripts autoload/ automatically loaded scripts autoload-functions colors/ color scheme files compiler/ compiler files ftplugin/ filetype plugins write-filetype-plugin import/ files that are found by :import indent/ indent scripts indent-expression pack/ packages :packadd plugin/ plugin scripts write-plugin syntax/ syntax files mysyntaxfile ~/.vim/syntax contains","title":"Configuration"},{"location":"vim/intro/#packages-plugins","text":":h packages'","title":"Packages (Plugins)"},{"location":"vim/intro/#links","text":"Learn vim script the hard way VIM cheatsheet VIM script cheatsheet","title":"Links"},{"location":"vim/languages/","text":"LSP \u00b6 Language Server Protocol Source: Microsoft on Github A language server runs as a separate process and development tools communicate with the server using the language protocol over JSON-RPC Example of server-client communication: Implementation \u00b6 Coc.vim \u00b6 has full support for Language Server Protocol completion LanguageClient-neovim \u00b6 Language specific \u00b6 go \u00b6 LSP server html \u00b6 :set omnifunc=htmlcomplete#CompleteTags Javascript \u00b6 vim-javascript , comment stuff out vim-polyglot , collection of language packs for Vim. Links: A guide to setting up Vim for JavaScript development JavaScript Documentation Standards Mardown md \u00b6 vim-markdown , Markdown Vim Mode. Python \u00b6 LSP server https://docs.python-guide.org/dev/env/ https://www.vimfromscratch.com/articles/vim-for-python/ https://github.com/neoclide/coc-python jedi-language-server Vim \u00b6 LSP server let g:markdown_fenced_languages = ['vim', 'help'] This is a JS project, installation done with yarn global add vim-language-server YAML \u00b6 LSP server","title":"Language support"},{"location":"vim/languages/#lsp","text":"Language Server Protocol Source: Microsoft on Github A language server runs as a separate process and development tools communicate with the server using the language protocol over JSON-RPC Example of server-client communication:","title":"LSP"},{"location":"vim/languages/#implementation","text":"","title":"Implementation"},{"location":"vim/languages/#cocvim","text":"has full support for Language Server Protocol completion","title":"Coc.vim"},{"location":"vim/languages/#languageclient-neovim","text":"","title":"LanguageClient-neovim"},{"location":"vim/languages/#language-specific","text":"","title":"Language specific"},{"location":"vim/languages/#go","text":"LSP server","title":"go"},{"location":"vim/languages/#html","text":":set omnifunc=htmlcomplete#CompleteTags","title":"html"},{"location":"vim/languages/#javascript","text":"vim-javascript , comment stuff out vim-polyglot , collection of language packs for Vim. Links: A guide to setting up Vim for JavaScript development JavaScript Documentation Standards","title":"Javascript"},{"location":"vim/languages/#mardown-md","text":"vim-markdown , Markdown Vim Mode.","title":"Mardown md"},{"location":"vim/languages/#python","text":"LSP server https://docs.python-guide.org/dev/env/ https://www.vimfromscratch.com/articles/vim-for-python/ https://github.com/neoclide/coc-python jedi-language-server","title":"Python"},{"location":"vim/languages/#vim","text":"LSP server let g:markdown_fenced_languages = ['vim', 'help'] This is a JS project, installation done with yarn global add vim-language-server","title":"Vim"},{"location":"vim/languages/#yaml","text":"LSP server","title":"YAML"},{"location":"vim/motion/","text":"The last motion commands can be repeated with ;","title":"Motion"},{"location":"vim/panes/","text":"Interface \u00b6 Close a terminal pane with C-w C-c To change two vertically split windows to horizonally split C-w t C-w K Horizontally to vertically: C-w t C-w H C-w t makes the first (topleft) window current C-w H moves the current window to full-height at far left C-w K moves the current window to full-width at the very top","title":"Panes"},{"location":"vim/panes/#interface","text":"Close a terminal pane with C-w C-c To change two vertically split windows to horizonally split C-w t C-w K Horizontally to vertically: C-w t C-w H C-w t makes the first (topleft) window current C-w H moves the current window to full-height at far left C-w K moves the current window to full-width at the very top","title":"Interface"},{"location":"vim/plugins/","text":"Plugins \u00b6 Vim interface \u00b6 Airline \u00b6 provides a status/tabline for vim. Airline integrates with a lot of utilities and therefor has a lot of configuration variables, see doc. Github project README +-----------------------------------------------------------------------------+ |~ | |~ | |~ VIM - Vi IMproved | |~ | |~ version 8.2 | |~ by Bram Moolenaar et al. | |~ Vim is open source and freely distributable | |~ | |~ type :h :q<Enter> to exit | |~ type :help<Enter> or <F1> for on-line help | |~ type :help version8<Enter> for version info | |~ | |~ | +-----------------------------------------------------------------------------+ | A | B | C X | Y | Z | [...] | +-----------------------------------------------------------------------------+ The statusline is the colored line at the bottom, which contains the sections (possibly in different colors): section meaning (example) A displays the mode + additional flags like crypt/spell/paste (INSERT) B Environment status (VCS information - branch, hunk summary (master), [battery][61] level) C filename + read-only flag (~/.vim/vimrc RO) X filetype (vim) Y file encoding[fileformat] (utf-8[unix]) Z current position in the file [...] additional sections (warning/errors/statistics) from external plugins (e.g. YCM, syntastic, ...) The information in Section Z looks like this: 10% \u2630 10/100 ln : 20 This means: 10% - 10 percent down the top of the file \u2630 10 - current line 10 /100 ln - of 100 lines : 20 - current column 20 Commands Command Descrption :AirlineTheme {theme-name} Displays or changes the current theme. random will switch to a random theme. :AirlineToggleWhitespace Toggles whitespace detection. :AirlineToggle between the standard 'statusline' and airline. :AirlineRefresh[!] Refreshes all highlight groups and redraws the statusline. With the '!' attribute, skips refreshing the highlighting groups. :AirlineExtensions Shows the status of all available airline extensions. Extern means, the extensions does not come bundled with Airline. Airline section variable names default content let g:airline_section_a (mode, crypt, paste, spell, iminsert) let g:airline_section_b (hunks, branch) let g:airline_section_c (bufferline or filename, readonly) let g:airline_section_gutter (csv) let g:airline_section_x (tagbar, filetype, virtualenv) let g:airline_section_y (fileencoding, fileformat) let g:airline_section_z (percentage, line number, column number) let g:airline_section_error (ycm_error_count, syntastic-err, eclim, languageclient_error_count) let g:airline_section_warning (ycm_warning_count, syntastic-warn, languageclient_warning_count, whitespace) Section b needs the fugitive plugin-in. Configuration \" the separator used on the left and right side let g :airline_left_sep = '' let g :airline_right_sep = '' \" enable fzf integration let g :airline#extensions#fzf#enabled = 1 \" tabline activated in airline let g :airline#extensions# tabline #enabled = 1 let g :airline#extensions# tabline #left_sep = ' ' let g :airline#extensions# tabline #left_alt_sep = '|' let g :airline#extensions# tabline #formatter = 'unique_tail_improved' \" let g:airline_theme = 'sonokai' let g :airline_powerline_fonts = 1 echodoc.vim displays function signatures from completions in the command line. Tags \u00b6 https://github.com/liuchengxu/vista.vi://github.com/liuchengxu/vista.vim Session \u00b6 obsession continuously updates session files. :mksession command to write a file. File editing \u00b6 vim-commentary comment stuff out vim-surround provides mapping for parentheses, brackets, quotes, XML tags, and more. vim-multiple-cursors is a Sublime Text style multiple selections for Vim Browse files: nnn \u00b6 Other projects: Ranger.vim , Ranger integration in vim search; fzf \u00b6 Commands \u00b6 Command Description :Files [PATH] Files (runs $FZF_DEFAULT_COMMAND if defined) :GFiles [OPTS] Git files ( git ls-files ) :GFiles? Git files ( git status ) :Buffers Open buffers :Colors Color schemes :Ag [PATTERN] ag search result ( ALT-A to select all, ALT-D to deselect all) :Rg [PATTERN] rg search result ( ALT-A to select all, ALT-D to deselect all) :Lines [QUERY] Lines in loaded buffers :BLines [QUERY] Lines in the current buffer :Tags [QUERY] Tags in the project ( ctags -R ) :BTags [QUERY] Tags in the current buffer :Marks Marks :Windows Windows :Locate PATTERN locate command output :History v:oldfiles and open buffers :History: Command history :History/ Search history :Snippets Snippets ( UltiSnips ) :Commits Git commits (requires [fugitive.vim][f]) :BCommits Git commits for the current buffer :Commands Commands :Maps Normal mode mappings :Helptags Help tags 1 :Filetypes File types Other projects: ctrlp.vim is a fuzzy file, buffer, mru, tag finder. ack.vim is a plugin for the Perl module / CLI script 'ack'. DB \u00b6 Modern database interface for Vim Linting: ALE \u00b6 ALE supports a wide range of tools","title":"Plugins"},{"location":"vim/plugins/#plugins","text":"","title":"Plugins"},{"location":"vim/plugins/#vim-interface","text":"","title":"Vim interface"},{"location":"vim/plugins/#airline","text":"provides a status/tabline for vim. Airline integrates with a lot of utilities and therefor has a lot of configuration variables, see doc. Github project README +-----------------------------------------------------------------------------+ |~ | |~ | |~ VIM - Vi IMproved | |~ | |~ version 8.2 | |~ by Bram Moolenaar et al. | |~ Vim is open source and freely distributable | |~ | |~ type :h :q<Enter> to exit | |~ type :help<Enter> or <F1> for on-line help | |~ type :help version8<Enter> for version info | |~ | |~ | +-----------------------------------------------------------------------------+ | A | B | C X | Y | Z | [...] | +-----------------------------------------------------------------------------+ The statusline is the colored line at the bottom, which contains the sections (possibly in different colors): section meaning (example) A displays the mode + additional flags like crypt/spell/paste (INSERT) B Environment status (VCS information - branch, hunk summary (master), [battery][61] level) C filename + read-only flag (~/.vim/vimrc RO) X filetype (vim) Y file encoding[fileformat] (utf-8[unix]) Z current position in the file [...] additional sections (warning/errors/statistics) from external plugins (e.g. YCM, syntastic, ...) The information in Section Z looks like this: 10% \u2630 10/100 ln : 20 This means: 10% - 10 percent down the top of the file \u2630 10 - current line 10 /100 ln - of 100 lines : 20 - current column 20","title":"Airline"},{"location":"vim/plugins/#tags","text":"https://github.com/liuchengxu/vista.vi://github.com/liuchengxu/vista.vim","title":"Tags"},{"location":"vim/plugins/#session","text":"obsession continuously updates session files. :mksession command to write a file.","title":"Session"},{"location":"vim/plugins/#file-editing","text":"vim-commentary comment stuff out vim-surround provides mapping for parentheses, brackets, quotes, XML tags, and more. vim-multiple-cursors is a Sublime Text style multiple selections for Vim","title":"File editing"},{"location":"vim/plugins/#browse-files-nnn","text":"Other projects: Ranger.vim , Ranger integration in vim","title":"Browse files: nnn"},{"location":"vim/plugins/#search-fzf","text":"","title":"search; fzf"},{"location":"vim/plugins/#commands","text":"Command Description :Files [PATH] Files (runs $FZF_DEFAULT_COMMAND if defined) :GFiles [OPTS] Git files ( git ls-files ) :GFiles? Git files ( git status ) :Buffers Open buffers :Colors Color schemes :Ag [PATTERN] ag search result ( ALT-A to select all, ALT-D to deselect all) :Rg [PATTERN] rg search result ( ALT-A to select all, ALT-D to deselect all) :Lines [QUERY] Lines in loaded buffers :BLines [QUERY] Lines in the current buffer :Tags [QUERY] Tags in the project ( ctags -R ) :BTags [QUERY] Tags in the current buffer :Marks Marks :Windows Windows :Locate PATTERN locate command output :History v:oldfiles and open buffers :History: Command history :History/ Search history :Snippets Snippets ( UltiSnips ) :Commits Git commits (requires [fugitive.vim][f]) :BCommits Git commits for the current buffer :Commands Commands :Maps Normal mode mappings :Helptags Help tags 1 :Filetypes File types Other projects: ctrlp.vim is a fuzzy file, buffer, mru, tag finder. ack.vim is a plugin for the Perl module / CLI script 'ack'.","title":"Commands"},{"location":"vim/plugins/#db","text":"Modern database interface for Vim","title":"DB"},{"location":"vim/plugins/#linting-ale","text":"ALE supports a wide range of tools","title":"Linting: ALE"},{"location":"vim/script/","text":"Vim script \u00b6 Options \u00b6 Set options : set or se Cmd Comment :se[t][!] show all options that differ from the default value, ! forces printing to new line :se[t][!] all show all but terminal options, if ! : every option is on a separate line. :se[t] {option}? show value of option :se[t] {option} Toggle option: set, switch it on. Number option: show value. String option: show value. Variables \u00b6 Scope: Scope Identifier Comment buffer-variable b: Local to the current buffer. window-variable w: Local to the current window tabpage-variable t: Local to the current tab page. global-variable g: Global. local-variable l: Local to a function. script-variable s: Local to a Vim script. function-argument a: Function argument (only inside a function). vim-variable v: Global, predefined by Vim. Commands \u00b6 Vim doc: :h user-commands : com [mand][ ! ] [{attr}...] {cmd} {rep} -nargs : specify that the command can take arguments. -nargs=0 No arguments are allowed (the default) -nargs=1 Exactly one argument is required, it includes spaces -nargs=* Any number of arguments are allowed (0, 1, or many), separated by white space -nargs=? 0 or 1 arguments are allowed -nargs=+ Arguments must be supplied, but any number are allowed -complete enables argument completion. -complete=arglist file names in argument list -complete=augroup autocmd groups -complete=buffer buffer names -complete=behave :behave suboptions -complete=color color schemes -complete=command Ex command (and arguments) -complete=compiler compilers -complete=cscope |:cscope| suboptions -complete=dir directory names -complete=environment environment variable names -complete=event autocommand events -complete=expression Vim expression -complete=file file and directory names -complete=file_in_path file and directory names in |'path'| -complete=filetype filetype names |'filetype'| -complete=function function name -complete=help help subjects -complete=highlight highlight groups -complete=history :history suboptions -complete=locale locale names (as output of locale -a) -complete=mapclear buffer argument -complete=mapping mapping name -complete=menu menus -complete=messages |:messages| suboptions -complete=option options -complete=packadd optional package |pack-add| names -complete=shellcmd Shell command -complete=sign |:sign| suboptions -complete=syntax syntax file names |'syntax'| -complete=syntime |:syntime| suboptions -complete=tag tags -complete=tag_listfiles tags, file names are shown when CTRL-D is hit -complete=user user names -complete=var user variables -complete=custom,{func} custom completion, defined via {func} -complete=customlist,{func} custom completion, defined via {func} -bang The command can take a ! modifier (like :q or :w) -bar The command can be followed by a \"|\" and another command. A \"|\" inside the command argument is not allowed then. Also checks for a \" to start a comment. -register The first argument to the command can be an optional register name (like :del, :put, :yank). -buffer The command will only be available in the current buffer. -range Range allowed, default is current line -range=% Range allowed, default is whole file (1,$) -range=N A count (default N) which is specified in the line number position (like |:split|); allows for zero line number. -count=N A count (default N) which is specified either in the line number position, or as an initial argument (like |:Next|). -count acts like -count=0 Note that -range=N and -count=N are mutually exclusive - only one should be specified.","title":"Script"},{"location":"vim/script/#vim-script","text":"","title":"Vim script"},{"location":"vim/script/#options","text":"Set options : set or se Cmd Comment :se[t][!] show all options that differ from the default value, ! forces printing to new line :se[t][!] all show all but terminal options, if ! : every option is on a separate line. :se[t] {option}? show value of option :se[t] {option} Toggle option: set, switch it on. Number option: show value. String option: show value.","title":"Options"},{"location":"vim/script/#variables","text":"Scope: Scope Identifier Comment buffer-variable b: Local to the current buffer. window-variable w: Local to the current window tabpage-variable t: Local to the current tab page. global-variable g: Global. local-variable l: Local to a function. script-variable s: Local to a Vim script. function-argument a: Function argument (only inside a function). vim-variable v: Global, predefined by Vim.","title":"Variables"},{"location":"vim/script/#commands","text":"Vim doc: :h user-commands : com [mand][ ! ] [{attr}...] {cmd} {rep} -nargs : specify that the command can take arguments. -nargs=0 No arguments are allowed (the default) -nargs=1 Exactly one argument is required, it includes spaces -nargs=* Any number of arguments are allowed (0, 1, or many), separated by white space -nargs=? 0 or 1 arguments are allowed -nargs=+ Arguments must be supplied, but any number are allowed -complete enables argument completion. -complete=arglist file names in argument list -complete=augroup autocmd groups -complete=buffer buffer names -complete=behave :behave suboptions -complete=color color schemes -complete=command Ex command (and arguments) -complete=compiler compilers -complete=cscope |:cscope| suboptions -complete=dir directory names -complete=environment environment variable names -complete=event autocommand events -complete=expression Vim expression -complete=file file and directory names -complete=file_in_path file and directory names in |'path'| -complete=filetype filetype names |'filetype'| -complete=function function name -complete=help help subjects -complete=highlight highlight groups -complete=history :history suboptions -complete=locale locale names (as output of locale -a) -complete=mapclear buffer argument -complete=mapping mapping name -complete=menu menus -complete=messages |:messages| suboptions -complete=option options -complete=packadd optional package |pack-add| names -complete=shellcmd Shell command -complete=sign |:sign| suboptions -complete=syntax syntax file names |'syntax'| -complete=syntime |:syntime| suboptions -complete=tag tags -complete=tag_listfiles tags, file names are shown when CTRL-D is hit -complete=user user names -complete=var user variables -complete=custom,{func} custom completion, defined via {func} -complete=customlist,{func} custom completion, defined via {func} -bang The command can take a ! modifier (like :q or :w) -bar The command can be followed by a \"|\" and another command. A \"|\" inside the command argument is not allowed then. Also checks for a \" to start a comment. -register The first argument to the command can be an optional register name (like :del, :put, :yank). -buffer The command will only be available in the current buffer. -range Range allowed, default is current line -range=% Range allowed, default is whole file (1,$) -range=N A count (default N) which is specified in the line number position (like |:split|); allows for zero line number. -count=N A count (default N) which is specified either in the line number position, or as an initial argument (like |:Next|). -count acts like -count=0 Note that -range=N and -count=N are mutually exclusive - only one should be specified.","title":"Commands"},{"location":"vim/search/","text":"Search \u00b6","title":"Search"},{"location":"vim/search/#search","text":"","title":"Search"},{"location":"vim/statusline/","text":"Status line \u00b6 Visibility \u00b6 Visibility is controled by set laststatus /badge-doc>","title":"Status line"},{"location":"vim/statusline/#status-line","text":"","title":"Status line"},{"location":"vim/statusline/#visibility","text":"Visibility is controled by set laststatus /badge-doc>","title":"Visibility"}]}