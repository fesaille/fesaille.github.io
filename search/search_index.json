{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"aze/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library. High-level \u00b6 In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia Interpreted \u00b6 There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled First, consider only the upper direct path. The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program. Bytecode example \u00b6 print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\"). General purpose \u00b6 https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python Garbage collected \u00b6 https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"Aze"},{"location":"aze/#high-level","text":"In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia","title":"High-level"},{"location":"aze/#interpreted","text":"There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled First, consider only the upper direct path. The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program.","title":"Interpreted"},{"location":"aze/#bytecode-example","text":"print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\").","title":"Bytecode example"},{"location":"aze/#general-purpose","text":"https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python","title":"General purpose"},{"location":"aze/#garbage-collected","text":"https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"Garbage collected"},{"location":"DB/intro/","text":"Database \u00b6 Entity Relationship Diagram (ERD) \u00b6 Type of data modeling representing objects or concepts within an information system or organization and their relation to one other. EdgeDB Framework \u00b6 Ibis \u00b6 Data catalog \u00b6 Intake \u00b6 Persisting data","title":"intro"},{"location":"DB/intro/#database","text":"","title":"Database"},{"location":"DB/intro/#entity-relationship-diagram-erd","text":"Type of data modeling representing objects or concepts within an information system or organization and their relation to one other. EdgeDB","title":"Entity Relationship Diagram (ERD)"},{"location":"DB/intro/#framework","text":"","title":"Framework"},{"location":"DB/intro/#ibis","text":"","title":"Ibis"},{"location":"DB/intro/#data-catalog","text":"","title":"Data catalog"},{"location":"DB/intro/#intake","text":"Persisting data","title":"Intake"},{"location":"DB/S3/_intro/","text":"Object Store (S3) \u00b6 MinIO \u00b6 https://docs.min.io/docs/minio-multi-user-quickstart-guide.html S3 API: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html","title":"Intro"},{"location":"DB/S3/_intro/#object-store-s3","text":"","title":"Object Store (S3)"},{"location":"DB/S3/_intro/#minio","text":"https://docs.min.io/docs/minio-multi-user-quickstart-guide.html S3 API: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html","title":"MinIO"},{"location":"DB/SQL/_intro/","text":"SQL within Python \u00b6 For sql like data access, SQLAlchemy consists of two distinct components, known as the Core (abstraction toolkit) and an optional but convenient ORM (Object Relational Mapper). For analytics, Pandas provides facili tes and loads the data into the memory of the local host, Ibis leaves the data in its storage, and performs the computations there For SQL command in jupyter, see the SQL jupyter magic and a notebook example","title":"Intro"},{"location":"DB/SQL/_intro/#sql-within-python","text":"For sql like data access, SQLAlchemy consists of two distinct components, known as the Core (abstraction toolkit) and an optional but convenient ORM (Object Relational Mapper). For analytics, Pandas provides facili tes and loads the data into the memory of the local host, Ibis leaves the data in its storage, and performs the computations there For SQL command in jupyter, see the SQL jupyter magic and a notebook example","title":"SQL within Python"},{"location":"DB/SQL/postgres/","text":"PostgreSQL \u00b6 Connect From Your Local Machine to a PostgreSQL Database in Docker https://medium.com/better-programming/connect-from-local-machine-to-postgresql-docker-container-f785f00461a7 Linux downloads (Ubuntu) https://www.postgresql.org/download/linux/ubuntu/ http://zetcode.com/db/postgresqlc/ Docker \u00b6","title":"PostgreSQL"},{"location":"DB/SQL/postgres/#postgresql","text":"Connect From Your Local Machine to a PostgreSQL Database in Docker https://medium.com/better-programming/connect-from-local-machine-to-postgresql-docker-container-f785f00461a7 Linux downloads (Ubuntu) https://www.postgresql.org/download/linux/ubuntu/ http://zetcode.com/db/postgresqlc/","title":"PostgreSQL"},{"location":"DB/SQL/postgres/#docker","text":"","title":"Docker"},{"location":"DB/mongoDB/Aggregation/","text":"Aggregation framework \u00b6 Selection stage \u00b6 $match - filtering documents \u00b6 Code { $ match : { < query > } } a $match may contain a $text query operator, but it must be the first in the pipeline $match should come early in the pipeline $where can not be used with $match $match uses the same syntax as find() $project - shaping document \u00b6 { $project: { } } specify fields to be retained _id must be explicitly removed let add new fields or reassign values can be used as many times as required in an aggregation pipeline $addFields : add transformation fields in the document \u00b6 $geoNear : filtering documents \u00b6 Cursor-like stages \u00b6 $limit : limit \u00b6 $skip : limit \u00b6 $count : limit \u00b6 $sort : limit \u00b6 $sample : limit \u00b6 Group stage \u00b6 $group : limit \u00b6","title":"Aggregation framework"},{"location":"DB/mongoDB/Aggregation/#aggregation-framework","text":"","title":"Aggregation framework"},{"location":"DB/mongoDB/Aggregation/#selection-stage","text":"","title":"Selection stage"},{"location":"DB/mongoDB/Aggregation/#match-filtering-documents","text":"Code { $ match : { < query > } } a $match may contain a $text query operator, but it must be the first in the pipeline $match should come early in the pipeline $where can not be used with $match $match uses the same syntax as find()","title":"$match - filtering documents"},{"location":"DB/mongoDB/Aggregation/#project-shaping-document","text":"{ $project: { } } specify fields to be retained _id must be explicitly removed let add new fields or reassign values can be used as many times as required in an aggregation pipeline","title":"$project - shaping document"},{"location":"DB/mongoDB/Aggregation/#addfields-add-transformation-fields-in-the-document","text":"","title":"$addFields: add transformation fields in the document"},{"location":"DB/mongoDB/Aggregation/#geonear-filtering-documents","text":"","title":"$geoNear: filtering    documents"},{"location":"DB/mongoDB/Aggregation/#cursor-like-stages","text":"","title":"Cursor-like stages"},{"location":"DB/mongoDB/Aggregation/#limit-limit","text":"","title":"$limit: limit"},{"location":"DB/mongoDB/Aggregation/#skip-limit","text":"","title":"$skip: limit"},{"location":"DB/mongoDB/Aggregation/#count-limit","text":"","title":"$count: limit"},{"location":"DB/mongoDB/Aggregation/#sort-limit","text":"","title":"$sort: limit"},{"location":"DB/mongoDB/Aggregation/#sample-limit","text":"","title":"$sample: limit"},{"location":"DB/mongoDB/Aggregation/#group-stage","text":"","title":"Group stage"},{"location":"DB/mongoDB/Aggregation/#group-limit","text":"","title":"$group: limit"},{"location":"DB/mongoDB/_intro/","text":"MongoDB \u00b6 Notation: field path: $fieldName system variable: $$UPPERCASE user variable: $$foo Docker image \u00b6 Jupyter kernel imongo \u00b6 imongo ipython wrapper kernel Jupyter messenging doc http://zguide.zeromq.org/page:all","title":"Intro"},{"location":"DB/mongoDB/_intro/#mongodb","text":"Notation: field path: $fieldName system variable: $$UPPERCASE user variable: $$foo","title":"MongoDB"},{"location":"DB/mongoDB/_intro/#docker-image","text":"","title":"Docker image"},{"location":"DB/mongoDB/_intro/#jupyter-kernel-imongo","text":"imongo ipython wrapper kernel Jupyter messenging doc http://zguide.zeromq.org/page:all","title":"Jupyter kernel imongo"},{"location":"Python/IterGen/","text":"Iterators, generators and coroutines \u00b6 Python standard library: Itertools David Beazley's PyCon'14 presentation","title":"Iterators, generators and coroutines"},{"location":"Python/IterGen/#iterators-generators-and-coroutines","text":"Python standard library: Itertools David Beazley's PyCon'14 presentation","title":"Iterators, generators and coroutines"},{"location":"Python/envs/","text":"Virtual environement \u00b6 venv \u00b6 Pipenv \u00b6 editable-dependencies pipenv install --dev -e . Poetry \u00b6","title":"Envs"},{"location":"Python/envs/#virtual-environement","text":"","title":"Virtual environement"},{"location":"Python/envs/#venv","text":"","title":"venv"},{"location":"Python/envs/#pipenv","text":"editable-dependencies pipenv install --dev -e .","title":"Pipenv"},{"location":"Python/envs/#poetry","text":"","title":"Poetry"},{"location":"Python/test/","text":"Tests \u00b6 tox","title":"Tests"},{"location":"Python/test/#tests","text":"tox","title":"Tests"},{"location":"Python/typing/","text":"Typing \u00b6 Sous-titre \u00b6 PEPS: Literature Overview for Type Hints Theory of Type Hints Type Hints TypedDict Protocols: Structural subtyping ClassVar ContextManager Counter DefaultDict Deque final Final Literal NewType NoReturn overload (note that older versions of typing only let you use overload in stubs) Protocol (except on Python 3.5.0) runtime (except on Python 3.5.0) Text Type TypedDict TYPE_CHECKING Package providing: pydantic","title":"Typing"},{"location":"Python/typing/#typing","text":"","title":"Typing"},{"location":"Python/typing/#sous-titre","text":"PEPS: Literature Overview for Type Hints Theory of Type Hints Type Hints TypedDict Protocols: Structural subtyping ClassVar ContextManager Counter DefaultDict Deque final Final Literal NewType NoReturn overload (note that older versions of typing only let you use overload in stubs) Protocol (except on Python 3.5.0) runtime (except on Python 3.5.0) Text Type TypedDict TYPE_CHECKING Package providing: pydantic","title":"Sous-titre"},{"location":"Viz/matplotlib/","text":"Matplotlib \u00b6 verything in matplotlib is organized in a hierarchy: at the top of the hierarchy is the matplotlib \"state-machine environment\" which is provided by the matplotlib.pyplot module. At this level, simple functions are used to add plot elements (lines, images, text, etc.) to the current axes in the current figure. https://dev.to/skotaro/artist-in-matplotlib---something-i-wanted-to-know-before-spending-tremendous-hours-on-googling-how-tos--31oo Anatomy of a figure \u00b6 https://matplotlib.org/tutorials/intermediate/artists.html Axis \u00b6 Accessor method Description get_scale The scale of the axis, e.g., 'log' or 'linear' get_view_interval The interval instance of the axis view limits get_data_interval The interval instance of the axis data limits get_gridlines A list of grid lines for the Axis get_label The axis label - a Text instance get_ticklabels A list of Text instances - keyword minor-True get_ticklines A list of Line2D instances - keyword minor-True get_ticklocs A list of Tick locations - keyword minor-True get_major_locator The matplotlib.ticker.Locator instance for major ticks get_major_formatter The matplotlib.ticker.Formatter instance for major ticks get_minor_locator The matplotlib.ticker.Locator instance for minor ticks get_minor_formatter The matplotlib.ticker.Formatter instance for minor ticks get_major_ticks A list of Tick instances for major ticks get_minor_ticks A list of Tick instances for minor ticks grid Turn the grid on or off for the major or minor ticks Spines \u00b6","title":"Matplolib"},{"location":"Viz/matplotlib/#matplotlib","text":"verything in matplotlib is organized in a hierarchy: at the top of the hierarchy is the matplotlib \"state-machine environment\" which is provided by the matplotlib.pyplot module. At this level, simple functions are used to add plot elements (lines, images, text, etc.) to the current axes in the current figure. https://dev.to/skotaro/artist-in-matplotlib---something-i-wanted-to-know-before-spending-tremendous-hours-on-googling-how-tos--31oo","title":"Matplotlib"},{"location":"Viz/matplotlib/#anatomy-of-a-figure","text":"https://matplotlib.org/tutorials/intermediate/artists.html","title":"Anatomy of a figure"},{"location":"Viz/matplotlib/#axis","text":"Accessor method Description get_scale The scale of the axis, e.g., 'log' or 'linear' get_view_interval The interval instance of the axis view limits get_data_interval The interval instance of the axis data limits get_gridlines A list of grid lines for the Axis get_label The axis label - a Text instance get_ticklabels A list of Text instances - keyword minor-True get_ticklines A list of Line2D instances - keyword minor-True get_ticklocs A list of Tick locations - keyword minor-True get_major_locator The matplotlib.ticker.Locator instance for major ticks get_major_formatter The matplotlib.ticker.Formatter instance for major ticks get_minor_locator The matplotlib.ticker.Locator instance for minor ticks get_minor_formatter The matplotlib.ticker.Formatter instance for minor ticks get_major_ticks A list of Tick instances for major ticks get_minor_ticks A list of Tick instances for minor ticks grid Turn the grid on or off for the major or minor ticks","title":"Axis"},{"location":"Viz/matplotlib/#spines","text":"","title":"Spines"},{"location":"WebDev/Intro/","text":"Web Developpment \u00b6 HTML and DOM specifications are issued from 2 main organisms, W3C and WHATWG 1 : WHATWG maintains the HTML and DOM Living Standards W3C bridges communities, develop use cases, fill issues, write tests, mediate issue resolution HTML semantic elements \u00b6 Elements, attributes, and attribute values in HTML are defined (by this specification) to have certain meanings (semantics). For example, the ol element represents an ordered list, and the lang attribute represents the language of the content. These definitions allow HTML processors, such as Web browsers or search engines, to present and use documents and applications in a wide variety of contexts that the author might not have considered. 2 Kind of content \u00b6 article aside nav section Heading content h1 h2 h3 h4 h5 h6 hgroup Web components \u00b6 JavaScript file defines a class called PopUpInfo , which extends HTMLElement . Inside the constructor, all the functionality the element will have when an instance of it is instantiated. Example Create a badge similar to the one at the top of the page: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class DocBadge extends HTMLElement { constructor () { // Always call super first in constructor super (); // Create a documentation badge var shadow = this . attachShadow ({ mode : 'open' }); var wrapper = document . createElement ( 'span' ); wrapper . setAttribute ( 'class' , 'myBadge' ); var href = this . hasAttribute ( 'href' ) ? this . getAttribute ( 'href' ) : 'img/default.png' ; var alt = this . hasAttribute ( 'alt' ) ? this . getAttribute ( 'alt' ) : 'Documentation' ; var label = this . hasAttribute ( 'label' ) ? this . getAttribute ( 'label' ) : 'docs' ; var message = this . hasAttribute ( 'message' ) ? this . getAttribute ( 'message' ) : 'stable' ; var color = this . hasAttribute ( 'color' ) ? this . getAttribute ( 'color' ) : 'brightgreen' ; var logo = this . hasAttribute ( 'logo' ) ? this . getAttribute ( 'logo' ) : 'Read-the-docs' ; var src = `https://img.shields.io/badge/ ${ label } - ${ message } - ${ color } ?style=flat&logo= ${ logo } ` ; var link = document . createElement ( 'a' ); link . setAttribute ( 'target' , '_blank' ); link . setAttribute ( 'href' , href ); var img = document . createElement ( 'img' ); img . setAttribute ( 'src' , src ); img . setAttribute ( 'alt' , alt ); shadow . appendChild ( wrapper ); wrapper . appendChild ( link ); link . appendChild ( img ); } } // register it customElements . define ( 'badge-doc' , DocBadge ); Usage: < badge-doc href = \"https://developer.mozilla.org/en-US/docs/Web/Web_Components\" message = \"MDN\" color = \"lightgrey\" ></ badge-doc > Resources \u00b6 Shield badges Simple icons W3C and WHATWG to work together to advance the open Web platform \u21a9 WHATWG spec \u21a9","title":"Intro"},{"location":"WebDev/Intro/#web-developpment","text":"HTML and DOM specifications are issued from 2 main organisms, W3C and WHATWG 1 : WHATWG maintains the HTML and DOM Living Standards W3C bridges communities, develop use cases, fill issues, write tests, mediate issue resolution","title":"Web Developpment"},{"location":"WebDev/Intro/#html-semantic-elements","text":"Elements, attributes, and attribute values in HTML are defined (by this specification) to have certain meanings (semantics). For example, the ol element represents an ordered list, and the lang attribute represents the language of the content. These definitions allow HTML processors, such as Web browsers or search engines, to present and use documents and applications in a wide variety of contexts that the author might not have considered. 2","title":"HTML semantic elements"},{"location":"WebDev/Intro/#kind-of-content","text":"article aside nav section Heading content h1 h2 h3 h4 h5 h6 hgroup","title":"Kind of content"},{"location":"WebDev/Intro/#web-components","text":"JavaScript file defines a class called PopUpInfo , which extends HTMLElement . Inside the constructor, all the functionality the element will have when an instance of it is instantiated. Example Create a badge similar to the one at the top of the page: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class DocBadge extends HTMLElement { constructor () { // Always call super first in constructor super (); // Create a documentation badge var shadow = this . attachShadow ({ mode : 'open' }); var wrapper = document . createElement ( 'span' ); wrapper . setAttribute ( 'class' , 'myBadge' ); var href = this . hasAttribute ( 'href' ) ? this . getAttribute ( 'href' ) : 'img/default.png' ; var alt = this . hasAttribute ( 'alt' ) ? this . getAttribute ( 'alt' ) : 'Documentation' ; var label = this . hasAttribute ( 'label' ) ? this . getAttribute ( 'label' ) : 'docs' ; var message = this . hasAttribute ( 'message' ) ? this . getAttribute ( 'message' ) : 'stable' ; var color = this . hasAttribute ( 'color' ) ? this . getAttribute ( 'color' ) : 'brightgreen' ; var logo = this . hasAttribute ( 'logo' ) ? this . getAttribute ( 'logo' ) : 'Read-the-docs' ; var src = `https://img.shields.io/badge/ ${ label } - ${ message } - ${ color } ?style=flat&logo= ${ logo } ` ; var link = document . createElement ( 'a' ); link . setAttribute ( 'target' , '_blank' ); link . setAttribute ( 'href' , href ); var img = document . createElement ( 'img' ); img . setAttribute ( 'src' , src ); img . setAttribute ( 'alt' , alt ); shadow . appendChild ( wrapper ); wrapper . appendChild ( link ); link . appendChild ( img ); } } // register it customElements . define ( 'badge-doc' , DocBadge ); Usage: < badge-doc href = \"https://developer.mozilla.org/en-US/docs/Web/Web_Components\" message = \"MDN\" color = \"lightgrey\" ></ badge-doc >","title":"Web components"},{"location":"WebDev/Intro/#resources","text":"Shield badges Simple icons W3C and WHATWG to work together to advance the open Web platform \u21a9 WHATWG spec \u21a9","title":"Resources"},{"location":"WebDev/REACT/","text":"REACT \u00b6 Synthetic events Theme \u00b6 material UI Forms \u00b6 See formik https://jaredpalmer.com/formik/docs/overview Hooks \u00b6 Introducing hooks Books \u00b6 Learning react by Kirupa Chinnathambi azeaze qsd Eloquent JavaScript by Marijn Haverbeke Read favorite Eloquent JavaScript by Marijn Haverbeke Read favorite","title":"REACT"},{"location":"WebDev/REACT/#react","text":"Synthetic events","title":"REACT"},{"location":"WebDev/REACT/#theme","text":"material UI","title":"Theme"},{"location":"WebDev/REACT/#forms","text":"See formik https://jaredpalmer.com/formik/docs/overview","title":"Forms"},{"location":"WebDev/REACT/#hooks","text":"Introducing hooks","title":"Hooks"},{"location":"WebDev/REACT/#books","text":"","title":"Books"},{"location":"WebDev/css/","text":"CSS \u00b6 Element size \u00b6 Width [ <length> | <percentage> ] && [ border-box | content-box ]? | available | min-content | max-content | fit-content | auto Flex box \u00b6 Initialisation \u00b6 display: flex; or display: inline-flex; Properties that apply to the parent \u00b6 Ordering and Orientation \u00b6 Property Value Comment flex-direction row | row-reverse | column | column-reverse Ex. : div { flex-direction: row; } flex-wrap nowrap | wrap | wrap-reverse Ex. : div { flex-direction: column; flex-wrap: wrap; } flex-flow see individual properties Shorthand for flex-direction and flex-wrap Ex. : div { felx-flow: row-reverse wrap-reverse; } 1 2 3 4 1 2 3 4 Ordering justify-content align-items align-content Property Value Comment justify-content flex-start | flex-end | center | space-between | space-around align-items flex-start | flex-end | center | baseline | stretch align-content flex-start | flex-end | center | space-between | space-around | stretch Properties that apply to the child elements \u00b6 Ordering order : flex flow direction Property Value order <integer> Flexibility Property Value flex-grow <number> flex-shrink <number> flex-basis content | <width>","title":"CSS"},{"location":"WebDev/css/#css","text":"","title":"CSS"},{"location":"WebDev/css/#element-size","text":"Width [ <length> | <percentage> ] && [ border-box | content-box ]? | available | min-content | max-content | fit-content | auto","title":"Element size"},{"location":"WebDev/css/#flex-box","text":"","title":"Flex box"},{"location":"WebDev/css/#initialisation","text":"display: flex; or display: inline-flex;","title":"Initialisation"},{"location":"WebDev/css/#properties-that-apply-to-the-parent","text":"","title":"Properties that apply to the parent"},{"location":"WebDev/css/#ordering-and-orientation","text":"Property Value Comment flex-direction row | row-reverse | column | column-reverse Ex. : div { flex-direction: row; } flex-wrap nowrap | wrap | wrap-reverse Ex. : div { flex-direction: column; flex-wrap: wrap; } flex-flow see individual properties Shorthand for flex-direction and flex-wrap Ex. : div { felx-flow: row-reverse wrap-reverse; } 1 2 3 4 1 2 3 4 Ordering justify-content align-items align-content Property Value Comment justify-content flex-start | flex-end | center | space-between | space-around align-items flex-start | flex-end | center | baseline | stretch align-content flex-start | flex-end | center | space-between | space-around | stretch","title":"Ordering and Orientation"},{"location":"WebDev/css/#properties-that-apply-to-the-child-elements","text":"Ordering order : flex flow direction Property Value order <integer> Flexibility Property Value flex-grow <number> flex-shrink <number> flex-basis content | <width>","title":"Properties that apply to the child elements"},{"location":"WebDev/node/","text":"Node.js \u00b6 List packages and version from package-lock.json using jq cat package-lock.json | jq '[.dependencies | to_entries[] | {\"key\": .key, \"value\": .value.version}] | from_entries'","title":"node"},{"location":"WebDev/node/#nodejs","text":"List packages and version from package-lock.json using jq cat package-lock.json | jq '[.dependencies | to_entries[] | {\"key\": .key, \"value\": .value.version}] | from_entries'","title":"Node.js"},{"location":"_nb/04_influxDB/01%20-%20Intro%20InfluxDB/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); InfluxDB is a time series database designed to handle timestamped data, including DevOps monitoring, application metrics, IoT sensor data, and real-time analytics. Key features \u00b6 CLI/HTTP write and query API. Expressive SQL-like query language Schemas don't have to be defined up front and schema preferences may change over time. Tags allow series to be indexed for fast and efficient queries. Retention policies efficiently auto-expire stale data. Plugins support for other data ingestion protocols such as Graphite, collectd, and OpenTSDB. Continuous queries automatically compute aggregate data to make frequent queries more efficient. InfluxDB isn\u2019t fully CRUD The open source edition of InfluxDB runs on a single node, high availability is only available in the InfluxDB Enterprise Edition. Data structure \u00b6 Time series key concepts : - time - a timestamp - is similar to a SQL primary key, - tags , zero to many key-values, contain any metadata about the value, tags are indexed - at least one key-value field set ( `field key identifies the measured element while field value are the measured value itself, e.g. \u201cvalue=0.64\u201d, or \u201ctemperature=21.2\u201d). **fields are not indexed** It\u2019s important to note that fields are not indexed. Queries that use field values as filters must scan all values that match the other conditions in the query. As a result, those queries are not performant relative to queries on tags. In general, fields should not contain commonly-queried metadata. Further concepts: - a measurement acts as a container for tags , fields , and the time column. Assimilable to a SQL table, where the primary index is always time . tags and fields are effectively columns in the table. - a series is the collection of data that share the same retention policy, measurement, and tag set. - a point represents a single data record that has four components: a measurement, tag set, field set, and a timestamp. A point is uniquely identified by its series and timestamp (similar to a row in a SQL database table) Element Optional/Required Description Type (See data types for more information.) Measurement Required The measurement name. InfluxDB accepts one measurement per point. String Tag set Optional All tag key-value pairs for the point. Tag keys and tag values are both strings. Field set Required. Points must have at least one field. All field key-value pairs for the point. Field keys are strings. Field values can be floats, integers, strings, or Booleans. Timestamp Optional. InfluxDB uses the server\u2019s local nanosecond timestamp in UTC if the timestamp is not included with the point. The timestamp for the data point. InfluxDB accepts one timestamp per point. Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API . Data type \u00b6 Datatype Element(s) Description Float Field values IEEE-754 64-bit floating-point numbers. This is the default numerical type. Examples: 1 , 1.0 , 1.e+78 , 1.E+78 . Integer Field values Signed 64-bit integers (-9223372036854775808 to 9223372036854775807). Specify an integer with a trailing i on the number. Example: 1i . String Measurements, tag keys, tag values, field keys, field values Length limit 64KB. Boolean Field values Stores TRUE or FALSE values. TRUE write syntax: [t, T, true, True, TRUE] . FALSE write syntax: [f, F, false, False, FALSE] Timestamp Timestamps Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API . The minimum valid timestamp is -9223372036854775806 or 1677-09-21T00:12:43.145224194Z . The maximum valid timestamp is 9223372036854775806 or 2262-04-11T23:47:16.854775806Z . Python module documentation Example \u00b6 *census*: time butterflies honeybees location scientist 2015-08-18T00:00:00Z 12 23 1 langstroth 2015-08-18T00:00:00Z 1 30 1 perpetua 2015-08-18T00:06:00Z 11 28 1 langstroth 015-08-18T00:06:00Z 3 28 1 perpetua 2015-08-18T05:54:00Z 2 11 2 langstroth 2015-08-18T06:00:00Z 1 10 2 langstroth 2015-08-18T06:06:00Z 8 23 2 perpetua 2015-08-18T06:12:00Z 7 22 2 perpetua **8 field sets** butterflies = 12 honeybees = 23 butterflies = 1 honeybees = 30 butterflies = 11 honeybees = 28 butterflies = 3 honeybees = 28 butterflies = 2 honeybees = 11 butterflies = 1 honeybees = 10 butterflies = 8 honeybees = 23 butterflies = 7 honeybees = 22 **4 tag sets** (different combinations of all the tag key-value pairs) location = 1, scientist = langstroth location = 2, scientist = langstroth location = 1, scientist = perpetua location = 2, scientist = perpetua Arbitrary series number Retention policy Measurement Tag set series 1 autogen census location = 1 , scientist = langstroth series 2 autogen census location = 2 , scientist = langstroth series 3 autogen census location = 1 , scientist = perpetua series 4 autogen census location = 2 , scientist = perpetua from datetime import ( datetime , timedelta ) from random import ( choice , randint , random , uniform , lognormvariate ) from influxdb import ( InfluxDBClient , DataFrameClient ) INFLUXDB_USER = 'telegraf' INFLUXDB_USER_PASSWORD = 'secretpassword' host = 'db.influxdb.app.com' port = 8086 \"\"\"Instantiate a connection to the InfluxDB.\"\"\" user = 'admin' password = 'supersecretpassword' dbname = 'example' dbuser = 'telegraf' dbuser_password = 'secretpassword' client = InfluxDBClient ( host , port , user , password , dbname ) DB init \u00b6 For creating the DB client.create_database(dbname) Define a specific retention policy, drop after 30d, with replica factor of 3 and applied by default to new elements client . create_retention_policy ( 'custom_policy' , '30d' , 3 , default = True ) # For dropping the policy: client.drop_retention_policy('custom_policy', dbname) client . switch_user ( dbuser , dbuser_password ) def feed_db ( n ): json_body = [ { \"measurement\" : \"starfleet_01\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"speed\" : lognormvariate ( 10 , 3 ), \"consumption\" : uniform ( 0 , 300 ), \"pressure_a\" : 3 + random (), \"status_b\" : choice (( True , False )) } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) def feed_db_array ( n ): json_body = [ { \"measurement\" : \"starfleet_02\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"curve_b[0]\" : 10 + random (), \"curve_b[1]\" : choice (( 15 + random (), 4 + random ())), \"curve_b[2]\" : 20 + random (), } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) % timeit feed_db ( 100_000 ) 13.2 s \u00b1 202 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) feed_db_array(1_000_000) Series can be deleted client.delete_series(database=\"example\", measurement=\"starfleet_01\") client . query ( query = 'select count(*) from starfleet_01' ) ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count_consumption': 1866653, 'count_pressure_a': 1866653, 'count_speed': 1866653, 'count_status_b': 1866653}]}) from IPython.core.magic import ( register_line_cell_magic ) @register_line_cell_magic def influxql ( line , cell = None ): \"Magic that works both as %lc magic and as %% lcmagic\" if cell is None : sqlstr = line else : sqlstr = \";\" . join (( op . strip ( \";\" ) for op in cell . strip ( \" \\n \" ) . split ( \" \\n \" ))) + \";\" return client . query ( query = sqlstr ) % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:05Z', 'speed': 774750.9698706511}, {'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}]}) result = % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; result ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}, {'time': '2019-08-19T20:52:25Z', 'speed': 9.829304084029904}]}) % influxql SELECT COUNT ( DISTINCT ( pressure_a )) FROM starfleet_01 ; ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count': 1000000}]}) % influxql SELECT COUNT ( pressure_a ) FROM starfleet_01 GROUP BY time ( 28 d ), region LIMIT 1 ; ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118099}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118282}], '('starfleet_01', {'region': 'Earth'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117988}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117959}]}) % influxql SELECT MEAN ( pressure_a ) FROM starfleet_01 GROUP BY region ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.499534039730786}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.4999780335201867}], '('starfleet_01', {'region': 'Earth'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5005520567253616}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5013387093463155}]}) You can explain query % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE region = 'Andoria' LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 750'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 2160'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 2160'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 5992395'}]}) % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE pressure_a > 3.5 LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 3000'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 8640'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 8640'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 23943525'}]}) res = % influxql SELECT * FROM \"starfleet_01\" WHERE pressure_a > 3.5 LIMIT 50 points = res . get_points ( tags = { \"region\" : \"Andoria\" }) from pandas import DataFrame df = DataFrame ( points ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region spacecraft speed status_b time 0 Archer 80.868742 3.764769 Andoria NX-1707 4.540769e+06 False 2019-07-28T01:35:50Z 1 Archer 64.351610 3.784118 Andoria NX-1707 8.549125e+05 False 2019-07-28T01:36:00Z 2 Archer 60.765559 3.907481 Andoria NX-1702 1.679463e+05 False 2019-07-28T01:36:04Z 3 Archer 252.870551 3.800938 Andoria NX-1706 1.444727e+04 True 2019-07-28T01:36:06Z 4 Kruge 192.871755 3.930994 Andoria NX-1702 4.376490e+03 False 2019-07-28T01:36:08Z df . groupby ( 'spacecraft' ) . max () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region speed status_b time spacecraft NX-1701 Kirk 226.626952 3.518973 Andoria 6.987498e+05 False 2019-07-28T01:38:44Z NX-1702 Kruge 217.135955 3.952388 Andoria 6.735246e+05 True 2019-07-28T01:37:38Z NX-1704 Kruge 278.172741 3.976138 Andoria 2.770339e+01 True 2019-07-28T01:37:54Z NX-1705 Kirk 197.423732 3.964069 Andoria 4.300635e+04 True 2019-07-28T01:37:42Z NX-1706 Kruge 252.870551 3.800938 Andoria 1.444727e+04 True 2019-07-28T01:37:02Z NX-1707 Kruge 289.899273 3.913948 Andoria 4.540769e+06 True 2019-07-28T01:38:46Z NX-1709 Kruge 272.085362 3.734222 Andoria 1.653500e+05 True 2019-07-28T01:37:30Z NX-1710 Kruge 297.309907 3.875039 Andoria 5.887814e+04 True 2019-07-28T01:38:20Z % influxql SHOW QUERIES ; ResultSet({'('results', None)': [{'qid': 2821, 'query': 'SHOW QUERIES', 'database': 'example', 'duration': '171\u00b5s', 'status': 'running'}]}) % influxql SHOW TAG KEYS ; ResultSet({'('starfleet_01', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}], '('starfleet_02', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}]})","title":"01   Intro InfluxDB"},{"location":"_nb/04_influxDB/01%20-%20Intro%20InfluxDB/#key-features","text":"CLI/HTTP write and query API. Expressive SQL-like query language Schemas don't have to be defined up front and schema preferences may change over time. Tags allow series to be indexed for fast and efficient queries. Retention policies efficiently auto-expire stale data. Plugins support for other data ingestion protocols such as Graphite, collectd, and OpenTSDB. Continuous queries automatically compute aggregate data to make frequent queries more efficient. InfluxDB isn\u2019t fully CRUD The open source edition of InfluxDB runs on a single node, high availability is only available in the InfluxDB Enterprise Edition.","title":"Key features"},{"location":"_nb/04_influxDB/01%20-%20Intro%20InfluxDB/#data-structure","text":"Time series key concepts : - time - a timestamp - is similar to a SQL primary key, - tags , zero to many key-values, contain any metadata about the value, tags are indexed - at least one key-value field set ( `field key identifies the measured element while field value are the measured value itself, e.g. \u201cvalue=0.64\u201d, or \u201ctemperature=21.2\u201d). **fields are not indexed** It\u2019s important to note that fields are not indexed. Queries that use field values as filters must scan all values that match the other conditions in the query. As a result, those queries are not performant relative to queries on tags. In general, fields should not contain commonly-queried metadata. Further concepts: - a measurement acts as a container for tags , fields , and the time column. Assimilable to a SQL table, where the primary index is always time . tags and fields are effectively columns in the table. - a series is the collection of data that share the same retention policy, measurement, and tag set. - a point represents a single data record that has four components: a measurement, tag set, field set, and a timestamp. A point is uniquely identified by its series and timestamp (similar to a row in a SQL database table) Element Optional/Required Description Type (See data types for more information.) Measurement Required The measurement name. InfluxDB accepts one measurement per point. String Tag set Optional All tag key-value pairs for the point. Tag keys and tag values are both strings. Field set Required. Points must have at least one field. All field key-value pairs for the point. Field keys are strings. Field values can be floats, integers, strings, or Booleans. Timestamp Optional. InfluxDB uses the server\u2019s local nanosecond timestamp in UTC if the timestamp is not included with the point. The timestamp for the data point. InfluxDB accepts one timestamp per point. Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API .","title":"Data structure"},{"location":"_nb/04_influxDB/01%20-%20Intro%20InfluxDB/#data-type","text":"Datatype Element(s) Description Float Field values IEEE-754 64-bit floating-point numbers. This is the default numerical type. Examples: 1 , 1.0 , 1.e+78 , 1.E+78 . Integer Field values Signed 64-bit integers (-9223372036854775808 to 9223372036854775807). Specify an integer with a trailing i on the number. Example: 1i . String Measurements, tag keys, tag values, field keys, field values Length limit 64KB. Boolean Field values Stores TRUE or FALSE values. TRUE write syntax: [t, T, true, True, TRUE] . FALSE write syntax: [f, F, false, False, FALSE] Timestamp Timestamps Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API . The minimum valid timestamp is -9223372036854775806 or 1677-09-21T00:12:43.145224194Z . The maximum valid timestamp is 9223372036854775806 or 2262-04-11T23:47:16.854775806Z . Python module documentation","title":"Data type"},{"location":"_nb/04_influxDB/01%20-%20Intro%20InfluxDB/#example","text":"*census*: time butterflies honeybees location scientist 2015-08-18T00:00:00Z 12 23 1 langstroth 2015-08-18T00:00:00Z 1 30 1 perpetua 2015-08-18T00:06:00Z 11 28 1 langstroth 015-08-18T00:06:00Z 3 28 1 perpetua 2015-08-18T05:54:00Z 2 11 2 langstroth 2015-08-18T06:00:00Z 1 10 2 langstroth 2015-08-18T06:06:00Z 8 23 2 perpetua 2015-08-18T06:12:00Z 7 22 2 perpetua **8 field sets** butterflies = 12 honeybees = 23 butterflies = 1 honeybees = 30 butterflies = 11 honeybees = 28 butterflies = 3 honeybees = 28 butterflies = 2 honeybees = 11 butterflies = 1 honeybees = 10 butterflies = 8 honeybees = 23 butterflies = 7 honeybees = 22 **4 tag sets** (different combinations of all the tag key-value pairs) location = 1, scientist = langstroth location = 2, scientist = langstroth location = 1, scientist = perpetua location = 2, scientist = perpetua Arbitrary series number Retention policy Measurement Tag set series 1 autogen census location = 1 , scientist = langstroth series 2 autogen census location = 2 , scientist = langstroth series 3 autogen census location = 1 , scientist = perpetua series 4 autogen census location = 2 , scientist = perpetua from datetime import ( datetime , timedelta ) from random import ( choice , randint , random , uniform , lognormvariate ) from influxdb import ( InfluxDBClient , DataFrameClient ) INFLUXDB_USER = 'telegraf' INFLUXDB_USER_PASSWORD = 'secretpassword' host = 'db.influxdb.app.com' port = 8086 \"\"\"Instantiate a connection to the InfluxDB.\"\"\" user = 'admin' password = 'supersecretpassword' dbname = 'example' dbuser = 'telegraf' dbuser_password = 'secretpassword' client = InfluxDBClient ( host , port , user , password , dbname )","title":"Example"},{"location":"_nb/04_influxDB/01%20-%20Intro%20InfluxDB/#db-init","text":"For creating the DB client.create_database(dbname) Define a specific retention policy, drop after 30d, with replica factor of 3 and applied by default to new elements client . create_retention_policy ( 'custom_policy' , '30d' , 3 , default = True ) # For dropping the policy: client.drop_retention_policy('custom_policy', dbname) client . switch_user ( dbuser , dbuser_password ) def feed_db ( n ): json_body = [ { \"measurement\" : \"starfleet_01\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"speed\" : lognormvariate ( 10 , 3 ), \"consumption\" : uniform ( 0 , 300 ), \"pressure_a\" : 3 + random (), \"status_b\" : choice (( True , False )) } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) def feed_db_array ( n ): json_body = [ { \"measurement\" : \"starfleet_02\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"curve_b[0]\" : 10 + random (), \"curve_b[1]\" : choice (( 15 + random (), 4 + random ())), \"curve_b[2]\" : 20 + random (), } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) % timeit feed_db ( 100_000 ) 13.2 s \u00b1 202 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) feed_db_array(1_000_000) Series can be deleted client.delete_series(database=\"example\", measurement=\"starfleet_01\") client . query ( query = 'select count(*) from starfleet_01' ) ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count_consumption': 1866653, 'count_pressure_a': 1866653, 'count_speed': 1866653, 'count_status_b': 1866653}]}) from IPython.core.magic import ( register_line_cell_magic ) @register_line_cell_magic def influxql ( line , cell = None ): \"Magic that works both as %lc magic and as %% lcmagic\" if cell is None : sqlstr = line else : sqlstr = \";\" . join (( op . strip ( \";\" ) for op in cell . strip ( \" \\n \" ) . split ( \" \\n \" ))) + \";\" return client . query ( query = sqlstr ) % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:05Z', 'speed': 774750.9698706511}, {'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}]}) result = % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; result ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}, {'time': '2019-08-19T20:52:25Z', 'speed': 9.829304084029904}]}) % influxql SELECT COUNT ( DISTINCT ( pressure_a )) FROM starfleet_01 ; ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count': 1000000}]}) % influxql SELECT COUNT ( pressure_a ) FROM starfleet_01 GROUP BY time ( 28 d ), region LIMIT 1 ; ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118099}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118282}], '('starfleet_01', {'region': 'Earth'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117988}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117959}]}) % influxql SELECT MEAN ( pressure_a ) FROM starfleet_01 GROUP BY region ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.499534039730786}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.4999780335201867}], '('starfleet_01', {'region': 'Earth'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5005520567253616}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5013387093463155}]}) You can explain query % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE region = 'Andoria' LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 750'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 2160'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 2160'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 5992395'}]}) % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE pressure_a > 3.5 LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 3000'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 8640'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 8640'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 23943525'}]}) res = % influxql SELECT * FROM \"starfleet_01\" WHERE pressure_a > 3.5 LIMIT 50 points = res . get_points ( tags = { \"region\" : \"Andoria\" }) from pandas import DataFrame df = DataFrame ( points ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region spacecraft speed status_b time 0 Archer 80.868742 3.764769 Andoria NX-1707 4.540769e+06 False 2019-07-28T01:35:50Z 1 Archer 64.351610 3.784118 Andoria NX-1707 8.549125e+05 False 2019-07-28T01:36:00Z 2 Archer 60.765559 3.907481 Andoria NX-1702 1.679463e+05 False 2019-07-28T01:36:04Z 3 Archer 252.870551 3.800938 Andoria NX-1706 1.444727e+04 True 2019-07-28T01:36:06Z 4 Kruge 192.871755 3.930994 Andoria NX-1702 4.376490e+03 False 2019-07-28T01:36:08Z df . groupby ( 'spacecraft' ) . max () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region speed status_b time spacecraft NX-1701 Kirk 226.626952 3.518973 Andoria 6.987498e+05 False 2019-07-28T01:38:44Z NX-1702 Kruge 217.135955 3.952388 Andoria 6.735246e+05 True 2019-07-28T01:37:38Z NX-1704 Kruge 278.172741 3.976138 Andoria 2.770339e+01 True 2019-07-28T01:37:54Z NX-1705 Kirk 197.423732 3.964069 Andoria 4.300635e+04 True 2019-07-28T01:37:42Z NX-1706 Kruge 252.870551 3.800938 Andoria 1.444727e+04 True 2019-07-28T01:37:02Z NX-1707 Kruge 289.899273 3.913948 Andoria 4.540769e+06 True 2019-07-28T01:38:46Z NX-1709 Kruge 272.085362 3.734222 Andoria 1.653500e+05 True 2019-07-28T01:37:30Z NX-1710 Kruge 297.309907 3.875039 Andoria 5.887814e+04 True 2019-07-28T01:38:20Z % influxql SHOW QUERIES ; ResultSet({'('results', None)': [{'qid': 2821, 'query': 'SHOW QUERIES', 'database': 'example', 'duration': '171\u00b5s', 'status': 'running'}]}) % influxql SHOW TAG KEYS ; ResultSet({'('starfleet_01', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}], '('starfleet_02', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}]})","title":"DB init"},{"location":"_nb/%3DC/C%20kernel%20Test/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); #include <stdio.h> int main () { int a ; char c [] = \"ABC\" ; char * b ; a = 34 ; b = & c [ 2 ]; printf ( \"Hello world %s \\n \" , b ); } Hello world C #include <stdio.h> int main () { int a = 2 ; printf ( \"The integer is %d \\n \" , a ); return 0 ; } The integer is 2 Titre \u00b6 #include <stdio.h> int main ( void ) { char name [] = \"Harry Potter\" ; printf ( \"%c\" , * name ); // Output: H printf ( \"%c\" , * ( name + 1 )); // Output: a printf ( \"%c\" , * ( name + 7 )); // Output: o char * namePtr ; namePtr = name ; printf ( \"%c\" , * namePtr ); // Output: H printf ( \"%c\" , * ( namePtr + 1 )); // Output: a printf ( \"%c\" , * ( namePtr + 7 )); // Output: o } HaoHao #include <stdio.h> #include <stdlib.h> int main () { int i , num = 10 ; float * data ; // Allocates the memory for 'num' elements. data = ( float * ) calloc ( num , sizeof ( float )); if ( data == NULL ) { printf ( \"Error!!! memory not allocated.\" ); exit ( 0 ); } printf ( \" \\n \" ); // Stores the number entered by the user. for ( i = 0 ; i < num ; ++ i ) { printf ( \"Enter Number %d: \" , i + 1 ); scanf ( \"%f\" , data + i ); } } Enter Number 1: Enter Number 2: Enter Number 3: Enter Number 4: Enter Number 5: Enter Number 6: Enter Number 7: Enter Number 8: Enter Number 9: Enter Number 10: #include <stdio.h> #include <unistd.h> /* sysconf(3) */ int main ( void ) { printf ( \"The page size for this system is %ld bytes. \\n \" , sysconf ( _SC_PAGESIZE )); /* _SC_PAGE_SIZE is OK too. */ return 0 ; } The page size for this system is 4096 bytes.","title":"C kernel Test"},{"location":"_nb/%3DC/C%20kernel%20Test/#titre","text":"#include <stdio.h> int main ( void ) { char name [] = \"Harry Potter\" ; printf ( \"%c\" , * name ); // Output: H printf ( \"%c\" , * ( name + 1 )); // Output: a printf ( \"%c\" , * ( name + 7 )); // Output: o char * namePtr ; namePtr = name ; printf ( \"%c\" , * namePtr ); // Output: H printf ( \"%c\" , * ( namePtr + 1 )); // Output: a printf ( \"%c\" , * ( namePtr + 7 )); // Output: o } HaoHao #include <stdio.h> #include <stdlib.h> int main () { int i , num = 10 ; float * data ; // Allocates the memory for 'num' elements. data = ( float * ) calloc ( num , sizeof ( float )); if ( data == NULL ) { printf ( \"Error!!! memory not allocated.\" ); exit ( 0 ); } printf ( \" \\n \" ); // Stores the number entered by the user. for ( i = 0 ; i < num ; ++ i ) { printf ( \"Enter Number %d: \" , i + 1 ); scanf ( \"%f\" , data + i ); } } Enter Number 1: Enter Number 2: Enter Number 3: Enter Number 4: Enter Number 5: Enter Number 6: Enter Number 7: Enter Number 8: Enter Number 9: Enter Number 10: #include <stdio.h> #include <unistd.h> /* sysconf(3) */ int main ( void ) { printf ( \"The page size for this system is %ld bytes. \\n \" , sysconf ( _SC_PAGESIZE )); /* _SC_PAGE_SIZE is OK too. */ return 0 ; } The page size for this system is 4096 bytes.","title":"Titre"},{"location":"_nb/%3DC/Jeux%20en%20C%20-%201/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); //%cflags:-ltlphi_hdr #include <tlphi_hdr.h> int main () { int sem_wait ( sem_t * sem ); return 0 } /tmp/tmpmr2p5q5y.c:2:10: fatal error: tlphi_hdr.h: No such file or directory #include <tlphi_hdr.h> ^~~~~~~~~~~~~ compilation terminated. [C kernel] GCC exited with code 1, the executable will not be executed //%cflags:-lm #include <stdio.h> #include <math.h> #define PI 3.14159265 double calc ( int * a ) { double val = PI * 3 * * a ; * a = 3 ; printf ( \"val= %lf \\n \" , val ); return val ; } int main () { int a = 2 ; double val = calc ( & a ) * sin ( a ); printf ( \"a = %lf, sin(a) = %lf\" , ( double ) a , val ); return 0 ; } val= 18.849556 a = 3.000000, sin(a) = 2.660049 #include <stdio.h> #include <stdlib.h> int main () { int n = 10 ; int a [ n ]; int * ptr = a ; for ( int i = 0 ; ptr < a + n ; ptr ++ , i ++ ) { * ptr = i * 3 ; printf ( \"index=%i, a[i]=%i \\n \" , i , * ( a + i )); } } index=0, a[i]=0 index=1, a[i]=3 index=2, a[i]=6 index=3, a[i]=9 index=4, a[i]=12 index=5, a[i]=15 index=6, a[i]=18 index=7, a[i]=21 index=8, a[i]=24 index=9, a[i]=27 #include <stdio.h> #include <stdlib.h> int main () { int n = 10 ; int a [ n ]; for ( int i = 0 ; i < n ; i ++ ) { a [ i ] = i * 2 ; printf ( \"index=%i, a[i]=%i \\n \" , i , a [ i ]); } } index=0, a[i]=0 index=1, a[i]=2 index=2, a[i]=4 index=3, a[i]=6 index=4, a[i]=8 index=5, a[i]=10 index=6, a[i]=12 index=7, a[i]=14 index=8, a[i]=16 index=9, a[i]=18 #include <stdio.h> #include <stdlib.h> int main () { int n = 10 ; float * fptr = malloc ( n * sizeof ( float )); register float * last = fptr + n ; * if ( fptr == NULL ) printf ( \"Hep\" ); for (; fptr < last ; fptr ++ ) printf ( \"index=%f \\n \" , * fptr ); } index=0.000000 index=0.000000 index=0.000000 index=0.000000 index=0.000000 index=0.000000 index=0.000000 index=0.000000 index=0.000000 index=0.000000","title":"Jeux en C   1"},{"location":"_nb/%3DGo/G0%2001/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import \"fmt\" const a int = 4 ; type rectangle struct { length float64 breadth float64 color string } r := rectangle { 10.5 , 25.10 , \"red\" } int ( r . color ) repl.go:1:5: cannot convert string to int: r.color r . length + 0.1 10.6 r . length + float64 ( a ) 14.5 rect1 := new ( rectangle ) rect1 . color type geometry struct { area int perimeter int } type rectangle struct { length int breadth int color string props geometry } rect2 := new ( rectangle ) rect2 . props . area 0 type Contact struct { phone , address string } type Employee struct { name string salary int contact Contact } func ( c * Contact ) changePhone ( newPhone string ) { c . phone = newPhone } e := Employee { name : \"Ross Geller\" , salary : 1200 , contact : Contact { phone : \"011 8080 8080\" , address : \"New Delhi, India\" , }, } f := & e e {Ross Geller 1200 {011 8080 8080 New Delhi, India}} e . contact . changePhone ( \"011 1010 1222\" ) e {Ross Geller 1200 {011 1010 1222 New Delhi, India}} f . salary = 1300 e {Ross Geller 1300 {011 1010 1222 New Delhi, India}} Methods \u00b6 Medium repl.go:1:7: expected ';', found 'IDENT' https","title":"G0 01"},{"location":"_nb/%3DGo/G0%2001/#methods","text":"Medium repl.go:1:7: expected ';', found 'IDENT' https","title":"Methods"},{"location":"_nb/%3DGo/Untitled/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import ( \"encoding/json\" \"fmt\" \"io/ioutil\" \"log\" \"net/http\" \"time\" ) type people struct { Number int `json:\"number\"` } func main ( url string ) { spaceClient := http . Client { Timeout : time . Second * 2 , // Maximum of 2 secs } req , err := http . NewRequest ( http . MethodGet , url , nil ) if err != nil { log . Fatal ( err ) } req . Header . Set ( \"User-Agent\" , \"spacecount-tutorial\" ) res , getErr := spaceClient . Do ( req ) if getErr != nil { log . Fatal ( getErr ) } body , readErr := ioutil . ReadAll ( res . Body ) if readErr != nil { log . Fatal ( readErr ) } people1 := people {} jsonErr := json . Unmarshal ( body , & people1 ) if jsonErr != nil { log . Fatal ( jsonErr ) } fmt . Println ( people1 . Number ) } main ( \"http://api.open-notify.org/astros.json\" ) 6","title":"Untitled"},{"location":"_nb/%3DJS/Apache%20arrow/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Imports \u00b6 const fetch = require ( \"node-fetch\" ); const arrow = require ( 'apache-arrow' ); dataUrl = \"https://raw.githubusercontent.com/RandomFractals/ChicagoCrimes/master/data/chicago-crimes-2017.arrow\" 'https://raw.githubusercontent.com/RandomFractals/ChicagoCrimes/master/data/chicago-crimes-2017.arrow' async function loadData ( dataUrl ){ const response = await fetch ( dataUrl ); return await response . arrayBuffer (); } fetch ( dataUrl ) . then ( res => { console . log ( res . ok ); console . log ( res . status ); console . log ( res . statusText ); console . log ( res . headers . raw ()); console . log ( res . headers . get ( 'content-type' )); }); true 200 OK [Object: null prototype] { 'content-security-policy': [ \"default-src 'none'; style-src 'unsafe-inline'; sandbox\" ], 'strict-transport-security': [ 'max-age=31536000' ], 'x-content-type-options': [ 'nosniff' ], 'x-frame-options': [ 'deny' ], 'x-xss-protection': [ '1; mode=block' ], etag: [ 'W/\"54801d6e8e8bce558eb964790a95105e16c4a597fef89e71c2edab21e18189a8\"' ], 'content-type': [ 'application/octet-stream' ], 'cache-control': [ 'max-age=300' ], 'x-geo-block-list': [ '' ], 'x-github-request-id': [ '9C90:1231:66FED:82564:5DC740BD' ], 'content-length': [ '3975450' ], 'accept-ranges': [ 'bytes' ], date: [ 'Sat, 09 Nov 2019 22:42:06 GMT' ], via: [ '1.1 varnish' ], connection: [ 'close' ], 'x-served-by': [ 'cache-hhn4067-HHN' ], 'x-cache': [ 'MISS' ], 'x-cache-hits': [ '0' ], 'x-timer': [ 'S1573339327.588676,VS0,VE208' ], vary: [ 'Authorization,Accept-Encoding' ], 'access-control-allow-origin': [ '*' ], 'x-fastly-request-id': [ '5480e6580b4a34022333d56daef2d409d3fa8c4e' ], expires: [ 'Sat, 09 Nov 2019 22:47:06 GMT' ], 'source-age': [ '0' ] } application/octet-stream const getBuffer = async url => { try { const response = await fetch(url); return await response.arrayBuffer(); } catch (error) { console.log(error); } }; buf = loadData ( dataUrl ) in script 1 in script 2 ArrayBuffer { [Uint8Contents]: <41 52 52 4f 57 31 00 00 00 eb 02 00 00 10 00 00 00 0c 00 0e 00 06 00 05 00 08 00 00 00 0c 00 00 00 00 01 02 00 10 00 00 00 00 00 0a 00 0c 00 00 00 04 00 08 00 0a 00 00 00 90 01 00 00 04 00 00 00 01 00 00 00 0c 00 00 00 08 00 0c 00 04 00 08 00 08 00 00 00 08 00 00 00 10 00 00 00 06 00 00 00 70 61 6e ... 3975350 more bytes>, byteLength: 3975450 } buf ArrayBuffer { [Uint8Contents]: <41 52 52 4f 57 31 00 00 00 eb 02 00 00 10 00 00 00 0c 00 0e 00 06 00 05 00 08 00 00 00 0c 00 00 00 00 01 02 00 10 00 00 00 00 00 0a 00 0c 00 00 00 04 00 08 00 0a 00 00 00 90 01 00 00 04 00 00 00 01 00 00 00 0c 00 00 00 08 00 0c 00 04 00 08 00 08 00 00 00 08 00 00 00 10 00 00 00 06 00 00 00 70 61 6e ... 3975350 more bytes>, byteLength: 3975450 } aze = { aze : 1 , qsd : \"aze\" } { aze: 1, qsd: 'aze' } t0 = new arrow . Float64 () Float64 [Float] { precision: 2 } f0 = new arrow . Field ( 'signal 0' , t0 , nullable = true , metadata = { label : 'A simple label' , unit : \"A label containing utf-8 character: \u00b5\" }) Field { name: 'signal 0', type: Float64 [Float] { precision: 2 }, nullable: true, metadata: { label: 'A simple label', unit: 'A label containing utf-8 character: \u00b5' } } function sayHello () { console . log ( \"Hello, World!\" ); } var t = setTimeout ( sayHello , 1000 ); LENGTH 2000 Hello, World! $$ . async (); console . log ( \"Hello, World!\" ); setTimeout ( $$ . done , 1000 ); \u0002hzzhzkh:20\u0003 let LENGTH = 2000 $$ . clear ({}) fields = [ { name : 'precipitation' , type : { name : 'floatingpoint' , precision : 'SINGLE' }, nullable : false , children : [] }, { name : 'date' , type : { name : 'date' , unit : 'MILLISECOND' }, nullable : false , children : [] } ] [ { name: 'precipitation', type: { name: 'floatingpoint', precision: 'SINGLE' }, nullable: false, children: [] }, { name: 'date', type: { name: 'date', unit: 'MILLISECOND' }, nullable: false, children: [] } ] Manipulating Flat Arrays, Arrow-Style \u00b6 https://observablehq.com/@lmeyerov/manipulating-flat-arrays-arrow-style rainAmounts = Array . from ({ length : LENGTH }, () => Number (( Math . random () * 20 ). toFixed ( 1 ))) rainDates = Array . from ({ length : LENGTH }, ( _ , i ) => Date . now () - 1000 * 60 * 60 * 24 * i ) rainfall = arrow . Table . from ({ schema : { fields : fields }, batches : [{ count : LENGTH , columns : [ { name : \"precipitation\" , count : LENGTH , VALIDITY : [], DATA : rainAmounts }, { name : \"date\" , count : LENGTH , VALIDITY : [], DATA : rainDates } ] }] }) Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 2, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 2000 ], _length: 2000, _numChildren: 2, _schema: Schema { fields: [ [Field], [Field] ], metadata: Map {}, dictionaries: Map {} } } rainfall . count () 2000 rainfall . get ( 10 ). toString () '{ \"precipitation\": 17.899999618530273, \"date\": Wed Oct 30 2019 11:17:50 GMT+0000 (Coordinated Universal Time) }' tab = arrow . Table . from ( new Uint8Array ([ 1 , 2 , 4 , 3 ])) Table { _nullCount: -1, _type: Struct { children: [] }, _chunks: [ _InternalEmptyPlaceholderRecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 0, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 0 ], _length: 0, _numChildren: 0, _schema: Schema { fields: [], metadata: Map {}, dictionaries: Map {} } } tab Schema { fields: [], metadata: Map {}, dictionaries: Map {} } data = fetch ( dataUrl ) . then ( res => { if ( res . status >= 400 ) { throw new Error ( \"Bad response from server\" ); } return res . arrayBuffer (); }) . then ( buffer => { return arrow . Table . from ( new Uint8Array ( buffer )); }) . catch ( err => { console . error ( err ); }); Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 3, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 165567 ], _length: 165567, _numChildren: 3, _schema: Schema { fields: [ [Field], [Field], [Field] ], metadata: Map { 'pandas' => '{\"index_columns\": [\"Date\"], \"columns\": [{\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Latitude\"}, {\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Longitude\"}, {\"numpy_type\": \"datetime64[ns]\", \"pandas_type\": \"datetime\", \"metadata\": null, \"name\": \"Date\"}], \"pandas_version\": \"0.20.3\"}' }, dictionaries: Map {} } } data Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 3, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 165567 ], _length: 165567, _numChildren: 3, _schema: Schema { fields: [ [Field], [Field], [Field] ], metadata: Map { 'pandas' => '{\"index_columns\": [\"Date\"], \"columns\": [{\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Latitude\"}, {\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Longitude\"}, {\"numpy_type\": \"datetime64[ns]\", \"pandas_type\": \"datetime\", \"metadata\": null, \"name\": \"Date\"}], \"pandas_version\": \"0.20.3\"}' }, dictionaries: Map {} } } crimes = loadData ( dataUrl ). then ( buffer => arrow . Table . from ( new Uint8Array ( buffer ))) in script 1 in script 2 Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 3, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 165567 ], _length: 165567, _numChildren: 3, _schema: Schema { fields: [ [Field], [Field], [Field] ], metadata: Map { 'pandas' => '{\"index_columns\": [\"Date\"], \"columns\": [{\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Latitude\"}, {\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Longitude\"}, {\"numpy_type\": \"datetime64[ns]\", \"pandas_type\": \"datetime\", \"metadata\": null, \"name\": \"Date\"}], \"pandas_version\": \"0.20.3\"}' }, dictionaries: Map {} } } rowCount = crimes . count () evalmachine.<anonymous>:1 rowCount = crimes.count() ^ TypeError: crimes.count is not a function at evalmachine.<anonymous>:1:19 at Script.runInThisContext (vm.js:124:20) at Object.runInThisContext (vm.js:314:38) at run ([eval]:1054:15) at onRunRequest ([eval]:888:18) at onMessage ([eval]:848:13) at process.emit (events.js:193:13) at emit (internal/child_process.js:848:12) at processTicksAndRejections (internal/process/task_queues.js:81:17) ( new Array ( 1 , 2 )). map (( elt , i ) => elt ) [ 1, 2 ]","title":"Apache arrow"},{"location":"_nb/%3DJS/Apache%20arrow/#imports","text":"const fetch = require ( \"node-fetch\" ); const arrow = require ( 'apache-arrow' ); dataUrl = \"https://raw.githubusercontent.com/RandomFractals/ChicagoCrimes/master/data/chicago-crimes-2017.arrow\" 'https://raw.githubusercontent.com/RandomFractals/ChicagoCrimes/master/data/chicago-crimes-2017.arrow' async function loadData ( dataUrl ){ const response = await fetch ( dataUrl ); return await response . arrayBuffer (); } fetch ( dataUrl ) . then ( res => { console . log ( res . ok ); console . log ( res . status ); console . log ( res . statusText ); console . log ( res . headers . raw ()); console . log ( res . headers . get ( 'content-type' )); }); true 200 OK [Object: null prototype] { 'content-security-policy': [ \"default-src 'none'; style-src 'unsafe-inline'; sandbox\" ], 'strict-transport-security': [ 'max-age=31536000' ], 'x-content-type-options': [ 'nosniff' ], 'x-frame-options': [ 'deny' ], 'x-xss-protection': [ '1; mode=block' ], etag: [ 'W/\"54801d6e8e8bce558eb964790a95105e16c4a597fef89e71c2edab21e18189a8\"' ], 'content-type': [ 'application/octet-stream' ], 'cache-control': [ 'max-age=300' ], 'x-geo-block-list': [ '' ], 'x-github-request-id': [ '9C90:1231:66FED:82564:5DC740BD' ], 'content-length': [ '3975450' ], 'accept-ranges': [ 'bytes' ], date: [ 'Sat, 09 Nov 2019 22:42:06 GMT' ], via: [ '1.1 varnish' ], connection: [ 'close' ], 'x-served-by': [ 'cache-hhn4067-HHN' ], 'x-cache': [ 'MISS' ], 'x-cache-hits': [ '0' ], 'x-timer': [ 'S1573339327.588676,VS0,VE208' ], vary: [ 'Authorization,Accept-Encoding' ], 'access-control-allow-origin': [ '*' ], 'x-fastly-request-id': [ '5480e6580b4a34022333d56daef2d409d3fa8c4e' ], expires: [ 'Sat, 09 Nov 2019 22:47:06 GMT' ], 'source-age': [ '0' ] } application/octet-stream const getBuffer = async url => { try { const response = await fetch(url); return await response.arrayBuffer(); } catch (error) { console.log(error); } }; buf = loadData ( dataUrl ) in script 1 in script 2 ArrayBuffer { [Uint8Contents]: <41 52 52 4f 57 31 00 00 00 eb 02 00 00 10 00 00 00 0c 00 0e 00 06 00 05 00 08 00 00 00 0c 00 00 00 00 01 02 00 10 00 00 00 00 00 0a 00 0c 00 00 00 04 00 08 00 0a 00 00 00 90 01 00 00 04 00 00 00 01 00 00 00 0c 00 00 00 08 00 0c 00 04 00 08 00 08 00 00 00 08 00 00 00 10 00 00 00 06 00 00 00 70 61 6e ... 3975350 more bytes>, byteLength: 3975450 } buf ArrayBuffer { [Uint8Contents]: <41 52 52 4f 57 31 00 00 00 eb 02 00 00 10 00 00 00 0c 00 0e 00 06 00 05 00 08 00 00 00 0c 00 00 00 00 01 02 00 10 00 00 00 00 00 0a 00 0c 00 00 00 04 00 08 00 0a 00 00 00 90 01 00 00 04 00 00 00 01 00 00 00 0c 00 00 00 08 00 0c 00 04 00 08 00 08 00 00 00 08 00 00 00 10 00 00 00 06 00 00 00 70 61 6e ... 3975350 more bytes>, byteLength: 3975450 } aze = { aze : 1 , qsd : \"aze\" } { aze: 1, qsd: 'aze' } t0 = new arrow . Float64 () Float64 [Float] { precision: 2 } f0 = new arrow . Field ( 'signal 0' , t0 , nullable = true , metadata = { label : 'A simple label' , unit : \"A label containing utf-8 character: \u00b5\" }) Field { name: 'signal 0', type: Float64 [Float] { precision: 2 }, nullable: true, metadata: { label: 'A simple label', unit: 'A label containing utf-8 character: \u00b5' } } function sayHello () { console . log ( \"Hello, World!\" ); } var t = setTimeout ( sayHello , 1000 ); LENGTH 2000 Hello, World! $$ . async (); console . log ( \"Hello, World!\" ); setTimeout ( $$ . done , 1000 ); \u0002hzzhzkh:20\u0003 let LENGTH = 2000 $$ . clear ({}) fields = [ { name : 'precipitation' , type : { name : 'floatingpoint' , precision : 'SINGLE' }, nullable : false , children : [] }, { name : 'date' , type : { name : 'date' , unit : 'MILLISECOND' }, nullable : false , children : [] } ] [ { name: 'precipitation', type: { name: 'floatingpoint', precision: 'SINGLE' }, nullable: false, children: [] }, { name: 'date', type: { name: 'date', unit: 'MILLISECOND' }, nullable: false, children: [] } ]","title":"Imports"},{"location":"_nb/%3DJS/Apache%20arrow/#manipulating-flat-arrays-arrow-style","text":"https://observablehq.com/@lmeyerov/manipulating-flat-arrays-arrow-style rainAmounts = Array . from ({ length : LENGTH }, () => Number (( Math . random () * 20 ). toFixed ( 1 ))) rainDates = Array . from ({ length : LENGTH }, ( _ , i ) => Date . now () - 1000 * 60 * 60 * 24 * i ) rainfall = arrow . Table . from ({ schema : { fields : fields }, batches : [{ count : LENGTH , columns : [ { name : \"precipitation\" , count : LENGTH , VALIDITY : [], DATA : rainAmounts }, { name : \"date\" , count : LENGTH , VALIDITY : [], DATA : rainDates } ] }] }) Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 2, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 2000 ], _length: 2000, _numChildren: 2, _schema: Schema { fields: [ [Field], [Field] ], metadata: Map {}, dictionaries: Map {} } } rainfall . count () 2000 rainfall . get ( 10 ). toString () '{ \"precipitation\": 17.899999618530273, \"date\": Wed Oct 30 2019 11:17:50 GMT+0000 (Coordinated Universal Time) }' tab = arrow . Table . from ( new Uint8Array ([ 1 , 2 , 4 , 3 ])) Table { _nullCount: -1, _type: Struct { children: [] }, _chunks: [ _InternalEmptyPlaceholderRecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 0, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 0 ], _length: 0, _numChildren: 0, _schema: Schema { fields: [], metadata: Map {}, dictionaries: Map {} } } tab Schema { fields: [], metadata: Map {}, dictionaries: Map {} } data = fetch ( dataUrl ) . then ( res => { if ( res . status >= 400 ) { throw new Error ( \"Bad response from server\" ); } return res . arrayBuffer (); }) . then ( buffer => { return arrow . Table . from ( new Uint8Array ( buffer )); }) . catch ( err => { console . error ( err ); }); Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 3, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 165567 ], _length: 165567, _numChildren: 3, _schema: Schema { fields: [ [Field], [Field], [Field] ], metadata: Map { 'pandas' => '{\"index_columns\": [\"Date\"], \"columns\": [{\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Latitude\"}, {\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Longitude\"}, {\"numpy_type\": \"datetime64[ns]\", \"pandas_type\": \"datetime\", \"metadata\": null, \"name\": \"Date\"}], \"pandas_version\": \"0.20.3\"}' }, dictionaries: Map {} } } data Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 3, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 165567 ], _length: 165567, _numChildren: 3, _schema: Schema { fields: [ [Field], [Field], [Field] ], metadata: Map { 'pandas' => '{\"index_columns\": [\"Date\"], \"columns\": [{\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Latitude\"}, {\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Longitude\"}, {\"numpy_type\": \"datetime64[ns]\", \"pandas_type\": \"datetime\", \"metadata\": null, \"name\": \"Date\"}], \"pandas_version\": \"0.20.3\"}' }, dictionaries: Map {} } } crimes = loadData ( dataUrl ). then ( buffer => arrow . Table . from ( new Uint8Array ( buffer ))) in script 1 in script 2 Table { _nullCount: -1, _type: Struct { children: [ [Field], [Field], [Field] ] }, _chunks: [ RecordBatch [StructVector<Struct>] { _children: undefined, numChildren: 3, data: [Data], _schema: [Schema] } ], _chunkOffsets: Uint32Array [ 0, 165567 ], _length: 165567, _numChildren: 3, _schema: Schema { fields: [ [Field], [Field], [Field] ], metadata: Map { 'pandas' => '{\"index_columns\": [\"Date\"], \"columns\": [{\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Latitude\"}, {\"numpy_type\": \"float64\", \"pandas_type\": \"float64\", \"metadata\": null, \"name\": \"Longitude\"}, {\"numpy_type\": \"datetime64[ns]\", \"pandas_type\": \"datetime\", \"metadata\": null, \"name\": \"Date\"}], \"pandas_version\": \"0.20.3\"}' }, dictionaries: Map {} } } rowCount = crimes . count () evalmachine.<anonymous>:1 rowCount = crimes.count() ^ TypeError: crimes.count is not a function at evalmachine.<anonymous>:1:19 at Script.runInThisContext (vm.js:124:20) at Object.runInThisContext (vm.js:314:38) at run ([eval]:1054:15) at onRunRequest ([eval]:888:18) at onMessage ([eval]:848:13) at process.emit (events.js:193:13) at emit (internal/child_process.js:848:12) at processTicksAndRejections (internal/process/task_queues.js:81:17) ( new Array ( 1 , 2 )). map (( elt , i ) => elt ) [ 1, 2 ]","title":"Manipulating Flat Arrays, Arrow-Style"},{"location":"_nb/%3DJS/Ramda%20-%20functionnal%20style/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); https://github.com/ramda/ramda","title":"Ramda   functionnal style"},{"location":"_nb/%3DJS/array/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); let foo = [ \"fee\" , \"fi\" , \"fo\" , \"fum\" ]; let numbers = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ]; Copying/Cloning an Array: Array.slice \u00b6 doc (fr) let fooCopy = foo . slice (); console . log ( foo == fooCopy , foo === fooCopy ) false false Checking if an Object Is an Array \u00b6 https://tc39.es/ecma262/#sec-relational-operators Array . isArray ( numbers ) true numbers . constructor === Array true let name = \"Homer Simpson\" ; name . constructor === Array false Deleting an Array Item \u00b6 let evenNumbers = [ 0 , 2 , 4 , 6 , 7 , 8 , 10 ]; console . log ( evenNumbers ) console . log ( evenNumbers . length ) // 7 items [ 0, 2, 4, 6, 7, 8, 10 ] 7 Array.splice replace (or remove) element inplace when delete nullate the element delete evenNumbers [ 1 ]; console . log ( evenNumbers ) [ 0, <1 empty item>, 4, 6, 7, 8, 10 ] evenNumbers . splice ( 1 , 2 , 10 , 20 ); console . log ( evenNumbers ) [ 0, 10, 20, 6, 7, 8, 10 ] evenNumbers . splice ( 1 , 2 ); console . log ( evenNumbers ) [ 0, 6, 7, 8, 10 ] Get index of element in Array \u00b6 let removeIndex = evenNumbers . indexOf ( 7 ); if ( removeIndex > - 1 ) { evenNumbers . splice ( removeIndex , 1 ); } console . log ( evenNumbers . length ) console . log ( evenNumbers ) 3 [ 0, 6, 10 ] Emptying an Array \u00b6 let myItems = [ \"apples\" , \"oranges\" , \"bananas\" , \"kiwis\" ]; console . log ( myItems . length ); // 4 myItems . length = 0 ; console . log ( myItems . length ); // 0 4 0 Extract unique elements of Array with Set \u00b6 let names = [ \"Peter\" , \"Joe\" , \"Cleveland\" , \"Quagmire\" , \"Joe\" ]; let uniqueNames = [... new Set ( names )]; console . log ( uniqueNames ); [ 'Peter', 'Joe', 'Cleveland', 'Quagmire' ] new Set ( names ) Set { 'Peter', 'Joe', 'Cleveland', 'Quagmire' } Array sort \u00b6 doc (fr) let numbers8 = [ 3 , 10 , 2 , 14 , 7 , 2 , 9 , 5 ]; let beatles = [ \"Ringo\" , \"George\" , \"Paul\" , \"John\" ]; numbers8 . sort ( compareValues ); beatles . sort ( compareValues ); function compareValues ( a , b ) { if ( a < b ) { // if a less than b return - 1 ; } else if ( a > b ) { // if a greater than b return 1 ; } else { // a and b are equal return 0 ; } } console . log ( numbers8 ); console . log ( beatles ); [ 2, 2, 3, 5, 7, 9, 10, 14 ] [ 'George', 'John', 'Paul', 'Ringo' ]","title":"Array"},{"location":"_nb/%3DJS/array/#copyingcloning-an-array-arrayslice","text":"doc (fr) let fooCopy = foo . slice (); console . log ( foo == fooCopy , foo === fooCopy ) false false","title":"Copying/Cloning an Array: Array.slice"},{"location":"_nb/%3DJS/array/#checking-if-an-object-is-an-array","text":"https://tc39.es/ecma262/#sec-relational-operators Array . isArray ( numbers ) true numbers . constructor === Array true let name = \"Homer Simpson\" ; name . constructor === Array false","title":"Checking if an Object Is an Array"},{"location":"_nb/%3DJS/array/#deleting-an-array-item","text":"let evenNumbers = [ 0 , 2 , 4 , 6 , 7 , 8 , 10 ]; console . log ( evenNumbers ) console . log ( evenNumbers . length ) // 7 items [ 0, 2, 4, 6, 7, 8, 10 ] 7 Array.splice replace (or remove) element inplace when delete nullate the element delete evenNumbers [ 1 ]; console . log ( evenNumbers ) [ 0, <1 empty item>, 4, 6, 7, 8, 10 ] evenNumbers . splice ( 1 , 2 , 10 , 20 ); console . log ( evenNumbers ) [ 0, 10, 20, 6, 7, 8, 10 ] evenNumbers . splice ( 1 , 2 ); console . log ( evenNumbers ) [ 0, 6, 7, 8, 10 ]","title":"Deleting an Array Item"},{"location":"_nb/%3DJS/array/#get-index-of-element-in-array","text":"let removeIndex = evenNumbers . indexOf ( 7 ); if ( removeIndex > - 1 ) { evenNumbers . splice ( removeIndex , 1 ); } console . log ( evenNumbers . length ) console . log ( evenNumbers ) 3 [ 0, 6, 10 ]","title":"Get index of element in Array"},{"location":"_nb/%3DJS/array/#emptying-an-array","text":"let myItems = [ \"apples\" , \"oranges\" , \"bananas\" , \"kiwis\" ]; console . log ( myItems . length ); // 4 myItems . length = 0 ; console . log ( myItems . length ); // 0 4 0","title":"Emptying an Array"},{"location":"_nb/%3DJS/array/#extract-unique-elements-of-array-with-set","text":"let names = [ \"Peter\" , \"Joe\" , \"Cleveland\" , \"Quagmire\" , \"Joe\" ]; let uniqueNames = [... new Set ( names )]; console . log ( uniqueNames ); [ 'Peter', 'Joe', 'Cleveland', 'Quagmire' ] new Set ( names ) Set { 'Peter', 'Joe', 'Cleveland', 'Quagmire' }","title":"Extract unique elements of Array with Set"},{"location":"_nb/%3DJS/array/#array-sort","text":"doc (fr) let numbers8 = [ 3 , 10 , 2 , 14 , 7 , 2 , 9 , 5 ]; let beatles = [ \"Ringo\" , \"George\" , \"Paul\" , \"John\" ]; numbers8 . sort ( compareValues ); beatles . sort ( compareValues ); function compareValues ( a , b ) { if ( a < b ) { // if a less than b return - 1 ; } else if ( a > b ) { // if a greater than b return 1 ; } else { // a and b are equal return 0 ; } } console . log ( numbers8 ); console . log ( beatles ); [ 2, 2, 3, 5, 7, 9, 10, 14 ] [ 'George', 'John', 'Paul', 'Ringo' ]","title":"Array sort"},{"location":"_nb/%3DJS/fetch/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); fetch in node.js const fetch = require ( 'node-fetch' ); fetch ( 'https://httpbin.org/post' , { method : 'POST' , body : 'a=1' }) . then ( res => res . json ()) // expecting a json response . then ( json => console . log ( json . headers )); { Accept: '*/*', 'Accept-Encoding': 'gzip,deflate', 'Content-Length': '3', 'Content-Type': 'text/plain;charset=UTF-8', Host: 'httpbin.org', 'User-Agent': 'node-fetch/1.0 (+https://github.com/bitinn/node-fetch)' }","title":"Fetch"},{"location":"_nb/%3DJS/viz%20-%20vega/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); var vega = require ( 'vega' ); const fetch = require ( 'node-fetch' ); var view ; fetch ( 'https://vega.github.io/vega/examples/bar-chart.vg.json' ) . then ( res => res . json ()) . then ( spec => render ( spec )) . catch ( err => console . error ( err )); function render ( spec ) { view = new vega . View ( vega . parse ( spec ), { renderer : 'canvas' , // renderer (canvas or svg) container : '#view' , // parent DOM container hover : true // enable hover processing }); return view . runAsync (); } ERROR DOM document instance not found. TypeError: Cannot read property 'getContext' of null at resize (/home/jovyan/node_modules/vega-scenegraph/build/vega-scenegraph.js:3442:26) at CanvasRenderer.prototype$6.resize (/home/jovyan/node_modules/vega-scenegraph/build/vega-scenegraph.js:3492:5) at CanvasRenderer.prototype$4.initialize (/home/jovyan/node_modules/vega-scenegraph/build/vega-scenegraph.js:3054:17) at CanvasRenderer.prototype$6.initialize (/home/jovyan/node_modules/vega-scenegraph/build/vega-scenegraph.js:3487:28) at initializeRenderer (/home/jovyan/node_modules/vega-view/build/vega-view.js:630:8) at View.initialize (/home/jovyan/node_modules/vega-view/build/vega-view.js:677:9) at new View (/home/jovyan/node_modules/vega-view/build/vega-view.js:1060:33) at render (evalmachine.<anonymous>:9:10) at fetch.then.then.spec (evalmachine.<anonymous>:5:17) at processTicksAndRejections (internal/process/task_queues.js:86:5) fetch ( 'https://vega.github.io/vega/examples/bar-chart.vg.json' ) . then ( res => res . json ()) { '$schema': 'https://vega.github.io/schema/vega/v5.json', width: 400, height: 200, padding: 5, data: [ { name: 'table', values: [Array] } ], signals: [ { name: 'tooltip', value: {}, on: [Array] } ], scales: [ { name: 'xscale', type: 'band', domain: [Object], range: 'width', padding: 0.05, round: true }, { name: 'yscale', domain: [Object], nice: true, range: 'height' } ], axes: [ { orient: 'bottom', scale: 'xscale' }, { orient: 'left', scale: 'yscale' } ], marks: [ { type: 'rect', from: [Object], encode: [Object] }, { type: 'text', encode: [Object] } ] }","title":"Viz   vega"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library. [src] Design of CPython\u2019s Compiler [src] Philip Guo CPython internals lectures [src] PyOhio PyCamp 2014 :: The Compiler [src] The missing Python AST docs [src] Visualize program execution High-level \u00b6 In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia Interpreted \u00b6 There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled Code structure \u00b6 The code directory structure is described in Python Developer's Guide . Guido van Rossum summarizes it in Yet another guided tour of CPython Include \u2014 header files Objects \u2014 object implementations, from int to type Python \u2014 interpreter, bytecode compiler and other essential infrastructure Parser \u2014 parser, lexer and parser generator Modules \u2014 stdlib extension modules, and main.c Programs \u2014 not much, but has the real main() function cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python In CPython, the compilation from source code to bytecode involves several steps [src] Parse source code into a parse tree (Parser/pgen.c) Transform parse tree into an Abstract Syntax Tree (Python/ast.c) Transform AST into a Control Flow Graph (Python/compile.c) Emit bytecode based on the Control Flow Graph (Python/compile.c) AST \u00b6 Doc The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . In python, everything is an object, AST represents logicaly each element as an object. A third pary documentation on AST import ast from ast import PyCF_ONLY_AST # The code is beeing striped to remove # left and right space before parsing # and limit thee size of the tree code = \"\"\" def hello(who: str) -> None: msg = f'Hello {who} ' print(msg) hello(\"world\") \"\"\" code = code . strip () Execute the code exec ( code ) Hello world tree = ast . parse ( code ) The code is seen as two elements in the tree for i , elt in enumerate ( tree . body ): print ( i , elt ) 0 <_ast.FunctionDef object at 0x7f79c9aa0690> 1 <_ast.Expr object at 0x7f79c9ad1890> # Get the FunctionDef fdef = tree . body [ 0 ] # Get the first function argument arg = fdef . args . args [ 0 ] Some informations from the tree can be retrieved: print ( f ' { arg . arg } : { arg . annotation . id } at col # { arg . col_offset } ' ) who: str at col #10 The code can be compiled lines = [ None ] + code . splitlines () # None at [0] so we can index lines from 1 test_namespace = {} for node in tree . body : wrapper = ast . Module ( body = [ node ]) try : co = compile ( wrapper , \"<ast>\" , 'exec' ) exec ( co , test_namespace ) except AssertionError as e : print ( \"Assertion failed on line\" , node . lineno , \":\" ) print ( lines [ node . lineno ]) # If the error has a message, show it. if e . args : print ( e ) print () Hello world code = compile ( tree , filename = \"<ast>\" , mode = \"exec\" ) class FuncLister ( ast . NodeVisitor ): def visit_FunctionDef ( self , node ): print ( node . name ) self . generic_visit ( node ) FuncLister () . visit ( tree ) hello Bytecode \u00b6 From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\"). With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program. Opcodes and main interpreter loop \u00b6 import tempfile from os.path import join as pjoin tmp = tempfile . gettempdir () fName = pjoin ( tmp , 'test.py' ) codeExemple = \"\"\"ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl]\"\"\" with open ( fName , 'w' ) as f : f . write ( codeExemple ) ! python - m dis { fName } 1 0 LOAD_CONST 0 ('Alice') 2 LOAD_CONST 1 ('Bob') 4 LOAD_CONST 2 ('Carol') 6 LOAD_CONST 3 ('Doug') 8 BUILD_LIST 4 10 STORE_NAME 0 (ppl) 2 12 LOAD_CONST 4 (<code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>) 14 LOAD_CONST 5 ('<listcomp>') 16 MAKE_FUNCTION 0 18 LOAD_NAME 0 (ppl) 20 GET_ITER 22 CALL_FUNCTION 1 24 STORE_NAME 1 (excited_ppl) 3 26 LOAD_CONST 6 (<code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>) 28 LOAD_CONST 5 ('<listcomp>') 30 MAKE_FUNCTION 0 32 LOAD_NAME 0 (ppl) 34 GET_ITER 36 CALL_FUNCTION 1 38 STORE_NAME 2 (ppl_len) 40 LOAD_CONST 7 (None) 42 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>: 2 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (e) 8 LOAD_FAST 1 (e) 10 LOAD_CONST 0 ('!!') 12 BINARY_ADD 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>: 3 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (x) 8 LOAD_GLOBAL 0 (len) 10 LOAD_FAST 1 (x) 12 CALL_FUNCTION 1 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE c = compile ( codeExemple , 'test.py' , 'exec' ) c . co_code b'd\\x00d\\x01d\\x02d\\x03g\\x04Z\\x00d\\x04d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x01d\\x06d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x02d\\x07S\\x00' ! cat { fName } ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl] opcode.h \u00b6 ! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Include / opcode . h - O { tmp } / opcode . h ! head - n 30 { tmp } / opcode . h /* Auto-generated by Tools/scripts/generate_opcode_h.py from Lib/opcode.py */ ifndef Py_OPCODE_H \u00b6 define Py_OPCODE_H \u00b6 ifdef __cplusplus \u00b6 extern \"C\" { endif \u00b6 /* Instruction opcodes for compiled code */ define POP_TOP 1 \u00b6 define ROT_TWO 2 \u00b6 define ROT_THREE 3 \u00b6 define DUP_TOP 4 \u00b6 define DUP_TOP_TWO 5 \u00b6 define ROT_FOUR 6 \u00b6 define NOP 9 \u00b6 define UNARY_POSITIVE 10 \u00b6 define UNARY_NEGATIVE 11 \u00b6 define UNARY_NOT 12 \u00b6 define UNARY_INVERT 15 \u00b6 define BINARY_MATRIX_MULTIPLY 16 \u00b6 define INPLACE_MATRIX_MULTIPLY 17 \u00b6 define BINARY_POWER 19 \u00b6 define BINARY_MULTIPLY 20 \u00b6 define BINARY_MODULO 22 \u00b6 define BINARY_ADD 23 \u00b6 define BINARY_SUBTRACT 24 \u00b6 define BINARY_SUBSCR 25 \u00b6 define BINARY_FLOOR_DIVIDE 26 \u00b6 define BINARY_TRUE_DIVIDE 27 \u00b6 ceval.c \u00b6 ! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Python / ceval . c - O { tmp } / ceval . c ! head - n 20 { tmp } / ceval . c /* Execute compiled code */ /* XXX TO DO: XXX speed up searching for keywords by using a dictionary XXX document it! */ /* enable more aggressive intra-module optimizations, where available */ define PY_LOCAL_AGGRESSIVE \u00b6 include \"Python.h\" \u00b6 include \"pycore_call.h\" \u00b6 include \"pycore_ceval.h\" \u00b6 include \"pycore_code.h\" \u00b6 include \"pycore_object.h\" \u00b6 include \"pycore_pyerrors.h\" \u00b6 include \"pycore_pylifecycle.h\" \u00b6 include \"pycore_pystate.h\" \u00b6 include \"pycore_tupleobject.h\" \u00b6 General purpose \u00b6 https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code Garbage collected \u00b6 https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"Intro"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#high-level","text":"In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia","title":"High-level"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#interpreted","text":"There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled","title":"Interpreted"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#code-structure","text":"The code directory structure is described in Python Developer's Guide . Guido van Rossum summarizes it in Yet another guided tour of CPython Include \u2014 header files Objects \u2014 object implementations, from int to type Python \u2014 interpreter, bytecode compiler and other essential infrastructure Parser \u2014 parser, lexer and parser generator Modules \u2014 stdlib extension modules, and main.c Programs \u2014 not much, but has the real main() function cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python In CPython, the compilation from source code to bytecode involves several steps [src] Parse source code into a parse tree (Parser/pgen.c) Transform parse tree into an Abstract Syntax Tree (Python/ast.c) Transform AST into a Control Flow Graph (Python/compile.c) Emit bytecode based on the Control Flow Graph (Python/compile.c)","title":"Code structure"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#ast","text":"Doc The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . In python, everything is an object, AST represents logicaly each element as an object. A third pary documentation on AST import ast from ast import PyCF_ONLY_AST # The code is beeing striped to remove # left and right space before parsing # and limit thee size of the tree code = \"\"\" def hello(who: str) -> None: msg = f'Hello {who} ' print(msg) hello(\"world\") \"\"\" code = code . strip () Execute the code exec ( code ) Hello world tree = ast . parse ( code ) The code is seen as two elements in the tree for i , elt in enumerate ( tree . body ): print ( i , elt ) 0 <_ast.FunctionDef object at 0x7f79c9aa0690> 1 <_ast.Expr object at 0x7f79c9ad1890> # Get the FunctionDef fdef = tree . body [ 0 ] # Get the first function argument arg = fdef . args . args [ 0 ] Some informations from the tree can be retrieved: print ( f ' { arg . arg } : { arg . annotation . id } at col # { arg . col_offset } ' ) who: str at col #10 The code can be compiled lines = [ None ] + code . splitlines () # None at [0] so we can index lines from 1 test_namespace = {} for node in tree . body : wrapper = ast . Module ( body = [ node ]) try : co = compile ( wrapper , \"<ast>\" , 'exec' ) exec ( co , test_namespace ) except AssertionError as e : print ( \"Assertion failed on line\" , node . lineno , \":\" ) print ( lines [ node . lineno ]) # If the error has a message, show it. if e . args : print ( e ) print () Hello world code = compile ( tree , filename = \"<ast>\" , mode = \"exec\" ) class FuncLister ( ast . NodeVisitor ): def visit_FunctionDef ( self , node ): print ( node . name ) self . generic_visit ( node ) FuncLister () . visit ( tree ) hello","title":"AST"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#bytecode","text":"From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\"). With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program.","title":"Bytecode"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#opcodes-and-main-interpreter-loop","text":"import tempfile from os.path import join as pjoin tmp = tempfile . gettempdir () fName = pjoin ( tmp , 'test.py' ) codeExemple = \"\"\"ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl]\"\"\" with open ( fName , 'w' ) as f : f . write ( codeExemple ) ! python - m dis { fName } 1 0 LOAD_CONST 0 ('Alice') 2 LOAD_CONST 1 ('Bob') 4 LOAD_CONST 2 ('Carol') 6 LOAD_CONST 3 ('Doug') 8 BUILD_LIST 4 10 STORE_NAME 0 (ppl) 2 12 LOAD_CONST 4 (<code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>) 14 LOAD_CONST 5 ('<listcomp>') 16 MAKE_FUNCTION 0 18 LOAD_NAME 0 (ppl) 20 GET_ITER 22 CALL_FUNCTION 1 24 STORE_NAME 1 (excited_ppl) 3 26 LOAD_CONST 6 (<code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>) 28 LOAD_CONST 5 ('<listcomp>') 30 MAKE_FUNCTION 0 32 LOAD_NAME 0 (ppl) 34 GET_ITER 36 CALL_FUNCTION 1 38 STORE_NAME 2 (ppl_len) 40 LOAD_CONST 7 (None) 42 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dc4ed0, file \"/tmp/test.py\", line 2>: 2 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (e) 8 LOAD_FAST 1 (e) 10 LOAD_CONST 0 ('!!') 12 BINARY_ADD 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE Disassembly of <code object <listcomp> at 0x7f43f9dca390, file \"/tmp/test.py\", line 3>: 3 0 BUILD_LIST 0 2 LOAD_FAST 0 (.0) >> 4 FOR_ITER 12 (to 18) 6 STORE_FAST 1 (x) 8 LOAD_GLOBAL 0 (len) 10 LOAD_FAST 1 (x) 12 CALL_FUNCTION 1 14 LIST_APPEND 2 16 JUMP_ABSOLUTE 4 >> 18 RETURN_VALUE c = compile ( codeExemple , 'test.py' , 'exec' ) c . co_code b'd\\x00d\\x01d\\x02d\\x03g\\x04Z\\x00d\\x04d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x01d\\x06d\\x05\\x84\\x00e\\x00D\\x00\\x83\\x01Z\\x02d\\x07S\\x00' ! cat { fName } ppl = ['Alice', 'Bob', 'Carol', 'Doug'] excited_ppl = [e + '!!' for e in ppl] ppl_len = [len(x) for x in ppl]","title":"Opcodes and main interpreter loop"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#opcodeh","text":"! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Include / opcode . h - O { tmp } / opcode . h ! head - n 30 { tmp } / opcode . h /* Auto-generated by Tools/scripts/generate_opcode_h.py from Lib/opcode.py */","title":"opcode.h"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#ifndef-py_opcode_h","text":"","title":"ifndef Py_OPCODE_H"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-py_opcode_h","text":"","title":"define Py_OPCODE_H"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#ifdef-__cplusplus","text":"extern \"C\" {","title":"ifdef __cplusplus"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#endif","text":"/* Instruction opcodes for compiled code */","title":"endif"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-pop_top-1","text":"","title":"define POP_TOP                   1"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-rot_two-2","text":"","title":"define ROT_TWO                   2"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-rot_three-3","text":"","title":"define ROT_THREE                 3"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-dup_top-4","text":"","title":"define DUP_TOP                   4"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-dup_top_two-5","text":"","title":"define DUP_TOP_TWO               5"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-rot_four-6","text":"","title":"define ROT_FOUR                  6"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-nop-9","text":"","title":"define NOP                       9"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-unary_positive-10","text":"","title":"define UNARY_POSITIVE           10"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-unary_negative-11","text":"","title":"define UNARY_NEGATIVE           11"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-unary_not-12","text":"","title":"define UNARY_NOT                12"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-unary_invert-15","text":"","title":"define UNARY_INVERT             15"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_matrix_multiply-16","text":"","title":"define BINARY_MATRIX_MULTIPLY   16"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-inplace_matrix_multiply-17","text":"","title":"define INPLACE_MATRIX_MULTIPLY  17"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_power-19","text":"","title":"define BINARY_POWER             19"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_multiply-20","text":"","title":"define BINARY_MULTIPLY          20"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_modulo-22","text":"","title":"define BINARY_MODULO            22"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_add-23","text":"","title":"define BINARY_ADD               23"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_subtract-24","text":"","title":"define BINARY_SUBTRACT          24"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_subscr-25","text":"","title":"define BINARY_SUBSCR            25"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_floor_divide-26","text":"","title":"define BINARY_FLOOR_DIVIDE      26"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-binary_true_divide-27","text":"","title":"define BINARY_TRUE_DIVIDE       27"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#cevalc","text":"! wget -- quiet https : // raw . githubusercontent . com / python / cpython / master / Python / ceval . c - O { tmp } / ceval . c ! head - n 20 { tmp } / ceval . c /* Execute compiled code */ /* XXX TO DO: XXX speed up searching for keywords by using a dictionary XXX document it! */ /* enable more aggressive intra-module optimizations, where available */","title":"ceval.c"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#define-py_local_aggressive","text":"","title":"define PY_LOCAL_AGGRESSIVE"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pythonh","text":"","title":"include &#34;Python.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_callh","text":"","title":"include &#34;pycore_call.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_cevalh","text":"","title":"include &#34;pycore_ceval.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_codeh","text":"","title":"include &#34;pycore_code.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_objecth","text":"","title":"include &#34;pycore_object.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_pyerrorsh","text":"","title":"include &#34;pycore_pyerrors.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_pylifecycleh","text":"","title":"include &#34;pycore_pylifecycle.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_pystateh","text":"","title":"include &#34;pycore_pystate.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#include-pycore_tupleobjecth","text":"","title":"include &#34;pycore_tupleobject.h&#34;"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#general-purpose","text":"https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code","title":"General purpose"},{"location":"_nb/%3DPy/01_Python/01%20-%20Python%20-%20CPython%20design/#garbage-collected","text":"https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"Garbage collected"},{"location":"_nb/%3DPy/01_Python_intro/01%20-%20Python%20-%20def/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a \"batteries included\" language due to its comprehensive standard library. High-level \u00b6 In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia Interpreted \u00b6 There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled First, consider only the upper direct path. The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program. Bytecode example \u00b6 print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\"). General purpose \u00b6 https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python Garbage collected \u00b6 https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"01   Python   def"},{"location":"_nb/%3DPy/01_Python_intro/01%20-%20Python%20-%20def/#high-level","text":"In computer science, a high-level programming language is a programming language with strong abstraction from the details of the computer. In contrast to low-level programming languages, it may use natural language elements, be easier to use, or may automate (or even hide entirely) significant areas of computing systems (e.g. memory management), making the process of developing a program simpler and more understandable than when using a lower-level language Wikipedia","title":"High-level"},{"location":"_nb/%3DPy/01_Python_intro/01%20-%20Python%20-%20def/#interpreted","text":"There are three general modes of execution for modern high-level languages: Interpreted : the syntax is read and then executed directly, with no compilation stage. A program called an interpreter reads each program statement, following the program flow, then decides what to do, and does it. Compiled : the code written in a language is compiled, its syntax is transformed into an executable form before running. There are two types of compilation: Machine code generation Intermediate representations : the code written in a language is compiled to an intermediate representation, that representation can be optimized or saved for later execution without the need to re-read the source file. When the intermediate representation is saved, it may be in a form such as bytecode. The intermediate representation must then be interpreted or further compiled to execute it. Source-to-source translated or transcompiled First, consider only the upper direct path. The code is parsed, i.e. split up into a list of pieces called tokens. These tokens are based on a set of rules for things that should be treated differently. For instance, the keyword if is a different token than a numeric value like 42 . The list of tokens is transformed to build an Abstract Syntax Tree, AST , collection of nodes which are linked together based on the Python language grammar . From an abstract syntax tree, the interpreter can produce a lower level form of instructions called bytecode . These instructions are things like BINARY_ADD and are meant to be very generic so that a computer can run them. With the bytecode instructions available, the interpreter can finally run your code. The bytecode is used to call functions in your operating system which will ultimately interact with a CPU and memory to run the program.","title":"Interpreted"},{"location":"_nb/%3DPy/01_Python_intro/01%20-%20Python%20-%20def/#bytecode-example","text":"print ( \"Hello, World!\" ) Hello, World! from dis import dis dis ( 'print(\"Hello, World!\")' ) 1 0 LOAD_NAME 0 (print) 2 LOAD_CONST 0 ('Hello, World!') 4 CALL_FUNCTION 1 6 RETURN_VALUE CPython uses a stack-based virtual machine. That is, it's oriented entirely around stack data structures (where you can \"push\" an item onto the \"top\" of the structure, or \"pop\" an item off the \"top\").","title":"Bytecode example"},{"location":"_nb/%3DPy/01_Python_intro/01%20-%20Python%20-%20def/#general-purpose","text":"https://awesome-python.com/ : References: - Your Guide to the CPython Source Code - Inside The Python Virtual Machine - An introduction to Python bytecode - Deciphering Python: How to use Abstract Syntax Trees (AST) to understand code cpython/ \u2502 \u251c\u2500\u2500 Doc \u2190 Source for the documentation \u251c\u2500\u2500 Grammar \u2190 The computer-readable language definition \u251c\u2500\u2500 Include \u2190 The C header files \u251c\u2500\u2500 Lib \u2190 Standard library modules written in Python \u251c\u2500\u2500 Mac \u2190 macOS support files \u251c\u2500\u2500 Misc \u2190 Miscellaneous files \u251c\u2500\u2500 Modules \u2190 Standard Library Modules written in C \u251c\u2500\u2500 Objects \u2190 Core types and the object model \u251c\u2500\u2500 Parser \u2190 The Python parser source code \u251c\u2500\u2500 PC \u2190 Windows build support files \u251c\u2500\u2500 PCbuild \u2190 Windows build support files for older Windows versions \u251c\u2500\u2500 Programs \u2190 Source code for the python executable and other binaries \u251c\u2500\u2500 Python \u2190 The CPython interpreter source code \u2514\u2500\u2500 Tools \u2190 Standalone tools useful for building or extending Python","title":"General purpose"},{"location":"_nb/%3DPy/01_Python_intro/01%20-%20Python%20-%20def/#garbage-collected","text":"https://github.com/python/cpython/blob/ce6a070414ed1e1374d1e6212bfbff61b6d5d755/Include/object.h#L104 from sys import getrefcount a = \"un\" getrefcount ( a ) 2 b = a b is a True getrefcount ( a ) 3 del ( b ) getrefcount ( a ) 2","title":"Garbage collected"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); The Python Interpreter \u00b6 $ python Python 3.7 . 3 ( default , Apr 3 2019 , 05 : 39 : 12 ) [ GCC 8.3 . 0 ] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information . >>> >>> a = 1 >>> print ( a ) 1 >>> exit () %% writefile hello_world . py print ( \"Hello world\" ) Overwriting hello_world.py $ python hello_world . py Hello world $ ipython Python 3 .6.0 | packaged by conda-forge | ( default, Jan 13 2017 , 23 :17:12 ) Type \"copyright\" , \"credits\" or \"license\" for more information. IPython 5 .1.0 -- An enhanced Interactive Python. ? -> Introduction and overview of IPython 's features. %quickref -> Quick reference. help -> Python' s own help system. object? -> Details about 'object' , use 'object??' for extra details. In [ 1 ] : %run hello_world.py Hello world In [ 2 ] : IPython Basics \u00b6 Running the IPython Shell \u00b6 from numpy.random import randn data = {i : randn() for i in range(7)} print(data) {0: -1.5948255432744511, 1: 0.10569006472787983, 2: 1.972367135977295, 3: 0.15455217573074576, 4: -0.24058577449429575, 5: -1.2904897053651216, 6: 0.3308507317325902} Running the Jupyter Notebook \u00b6 $ jupyter notebook [ I 15 :20:52.739 NotebookApp ] Serving notebooks from local directory: /home/wesm/code/pydata-book [ I 15 :20:52.739 NotebookApp ] 0 active kernels [ I 15 :20:52.739 NotebookApp ] The Jupyter Notebook is running at: http://localhost:8888/ [ I 15 :20:52.740 NotebookApp ] Use Control-C to stop this server and shut down all kernels ( twice to skip confirmation ) . Created new window in existing browser session. Tab Completion \u00b6 In [1]: an_apple = 27 In [2]: an_example = 42 In [3]: an In [3]: b = [1, 2, 3] In [4]: b. In [1]: import datetime In [2]: datetime. In [7]: datasets/movielens/ Introspection \u00b6 In [8]: b = [1, 2, 3] In [9]: b? Type: list String Form:[1, 2, 3] Length: 3 Docstring: list() -> new empty list list(iterable) -> new list initialized from iterable's items In [10]: print? Docstring: print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. Type: builtin_function_or_method def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b In [ 11 ]: add_numbers ? Signature : add_numbers ( a , b ) Docstring : Add two numbers together Returns ------- the_sum : type of arguments File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 12 ]: add_numbers ?? Signature : add_numbers ( a , b ) Source : def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 13 ]: np .* load * ? np . __loader__ np . load np . loads np . loadtxt np . pkgload Interrupting running code \u00b6 Python Language Basics \u00b6 Language Semantics \u00b6 Indentation, not braces \u00b6 for x in array : if x < pivot : less . append ( x ) else : greater . append ( x ) a = 5 ; b = 6 ; c = 7 %% javascript ( new Array ([ 1 , 2 ])). then ( elt => elt ) var element = $('#ef8ac35f-9ae5-41e1-83a8-e6963a5a74fd'); (new Array([1, 2])).then(elt => elt) Everything is an object \u00b6 A = dict ( first = 1 , second = 2 ) A {'first': 1, 'second': 2} type ( A ) dict type ( type ( A )) type type ( type ( type ( A ))) type Comments \u00b6 results = [] for line in file_handle : # keep the empty lines for now # if len(line) == 0: # continue results . append ( line . replace ( 'foo' , 'bar' )) print ( \"Reached this line\" ) # Simple status report Function and object method calls \u00b6 result = f(x, y, z) g() obj.some_method(x, y, z) result = f ( a , b , c , d = 5 , e = 'foo' ) Variables and argument passing \u00b6 a = [ 1 , 2 , 3 ] b = a a . append ( 4 ) b [1, 2, 3, 4] a [1, 2, 3, 4] def append_element ( some_list , element ): some_list . append ( element ) In [ 27 ]: data = [ 1 , 2 , 3 ] In [ 28 ]: append_element ( data , 4 ) In [ 29 ]: data Out [ 29 ]: [ 1 , 2 , 3 , 4 ] Dynamic references, strong types \u00b6 a = 5 type ( a ) int a = 'foo' type ( a ) str '5' + 5 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-73-4dd8efb5fac1> in <module> ----> 1 '5' + 5 TypeError : can only concatenate str (not \"int\") to str a = 4.5 b = 2 # String formatting, to be visited later print ( f 'a is { type ( a ) } , b is { type ( b ) } ' ) a / b a is <class 'float'>, b is <class 'int'> 2.25 a = 5 isinstance ( a , int ) True a = 5 ; b = 4.5 isinstance ( a , ( int , float )) True isinstance ( b , ( int , float )) True Attributes and methods \u00b6 In [ 1 ]: a = 'foo' In [ 2 ]: a .< Press Tab > a . capitalize a . format a . isupper a . rindex a . strip a . center a . index a . join a . rjust a . swapcase a . count a . isalnum a . ljust a . rpartition a . title a . decode a . isalpha a . lower a . rsplit a . translate a . encode a . isdigit a . lstrip a . rstrip a . upper a . endswith a . islower a . partition a . split a . zfill a . expandtabs a . isspace a . replace a . splitlines a . find a . istitle a . rfind a . startswith a = 'foo' getattr ( a , 'split' ) <function str.split(sep=None, maxsplit=-1)> Duck typing \u00b6 def isiterable ( obj ): try : iter ( obj ) return True except TypeError : # not iterable return False isiterable ( 'a string' ) isiterable ([ 1 , 2 , 3 ]) isiterable ( 5 ) False if not isinstance(x, list) and isiterable(x): x = list(x) Imports \u00b6 # some_module.py PI = 3.14159 def f ( x ): return x + 2 def g ( a , b ): return a + b import some_module result = some_module.f(5) pi = some_module.PI from some_module import f, g, PI result = g(5, PI) import some_module as sm from some_module import PI as pi, g as gf r1 = sm.f(pi) r2 = gf(6, pi) Binary operators and comparisons \u00b6 5 - 7 12 + 21.5 5 <= 2 a = [ 1 , 2 , 3 ] b = a c = list ( a ) a is b a is not c a == c a = None a is None Mutable and immutable objects \u00b6 a_list = [ 'foo' , 2 , [ 4 , 5 ]] a_list [ 2 ] = ( 3 , 4 ) a_list a_tuple = ( 3 , 5 , ( 4 , 5 )) a_tuple [ 1 ] = 'four' Scalar Types \u00b6 Numeric types \u00b6 ival = 17239871 ival ** 6 fval = 7.243 fval2 = 6.78e-5 3 / 2 3 // 2 Strings \u00b6 a = 'one way of writing a string' b = \"another way\" c = \"\"\" This is a longer string that spans multiple lines \"\"\" c . count ( ' \\n ' ) a = 'this is a string' a [ 10 ] = 'f' b = a . replace ( 'string' , 'longer string' ) b a a = 5.6 s = str ( a ) print ( s ) s = 'python' list ( s ) s [: 3 ] s = '12 \\\\ 34' print ( s ) s = r 'this\\has\\no\\special\\characters' s a = 'this is the first half ' b = 'and this is the second half' a + b template = ' {0:.2f} {1:s} are worth US$ {2:d} ' template . format ( 4.5560 , 'Argentine Pesos' , 1 ) Bytes and Unicode \u00b6 val = \"espa\u00f1ol\" val val_utf8 = val . encode ( 'utf-8' ) val_utf8 type ( val_utf8 ) val_utf8 . decode ( 'utf-8' ) val . encode ( 'latin1' ) val . encode ( 'utf-16' ) val . encode ( 'utf-16le' ) bytes_val = b 'this is bytes' bytes_val decoded = bytes_val . decode ( 'utf8' ) decoded # this is str (Unicode) now Booleans \u00b6 True and True False or True Type casting \u00b6 s = '3.14159' fval = float ( s ) type ( fval ) int ( fval ) bool ( fval ) bool ( 0 ) None \u00b6 a = None a is None b = 5 b is not None def add_and_maybe_multiply(a, b, c=None): result = a + b if c is not None: result = result * c return result type ( None ) Dates and times \u00b6 from datetime import datetime , date , time dt = datetime ( 2011 , 10 , 29 , 20 , 30 , 21 ) dt . day dt . minute dt . date () dt . time () dt . strftime ( '%m/ %d /%Y %H:%M' ) datetime . strptime ( '20091031' , '%Y%m %d ' ) dt . replace ( minute = 0 , second = 0 ) dt2 = datetime ( 2011 , 11 , 15 , 22 , 30 ) delta = dt2 - dt delta type ( delta ) dt dt + delta Control Flow \u00b6 if, elif, and else \u00b6 if x < 0: print('It's negative') if x < 0: print('It's negative') elif x == 0: print('Equal to zero') elif 0 < x < 5: print('Positive but smaller than 5') else: print('Positive and larger than or equal to 5') a = 5 ; b = 7 c = 8 ; d = 4 if a < b or c > d : print ( 'Made it' ) 4 > 3 > 2 > 1 for loops \u00b6 for value in collection: # do something with value sequence = [1, 2, None, 4, None, 5] total = 0 for value in sequence: if value is None: continue total += value sequence = [1, 2, 0, 4, 6, 5, 2, 1] total_until_5 = 0 for value in sequence: if value == 5: break total_until_5 += value for i in range ( 4 ): for j in range ( 4 ): if j > i : break print (( i , j )) for a, b, c in iterator: # do something while loops \u00b6 x = 256 total = 0 while x > 0: if total > 500: break total += x x = x // 2 pass \u00b6 if x < 0: print('negative!') elif x == 0: # TODO: put something smart here pass else: print('positive!') range \u00b6 range ( 10 ) list ( range ( 10 )) list ( range ( 0 , 20 , 2 )) list ( range ( 5 , 0 , - 1 )) seq = [1, 2, 3, 4] for i in range(len(seq)): val = seq[i] sum = 0 for i in range(100000): # % is the modulo operator if i % 3 == 0 or i % 5 == 0: sum += i Ternary expressions \u00b6 value = if x = 5 'Non-negative' if x >= 0 else 'Negative' References: - Python for Data Analysis\" by Wes McKinney, published by O'Reilly Media","title":"02   Python   intro"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#the-python-interpreter","text":"$ python Python 3.7 . 3 ( default , Apr 3 2019 , 05 : 39 : 12 ) [ GCC 8.3 . 0 ] on linux Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information . >>> >>> a = 1 >>> print ( a ) 1 >>> exit () %% writefile hello_world . py print ( \"Hello world\" ) Overwriting hello_world.py $ python hello_world . py Hello world $ ipython Python 3 .6.0 | packaged by conda-forge | ( default, Jan 13 2017 , 23 :17:12 ) Type \"copyright\" , \"credits\" or \"license\" for more information. IPython 5 .1.0 -- An enhanced Interactive Python. ? -> Introduction and overview of IPython 's features. %quickref -> Quick reference. help -> Python' s own help system. object? -> Details about 'object' , use 'object??' for extra details. In [ 1 ] : %run hello_world.py Hello world In [ 2 ] :","title":"The Python Interpreter"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#ipython-basics","text":"","title":"IPython Basics"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#running-the-ipython-shell","text":"from numpy.random import randn data = {i : randn() for i in range(7)} print(data) {0: -1.5948255432744511, 1: 0.10569006472787983, 2: 1.972367135977295, 3: 0.15455217573074576, 4: -0.24058577449429575, 5: -1.2904897053651216, 6: 0.3308507317325902}","title":"Running the IPython Shell"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#running-the-jupyter-notebook","text":"$ jupyter notebook [ I 15 :20:52.739 NotebookApp ] Serving notebooks from local directory: /home/wesm/code/pydata-book [ I 15 :20:52.739 NotebookApp ] 0 active kernels [ I 15 :20:52.739 NotebookApp ] The Jupyter Notebook is running at: http://localhost:8888/ [ I 15 :20:52.740 NotebookApp ] Use Control-C to stop this server and shut down all kernels ( twice to skip confirmation ) . Created new window in existing browser session.","title":"Running the Jupyter Notebook"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#tab-completion","text":"In [1]: an_apple = 27 In [2]: an_example = 42 In [3]: an In [3]: b = [1, 2, 3] In [4]: b. In [1]: import datetime In [2]: datetime. In [7]: datasets/movielens/","title":"Tab Completion"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#introspection","text":"In [8]: b = [1, 2, 3] In [9]: b? Type: list String Form:[1, 2, 3] Length: 3 Docstring: list() -> new empty list list(iterable) -> new list initialized from iterable's items In [10]: print? Docstring: print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. Type: builtin_function_or_method def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b In [ 11 ]: add_numbers ? Signature : add_numbers ( a , b ) Docstring : Add two numbers together Returns ------- the_sum : type of arguments File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 12 ]: add_numbers ?? Signature : add_numbers ( a , b ) Source : def add_numbers ( a , b ): \"\"\" Add two numbers together Returns ------- the_sum : type of arguments \"\"\" return a + b File : < ipython - input - 9 - 6 a548a216e27 > Type : function In [ 13 ]: np .* load * ? np . __loader__ np . load np . loads np . loadtxt np . pkgload","title":"Introspection"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#interrupting-running-code","text":"","title":"Interrupting running code"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#python-language-basics","text":"","title":"Python Language Basics"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#language-semantics","text":"","title":"Language Semantics"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#indentation-not-braces","text":"for x in array : if x < pivot : less . append ( x ) else : greater . append ( x ) a = 5 ; b = 6 ; c = 7 %% javascript ( new Array ([ 1 , 2 ])). then ( elt => elt ) var element = $('#ef8ac35f-9ae5-41e1-83a8-e6963a5a74fd'); (new Array([1, 2])).then(elt => elt)","title":"Indentation, not braces"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#everything-is-an-object","text":"A = dict ( first = 1 , second = 2 ) A {'first': 1, 'second': 2} type ( A ) dict type ( type ( A )) type type ( type ( type ( A ))) type","title":"Everything is an object"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#comments","text":"results = [] for line in file_handle : # keep the empty lines for now # if len(line) == 0: # continue results . append ( line . replace ( 'foo' , 'bar' )) print ( \"Reached this line\" ) # Simple status report","title":"Comments"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#function-and-object-method-calls","text":"result = f(x, y, z) g() obj.some_method(x, y, z) result = f ( a , b , c , d = 5 , e = 'foo' )","title":"Function and object method calls"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#variables-and-argument-passing","text":"a = [ 1 , 2 , 3 ] b = a a . append ( 4 ) b [1, 2, 3, 4] a [1, 2, 3, 4] def append_element ( some_list , element ): some_list . append ( element ) In [ 27 ]: data = [ 1 , 2 , 3 ] In [ 28 ]: append_element ( data , 4 ) In [ 29 ]: data Out [ 29 ]: [ 1 , 2 , 3 , 4 ]","title":"Variables and argument passing"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#dynamic-references-strong-types","text":"a = 5 type ( a ) int a = 'foo' type ( a ) str '5' + 5 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-73-4dd8efb5fac1> in <module> ----> 1 '5' + 5 TypeError : can only concatenate str (not \"int\") to str a = 4.5 b = 2 # String formatting, to be visited later print ( f 'a is { type ( a ) } , b is { type ( b ) } ' ) a / b a is <class 'float'>, b is <class 'int'> 2.25 a = 5 isinstance ( a , int ) True a = 5 ; b = 4.5 isinstance ( a , ( int , float )) True isinstance ( b , ( int , float )) True","title":"Dynamic references, strong types"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#attributes-and-methods","text":"In [ 1 ]: a = 'foo' In [ 2 ]: a .< Press Tab > a . capitalize a . format a . isupper a . rindex a . strip a . center a . index a . join a . rjust a . swapcase a . count a . isalnum a . ljust a . rpartition a . title a . decode a . isalpha a . lower a . rsplit a . translate a . encode a . isdigit a . lstrip a . rstrip a . upper a . endswith a . islower a . partition a . split a . zfill a . expandtabs a . isspace a . replace a . splitlines a . find a . istitle a . rfind a . startswith a = 'foo' getattr ( a , 'split' ) <function str.split(sep=None, maxsplit=-1)>","title":"Attributes and methods"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#duck-typing","text":"def isiterable ( obj ): try : iter ( obj ) return True except TypeError : # not iterable return False isiterable ( 'a string' ) isiterable ([ 1 , 2 , 3 ]) isiterable ( 5 ) False if not isinstance(x, list) and isiterable(x): x = list(x)","title":"Duck typing"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#imports","text":"# some_module.py PI = 3.14159 def f ( x ): return x + 2 def g ( a , b ): return a + b import some_module result = some_module.f(5) pi = some_module.PI from some_module import f, g, PI result = g(5, PI) import some_module as sm from some_module import PI as pi, g as gf r1 = sm.f(pi) r2 = gf(6, pi)","title":"Imports"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#binary-operators-and-comparisons","text":"5 - 7 12 + 21.5 5 <= 2 a = [ 1 , 2 , 3 ] b = a c = list ( a ) a is b a is not c a == c a = None a is None","title":"Binary operators and comparisons"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#mutable-and-immutable-objects","text":"a_list = [ 'foo' , 2 , [ 4 , 5 ]] a_list [ 2 ] = ( 3 , 4 ) a_list a_tuple = ( 3 , 5 , ( 4 , 5 )) a_tuple [ 1 ] = 'four'","title":"Mutable and immutable objects"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#scalar-types","text":"","title":"Scalar Types"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#numeric-types","text":"ival = 17239871 ival ** 6 fval = 7.243 fval2 = 6.78e-5 3 / 2 3 // 2","title":"Numeric types"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#strings","text":"a = 'one way of writing a string' b = \"another way\" c = \"\"\" This is a longer string that spans multiple lines \"\"\" c . count ( ' \\n ' ) a = 'this is a string' a [ 10 ] = 'f' b = a . replace ( 'string' , 'longer string' ) b a a = 5.6 s = str ( a ) print ( s ) s = 'python' list ( s ) s [: 3 ] s = '12 \\\\ 34' print ( s ) s = r 'this\\has\\no\\special\\characters' s a = 'this is the first half ' b = 'and this is the second half' a + b template = ' {0:.2f} {1:s} are worth US$ {2:d} ' template . format ( 4.5560 , 'Argentine Pesos' , 1 )","title":"Strings"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#bytes-and-unicode","text":"val = \"espa\u00f1ol\" val val_utf8 = val . encode ( 'utf-8' ) val_utf8 type ( val_utf8 ) val_utf8 . decode ( 'utf-8' ) val . encode ( 'latin1' ) val . encode ( 'utf-16' ) val . encode ( 'utf-16le' ) bytes_val = b 'this is bytes' bytes_val decoded = bytes_val . decode ( 'utf8' ) decoded # this is str (Unicode) now","title":"Bytes and Unicode"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#booleans","text":"True and True False or True","title":"Booleans"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#type-casting","text":"s = '3.14159' fval = float ( s ) type ( fval ) int ( fval ) bool ( fval ) bool ( 0 )","title":"Type casting"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#none","text":"a = None a is None b = 5 b is not None def add_and_maybe_multiply(a, b, c=None): result = a + b if c is not None: result = result * c return result type ( None )","title":"None"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#dates-and-times","text":"from datetime import datetime , date , time dt = datetime ( 2011 , 10 , 29 , 20 , 30 , 21 ) dt . day dt . minute dt . date () dt . time () dt . strftime ( '%m/ %d /%Y %H:%M' ) datetime . strptime ( '20091031' , '%Y%m %d ' ) dt . replace ( minute = 0 , second = 0 ) dt2 = datetime ( 2011 , 11 , 15 , 22 , 30 ) delta = dt2 - dt delta type ( delta ) dt dt + delta","title":"Dates and times"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#control-flow","text":"","title":"Control Flow"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#if-elif-and-else","text":"if x < 0: print('It's negative') if x < 0: print('It's negative') elif x == 0: print('Equal to zero') elif 0 < x < 5: print('Positive but smaller than 5') else: print('Positive and larger than or equal to 5') a = 5 ; b = 7 c = 8 ; d = 4 if a < b or c > d : print ( 'Made it' ) 4 > 3 > 2 > 1","title":"if, elif, and else"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#for-loops","text":"for value in collection: # do something with value sequence = [1, 2, None, 4, None, 5] total = 0 for value in sequence: if value is None: continue total += value sequence = [1, 2, 0, 4, 6, 5, 2, 1] total_until_5 = 0 for value in sequence: if value == 5: break total_until_5 += value for i in range ( 4 ): for j in range ( 4 ): if j > i : break print (( i , j )) for a, b, c in iterator: # do something","title":"for loops"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#while-loops","text":"x = 256 total = 0 while x > 0: if total > 500: break total += x x = x // 2","title":"while loops"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#pass","text":"if x < 0: print('negative!') elif x == 0: # TODO: put something smart here pass else: print('positive!')","title":"pass"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#range","text":"range ( 10 ) list ( range ( 10 )) list ( range ( 0 , 20 , 2 )) list ( range ( 5 , 0 , - 1 )) seq = [1, 2, 3, 4] for i in range(len(seq)): val = seq[i] sum = 0 for i in range(100000): # % is the modulo operator if i % 3 == 0 or i % 5 == 0: sum += i","title":"range"},{"location":"_nb/%3DPy/01_Python_intro/02%20-%20Python%20-%20intro/#ternary-expressions","text":"value = if x = 5 'Non-negative' if x >= 0 else 'Negative' References: - Python for Data Analysis\" by Wes McKinney, published by O'Reilly Media","title":"Ternary expressions"},{"location":"_nb/%3DPy/02_SQL/00_Init/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import intake from numpy import int8 accounts = intake . open_csv ( \"../data/accounts/*.csv\" , csv_kwargs = { \"dtype\" : { 'id' : int8 , 'names' : str } } ) accounts . shape = ( 3_000_000 , 3 ) accounts . discover () {'datashape': None, 'dtype': {'id': 'int8', 'names': 'object', 'amount': 'int64'}, 'shape': (None, 3), 'npartitions': 3, 'metadata': {}} accounts . dtype [ 'names' ] = str df = accounts . to_dask () from numpy import arange df . memory_usage () Dask Series Structure: npartitions=1 int64 ... dtype: int64 Dask Name: series-groupby-sum-agg, 19 tasks df . memory_usage () . compute () Index 240 amount 24000000 id 3000000 names 24000000 dtype: int64 gp = df . groupby ( 'id' ) gp = df . compute () . groupby ( 'id' ) import numpy as np gp . agg ( lambda x : len ( np . unique ( x ))) . names . max () 2 gp . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount 0 59 Tim -330 1 43 Yvonne 2731 2 58 Hannah 888 3 65 Wendy 1670 4 82 Zelda -1114 5 -108 Ray 2221 6 122 Victor 1068 7 96 Charlie 373 8 2 Ray 45 9 -85 Ingrid 1684 10 104 Yvonne 454 11 28 Quinn 559 12 -84 Hannah 583 13 -104 Tim 0 14 -72 Ray 1836 15 87 Jerry -16 16 71 George 50 17 -61 Patricia 675 18 94 Yvonne 1581 19 94 Laura 669 20 -39 Quinn 1938 21 -9 Frank 117 22 -24 Ursula 479 23 110 Xavier 24 24 72 Laura 3620 25 85 Kevin 274 26 25 Edith 125 27 28 Quinn 606 28 -56 Charlie 1565 29 -120 Dan 1560 ... ... ... ... 7293 7 Zelda -176 7305 -101 Norbert 1047 7496 40 Ingrid 2373 7500 -19 Quinn 25 7516 -101 Norbert 1083 7716 -98 Yvonne 603 7823 -1 Yvonne 4222 7835 -1 Yvonne 4501 7841 -117 Dan 483 8015 -105 Norbert 1715 8043 -25 Ray 4943 8565 7 Zelda -183 8653 40 Ingrid 2466 8671 -53 Charlie 1051 9268 -105 Norbert 1694 9301 -19 Quinn 32 9824 -4 Michael 2126 10776 -8 Frank 116 10809 -117 Dan 517 10987 -105 Norbert 1581 11002 -117 Dan 519 11345 -25 Ray 4029 12017 -12 Michael 74 14472 -12 Michael 52 14700 -12 Michael -35 14955 -12 Michael 73 15474 -8 Frank 116 15895 -105 Norbert 1598 17015 -4 Michael 2070 17635 -105 Norbert 1781 1280 rows \u00d7 3 columns newIndex = np . arange ( df . shape [ 0 ]) newIndex . shape (3000000,) df . reindex ( axis = 0 , method = \"pad\" ) . tail () --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) <ipython-input-36-df976a66ae41> in <module> ----> 1 df . reindex ( axis = 0 , method = \"pad\" ) . tail ( ) /opt/conda/lib/python3.7/site-packages/dask/dataframe/core.py in __getattr__ (self, key) 2586 return self [ key ] 2587 else : -> 2588 raise AttributeError ( \"'DataFrame' object has no attribute %r\" % key ) 2589 2590 def __dir__ ( self ) : AttributeError : 'DataFrame' object has no attribute 'reindex' # %timeit df.names.map(lambda x: len(x)).max() import pandas as pd dfp = pd . DataFrame ( df . values . compute (), columns = df . columns ) # dfp.names = dfp.names.astype(np.dtype('|S8')) dfp . id = dfp . id . astype ( np . int32 ) dfp . amount = dfp . amount . astype ( np . int64 ) # dfp.names = dfp.names.astype(np.dtype('|S16')) dfp . names = dfp . names . astype ( str ) dfp . dtypes id int32 names object amount int64 dtype: object dfp . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount 0 59 Tim -330 1 43 Yvonne 2731 2 58 Hannah 888 3 65 Wendy 1670 4 82 Zelda -1114 dfp . memory_usage () Index 80 id 12000000 names 24000000 amount 24000000 dtype: int64 dfp . to_sql ? Signature: dfp . to_sql ( name , con , schema = None , if_exists = 'fail' , index = True , index_label = None , chunksize = None , dtype = None , method = None , ) Docstring: Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1]_ are supported. Tables can be newly created, appended to, or overwritten. Parameters ---------- name : string Name of SQL table. con : sqlalchemy.engine.Engine or sqlite3.Connection Using SQLAlchemy makes it possible to use any DB supported by that library. Legacy support is provided for sqlite3.Connection objects. schema : string, optional Specify the schema (if database flavor supports this). If None, use default schema. if_exists : {'fail', 'replace', 'append'}, default 'fail' How to behave if the table already exists. * fail: Raise a ValueError. * replace: Drop the table before inserting new values. * append: Insert new values to the existing table. index : bool, default True Write DataFrame index as a column. Uses `index_label` as the column name in the table. index_label : string or sequence, default None Column label for index column(s). If None is given (default) and `index` is True, then the index names are used. A sequence should be given if the DataFrame uses MultiIndex. chunksize : int, optional Rows will be written in batches of this size at a time. By default, all rows will be written at once. dtype : dict, optional Specifying the datatype for columns. The keys should be the column names and the values should be the SQLAlchemy types or strings for the sqlite3 legacy mode. method : {None, 'multi', callable}, default None Controls the SQL insertion clause used: * None : Uses standard SQL ``INSERT`` clause (one per row). * 'multi': Pass multiple values in a single ``INSERT`` clause. * callable with signature ``(pd_table, conn, keys, data_iter)``. Details and a sample callable implementation can be found in the section :ref:`insert method <io.sql.method>`. .. versionadded:: 0.24.0 Raises ------ ValueError When the table already exists and `if_exists` is 'fail' (the default). See Also -------- read_sql : Read a DataFrame from a table. Notes ----- Timezone aware datetime columns will be written as ``Timestamp with timezone`` type with SQLAlchemy if supported by the database. Otherwise, the datetimes will be stored as timezone unaware timestamps local to the original timezone. .. versionadded:: 0.24.0 References ---------- .. [1] http://docs.sqlalchemy.org .. [2] https://www.python.org/dev/peps/pep-0249/ Examples -------- Create an in-memory SQLite database. >>> from sqlalchemy import create_engine >>> engine = create_engine('sqlite://', echo=False) Create a table from scratch with 3 rows. >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']}) >>> df name 0 User 1 1 User 2 2 User 3 >>> df.to_sql('users', con=engine) >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')] >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']}) >>> df1.to_sql('users', con=engine, if_exists='append') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'), (0, 'User 4'), (1, 'User 5')] Overwrite the table with just ``df1``. >>> df1.to_sql('users', con=engine, if_exists='replace', ... index_label='id') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 4'), (1, 'User 5')] Specify the dtype (especially useful for integers with missing values). Notice that while pandas is forced to store the data as floating point, the database supports nullable integers. When fetching the data with Python, we get back integer scalars. >>> df = pd.DataFrame({\"A\": [1, None, 2]}) >>> df A 0 1.0 1 NaN 2 2.0 >>> from sqlalchemy.types import Integer >>> df.to_sql('integers', con=engine, index=False, ... dtype={\"A\": Integer()}) >>> engine.execute(\"SELECT * FROM integers\").fetchall() [(1,), (None,), (2,)] File: /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py Type: method from sqlalchemy.types import String String ( 16 ) String(length=16) from sqlalchemy import create_engine uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com/postgres\" dfp . to_sql ( \"accounts\" , con = create_engine ( uri ) . connect (), index = False , if_exists = 'replace' ) % timeit dfp . names . map ( lambda x : len ( x )) . max () 1.16 s \u00b1 8.62 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } longitude latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value ocean_proximity 0 -122.23 37.88 41.0 880.0 129.0 322.0 126.0 8.3252 452600.0 NEAR BAY 1 -122.22 37.86 21.0 7099.0 1106.0 2401.0 1138.0 8.3014 358500.0 NEAR BAY 2 -122.24 37.85 52.0 1467.0 190.0 496.0 177.0 7.2574 352100.0 NEAR BAY 3 -122.25 37.85 52.0 1274.0 235.0 558.0 219.0 5.6431 341300.0 NEAR BAY 4 -122.25 37.85 52.0 1627.0 280.0 565.0 259.0 3.8462 342200.0 NEAR BAY ibis . schema ? Signature: ibis . schema ( pairs = None , names = None , types = None ) Docstring: Validate and return an Ibis Schema object Ibis uses its own type aliases that map onto database types. See, for example, the correspondence between Ibis type names and Impala type names: Ibis type Impala Type ~~~~~~~~~ ~~~~~~~~~~~ int8 TINYINT int16 SMALLINT int32 INT int64 BIGINT float FLOAT double DOUBLE boolean BOOLEAN string STRING timestamp TIMESTAMP decimal(p, s) DECIMAL(p,s) interval(u) INTERVAL(u) Parameters ---------- pairs : list of (name, type) tuples Mutually exclusive with names/types names : list of string Field names types : list of string Field types Examples -------- >>> from ibis import schema >>> sc = schema([('foo', 'string'), ... ('bar', 'int64'), ... ('baz', 'boolean')]) >>> sc2 = schema(names=['foo', 'bar', 'baz'], ... types=['string', 'int64', 'boolean']) Returns ------- schema : Schema File: /opt/conda/lib/python3.7/site-packages/ibis/expr/api.py Type: function accounts = con . table ( 'accounts' ) --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-66-b976ae21ec75> in <module> ----> 1 accounts = con . table ( 'accounts' ) NameError : name 'con' is not defined accounts . names ? Call signature: accounts . names ( f , * args , ** kwargs ) Type: StringColumn String form: ref_0 PostgreSQLTable[table] name: accounts schema: index : int64 id : int32 names : string amount : int64 names = Column[string*] 'names' from table ref_0 File: /opt/conda/lib/python3.7/site-packages/ibis/expr/types.py Docstring: <no docstring> Class docstring: Base class for a data generating expression having a fixed and known type, either a single value (scalar) Call docstring: Generic composition function to enable expression pipelining. Parameters ---------- f : function or (function, arg_name) tuple If the expression needs to be passed as anything other than the first argument to the function, pass a tuple with the argument name. For example, (f, 'data') if the function f expects a 'data' keyword args : positional arguments kwargs : keyword arguments Examples -------- >>> import ibis >>> t = ibis.table([('a', 'int64'), ('b', 'string')], name='t') >>> f = lambda a: (a + 1).name('a') >>> g = lambda a: (a * 2).name('a') >>> result1 = t.a.pipe(f).pipe(g) >>> result1 # doctest: +NORMALIZE_WHITESPACE ref_0 UnboundTable[table] name: t schema: a : int64 b : string a = Multiply[int64*] left: a = Add[int64*] left: a = Column[int64*] 'a' from table ref_0 right: Literal[int8] 1 right: Literal[int8] 2 >>> result2 = g(f(t.a)) # equivalent to the above >>> result1.equals(result2) True Returns ------- result : result type of passed function","title":"00 Init"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); S01 Relational Databases \u00b6 For a simple tutorial on database design, see Introduction to Database Design For a deep dive, see Database Design for Mere Mortals 0. Packages for working with relational databases in Python \u00b6 - Python Database API Specification v2.0 - The standard Python Database API - sqlite3 - API for builit-in sqlite3 package - Database drivers - For connecting to other databases - ipython-sql - SQL magic in Jupyter - SQLAlchemy - Most well-known Object Relational Mapper (ORM) - Pony ORM - Alternative ORM 1. Motivation \u00b6 Why relational databases and SQL? History of databases ACID Data integrity Schema 2. RDBMS \u00b6 Memory Storage Dictionary Query language 3. Anatomy \u00b6 Table (Relation): Represents a subject or an event . Column (Attribute): Represents a single variable or feature .- Row (Tuple): represents an observation . 4. Concepts \u00b6 Constraints \u00b6 You can impose constraints that values in a column have to take. For example, you can specify that values are compulsory (NOT NULL), or UNIQUE or fall within a certain range. Referential integrity \u00b6 - Primary key represents a unique identifier of a row. It may be simple or composite. - Unique - Non-null - Never optional - Foreign key is a column containing the primary key of a different table. It enforces referential integrity . Relationships \u00b6 - One to one - One to many - Many to many What happens on delete? Restrict Cascade Indexes \u00b6 An index is a data structure that allows fast search of a column (typically from linear to log time complexity). Most databases will automatically build an index for every primary key column, but you can also manually specify columns to build indexes for. Views \u00b6 - Temporary virtual table returned as a result of a query . - Views only specify the strucutre of a table - the contents are constructed on the fly from existing tables. - Queries return a Result Set 5. Design \u00b6 Columns \u00b6 - Use singlular form for name - Use informative names - Use unique names not shared by any other table (except foreign keys) - Column must be an attribute of the table's subject - Eliminate multi-part columns - Eliminate multi-value columsn - Eliminate redundant columns Tables \u00b6 - Use singular/plural forms for name (controversial) - Enusre every table has a primary key - Eliminate duplicate columns Relationships \u00b6 - Establish participation type and degree of relationship - One to one - One to many - Many to many 6. Example \u00b6 Use sqlmagic as alternative to using sqlite3 driver. % env DATABASE_URL = postgresql + psycopg2 : // postgres : postgres @db . postgres . app . com env: DATABASE_URL=postgresql+psycopg2://postgres:postgres@db.postgres.app.com % load_ext sql Connect to Postgres % config SqlMagic SqlMagic options -------------- SqlMagic.autocommit=<Bool> Current: True Set autocommit mode SqlMagic.autolimit=<Int> Current: 0 Automatically limit the size of the returned result sets SqlMagic.autopandas=<Bool> Current: False Return Pandas DataFrames instead of regular result sets SqlMagic.column_local_vars=<Bool> Current: False Return data into local variables from column names SqlMagic.displaylimit=<Int> Current: None Automatically limit the number of rows displayed (full result set is still stored) SqlMagic.dsn_filename=<Unicode> Current: 'odbc.ini' Path to DSN file. When the first argument is of the form [section], a sqlalchemy connection string is formed from the matching section in the DSN file. SqlMagic.feedback=<Bool> Current: True Print number of rows affected by DML SqlMagic.short_errors=<Bool> Current: True Don't display the full traceback on SQL Programming Error SqlMagic.style=<Unicode> Current: 'DEFAULT' Set the table printing style to any of prettytable's defined styles (currently DEFAULT, MSWORD_FRIENDLY, PLAIN_COLUMNS, RANDOM) %% sql \\ d 6 rows affected. Schema Name Type Owner public accounts table postgres public flat table postgres public t_cities table postgres public t_cities_id_seq sequence postgres public t_weather_observations table postgres public t_weather_observations_id_seq sequence postgres uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com\" % sql { uri } 'Connected: postgres@None' SQL for table deletion and creation %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , person_first varchar ( 255 ), person_last varchar ( 255 ), country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ) ); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres Done. Done. Done. Done. [] %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema' ; * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False True False public person postgres None True False True False SQL to insert rows. %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] The pg_relation_size() function returns the size of the table only, not included indexes or additional objects. %% sql SELECT pg_size_pretty ( pg_relation_size ( 'Country' )); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 1 rows affected. pg_size_pretty 8192 bytes %% sql INSERT INTO Person ( person_first , person_last , country_id ) VALUES ( 'Napolean' , 'Bonaparte' , 'FR' ), ( 'Luis' , 'Alvarez' , 'CU' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] Accessing the RDBMS dictionary. %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 9 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False True False public person postgres None True False True False information_schema sql_features postgres None False False False False information_schema sql_implementation_info postgres None False False False False information_schema sql_languages postgres None False False False False information_schema sql_packages postgres None False False False False information_schema sql_parts postgres None False False False False information_schema sql_sizing postgres None False False False False information_schema sql_sizing_profiles postgres None False False False False %% sql SELECT sql FROM postgres WHERE name = 'Person' ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres (psycopg2.errors.UndefinedTable) relation \"postgres\" does not exist LINE 1: SELECT sql FROM postgres ^ [SQL: SELECT sql FROM postgres WHERE name='Person';] (Background on this error at: http://sqlalche.me/e/f405) SQL as a Query Language. %% sql SELECT person_first as first , person_last AS last , country_name AS nationality FROM Person INNER JOIN country ON Person . country_id = Country . country_id ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. first last nationality Napolean Bonaparte France Luis Alvarez CUBA Visualizing the entitry-relationship diagram (ERd). % config ? Docstring: configure IPython %config Class[.trait=value] This magic exposes most of the IPython config system. Any Configurable class should be able to be configured with the simple line:: %config Class.trait=value Where `value` will be resolved in the user's namespace, if it is an expression or variable name. Examples -------- To see what classes are available for config, pass no arguments:: In [1]: %config Available objects for config: TerminalInteractiveShell HistoryManager PrefilterManager AliasManager IPCompleter DisplayFormatter To view what is configurable on a given class, just pass the class name:: In [2]: %config IPCompleter IPCompleter options ----------------- IPCompleter.omit__names=<Enum> Current: 2 Choices: (0, 1, 2) Instruct the completer to omit private method names Specifically, when completing on ``object.<tab>``. When 2 [default]: all names that start with '_' will be excluded. When 1: all 'magic' names (``__foo__``) will be excluded. When 0: nothing will be excluded. IPCompleter.merge_completions=<CBool> Current: True Whether to merge completion results into a single list If False, only the completion results from the first non-empty completer will be returned. IPCompleter.limit_to__all__=<CBool> Current: False Instruct the completer to use __all__ for the completion Specifically, when completing on ``object.<tab>``. When True: only those names in obj.__all__ will be included. When False [default]: the __all__ attribute is ignored IPCompleter.greedy=<CBool> Current: False Activate greedy completion This will enable completion on elements of lists, results of function calls, etc., but can be unsafe because the code is actually evaluated on TAB. but the real use is in setting values:: In [3]: %config IPCompleter.greedy = True and these values are read from the user_ns if they are variables:: In [4]: feeling_greedy=False In [5]: %config IPCompleter.greedy = feeling_greedy File: /opt/conda/lib/python3.7/site-packages/IPython/core/magics/config.py import ibis import eralchemy from sqlalchemy import create_engine engine = create_engine ( uri ) conn = engine . connect () import os from eralchemy import render_er if not os . path . exists ( 'erd_from_sqlalchemy.png' ): render_er ( uri , 'erd_from_sqlalchemy.png' ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/base.py:2972: SAWarning: Did not recognize type 'point' of column 'location' \"Did not recognize type '%s' of column '%s'\" % (attype, name) Homework walk-through \u00b6 Convert the flat file data in data/flat.csv into a well-structured relational database in SQLite3 stored as data/faculty.db . Note - salary information is confidential and should be kept in a separate table from other personal data. import pandas as pd flat = pd . read_csv ( '../data/flat.csv' , keep_default_na = False ) flat . sample ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name gender age height weight salary nationality code country language1 language2 language3 first last 899 Lucien Pittman Male 61 1.87 58 73000 Danish DK Denmark AutoIt Dylan Transact-SQL Lucien Pittman 1516 Zane Calhoun Male 60 1.93 48 127000 Greek GR Greece Io Java Zane Calhoun 827 Lauran Willis Female 34 1.92 75 89000 Romanian RO Romania Lauran Willis flat . to_sql ( 'flat' , conn ) %% sql \\ d * postgresql+psycopg2://postgres:***@db.postgres.app.com 6 rows affected. Schema Name Type Owner public accounts table postgres public flat table postgres public t_cities table postgres public t_cities_id_seq sequence postgres public t_weather_observations table postgres public t_weather_observations_id_seq sequence postgres %% sql USE faculty ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres (psycopg2.errors.SyntaxError) syntax error at or near \"USE\" LINE 1: USE faculty; ^ [SQL: USE faculty;] (Background on this error at: http://sqlalche.me/e/f405) %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , name varchar ( 255 ), age INTEGER NOT NULL , country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ) ); * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres Done. Done. Done. Done. [] %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] %% sql DELETE FROM Country * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] %% sql SELECT * FROM Country * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 0 rows affected. country_id country_name from sqlalchemy import create_engine engine = create_engine ( uri ) conn = engine . connect () flat . columns Index(['name', 'gender', 'age', 'height', 'weight', 'salary', 'nationality', 'code', 'country', 'language1', 'language2', 'language3', 'first', 'last'], dtype='object') flat . rename ( mapper = { 'code' : 'country_id' , 'country' : 'country_name' }, inplace = True ) country = flat[['country_id', 'country_name']]country.set_index('country_id').to_sql('Country', engine, if_exists='append') %%sql \u00b6 SELECT * FROM Country flat . to_sql ? Signature: flat . to_sql ( name , con , schema = None , if_exists = 'fail' , index = True , index_label = None , chunksize = None , dtype = None , method = None , ) Docstring: Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1]_ are supported. Tables can be newly created, appended to, or overwritten. Parameters ---------- name : string Name of SQL table. con : sqlalchemy.engine.Engine or sqlite3.Connection Using SQLAlchemy makes it possible to use any DB supported by that library. Legacy support is provided for sqlite3.Connection objects. schema : string, optional Specify the schema (if database flavor supports this). If None, use default schema. if_exists : {'fail', 'replace', 'append'}, default 'fail' How to behave if the table already exists. * fail: Raise a ValueError. * replace: Drop the table before inserting new values. * append: Insert new values to the existing table. index : bool, default True Write DataFrame index as a column. Uses `index_label` as the column name in the table. index_label : string or sequence, default None Column label for index column(s). If None is given (default) and `index` is True, then the index names are used. A sequence should be given if the DataFrame uses MultiIndex. chunksize : int, optional Rows will be written in batches of this size at a time. By default, all rows will be written at once. dtype : dict, optional Specifying the datatype for columns. The keys should be the column names and the values should be the SQLAlchemy types or strings for the sqlite3 legacy mode. method : {None, 'multi', callable}, default None Controls the SQL insertion clause used: * None : Uses standard SQL ``INSERT`` clause (one per row). * 'multi': Pass multiple values in a single ``INSERT`` clause. * callable with signature ``(pd_table, conn, keys, data_iter)``. Details and a sample callable implementation can be found in the section :ref:`insert method <io.sql.method>`. .. versionadded:: 0.24.0 Raises ------ ValueError When the table already exists and `if_exists` is 'fail' (the default). See Also -------- read_sql : Read a DataFrame from a table. Notes ----- Timezone aware datetime columns will be written as ``Timestamp with timezone`` type with SQLAlchemy if supported by the database. Otherwise, the datetimes will be stored as timezone unaware timestamps local to the original timezone. .. versionadded:: 0.24.0 References ---------- .. [1] http://docs.sqlalchemy.org .. [2] https://www.python.org/dev/peps/pep-0249/ Examples -------- Create an in-memory SQLite database. >>> from sqlalchemy import create_engine >>> engine = create_engine('sqlite://', echo=False) Create a table from scratch with 3 rows. >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']}) >>> df name 0 User 1 1 User 2 2 User 3 >>> df.to_sql('users', con=engine) >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')] >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']}) >>> df1.to_sql('users', con=engine, if_exists='append') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'), (0, 'User 4'), (1, 'User 5')] Overwrite the table with just ``df1``. >>> df1.to_sql('users', con=engine, if_exists='replace', ... index_label='id') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 4'), (1, 'User 5')] Specify the dtype (especially useful for integers with missing values). Notice that while pandas is forced to store the data as floating point, the database supports nullable integers. When fetching the data with Python, we get back integer scalars. >>> df = pd.DataFrame({\"A\": [1, None, 2]}) >>> df A 0 1.0 1 NaN 2 2.0 >>> from sqlalchemy.types import Integer >>> df.to_sql('integers', con=engine, index=False, ... dtype={\"A\": Integer()}) >>> engine.execute(\"SELECT * FROM integers\").fetchall() [(1,), (None,), (2,)] File: /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py Type: method","title":"01 RDBMS"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#s01-relational-databases","text":"For a simple tutorial on database design, see Introduction to Database Design For a deep dive, see Database Design for Mere Mortals","title":"S01 Relational Databases"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#0-packages-for-working-with-relational-databases-in-python","text":"- Python Database API Specification v2.0 - The standard Python Database API - sqlite3 - API for builit-in sqlite3 package - Database drivers - For connecting to other databases - ipython-sql - SQL magic in Jupyter - SQLAlchemy - Most well-known Object Relational Mapper (ORM) - Pony ORM - Alternative ORM","title":"0. Packages for working with relational databases in Python"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#1-motivation","text":"Why relational databases and SQL? History of databases ACID Data integrity Schema","title":"1. Motivation"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#2-rdbms","text":"Memory Storage Dictionary Query language","title":"2. RDBMS"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#3-anatomy","text":"Table (Relation): Represents a subject or an event . Column (Attribute): Represents a single variable or feature .- Row (Tuple): represents an observation .","title":"3. Anatomy"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#4-concepts","text":"","title":"4. Concepts"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#constraints","text":"You can impose constraints that values in a column have to take. For example, you can specify that values are compulsory (NOT NULL), or UNIQUE or fall within a certain range.","title":"Constraints"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#referential-integrity","text":"- Primary key represents a unique identifier of a row. It may be simple or composite. - Unique - Non-null - Never optional - Foreign key is a column containing the primary key of a different table. It enforces referential integrity .","title":"Referential integrity"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#relationships","text":"- One to one - One to many - Many to many What happens on delete? Restrict Cascade","title":"Relationships"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#indexes","text":"An index is a data structure that allows fast search of a column (typically from linear to log time complexity). Most databases will automatically build an index for every primary key column, but you can also manually specify columns to build indexes for.","title":"Indexes"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#views","text":"- Temporary virtual table returned as a result of a query . - Views only specify the strucutre of a table - the contents are constructed on the fly from existing tables. - Queries return a Result Set","title":"Views"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#5-design","text":"","title":"5. Design"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#columns","text":"- Use singlular form for name - Use informative names - Use unique names not shared by any other table (except foreign keys) - Column must be an attribute of the table's subject - Eliminate multi-part columns - Eliminate multi-value columsn - Eliminate redundant columns","title":"Columns"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#tables","text":"- Use singular/plural forms for name (controversial) - Enusre every table has a primary key - Eliminate duplicate columns","title":"Tables"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#relationships_1","text":"- Establish participation type and degree of relationship - One to one - One to many - Many to many","title":"Relationships"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#6-example","text":"Use sqlmagic as alternative to using sqlite3 driver. % env DATABASE_URL = postgresql + psycopg2 : // postgres : postgres @db . postgres . app . com env: DATABASE_URL=postgresql+psycopg2://postgres:postgres@db.postgres.app.com % load_ext sql Connect to Postgres % config SqlMagic SqlMagic options -------------- SqlMagic.autocommit=<Bool> Current: True Set autocommit mode SqlMagic.autolimit=<Int> Current: 0 Automatically limit the size of the returned result sets SqlMagic.autopandas=<Bool> Current: False Return Pandas DataFrames instead of regular result sets SqlMagic.column_local_vars=<Bool> Current: False Return data into local variables from column names SqlMagic.displaylimit=<Int> Current: None Automatically limit the number of rows displayed (full result set is still stored) SqlMagic.dsn_filename=<Unicode> Current: 'odbc.ini' Path to DSN file. When the first argument is of the form [section], a sqlalchemy connection string is formed from the matching section in the DSN file. SqlMagic.feedback=<Bool> Current: True Print number of rows affected by DML SqlMagic.short_errors=<Bool> Current: True Don't display the full traceback on SQL Programming Error SqlMagic.style=<Unicode> Current: 'DEFAULT' Set the table printing style to any of prettytable's defined styles (currently DEFAULT, MSWORD_FRIENDLY, PLAIN_COLUMNS, RANDOM) %% sql \\ d 6 rows affected. Schema Name Type Owner public accounts table postgres public flat table postgres public t_cities table postgres public t_cities_id_seq sequence postgres public t_weather_observations table postgres public t_weather_observations_id_seq sequence postgres uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com\" % sql { uri } 'Connected: postgres@None' SQL for table deletion and creation %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , person_first varchar ( 255 ), person_last varchar ( 255 ), country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ) ); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres Done. Done. Done. Done. [] %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema' ; * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False True False public person postgres None True False True False SQL to insert rows. %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] The pg_relation_size() function returns the size of the table only, not included indexes or additional objects. %% sql SELECT pg_size_pretty ( pg_relation_size ( 'Country' )); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 1 rows affected. pg_size_pretty 8192 bytes %% sql INSERT INTO Person ( person_first , person_last , country_id ) VALUES ( 'Napolean' , 'Bonaparte' , 'FR' ), ( 'Luis' , 'Alvarez' , 'CU' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] Accessing the RDBMS dictionary. %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 9 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False True False public person postgres None True False True False information_schema sql_features postgres None False False False False information_schema sql_implementation_info postgres None False False False False information_schema sql_languages postgres None False False False False information_schema sql_packages postgres None False False False False information_schema sql_parts postgres None False False False False information_schema sql_sizing postgres None False False False False information_schema sql_sizing_profiles postgres None False False False False %% sql SELECT sql FROM postgres WHERE name = 'Person' ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres (psycopg2.errors.UndefinedTable) relation \"postgres\" does not exist LINE 1: SELECT sql FROM postgres ^ [SQL: SELECT sql FROM postgres WHERE name='Person';] (Background on this error at: http://sqlalche.me/e/f405) SQL as a Query Language. %% sql SELECT person_first as first , person_last AS last , country_name AS nationality FROM Person INNER JOIN country ON Person . country_id = Country . country_id ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. first last nationality Napolean Bonaparte France Luis Alvarez CUBA Visualizing the entitry-relationship diagram (ERd). % config ? Docstring: configure IPython %config Class[.trait=value] This magic exposes most of the IPython config system. Any Configurable class should be able to be configured with the simple line:: %config Class.trait=value Where `value` will be resolved in the user's namespace, if it is an expression or variable name. Examples -------- To see what classes are available for config, pass no arguments:: In [1]: %config Available objects for config: TerminalInteractiveShell HistoryManager PrefilterManager AliasManager IPCompleter DisplayFormatter To view what is configurable on a given class, just pass the class name:: In [2]: %config IPCompleter IPCompleter options ----------------- IPCompleter.omit__names=<Enum> Current: 2 Choices: (0, 1, 2) Instruct the completer to omit private method names Specifically, when completing on ``object.<tab>``. When 2 [default]: all names that start with '_' will be excluded. When 1: all 'magic' names (``__foo__``) will be excluded. When 0: nothing will be excluded. IPCompleter.merge_completions=<CBool> Current: True Whether to merge completion results into a single list If False, only the completion results from the first non-empty completer will be returned. IPCompleter.limit_to__all__=<CBool> Current: False Instruct the completer to use __all__ for the completion Specifically, when completing on ``object.<tab>``. When True: only those names in obj.__all__ will be included. When False [default]: the __all__ attribute is ignored IPCompleter.greedy=<CBool> Current: False Activate greedy completion This will enable completion on elements of lists, results of function calls, etc., but can be unsafe because the code is actually evaluated on TAB. but the real use is in setting values:: In [3]: %config IPCompleter.greedy = True and these values are read from the user_ns if they are variables:: In [4]: feeling_greedy=False In [5]: %config IPCompleter.greedy = feeling_greedy File: /opt/conda/lib/python3.7/site-packages/IPython/core/magics/config.py import ibis import eralchemy from sqlalchemy import create_engine engine = create_engine ( uri ) conn = engine . connect () import os from eralchemy import render_er if not os . path . exists ( 'erd_from_sqlalchemy.png' ): render_er ( uri , 'erd_from_sqlalchemy.png' ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/base.py:2972: SAWarning: Did not recognize type 'point' of column 'location' \"Did not recognize type '%s' of column '%s'\" % (attype, name)","title":"6. Example"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#homework-walk-through","text":"Convert the flat file data in data/flat.csv into a well-structured relational database in SQLite3 stored as data/faculty.db . Note - salary information is confidential and should be kept in a separate table from other personal data. import pandas as pd flat = pd . read_csv ( '../data/flat.csv' , keep_default_na = False ) flat . sample ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name gender age height weight salary nationality code country language1 language2 language3 first last 899 Lucien Pittman Male 61 1.87 58 73000 Danish DK Denmark AutoIt Dylan Transact-SQL Lucien Pittman 1516 Zane Calhoun Male 60 1.93 48 127000 Greek GR Greece Io Java Zane Calhoun 827 Lauran Willis Female 34 1.92 75 89000 Romanian RO Romania Lauran Willis flat . to_sql ( 'flat' , conn ) %% sql \\ d * postgresql+psycopg2://postgres:***@db.postgres.app.com 6 rows affected. Schema Name Type Owner public accounts table postgres public flat table postgres public t_cities table postgres public t_cities_id_seq sequence postgres public t_weather_observations table postgres public t_weather_observations_id_seq sequence postgres %% sql USE faculty ; * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres (psycopg2.errors.SyntaxError) syntax error at or near \"USE\" LINE 1: USE faculty; ^ [SQL: USE faculty;] (Background on this error at: http://sqlalche.me/e/f405) %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , name varchar ( 255 ), age INTEGER NOT NULL , country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ) ); * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres Done. Done. Done. Done. [] %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] %% sql DELETE FROM Country * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 2 rows affected. [] %% sql SELECT * FROM Country * postgresql+psycopg2://postgres:***@db.postgres.app.com/postgres 0 rows affected. country_id country_name from sqlalchemy import create_engine engine = create_engine ( uri ) conn = engine . connect () flat . columns Index(['name', 'gender', 'age', 'height', 'weight', 'salary', 'nationality', 'code', 'country', 'language1', 'language2', 'language3', 'first', 'last'], dtype='object') flat . rename ( mapper = { 'code' : 'country_id' , 'country' : 'country_name' }, inplace = True ) country = flat[['country_id', 'country_name']]country.set_index('country_id').to_sql('Country', engine, if_exists='append')","title":"Homework walk-through"},{"location":"_nb/%3DPy/02_SQL/01_RDBMS/#sql","text":"SELECT * FROM Country flat . to_sql ? Signature: flat . to_sql ( name , con , schema = None , if_exists = 'fail' , index = True , index_label = None , chunksize = None , dtype = None , method = None , ) Docstring: Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1]_ are supported. Tables can be newly created, appended to, or overwritten. Parameters ---------- name : string Name of SQL table. con : sqlalchemy.engine.Engine or sqlite3.Connection Using SQLAlchemy makes it possible to use any DB supported by that library. Legacy support is provided for sqlite3.Connection objects. schema : string, optional Specify the schema (if database flavor supports this). If None, use default schema. if_exists : {'fail', 'replace', 'append'}, default 'fail' How to behave if the table already exists. * fail: Raise a ValueError. * replace: Drop the table before inserting new values. * append: Insert new values to the existing table. index : bool, default True Write DataFrame index as a column. Uses `index_label` as the column name in the table. index_label : string or sequence, default None Column label for index column(s). If None is given (default) and `index` is True, then the index names are used. A sequence should be given if the DataFrame uses MultiIndex. chunksize : int, optional Rows will be written in batches of this size at a time. By default, all rows will be written at once. dtype : dict, optional Specifying the datatype for columns. The keys should be the column names and the values should be the SQLAlchemy types or strings for the sqlite3 legacy mode. method : {None, 'multi', callable}, default None Controls the SQL insertion clause used: * None : Uses standard SQL ``INSERT`` clause (one per row). * 'multi': Pass multiple values in a single ``INSERT`` clause. * callable with signature ``(pd_table, conn, keys, data_iter)``. Details and a sample callable implementation can be found in the section :ref:`insert method <io.sql.method>`. .. versionadded:: 0.24.0 Raises ------ ValueError When the table already exists and `if_exists` is 'fail' (the default). See Also -------- read_sql : Read a DataFrame from a table. Notes ----- Timezone aware datetime columns will be written as ``Timestamp with timezone`` type with SQLAlchemy if supported by the database. Otherwise, the datetimes will be stored as timezone unaware timestamps local to the original timezone. .. versionadded:: 0.24.0 References ---------- .. [1] http://docs.sqlalchemy.org .. [2] https://www.python.org/dev/peps/pep-0249/ Examples -------- Create an in-memory SQLite database. >>> from sqlalchemy import create_engine >>> engine = create_engine('sqlite://', echo=False) Create a table from scratch with 3 rows. >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']}) >>> df name 0 User 1 1 User 2 2 User 3 >>> df.to_sql('users', con=engine) >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')] >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']}) >>> df1.to_sql('users', con=engine, if_exists='append') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'), (0, 'User 4'), (1, 'User 5')] Overwrite the table with just ``df1``. >>> df1.to_sql('users', con=engine, if_exists='replace', ... index_label='id') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 4'), (1, 'User 5')] Specify the dtype (especially useful for integers with missing values). Notice that while pandas is forced to store the data as floating point, the database supports nullable integers. When fetching the data with Python, we get back integer scalars. >>> df = pd.DataFrame({\"A\": [1, None, 2]}) >>> df A 0 1.0 1 NaN 2 2.0 >>> from sqlalchemy.types import Integer >>> df.to_sql('integers', con=engine, index=False, ... dtype={\"A\": Integer()}) >>> engine.execute(\"SELECT * FROM integers\").fetchall() [(1,), (None,), (2,)] File: /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py Type: method","title":"%%sql"},{"location":"_nb/%3DPy/02_SQL/02_SQL/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); RDBMS For more SQL examples in the SQLite3 dialect, seee SQLite3 tutorial . For a deep dive, see SQL Queries for Mere Mortals . RDBMS concepts \u00b6 Codd's 12 rules OLTP and OLAP \u00b6 OLTP Normalized schema OLAP (Online analytical processing): At the core is an OLAP cube (also called a 'multidimensional cube' or a hypercube) numeric facts called measures that are categorized by dimensions denormalized schema multi-dimensional analytical (MDA) queries typically stored in a star schema or snowflake schema mostly optimized for read Generated from OLTP databases by ETL (Extract-Transform-Load) operations consolidation (roll-up), drill-down, and slicing and dicing Rotate (or Pivot ) : s\u00e9lection du couple de dimensions qui formera le r\u00e9sultat de la requ\u00eate, Slicing : extraction d'une tranche d'information, Scoping (or Dicing ) : extraction d'un bloc de [[donn\u00e9e]]s (op\u00e9ration plus g\u00e9n\u00e9rale que le ''slicing''), Drill-up : synth\u00e8se des informations en fonction d'une dimension (exemple de ''drill-up'' sur l'axe temps : passer de la pr\u00e9sentation de l'information jour par jour sur une ann\u00e9e, \u00e0 une valeur synth\u00e9tique pour l'ann\u00e9e), Drill-down : c'est l'\u00e9quivalent d'un \u00ab zoom \u00bb, op\u00e9ration inverse du ''drill-up'', Drill-through : lorsqu'on ne dispose que de [[donn\u00e9e]]s agr\u00e9g\u00e9es (indicateurs totalis\u00e9s), le ''drill through'' permet d'acc\u00e9der au d\u00e9tail \u00e9l\u00e9mentaire des informations (voir notamment les outils H-OLAP). Types of REBMS \u00b6 Data lake Data warehouse Data mart Data marts typically use a star schema that is customized for the analysis needs. For example, the finance department in a hospital may be most interested in Facts about Claims. Robustness and scaling \u00b6 Replication Sharding B. Basic SQL queries \u00b6 Data we will work with in Part B \u00b6 % load_ext sql % sql sqlite : /// data / faculty . db 'Connected: @data/faculty.db' %% sql SELECT * FROM sqlite_master WHERE type = 'table' ; * sqlite:///data/faculty.db Done. type name tbl_name rootpage sql table person person 2 CREATE TABLE person ( \"index\" BIGINT, person_id BIGINT, first TEXT, last TEXT, age BIGINT, height FLOAT, weight BIGINT, country_id TEXT, gender_id BIGINT ) table confidential confidential 18 CREATE TABLE confidential ( \"index\" BIGINT, person_id BIGINT, salary BIGINT ) table person_language person_language 33 CREATE TABLE person_language ( \"index\" BIGINT, person_id BIGINT, language_id BIGINT ) table language language 50 CREATE TABLE language ( \"index\" BIGINT, language_id BIGINT, language_name TEXT ) table gender gender 55 CREATE TABLE gender ( \"index\" BIGINT, gender_id BIGINT, gender TEXT ) table country country 57 CREATE TABLE country ( \"index\" BIGINT, country_id TEXT, country TEXT, nationality TEXT ) table df df 59 CREATE TABLE df ( \"index\" BIGINT, person TEXT, time BIGINT, bsl BIGINT ) Basic Structure \u00b6 SELECT DISTINCT value_expression AS alias FROM tables AS alias WHERE predicate ORDER BY value_expression Types \u00b6 - Character (Fixed width, variable width) - National Character (Fixed width, variable width) - Binary - Numeric (Exact, Arpproximate) - Boolean - DateTime - Interval The SQL standard specifies that character strings and datetime literals are enclosed by single quotes. Two single quotes wihtin a string is intepreted as a literal single quote. 'Gilligan''s island' The CAST function \u00b6 CAST ( X as CHARACTER ( 10 )) Value expreesion \u00b6 Literal Column reference Function CASES (Value expression) (SELECT expression) which may be prefixed with unary operaors - and + and combined with binary operators appropriate for the data type. Bineary operators \u00b6 Concatenation \u00b6 A || B Mathematical \u00b6 A + B A - B A * B A / B Data and time arithmetic \u00b6 '2018-08-29' + 3 '11:59' + '00:01' %% sql SELECT DISTINCT language_name FROM language LIMIT 5 ; * sqlite:///data/faculty.db Done. language_name PHP Clojure Dylan GNU Octave D Sorting \u00b6 SELECT DISTINCT value_expression AS alias FROM tables AS alias ORDER BY value_expression %% sql SELECT DISTINCT language_name FROM language ORDER BY language_name ASC LIMIT 5 ; * sqlite:///data/faculty.db Done. language_name ASP Assembly AutoIt Awk Bash Filtering \u00b6 For efficiency, place the most stringent filters first. SELECT DISTINCT value_expression AS alias FROM tables AS alias WHERE predicate ORDER BY value_expression Predicates for filtering rows \u00b6 - Comparison operators (=, <>, <, >, <=, >=) - BETWEEN start AND end - IN(A, B, C) - LIKE - IS NULL - REGEX Use NOT prefix for negation Combining predicates \u00b6 AND OR USe parenthesis to indicate order of evaluation for compound statements. %% sql SELECT first , last , age FROM person WHERE age BETWEEN 16 AND 17 LIMIT 5 ; * sqlite:///data/faculty.db Done. first last age Antoine Beard 16 Augustine Mejia 16 Boris Mejia 16 Brain Haney 16 Burl Mayo 17 Joins \u00b6 Joins combine data from 1 or more tables to form a new result set. Natural join \u00b6 Uses all common columns in Tables 1 and 2 for JOIN FROM Table1 NATURAL INNER JOIN Table 2 Inner join \u00b6 General form of INNER JOIN uisng ON FROM Table1 INNER JOIN Table2 ON Table1 . Column = Table2 . Column If there is a common column in both tables FROM Table1 INNER JOIN Table2 USING Column Joining more than two tables From ( Table1 INNER JOIN Table2 ON Table1 . column1 = Table2 . Column1 ) INNER JOIN Table3 ON Table3 . column2 = Table2 . Column2 Outer join \u00b6 General form of OUTER JOIN uisng ON FROM Table1 RIGHT OUTER JOIN Table2 ON Table1 . Column = Table2 . Column FROM Table1 LEFT OUTER JOIN Table2 ON Table1 . Column = Table2 . Column FROM Table1 FULL OUTER JOIN Table2 ON Table1 . Column = Table2 . Column %% sql SELECT first , last , language_name FROM person INNER JOIN person_language ON person . person_id = person_language . person_id INNER JOIN language ON language . language_id = person_language . language_id LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Aaron Kirby GNU Octave Aaron Kirby haXe Aaron Kirby Falcon Abram Allen TypeScript Abram Boyer Io Abram Boyer Lua Abram Boyer Falcon Adan Brown F# Adolph Dalton Dart Set operations \u00b6 SELECT a , b FROM table1 SetOp SELECT a , b FROM table2 wehre SetOp is INTERSECT , EXCEPT , UNION or UNION ALL . Intersection \u00b6 INTERSECT Alternative using INNER JOIN Union \u00b6 UNION UNION ALL ( does not eliminate duplicate rows ) Difference \u00b6 EXCEPT Alternative using OUTER JOIN with test for NULL %% sql DROP VIEW IF EXISTS language_view ; CREATE VIEW language_view AS SELECT first , last , language_name FROM person INNER JOIN person_language ON person . person_id = person_language . person_id INNER JOIN language ON language . language_id = person_language . language_id ; * sqlite:///data/faculty.db Done. Done. [] %% sql SELECt * FROM language_view LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Aaron Kirby GNU Octave Aaron Kirby haXe Aaron Kirby Falcon Abram Allen TypeScript Abram Boyer Io Abram Boyer Lua Abram Boyer Falcon Adan Brown F# Adolph Dalton Dart %% sql SELECt * FROM language_view WHERE language_name = 'Python' UNION SELECt * FROM language_view WHERE language_name = 'Haskell' LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Andree Douglas Haskell Arlie Terrell Python Boyd Blackwell Haskell Buck Howe Haskell Carlton Richard Haskell Carylon Zamora Python Clarisa Rodgers Python Dinorah O'brien Haskell Dorian Lloyd Haskell %% sql SELECt * FROM language_view WHERE language_name IN ( 'Python' , 'Haskell' ) ORDER BY first LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Andree Douglas Haskell Arlie Terrell Python Boyd Blackwell Haskell Buck Howe Haskell Carlton Richard Haskell Carylon Zamora Python Clarisa Rodgers Python Dinorah O'brien Haskell Dorian Lloyd Haskell Subqueries \u00b6 As column expresions \u00b6 SELECT a , b , ( SELECT MAX ( c ) FROM table2 INNER JOIN table1 USING column1 ) as max_c FROM table1 As filters \u00b6 SELECT a , b , FROM table1 WHERE b > ( SELECT AVG ( b ) FROM table1 ) Quantified Subqueires \u00b6 ALl SOME ANY EXISTS SELECT a , b , FROM table1 WHERE EXISTS ( SELECT c FROM table2 ) %% sql SELECT first , last , language_name FROM person , language WHERE language_name IN ( SELECT language_name FROM language_view WHERe first = 'Abram' AND last = 'Boyer' ) LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Io Aaron Kirby Io Abram Allen Io Abram Boyer Io Adan Brown Io Adolph Dalton Io Adrian Blevins Io Agustin Fulton Io Agustin Mcdonald Io Alberto Dudley Io Aggregate functions \u00b6 COUNT MIN MAX AVG SUM %% sql SELECT count ( language_name ) FROM language_view ; * sqlite:///data/faculty.db Done. count(language_name) 2297 Grouping \u00b6 SELECT a , MIN ( b ) AS min_b , MAX ( b ) AS max_b , AVG ( b ) AS mean_b FROM table GROUP BY a HAVING mean_b > 5 The HAVING is analagous to the WHERE clause, but filters on aggregate conditions. Note that the WHERE statement filters rows BEFORE the grouping is done. Note: Any variable in the SELECT part that is not an aggregte function needs to be in the GROUP BY part. SELECT a , b , c , COUNT ( d ) FROM table GROUP BY a , b , c %% sql SELECT language_name , count ( * ) AS n FROM language_view GROUP BY language_name HAVING n > 45 ; * sqlite:///data/faculty.db Done. language_name n AutoIt 61 Bash 48 ECMAScript 48 GNU Octave 49 JavaScript 48 Perl 55 PowerShell 50 Prolog 50 The CASE switch \u00b6 Simple CASE \u00b6 SELECT name , ( CASE sex WHEN 'M' THEN 1 . 5 * dose WHEN 'F' THEN dose END ) as adjusted_dose FROM table Searched CASE \u00b6 SELECT name , ( CASE WHEN sex = 'M' THEN 1 . 5 * dose WHEN sex = 'F' THEN dose END ) as adjusted_dose FROM table %% sql SELECT first , last , language_name , ( CASE WHEN language_name LIKE 'H%' THEN 'Hire' ELSE 'FIRE' END ) AS outcome FROM language_view LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name outcome Aaron Alexander Haskell Hire Aaron Kirby GNU Octave FIRE Aaron Kirby haXe Hire Aaron Kirby Falcon FIRE Abram Allen TypeScript FIRE Abram Boyer Io FIRE Abram Boyer Lua FIRE Abram Boyer Falcon FIRE Adan Brown F# FIRE Adolph Dalton Dart FIRE C. Window Functions \u00b6 We use the PostgreSQL databsaee because window functions are not supported in SQLite3 yet % load_ext sql % sql postgresql : // postgres : postgres @postgres . app . com / postgres 'Connected: postgres@postgres' import pandas as pd import numpy as np from collections import OrderedDict np . random . seed ( 23 ) n = 10 df = pd . DataFrame ( OrderedDict ( person = np . random . choice ([ 'A' , 'B' , 'C' , 'D' ], n ,), time = np . random . randint ( 0 , 10 , n ), bsl = np . random . randint ( 50 , 400 , n ))) df . sort_values ([ 'person' , 'time' ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } person time bsl 8 A 0 115 5 A 2 237 2 A 3 129 7 B 5 86 3 B 6 396 4 C 1 107 1 C 9 347 6 D 5 89 9 D 5 221 0 D 7 98 % sql DROP TABLE IF EXISTS df * postgresql://postgres:***@172.26.0.3/postgres Done. [] Magic shortcut to creating a database table from pandas DataFrame. % sql persist df * postgresql://postgres:***@172.26.0.3/postgres 'Persisted df' Over creates widows \u00b6 %% sql SELECT person , time , bsl , row_number () OVER () FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number D 7 98 1 C 9 347 2 A 3 129 3 B 6 396 4 C 1 107 5 A 2 237 6 D 5 89 7 B 5 86 8 A 0 115 9 D 5 221 10 Order by \u00b6 %% sql SELECT person , time , bsl , row_number () OVER ( ORDER BY person , time ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number A 0 115 1 A 2 237 2 A 3 129 3 B 5 86 4 B 6 396 5 C 1 107 6 C 9 347 7 D 5 221 8 D 5 89 9 D 7 98 10 Partition by \u00b6 %% sql SELECT person , time , bsl , row_number () OVER ( PARTITION BY person ORDER BY time ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number A 0 115 1 A 2 237 2 A 3 129 3 B 5 86 1 B 6 396 2 C 1 107 1 C 9 347 2 D 5 221 1 D 5 89 2 D 7 98 3 %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER ( PARTITION BY person ORDER BY time ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl string_agg A 0 115 115 A 2 237 115, 237 A 3 129 115, 237, 129 B 5 86 86 B 6 396 86, 396 C 1 107 107 C 9 347 107, 347 D 5 221 221, 89 D 5 89 221, 89 D 7 98 221, 89, 98 Specifying rows in window \u00b6 %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER ( PARTITION BY person ORDER BY time ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl string_agg A 0 115 115, 237 A 2 237 115, 237, 129 A 3 129 237, 129 B 5 86 86, 396 B 6 396 86, 396 C 1 107 107, 347 C 9 347 107, 347 D 5 221 221, 89 D 5 89 221, 89, 98 D 7 98 89, 98 Using window functions \u00b6 %% sql SELECT person , time , bsl , row_number () OVER win AS row_number , rank () OVER win AS rank , dense_rank () OVER win AS dense_rank , percent_rank () OVER win AS percent_rank , cume_dist () OVER win AS cume_dist FROM df WINDOW win AS ( ORDER BY person ); * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number rank dense_rank percent_rank cume_dist A 0 115 1 1 1 0.0 0.3 A 2 237 2 1 1 0.0 0.3 A 3 129 3 1 1 0.0 0.3 B 6 396 4 4 2 0.333333333333333 0.5 B 5 86 5 4 2 0.333333333333333 0.5 C 1 107 6 6 3 0.555555555555556 0.7 C 9 347 7 6 3 0.555555555555556 0.7 D 5 221 8 8 4 0.777777777777778 1.0 D 5 89 9 8 4 0.777777777777778 1.0 D 7 98 10 8 4 0.777777777777778 1.0 Using aggregate functions \u00b6 %% sql SELECT person , time , bsl , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg , MIN ( bsl ) OVER win AS bsl_min , MAX ( bsl ) over win as bsl_max , FIRST_VALUE ( bsl ) OVER win as bsl_start , LAST_VALUE ( bsl ) OVER win as bsl_end FROM df WINDOW win AS ( PARTITION BY person ORDER BY time ); * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl bsl_sum bsl_avg bsl_min bsl_max bsl_start bsl_end A 0 115 115 115.0000000000000000 115 115 115 115 A 2 237 352 176.0000000000000000 115 237 115 237 A 3 129 481 160.3333333333333333 115 237 115 129 B 5 86 86 86.0000000000000000 86 86 86 86 B 6 396 482 241.0000000000000000 86 396 86 396 C 1 107 107 107.0000000000000000 107 107 107 107 C 9 347 454 227.0000000000000000 107 347 107 347 D 5 221 310 155.0000000000000000 89 221 221 89 D 5 89 310 155.0000000000000000 89 221 221 89 D 7 98 408 136.0000000000000000 89 221 221 98 Using rows and range to constrain windows \u00b6 %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER win AS vals , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg FROM df WINDOW win AS ( PARTITION BY person ORDER BY time ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING ) ORDER BY person , time ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl vals bsl_sum bsl_avg A 0 115 115, 237 352 176.0000000000000000 A 2 237 115, 237, 129 481 160.3333333333333333 A 3 129 237, 129 366 183.0000000000000000 B 5 86 86, 396 482 241.0000000000000000 B 6 396 86, 396 482 241.0000000000000000 C 1 107 107, 347 454 227.0000000000000000 C 9 347 107, 347 454 227.0000000000000000 D 5 221 221, 89 310 155.0000000000000000 D 5 89 221, 89, 98 408 136.0000000000000000 D 7 98 89, 98 187 93.5000000000000000 Frames using Rows and Range \u00b6 For Range, all rows with the same ORDER BY value are considered peers. %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER win AS vals , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg FROM df WINDOW win AS ( ORDER BY person ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) ORDER BY person , time ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl vals bsl_sum bsl_avg A 0 115 115 115 115.0000000000000000 A 2 237 115, 237 352 176.0000000000000000 A 3 129 115, 237, 129 481 160.3333333333333333 B 5 86 115, 237, 129, 396, 86 963 192.6000000000000000 B 6 396 115, 237, 129, 396 877 219.2500000000000000 C 1 107 115, 237, 129, 396, 86, 107 1070 178.3333333333333333 C 9 347 115, 237, 129, 396, 86, 107, 347 1417 202.4285714285714286 D 5 221 115, 237, 129, 396, 86, 107, 347, 221 1638 204.7500000000000000 D 5 89 115, 237, 129, 396, 86, 107, 347, 221, 89 1727 191.8888888888888889 D 7 98 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000 %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER win AS vals , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg FROM df WINDOW win AS ( ORDER BY person RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) ORDER BY person , time ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl vals bsl_sum bsl_avg A 0 115 115, 237, 129 481 160.3333333333333333 A 2 237 115, 237, 129 481 160.3333333333333333 A 3 129 115, 237, 129 481 160.3333333333333333 B 5 86 115, 237, 129, 396, 86 963 192.6000000000000000 B 6 396 115, 237, 129, 396, 86 963 192.6000000000000000 C 1 107 115, 237, 129, 396, 86, 107, 347 1417 202.4285714285714286 C 9 347 115, 237, 129, 396, 86, 107, 347 1417 202.4285714285714286 D 5 221 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000 D 5 89 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000 D 7 98 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000","title":"02 SQL"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#rdbms-concepts","text":"Codd's 12 rules","title":"RDBMS concepts"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#oltp-and-olap","text":"OLTP Normalized schema OLAP (Online analytical processing): At the core is an OLAP cube (also called a 'multidimensional cube' or a hypercube) numeric facts called measures that are categorized by dimensions denormalized schema multi-dimensional analytical (MDA) queries typically stored in a star schema or snowflake schema mostly optimized for read Generated from OLTP databases by ETL (Extract-Transform-Load) operations consolidation (roll-up), drill-down, and slicing and dicing Rotate (or Pivot ) : s\u00e9lection du couple de dimensions qui formera le r\u00e9sultat de la requ\u00eate, Slicing : extraction d'une tranche d'information, Scoping (or Dicing ) : extraction d'un bloc de [[donn\u00e9e]]s (op\u00e9ration plus g\u00e9n\u00e9rale que le ''slicing''), Drill-up : synth\u00e8se des informations en fonction d'une dimension (exemple de ''drill-up'' sur l'axe temps : passer de la pr\u00e9sentation de l'information jour par jour sur une ann\u00e9e, \u00e0 une valeur synth\u00e9tique pour l'ann\u00e9e), Drill-down : c'est l'\u00e9quivalent d'un \u00ab zoom \u00bb, op\u00e9ration inverse du ''drill-up'', Drill-through : lorsqu'on ne dispose que de [[donn\u00e9e]]s agr\u00e9g\u00e9es (indicateurs totalis\u00e9s), le ''drill through'' permet d'acc\u00e9der au d\u00e9tail \u00e9l\u00e9mentaire des informations (voir notamment les outils H-OLAP).","title":"OLTP and OLAP"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#types-of-rebms","text":"Data lake Data warehouse Data mart Data marts typically use a star schema that is customized for the analysis needs. For example, the finance department in a hospital may be most interested in Facts about Claims.","title":"Types of REBMS"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#robustness-and-scaling","text":"Replication Sharding","title":"Robustness and scaling"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#b-basic-sql-queries","text":"","title":"B. Basic SQL queries"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#data-we-will-work-with-in-part-b","text":"% load_ext sql % sql sqlite : /// data / faculty . db 'Connected: @data/faculty.db' %% sql SELECT * FROM sqlite_master WHERE type = 'table' ; * sqlite:///data/faculty.db Done. type name tbl_name rootpage sql table person person 2 CREATE TABLE person ( \"index\" BIGINT, person_id BIGINT, first TEXT, last TEXT, age BIGINT, height FLOAT, weight BIGINT, country_id TEXT, gender_id BIGINT ) table confidential confidential 18 CREATE TABLE confidential ( \"index\" BIGINT, person_id BIGINT, salary BIGINT ) table person_language person_language 33 CREATE TABLE person_language ( \"index\" BIGINT, person_id BIGINT, language_id BIGINT ) table language language 50 CREATE TABLE language ( \"index\" BIGINT, language_id BIGINT, language_name TEXT ) table gender gender 55 CREATE TABLE gender ( \"index\" BIGINT, gender_id BIGINT, gender TEXT ) table country country 57 CREATE TABLE country ( \"index\" BIGINT, country_id TEXT, country TEXT, nationality TEXT ) table df df 59 CREATE TABLE df ( \"index\" BIGINT, person TEXT, time BIGINT, bsl BIGINT )","title":"Data we will work with in Part B"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#basic-structure","text":"SELECT DISTINCT value_expression AS alias FROM tables AS alias WHERE predicate ORDER BY value_expression","title":"Basic Structure"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#types","text":"- Character (Fixed width, variable width) - National Character (Fixed width, variable width) - Binary - Numeric (Exact, Arpproximate) - Boolean - DateTime - Interval The SQL standard specifies that character strings and datetime literals are enclosed by single quotes. Two single quotes wihtin a string is intepreted as a literal single quote. 'Gilligan''s island'","title":"Types"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#the-cast-function","text":"CAST ( X as CHARACTER ( 10 ))","title":"The CAST function"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#value-expreesion","text":"Literal Column reference Function CASES (Value expression) (SELECT expression) which may be prefixed with unary operaors - and + and combined with binary operators appropriate for the data type.","title":"Value expreesion"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#bineary-operators","text":"","title":"Bineary operators"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#concatenation","text":"A || B","title":"Concatenation"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#mathematical","text":"A + B A - B A * B A / B","title":"Mathematical"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#data-and-time-arithmetic","text":"'2018-08-29' + 3 '11:59' + '00:01' %% sql SELECT DISTINCT language_name FROM language LIMIT 5 ; * sqlite:///data/faculty.db Done. language_name PHP Clojure Dylan GNU Octave D","title":"Data and time arithmetic"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#sorting","text":"SELECT DISTINCT value_expression AS alias FROM tables AS alias ORDER BY value_expression %% sql SELECT DISTINCT language_name FROM language ORDER BY language_name ASC LIMIT 5 ; * sqlite:///data/faculty.db Done. language_name ASP Assembly AutoIt Awk Bash","title":"Sorting"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#filtering","text":"For efficiency, place the most stringent filters first. SELECT DISTINCT value_expression AS alias FROM tables AS alias WHERE predicate ORDER BY value_expression","title":"Filtering"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#predicates-for-filtering-rows","text":"- Comparison operators (=, <>, <, >, <=, >=) - BETWEEN start AND end - IN(A, B, C) - LIKE - IS NULL - REGEX Use NOT prefix for negation","title":"Predicates for filtering rows"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#combining-predicates","text":"AND OR USe parenthesis to indicate order of evaluation for compound statements. %% sql SELECT first , last , age FROM person WHERE age BETWEEN 16 AND 17 LIMIT 5 ; * sqlite:///data/faculty.db Done. first last age Antoine Beard 16 Augustine Mejia 16 Boris Mejia 16 Brain Haney 16 Burl Mayo 17","title":"Combining predicates"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#joins","text":"Joins combine data from 1 or more tables to form a new result set.","title":"Joins"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#natural-join","text":"Uses all common columns in Tables 1 and 2 for JOIN FROM Table1 NATURAL INNER JOIN Table 2","title":"Natural join"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#inner-join","text":"General form of INNER JOIN uisng ON FROM Table1 INNER JOIN Table2 ON Table1 . Column = Table2 . Column If there is a common column in both tables FROM Table1 INNER JOIN Table2 USING Column Joining more than two tables From ( Table1 INNER JOIN Table2 ON Table1 . column1 = Table2 . Column1 ) INNER JOIN Table3 ON Table3 . column2 = Table2 . Column2","title":"Inner join"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#outer-join","text":"General form of OUTER JOIN uisng ON FROM Table1 RIGHT OUTER JOIN Table2 ON Table1 . Column = Table2 . Column FROM Table1 LEFT OUTER JOIN Table2 ON Table1 . Column = Table2 . Column FROM Table1 FULL OUTER JOIN Table2 ON Table1 . Column = Table2 . Column %% sql SELECT first , last , language_name FROM person INNER JOIN person_language ON person . person_id = person_language . person_id INNER JOIN language ON language . language_id = person_language . language_id LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Aaron Kirby GNU Octave Aaron Kirby haXe Aaron Kirby Falcon Abram Allen TypeScript Abram Boyer Io Abram Boyer Lua Abram Boyer Falcon Adan Brown F# Adolph Dalton Dart","title":"Outer join"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#set-operations","text":"SELECT a , b FROM table1 SetOp SELECT a , b FROM table2 wehre SetOp is INTERSECT , EXCEPT , UNION or UNION ALL .","title":"Set operations"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#intersection","text":"INTERSECT Alternative using INNER JOIN","title":"Intersection"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#union","text":"UNION UNION ALL ( does not eliminate duplicate rows )","title":"Union"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#difference","text":"EXCEPT Alternative using OUTER JOIN with test for NULL %% sql DROP VIEW IF EXISTS language_view ; CREATE VIEW language_view AS SELECT first , last , language_name FROM person INNER JOIN person_language ON person . person_id = person_language . person_id INNER JOIN language ON language . language_id = person_language . language_id ; * sqlite:///data/faculty.db Done. Done. [] %% sql SELECt * FROM language_view LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Aaron Kirby GNU Octave Aaron Kirby haXe Aaron Kirby Falcon Abram Allen TypeScript Abram Boyer Io Abram Boyer Lua Abram Boyer Falcon Adan Brown F# Adolph Dalton Dart %% sql SELECt * FROM language_view WHERE language_name = 'Python' UNION SELECt * FROM language_view WHERE language_name = 'Haskell' LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Andree Douglas Haskell Arlie Terrell Python Boyd Blackwell Haskell Buck Howe Haskell Carlton Richard Haskell Carylon Zamora Python Clarisa Rodgers Python Dinorah O'brien Haskell Dorian Lloyd Haskell %% sql SELECt * FROM language_view WHERE language_name IN ( 'Python' , 'Haskell' ) ORDER BY first LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Haskell Andree Douglas Haskell Arlie Terrell Python Boyd Blackwell Haskell Buck Howe Haskell Carlton Richard Haskell Carylon Zamora Python Clarisa Rodgers Python Dinorah O'brien Haskell Dorian Lloyd Haskell","title":"Difference"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#subqueries","text":"","title":"Subqueries"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#as-column-expresions","text":"SELECT a , b , ( SELECT MAX ( c ) FROM table2 INNER JOIN table1 USING column1 ) as max_c FROM table1","title":"As column expresions"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#as-filters","text":"SELECT a , b , FROM table1 WHERE b > ( SELECT AVG ( b ) FROM table1 )","title":"As filters"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#quantified-subqueires","text":"ALl SOME ANY EXISTS SELECT a , b , FROM table1 WHERE EXISTS ( SELECT c FROM table2 ) %% sql SELECT first , last , language_name FROM person , language WHERE language_name IN ( SELECT language_name FROM language_view WHERe first = 'Abram' AND last = 'Boyer' ) LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name Aaron Alexander Io Aaron Kirby Io Abram Allen Io Abram Boyer Io Adan Brown Io Adolph Dalton Io Adrian Blevins Io Agustin Fulton Io Agustin Mcdonald Io Alberto Dudley Io","title":"Quantified Subqueires"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#aggregate-functions","text":"COUNT MIN MAX AVG SUM %% sql SELECT count ( language_name ) FROM language_view ; * sqlite:///data/faculty.db Done. count(language_name) 2297","title":"Aggregate functions"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#grouping","text":"SELECT a , MIN ( b ) AS min_b , MAX ( b ) AS max_b , AVG ( b ) AS mean_b FROM table GROUP BY a HAVING mean_b > 5 The HAVING is analagous to the WHERE clause, but filters on aggregate conditions. Note that the WHERE statement filters rows BEFORE the grouping is done. Note: Any variable in the SELECT part that is not an aggregte function needs to be in the GROUP BY part. SELECT a , b , c , COUNT ( d ) FROM table GROUP BY a , b , c %% sql SELECT language_name , count ( * ) AS n FROM language_view GROUP BY language_name HAVING n > 45 ; * sqlite:///data/faculty.db Done. language_name n AutoIt 61 Bash 48 ECMAScript 48 GNU Octave 49 JavaScript 48 Perl 55 PowerShell 50 Prolog 50","title":"Grouping"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#the-case-switch","text":"","title":"The CASE switch"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#simple-case","text":"SELECT name , ( CASE sex WHEN 'M' THEN 1 . 5 * dose WHEN 'F' THEN dose END ) as adjusted_dose FROM table","title":"Simple CASE"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#searched-case","text":"SELECT name , ( CASE WHEN sex = 'M' THEN 1 . 5 * dose WHEN sex = 'F' THEN dose END ) as adjusted_dose FROM table %% sql SELECT first , last , language_name , ( CASE WHEN language_name LIKE 'H%' THEN 'Hire' ELSE 'FIRE' END ) AS outcome FROM language_view LIMIT 10 ; * sqlite:///data/faculty.db Done. first last language_name outcome Aaron Alexander Haskell Hire Aaron Kirby GNU Octave FIRE Aaron Kirby haXe Hire Aaron Kirby Falcon FIRE Abram Allen TypeScript FIRE Abram Boyer Io FIRE Abram Boyer Lua FIRE Abram Boyer Falcon FIRE Adan Brown F# FIRE Adolph Dalton Dart FIRE","title":"Searched CASE"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#c-window-functions","text":"We use the PostgreSQL databsaee because window functions are not supported in SQLite3 yet % load_ext sql % sql postgresql : // postgres : postgres @postgres . app . com / postgres 'Connected: postgres@postgres' import pandas as pd import numpy as np from collections import OrderedDict np . random . seed ( 23 ) n = 10 df = pd . DataFrame ( OrderedDict ( person = np . random . choice ([ 'A' , 'B' , 'C' , 'D' ], n ,), time = np . random . randint ( 0 , 10 , n ), bsl = np . random . randint ( 50 , 400 , n ))) df . sort_values ([ 'person' , 'time' ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } person time bsl 8 A 0 115 5 A 2 237 2 A 3 129 7 B 5 86 3 B 6 396 4 C 1 107 1 C 9 347 6 D 5 89 9 D 5 221 0 D 7 98 % sql DROP TABLE IF EXISTS df * postgresql://postgres:***@172.26.0.3/postgres Done. [] Magic shortcut to creating a database table from pandas DataFrame. % sql persist df * postgresql://postgres:***@172.26.0.3/postgres 'Persisted df'","title":"C.  Window Functions"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#over-creates-widows","text":"%% sql SELECT person , time , bsl , row_number () OVER () FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number D 7 98 1 C 9 347 2 A 3 129 3 B 6 396 4 C 1 107 5 A 2 237 6 D 5 89 7 B 5 86 8 A 0 115 9 D 5 221 10","title":"Over  creates widows"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#order-by","text":"%% sql SELECT person , time , bsl , row_number () OVER ( ORDER BY person , time ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number A 0 115 1 A 2 237 2 A 3 129 3 B 5 86 4 B 6 396 5 C 1 107 6 C 9 347 7 D 5 221 8 D 5 89 9 D 7 98 10","title":"Order by"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#partition-by","text":"%% sql SELECT person , time , bsl , row_number () OVER ( PARTITION BY person ORDER BY time ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number A 0 115 1 A 2 237 2 A 3 129 3 B 5 86 1 B 6 396 2 C 1 107 1 C 9 347 2 D 5 221 1 D 5 89 2 D 7 98 3 %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER ( PARTITION BY person ORDER BY time ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl string_agg A 0 115 115 A 2 237 115, 237 A 3 129 115, 237, 129 B 5 86 86 B 6 396 86, 396 C 1 107 107 C 9 347 107, 347 D 5 221 221, 89 D 5 89 221, 89 D 7 98 221, 89, 98","title":"Partition by"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#specifying-rows-in-window","text":"%% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER ( PARTITION BY person ORDER BY time ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING ) FROM df ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl string_agg A 0 115 115, 237 A 2 237 115, 237, 129 A 3 129 237, 129 B 5 86 86, 396 B 6 396 86, 396 C 1 107 107, 347 C 9 347 107, 347 D 5 221 221, 89 D 5 89 221, 89, 98 D 7 98 89, 98","title":"Specifying rows in window"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#using-window-functions","text":"%% sql SELECT person , time , bsl , row_number () OVER win AS row_number , rank () OVER win AS rank , dense_rank () OVER win AS dense_rank , percent_rank () OVER win AS percent_rank , cume_dist () OVER win AS cume_dist FROM df WINDOW win AS ( ORDER BY person ); * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl row_number rank dense_rank percent_rank cume_dist A 0 115 1 1 1 0.0 0.3 A 2 237 2 1 1 0.0 0.3 A 3 129 3 1 1 0.0 0.3 B 6 396 4 4 2 0.333333333333333 0.5 B 5 86 5 4 2 0.333333333333333 0.5 C 1 107 6 6 3 0.555555555555556 0.7 C 9 347 7 6 3 0.555555555555556 0.7 D 5 221 8 8 4 0.777777777777778 1.0 D 5 89 9 8 4 0.777777777777778 1.0 D 7 98 10 8 4 0.777777777777778 1.0","title":"Using window functions"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#using-aggregate-functions","text":"%% sql SELECT person , time , bsl , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg , MIN ( bsl ) OVER win AS bsl_min , MAX ( bsl ) over win as bsl_max , FIRST_VALUE ( bsl ) OVER win as bsl_start , LAST_VALUE ( bsl ) OVER win as bsl_end FROM df WINDOW win AS ( PARTITION BY person ORDER BY time ); * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl bsl_sum bsl_avg bsl_min bsl_max bsl_start bsl_end A 0 115 115 115.0000000000000000 115 115 115 115 A 2 237 352 176.0000000000000000 115 237 115 237 A 3 129 481 160.3333333333333333 115 237 115 129 B 5 86 86 86.0000000000000000 86 86 86 86 B 6 396 482 241.0000000000000000 86 396 86 396 C 1 107 107 107.0000000000000000 107 107 107 107 C 9 347 454 227.0000000000000000 107 347 107 347 D 5 221 310 155.0000000000000000 89 221 221 89 D 5 89 310 155.0000000000000000 89 221 221 89 D 7 98 408 136.0000000000000000 89 221 221 98","title":"Using aggregate functions"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#using-rows-and-range-to-constrain-windows","text":"%% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER win AS vals , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg FROM df WINDOW win AS ( PARTITION BY person ORDER BY time ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING ) ORDER BY person , time ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl vals bsl_sum bsl_avg A 0 115 115, 237 352 176.0000000000000000 A 2 237 115, 237, 129 481 160.3333333333333333 A 3 129 237, 129 366 183.0000000000000000 B 5 86 86, 396 482 241.0000000000000000 B 6 396 86, 396 482 241.0000000000000000 C 1 107 107, 347 454 227.0000000000000000 C 9 347 107, 347 454 227.0000000000000000 D 5 221 221, 89 310 155.0000000000000000 D 5 89 221, 89, 98 408 136.0000000000000000 D 7 98 89, 98 187 93.5000000000000000","title":"Using rows and range to constrain windows"},{"location":"_nb/%3DPy/02_SQL/02_SQL/#frames-using-rows-and-range","text":"For Range, all rows with the same ORDER BY value are considered peers. %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER win AS vals , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg FROM df WINDOW win AS ( ORDER BY person ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) ORDER BY person , time ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl vals bsl_sum bsl_avg A 0 115 115 115 115.0000000000000000 A 2 237 115, 237 352 176.0000000000000000 A 3 129 115, 237, 129 481 160.3333333333333333 B 5 86 115, 237, 129, 396, 86 963 192.6000000000000000 B 6 396 115, 237, 129, 396 877 219.2500000000000000 C 1 107 115, 237, 129, 396, 86, 107 1070 178.3333333333333333 C 9 347 115, 237, 129, 396, 86, 107, 347 1417 202.4285714285714286 D 5 221 115, 237, 129, 396, 86, 107, 347, 221 1638 204.7500000000000000 D 5 89 115, 237, 129, 396, 86, 107, 347, 221, 89 1727 191.8888888888888889 D 7 98 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000 %% sql SELECT person , time , bsl , STRING_AGG ( CAST ( bsl AS TEXT ), ', ' ) OVER win AS vals , SUM ( bsl ) OVER win AS bsl_sum , AVG ( bsl ) OVER win AS bsl_avg FROM df WINDOW win AS ( ORDER BY person RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) ORDER BY person , time ; * postgresql://postgres:***@172.26.0.3/postgres 10 rows affected. person time bsl vals bsl_sum bsl_avg A 0 115 115, 237, 129 481 160.3333333333333333 A 2 237 115, 237, 129 481 160.3333333333333333 A 3 129 115, 237, 129 481 160.3333333333333333 B 5 86 115, 237, 129, 396, 86 963 192.6000000000000000 B 6 396 115, 237, 129, 396, 86 963 192.6000000000000000 C 1 107 115, 237, 129, 396, 86, 107, 347 1417 202.4285714285714286 C 9 347 115, 237, 129, 396, 86, 107, 347 1417 202.4285714285714286 D 5 221 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000 D 5 89 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000 D 7 98 115, 237, 129, 396, 86, 107, 347, 221, 89, 98 1825 182.5000000000000000","title":"Frames using Rows and Range"},{"location":"_nb/%3DPy/02_SQL/03_Postgres/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Tutorials: - http://www.postgresqltutorial.com/ - https://www.postgresql.org/docs/11/tutorial-sql.html Postgres jupyter kernel: https://github.com/bgschiller/postgres_kernel pgspecial must be installed for running special command postgres command in this notebook %pip install pgspecial Use sqlmagic and set sqlmagic compatible uri % load_ext sql The sql extension is already loaded. To reload it, use: %reload_ext sql Initialisation \u00b6 uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com\" % sql { uri } 'Connected: postgres@None' SQL for table deletion and creation % sql select current_database () * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. current_database postgres %% sql SELECT * FROM pg_tables WHERE schemaname NOT IN ( 'pg_catalog' , 'information_schema' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False False False %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; * postgresql+psycopg2://postgres: * @db.postgres.app.com Done. Done. [] Create table \u00b6 Primary key , auto-increment (see post ): - usage of the SERIAL or BIGSERIAL data types when CREATING a new table. - creating a custom SEQUENCE %% sql CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , person_first varchar ( 255 ), person_last varchar ( 255 ), country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ), CON ); * postgresql+psycopg2://postgres: * @db.postgres.app.com Done. (psycopg2.errors.SyntaxError) syntax error at or near \")\" LINE 8: ); ^ [SQL: CREATE TABLE Person ( person_id SERIAL PRIMARY KEY, person_first varchar(255), person_last varchar(255), country_id varchar(2) NOT NULL, FOREIGN KEY (country_id) REFERENCES Country(country_id), CON );] (Background on this error at: http://sqlalche.me/e/f405) View table list, either with postgres special command \\dt or from pg_catalog %% sql \\ dt * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. Schema Name Type Owner public country table postgres %% sql DESCRIBE accounts ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.SyntaxError) syntax error at or near \"DESCRIBE\" LINE 1: DESCRIBE accounts; ^ [SQL: DESCRIBE accounts;] (Background on this error at: http://sqlalche.me/e/f405) %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema' ; * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False False False Insert rows \u00b6 %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com 2 rows affected. [] The pg_relation_size() function returns the size of the table only, not included indexes or additional objects. %% sql SELECT pg_size_pretty ( pg_relation_size ( 'Country' )); * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. pg_size_pretty 8192 bytes %% sql INSERT INTO Person ( person_first , person_last , country_id ) VALUES ( 'Napolean' , 'Bonaparte' , 'FR' ), ( 'Luis' , 'Alvarez' , 'CU' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.UndefinedTable) relation \"person\" does not exist LINE 1: INSERT INTO Person (person_first, person_last, country_id) ^ [SQL: INSERT INTO Person (person_first, person_last, country_id) VALUES ('Napolean', 'Bonaparte', 'FR'), ('Luis','Alvarez', 'CU');] (Background on this error at: http://sqlalche.me/e/f405) Accessing the RDBMS dictionary. %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' ; * postgresql+psycopg2://postgres: * @db.postgres.app.com 8 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False False False information_schema sql_features postgres None False False False False information_schema sql_implementation_info postgres None False False False False information_schema sql_languages postgres None False False False False information_schema sql_packages postgres None False False False False information_schema sql_parts postgres None False False False False information_schema sql_sizing postgres None False False False False information_schema sql_sizing_profiles postgres None False False False False %% sql SELECT sql FROM postgres WHERE name = 'Person' ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.UndefinedTable) relation \"postgres\" does not exist LINE 1: SELECT sql FROM postgres ^ [SQL: SELECT sql FROM postgres WHERE name='Person';] (Background on this error at: http://sqlalche.me/e/f405) SQL as a Query Language. %% sql SELECT person_first as first , person_last AS last , country_name AS nationality FROM Person INNER JOIN country ON Person . country_id = Country . country_id ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.UndefinedTable) relation \"person\" does not exist LINE 2: FROM Person ^ [SQL: SELECT person_first as first, person_last AS last, country_name AS nationality FROM Person INNER JOIN country ON Person.country_id = Country.country_id;] (Background on this error at: http://sqlalche.me/e/f405) Visualizing the entitry-relationship diagram (ERd). import ibis import eralchemy import os from eralchemy import render_er if not os.path.exists('erd_from_sqlalchemy.png'): render_er(uri, 'erd_from_sqlalchemy.png') Homework walk-through \u00b6 Convert the flat file data in data/flat.csv into a well-structured relational database in SQLite3 stored as data/faculty.db . Note - salary information is confidential and should be kept in a separate table from other personal data. import pandas as pd flat = pd . read_csv ( '../data/flat.csv' , keep_default_na = False ) flat . sample ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name gender age height weight salary nationality code country language1 language2 language3 first last 915 Lynwood Pope Male 20 1.51 40 88000 Jordanian JO Jordan ASP Scala Lynwood Pope 1 Aaron Kirby Male 59 1.69 43 80000 Spanish SP Spain Falcon haXe GNU Octave Aaron Kirby 239 Clarita Carver Female 35 1.66 71 84000 Finnish FI Finland Prolog Erlang Smalltalk Clarita Carver %% sql USE faculty ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.SyntaxError) syntax error at or near \"USE\" LINE 1: USE faculty; ^ [SQL: USE faculty;] (Background on this error at: http://sqlalche.me/e/f405) %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , name varchar ( 255 ), age INTEGER NOT NULL , country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ) ); * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres Done. Done. Done. Done. [] %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres 2 rows affected. [] %% sql DELETE FROM Country * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres 2 rows affected. [] %% sql SELECT * FROM Country * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres 0 rows affected. country_id country_name from sqlalchemy import create_engine engine = create_engine ( uri ) conn = engine . connect () flat . columns Index(['name', 'gender', 'age', 'height', 'weight', 'salary', 'nationality', 'code', 'country', 'language1', 'language2', 'language3', 'first', 'last'], dtype='object') flat . rename ( mapper = { 'code' : 'country_id' , 'country' : 'country_name' }, inplace = True ) country = flat [[ 'country_id' , 'country_name' ]] --------------------------------------------------------------------------- KeyError Traceback (most recent call last) <ipython-input-31-f9749b54edd5> in <module> ----> 1 country = flat [ [ 'country_id' , 'country_name' ] ] /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__ (self, key) 2932 key = list ( key ) 2933 indexer = self.loc._convert_to_indexer(key, axis=1, -> 2934 raise_missing=True) 2935 2936 # take() does not accept boolean indexers /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py in _convert_to_indexer (self, obj, axis, is_setter, raise_missing) 1352 kwargs = {'raise_missing': True if is_setter else 1353 raise_missing} -> 1354 return self . _get_listlike_indexer ( obj , axis , ** kwargs ) [ 1 ] 1355 else : 1356 try : /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py in _get_listlike_indexer (self, key, axis, raise_missing) 1159 self._validate_read_indexer(keyarr, indexer, 1160 o . _get_axis_number ( axis ) , -> 1161 raise_missing=raise_missing) 1162 return keyarr , indexer 1163 /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py in _validate_read_indexer (self, key, indexer, axis, raise_missing) 1244 raise KeyError( 1245 u\"None of [{key}] are in the [{axis}]\".format( -> 1246 key=key, axis=self.obj._get_axis_name(axis))) 1247 1248 # We (temporarily) allow for some missing keys with .loc, except in KeyError : \"None of [Index(['country_id', 'country_name'], dtype='object')] are in the [columns]\" country . set_index ( 'country_id' ) . to_sql ( 'Country' , engine , if_exists = 'append' ) --------------------------------------------------------------------------- UndefinedColumn Traceback (most recent call last) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1223 self.dialect.do_executemany( -> 1224 cursor , statement , parameters , context 1225 ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py in do_executemany (self, cursor, statement, parameters, context) 751 else : --> 752 cursor . executemany ( statement , parameters ) 753 UndefinedColumn : column \"country_id\" of relation \"Country\" does not exist LINE 1: INSERT INTO \"Country\" (country_id, country_name) VALUES ('GB... ^ The above exception was the direct cause of the following exception: ProgrammingError Traceback (most recent call last) <ipython-input-103-42976342ffd9> in <module> ----> 1 country . set_index ( 'country_id' ) . to_sql ( 'Country' , engine , if_exists = 'append' ) /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in to_sql (self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method) 2529 sql.to_sql(self, name, con, schema=schema, if_exists=if_exists, 2530 index = index , index_label = index_label , chunksize = chunksize , -> 2531 dtype=dtype, method=method) 2532 2533 def to_pickle(self, path, compression='infer', /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in to_sql (frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method) 458 pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index, 459 index_label = index_label , schema = schema , --> 460 chunksize=chunksize, dtype=dtype, method=method) 461 462 /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in to_sql (self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method) 1172 schema=schema, dtype=dtype) 1173 table . create ( ) -> 1174 table . insert ( chunksize , method = method ) 1175 if ( not name . isdigit ( ) and not name . islower ( ) ) : 1176 # check for potentially case sensitivity issues (GH7815) /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in insert (self, chunksize, method) 684 685 chunk_iter = zip ( * [ arr [ start_i : end_i ] for arr in data_list ] ) --> 686 exec_insert ( conn , keys , chunk_iter ) 687 688 def _query_iterator(self, result, chunksize, columns, coerce_float=True, /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in _execute_insert (self, conn, keys, data_iter) 597 \"\"\" 598 data = [ dict ( zip ( keys , row ) ) for row in data_iter ] --> 599 conn . execute ( self . table . insert ( ) , data ) 600 601 def _execute_insert_multi ( self , conn , keys , data_iter ) : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in execute (self, object_, *multiparams, **params) 986 raise exc . ObjectNotExecutableError ( object_ ) 987 else : --> 988 return meth ( self , multiparams , params ) 989 990 def _execute_function ( self , func , multiparams , params ) : /opt/conda/lib/python3.7/site-packages/sqlalchemy/sql/elements.py in _execute_on_connection (self, connection, multiparams, params) 285 def _execute_on_connection ( self , connection , multiparams , params ) : 286 if self . supports_execution : --> 287 return connection . _execute_clauseelement ( self , multiparams , params ) 288 else : 289 raise exc . ObjectNotExecutableError ( self ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_clauseelement (self, elem, multiparams, params) 1105 distilled_params , 1106 compiled_sql , -> 1107 distilled_params , 1108 ) 1109 if self . _has_events or self . engine . _has_events : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1246 except BaseException as e : 1247 self._handle_dbapi_exception( -> 1248 e , statement , parameters , cursor , context 1249 ) 1250 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _handle_dbapi_exception (self, e, statement, parameters, cursor, context) 1464 util . raise_from_cause ( newraise , exc_info ) 1465 elif should_wrap : -> 1466 util . raise_from_cause ( sqlalchemy_exception , exc_info ) 1467 else : 1468 util . reraise ( * exc_info ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in raise_from_cause (exception, exc_info) 381 exc_type , exc_value , exc_tb = exc_info 382 cause = exc_value if exc_value is not exception else None --> 383 reraise ( type ( exception ) , exception , tb = exc_tb , cause = cause ) 384 385 /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in reraise (tp, value, tb, cause) 126 value . __cause__ = cause 127 if value . __traceback__ is not tb : --> 128 raise value . with_traceback ( tb ) 129 raise value 130 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1222 if not evt_handled : 1223 self.dialect.do_executemany( -> 1224 cursor , statement , parameters , context 1225 ) 1226 elif not parameters and context . no_parameters : /opt/conda/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py in do_executemany (self, cursor, statement, parameters, context) 750 extras . execute_batch ( cursor , statement , parameters ) 751 else : --> 752 cursor . executemany ( statement , parameters ) 753 754 @ util . memoized_instancemethod ProgrammingError : (psycopg2.errors.UndefinedColumn) column \"country_id\" of relation \"Country\" does not exist LINE 1: INSERT INTO \"Country\" (country_id, country_name) VALUES ('GB... ^ [SQL: INSERT INTO \"Country\" (country_id, country_name) VALUES (%(country_id)s, %(country_name)s)] [parameters: ({'country_id': 'GB', 'country_name': 'United Kingdom'}, {'country_id': 'SP', 'country_name': 'Spain'}, {'country_id': 'IT', 'country_name': 'Italy'}, {'country_id': 'IT', 'country_name': 'Italy'}, {'country_id': 'UY', 'country_name': 'Uruguay'}, {'country_id': 'CM', 'country_name': 'Cambodia'}, {'country_id': 'CM', 'country_name': 'Cameroon'}, {'country_id': 'BE', 'country_name': 'Belgium'} ... displaying 10 of 1523 total bound parameter sets ... {'country_id': 'ET', 'country_name': 'Ethiopia'}, {'country_id': 'VE', 'country_name': 'Venezuela'})] (Background on this error at: http://sqlalche.me/e/f405) %%sql \u00b6 SELECT * FROM Country flat . to_sql ? Signature: flat . to_sql ( name , con , schema = None , if_exists = 'fail' , index = True , index_label = None , chunksize = None , dtype = None , method = None , ) Docstring: Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1]_ are supported. Tables can be newly created, appended to, or overwritten. Parameters ---------- name : string Name of SQL table. con : sqlalchemy.engine.Engine or sqlite3.Connection Using SQLAlchemy makes it possible to use any DB supported by that library. Legacy support is provided for sqlite3.Connection objects. schema : string, optional Specify the schema (if database flavor supports this). If None, use default schema. if_exists : {'fail', 'replace', 'append'}, default 'fail' How to behave if the table already exists. * fail: Raise a ValueError. * replace: Drop the table before inserting new values. * append: Insert new values to the existing table. index : bool, default True Write DataFrame index as a column. Uses `index_label` as the column name in the table. index_label : string or sequence, default None Column label for index column(s). If None is given (default) and `index` is True, then the index names are used. A sequence should be given if the DataFrame uses MultiIndex. chunksize : int, optional Rows will be written in batches of this size at a time. By default, all rows will be written at once. dtype : dict, optional Specifying the datatype for columns. The keys should be the column names and the values should be the SQLAlchemy types or strings for the sqlite3 legacy mode. method : {None, 'multi', callable}, default None Controls the SQL insertion clause used: * None : Uses standard SQL ``INSERT`` clause (one per row). * 'multi': Pass multiple values in a single ``INSERT`` clause. * callable with signature ``(pd_table, conn, keys, data_iter)``. Details and a sample callable implementation can be found in the section :ref:`insert method <io.sql.method>`. .. versionadded:: 0.24.0 Raises ------ ValueError When the table already exists and `if_exists` is 'fail' (the default). See Also -------- read_sql : Read a DataFrame from a table. Notes ----- Timezone aware datetime columns will be written as ``Timestamp with timezone`` type with SQLAlchemy if supported by the database. Otherwise, the datetimes will be stored as timezone unaware timestamps local to the original timezone. .. versionadded:: 0.24.0 References ---------- .. [1] http://docs.sqlalchemy.org .. [2] https://www.python.org/dev/peps/pep-0249/ Examples -------- Create an in-memory SQLite database. >>> from sqlalchemy import create_engine >>> engine = create_engine('sqlite://', echo=False) Create a table from scratch with 3 rows. >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']}) >>> df name 0 User 1 1 User 2 2 User 3 >>> df.to_sql('users', con=engine) >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')] >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']}) >>> df1.to_sql('users', con=engine, if_exists='append') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'), (0, 'User 4'), (1, 'User 5')] Overwrite the table with just ``df1``. >>> df1.to_sql('users', con=engine, if_exists='replace', ... index_label='id') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 4'), (1, 'User 5')] Specify the dtype (especially useful for integers with missing values). Notice that while pandas is forced to store the data as floating point, the database supports nullable integers. When fetching the data with Python, we get back integer scalars. >>> df = pd.DataFrame({\"A\": [1, None, 2]}) >>> df A 0 1.0 1 NaN 2 2.0 >>> from sqlalchemy.types import Integer >>> df.to_sql('integers', con=engine, index=False, ... dtype={\"A\": Integer()}) >>> engine.execute(\"SELECT * FROM integers\").fetchall() [(1,), (None,), (2,)] File: /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py Type: method import asyncio async def coro ( int ): print ( f \"running { int } \" ) await asyncio . sleep ( 1 ) print ( f \"continuing { int } \" ) return int asyncio . run ( coro ) --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) <ipython-input-109-550412da50e5> in <module> ----> 1 asyncio . run ( coro ) /opt/conda/lib/python3.7/asyncio/runners.py in run (main, debug) 32 if events . _get_running_loop ( ) is not None : 33 raise RuntimeError( ---> 34 \"asyncio.run() cannot be called from a running event loop\") 35 36 if not coroutines . iscoroutine ( main ) : RuntimeError : asyncio.run() cannot be called from a running event loop","title":"03 Postgres"},{"location":"_nb/%3DPy/02_SQL/03_Postgres/#initialisation","text":"uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com\" % sql { uri } 'Connected: postgres@None' SQL for table deletion and creation % sql select current_database () * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. current_database postgres %% sql SELECT * FROM pg_tables WHERE schemaname NOT IN ( 'pg_catalog' , 'information_schema' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False False False %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; * postgresql+psycopg2://postgres: * @db.postgres.app.com Done. Done. []","title":"Initialisation"},{"location":"_nb/%3DPy/02_SQL/03_Postgres/#create-table","text":"Primary key , auto-increment (see post ): - usage of the SERIAL or BIGSERIAL data types when CREATING a new table. - creating a custom SEQUENCE %% sql CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , person_first varchar ( 255 ), person_last varchar ( 255 ), country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ), CON ); * postgresql+psycopg2://postgres: * @db.postgres.app.com Done. (psycopg2.errors.SyntaxError) syntax error at or near \")\" LINE 8: ); ^ [SQL: CREATE TABLE Person ( person_id SERIAL PRIMARY KEY, person_first varchar(255), person_last varchar(255), country_id varchar(2) NOT NULL, FOREIGN KEY (country_id) REFERENCES Country(country_id), CON );] (Background on this error at: http://sqlalche.me/e/f405) View table list, either with postgres special command \\dt or from pg_catalog %% sql \\ dt * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. Schema Name Type Owner public country table postgres %% sql DESCRIBE accounts ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.SyntaxError) syntax error at or near \"DESCRIBE\" LINE 1: DESCRIBE accounts; ^ [SQL: DESCRIBE accounts;] (Background on this error at: http://sqlalche.me/e/f405) %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema' ; * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False False False","title":"Create table"},{"location":"_nb/%3DPy/02_SQL/03_Postgres/#insert-rows","text":"%% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com 2 rows affected. [] The pg_relation_size() function returns the size of the table only, not included indexes or additional objects. %% sql SELECT pg_size_pretty ( pg_relation_size ( 'Country' )); * postgresql+psycopg2://postgres: * @db.postgres.app.com 1 rows affected. pg_size_pretty 8192 bytes %% sql INSERT INTO Person ( person_first , person_last , country_id ) VALUES ( 'Napolean' , 'Bonaparte' , 'FR' ), ( 'Luis' , 'Alvarez' , 'CU' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.UndefinedTable) relation \"person\" does not exist LINE 1: INSERT INTO Person (person_first, person_last, country_id) ^ [SQL: INSERT INTO Person (person_first, person_last, country_id) VALUES ('Napolean', 'Bonaparte', 'FR'), ('Luis','Alvarez', 'CU');] (Background on this error at: http://sqlalche.me/e/f405) Accessing the RDBMS dictionary. %% sql SELECT * FROM pg_catalog . pg_tables WHERE schemaname != 'pg_catalog' ; * postgresql+psycopg2://postgres: * @db.postgres.app.com 8 rows affected. schemaname tablename tableowner tablespace hasindexes hasrules hastriggers rowsecurity public country postgres None True False False False information_schema sql_features postgres None False False False False information_schema sql_implementation_info postgres None False False False False information_schema sql_languages postgres None False False False False information_schema sql_packages postgres None False False False False information_schema sql_parts postgres None False False False False information_schema sql_sizing postgres None False False False False information_schema sql_sizing_profiles postgres None False False False False %% sql SELECT sql FROM postgres WHERE name = 'Person' ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.UndefinedTable) relation \"postgres\" does not exist LINE 1: SELECT sql FROM postgres ^ [SQL: SELECT sql FROM postgres WHERE name='Person';] (Background on this error at: http://sqlalche.me/e/f405) SQL as a Query Language. %% sql SELECT person_first as first , person_last AS last , country_name AS nationality FROM Person INNER JOIN country ON Person . country_id = Country . country_id ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.UndefinedTable) relation \"person\" does not exist LINE 2: FROM Person ^ [SQL: SELECT person_first as first, person_last AS last, country_name AS nationality FROM Person INNER JOIN country ON Person.country_id = Country.country_id;] (Background on this error at: http://sqlalche.me/e/f405) Visualizing the entitry-relationship diagram (ERd). import ibis import eralchemy import os from eralchemy import render_er if not os.path.exists('erd_from_sqlalchemy.png'): render_er(uri, 'erd_from_sqlalchemy.png')","title":"Insert rows"},{"location":"_nb/%3DPy/02_SQL/03_Postgres/#homework-walk-through","text":"Convert the flat file data in data/flat.csv into a well-structured relational database in SQLite3 stored as data/faculty.db . Note - salary information is confidential and should be kept in a separate table from other personal data. import pandas as pd flat = pd . read_csv ( '../data/flat.csv' , keep_default_na = False ) flat . sample ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name gender age height weight salary nationality code country language1 language2 language3 first last 915 Lynwood Pope Male 20 1.51 40 88000 Jordanian JO Jordan ASP Scala Lynwood Pope 1 Aaron Kirby Male 59 1.69 43 80000 Spanish SP Spain Falcon haXe GNU Octave Aaron Kirby 239 Clarita Carver Female 35 1.66 71 84000 Finnish FI Finland Prolog Erlang Smalltalk Clarita Carver %% sql USE faculty ; * postgresql+psycopg2://postgres: * @db.postgres.app.com (psycopg2.errors.SyntaxError) syntax error at or near \"USE\" LINE 1: USE faculty; ^ [SQL: USE faculty;] (Background on this error at: http://sqlalche.me/e/f405) %% sql DROP TABLE IF EXISTS Person ; DROP TABLE IF EXISTS Country ; CREATE TABLE Country ( country_id varchar ( 2 ) PRIMARY KEY , country_name varchar ( 255 ) ); CREATE TABLE Person ( person_id SERIAL PRIMARY KEY , name varchar ( 255 ), age INTEGER NOT NULL , country_id varchar ( 2 ) NOT NULL , FOREIGN KEY ( country_id ) REFERENCES Country ( country_id ) ); * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres Done. Done. Done. Done. [] %% sql INSERT INTO Country ( country_id , country_name ) VALUES ( 'FR' , 'France' ), ( 'CU' , 'CUBA' ); * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres 2 rows affected. [] %% sql DELETE FROM Country * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres 2 rows affected. [] %% sql SELECT * FROM Country * postgresql+psycopg2://postgres: * @db.postgres.app.com/postgres 0 rows affected. country_id country_name from sqlalchemy import create_engine engine = create_engine ( uri ) conn = engine . connect () flat . columns Index(['name', 'gender', 'age', 'height', 'weight', 'salary', 'nationality', 'code', 'country', 'language1', 'language2', 'language3', 'first', 'last'], dtype='object') flat . rename ( mapper = { 'code' : 'country_id' , 'country' : 'country_name' }, inplace = True ) country = flat [[ 'country_id' , 'country_name' ]] --------------------------------------------------------------------------- KeyError Traceback (most recent call last) <ipython-input-31-f9749b54edd5> in <module> ----> 1 country = flat [ [ 'country_id' , 'country_name' ] ] /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__ (self, key) 2932 key = list ( key ) 2933 indexer = self.loc._convert_to_indexer(key, axis=1, -> 2934 raise_missing=True) 2935 2936 # take() does not accept boolean indexers /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py in _convert_to_indexer (self, obj, axis, is_setter, raise_missing) 1352 kwargs = {'raise_missing': True if is_setter else 1353 raise_missing} -> 1354 return self . _get_listlike_indexer ( obj , axis , ** kwargs ) [ 1 ] 1355 else : 1356 try : /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py in _get_listlike_indexer (self, key, axis, raise_missing) 1159 self._validate_read_indexer(keyarr, indexer, 1160 o . _get_axis_number ( axis ) , -> 1161 raise_missing=raise_missing) 1162 return keyarr , indexer 1163 /opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py in _validate_read_indexer (self, key, indexer, axis, raise_missing) 1244 raise KeyError( 1245 u\"None of [{key}] are in the [{axis}]\".format( -> 1246 key=key, axis=self.obj._get_axis_name(axis))) 1247 1248 # We (temporarily) allow for some missing keys with .loc, except in KeyError : \"None of [Index(['country_id', 'country_name'], dtype='object')] are in the [columns]\" country . set_index ( 'country_id' ) . to_sql ( 'Country' , engine , if_exists = 'append' ) --------------------------------------------------------------------------- UndefinedColumn Traceback (most recent call last) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1223 self.dialect.do_executemany( -> 1224 cursor , statement , parameters , context 1225 ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py in do_executemany (self, cursor, statement, parameters, context) 751 else : --> 752 cursor . executemany ( statement , parameters ) 753 UndefinedColumn : column \"country_id\" of relation \"Country\" does not exist LINE 1: INSERT INTO \"Country\" (country_id, country_name) VALUES ('GB... ^ The above exception was the direct cause of the following exception: ProgrammingError Traceback (most recent call last) <ipython-input-103-42976342ffd9> in <module> ----> 1 country . set_index ( 'country_id' ) . to_sql ( 'Country' , engine , if_exists = 'append' ) /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in to_sql (self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method) 2529 sql.to_sql(self, name, con, schema=schema, if_exists=if_exists, 2530 index = index , index_label = index_label , chunksize = chunksize , -> 2531 dtype=dtype, method=method) 2532 2533 def to_pickle(self, path, compression='infer', /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in to_sql (frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method) 458 pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index, 459 index_label = index_label , schema = schema , --> 460 chunksize=chunksize, dtype=dtype, method=method) 461 462 /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in to_sql (self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method) 1172 schema=schema, dtype=dtype) 1173 table . create ( ) -> 1174 table . insert ( chunksize , method = method ) 1175 if ( not name . isdigit ( ) and not name . islower ( ) ) : 1176 # check for potentially case sensitivity issues (GH7815) /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in insert (self, chunksize, method) 684 685 chunk_iter = zip ( * [ arr [ start_i : end_i ] for arr in data_list ] ) --> 686 exec_insert ( conn , keys , chunk_iter ) 687 688 def _query_iterator(self, result, chunksize, columns, coerce_float=True, /opt/conda/lib/python3.7/site-packages/pandas/io/sql.py in _execute_insert (self, conn, keys, data_iter) 597 \"\"\" 598 data = [ dict ( zip ( keys , row ) ) for row in data_iter ] --> 599 conn . execute ( self . table . insert ( ) , data ) 600 601 def _execute_insert_multi ( self , conn , keys , data_iter ) : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in execute (self, object_, *multiparams, **params) 986 raise exc . ObjectNotExecutableError ( object_ ) 987 else : --> 988 return meth ( self , multiparams , params ) 989 990 def _execute_function ( self , func , multiparams , params ) : /opt/conda/lib/python3.7/site-packages/sqlalchemy/sql/elements.py in _execute_on_connection (self, connection, multiparams, params) 285 def _execute_on_connection ( self , connection , multiparams , params ) : 286 if self . supports_execution : --> 287 return connection . _execute_clauseelement ( self , multiparams , params ) 288 else : 289 raise exc . ObjectNotExecutableError ( self ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_clauseelement (self, elem, multiparams, params) 1105 distilled_params , 1106 compiled_sql , -> 1107 distilled_params , 1108 ) 1109 if self . _has_events or self . engine . _has_events : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1246 except BaseException as e : 1247 self._handle_dbapi_exception( -> 1248 e , statement , parameters , cursor , context 1249 ) 1250 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _handle_dbapi_exception (self, e, statement, parameters, cursor, context) 1464 util . raise_from_cause ( newraise , exc_info ) 1465 elif should_wrap : -> 1466 util . raise_from_cause ( sqlalchemy_exception , exc_info ) 1467 else : 1468 util . reraise ( * exc_info ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in raise_from_cause (exception, exc_info) 381 exc_type , exc_value , exc_tb = exc_info 382 cause = exc_value if exc_value is not exception else None --> 383 reraise ( type ( exception ) , exception , tb = exc_tb , cause = cause ) 384 385 /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in reraise (tp, value, tb, cause) 126 value . __cause__ = cause 127 if value . __traceback__ is not tb : --> 128 raise value . with_traceback ( tb ) 129 raise value 130 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1222 if not evt_handled : 1223 self.dialect.do_executemany( -> 1224 cursor , statement , parameters , context 1225 ) 1226 elif not parameters and context . no_parameters : /opt/conda/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py in do_executemany (self, cursor, statement, parameters, context) 750 extras . execute_batch ( cursor , statement , parameters ) 751 else : --> 752 cursor . executemany ( statement , parameters ) 753 754 @ util . memoized_instancemethod ProgrammingError : (psycopg2.errors.UndefinedColumn) column \"country_id\" of relation \"Country\" does not exist LINE 1: INSERT INTO \"Country\" (country_id, country_name) VALUES ('GB... ^ [SQL: INSERT INTO \"Country\" (country_id, country_name) VALUES (%(country_id)s, %(country_name)s)] [parameters: ({'country_id': 'GB', 'country_name': 'United Kingdom'}, {'country_id': 'SP', 'country_name': 'Spain'}, {'country_id': 'IT', 'country_name': 'Italy'}, {'country_id': 'IT', 'country_name': 'Italy'}, {'country_id': 'UY', 'country_name': 'Uruguay'}, {'country_id': 'CM', 'country_name': 'Cambodia'}, {'country_id': 'CM', 'country_name': 'Cameroon'}, {'country_id': 'BE', 'country_name': 'Belgium'} ... displaying 10 of 1523 total bound parameter sets ... {'country_id': 'ET', 'country_name': 'Ethiopia'}, {'country_id': 'VE', 'country_name': 'Venezuela'})] (Background on this error at: http://sqlalche.me/e/f405)","title":"Homework walk-through"},{"location":"_nb/%3DPy/02_SQL/03_Postgres/#sql","text":"SELECT * FROM Country flat . to_sql ? Signature: flat . to_sql ( name , con , schema = None , if_exists = 'fail' , index = True , index_label = None , chunksize = None , dtype = None , method = None , ) Docstring: Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1]_ are supported. Tables can be newly created, appended to, or overwritten. Parameters ---------- name : string Name of SQL table. con : sqlalchemy.engine.Engine or sqlite3.Connection Using SQLAlchemy makes it possible to use any DB supported by that library. Legacy support is provided for sqlite3.Connection objects. schema : string, optional Specify the schema (if database flavor supports this). If None, use default schema. if_exists : {'fail', 'replace', 'append'}, default 'fail' How to behave if the table already exists. * fail: Raise a ValueError. * replace: Drop the table before inserting new values. * append: Insert new values to the existing table. index : bool, default True Write DataFrame index as a column. Uses `index_label` as the column name in the table. index_label : string or sequence, default None Column label for index column(s). If None is given (default) and `index` is True, then the index names are used. A sequence should be given if the DataFrame uses MultiIndex. chunksize : int, optional Rows will be written in batches of this size at a time. By default, all rows will be written at once. dtype : dict, optional Specifying the datatype for columns. The keys should be the column names and the values should be the SQLAlchemy types or strings for the sqlite3 legacy mode. method : {None, 'multi', callable}, default None Controls the SQL insertion clause used: * None : Uses standard SQL ``INSERT`` clause (one per row). * 'multi': Pass multiple values in a single ``INSERT`` clause. * callable with signature ``(pd_table, conn, keys, data_iter)``. Details and a sample callable implementation can be found in the section :ref:`insert method <io.sql.method>`. .. versionadded:: 0.24.0 Raises ------ ValueError When the table already exists and `if_exists` is 'fail' (the default). See Also -------- read_sql : Read a DataFrame from a table. Notes ----- Timezone aware datetime columns will be written as ``Timestamp with timezone`` type with SQLAlchemy if supported by the database. Otherwise, the datetimes will be stored as timezone unaware timestamps local to the original timezone. .. versionadded:: 0.24.0 References ---------- .. [1] http://docs.sqlalchemy.org .. [2] https://www.python.org/dev/peps/pep-0249/ Examples -------- Create an in-memory SQLite database. >>> from sqlalchemy import create_engine >>> engine = create_engine('sqlite://', echo=False) Create a table from scratch with 3 rows. >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']}) >>> df name 0 User 1 1 User 2 2 User 3 >>> df.to_sql('users', con=engine) >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')] >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']}) >>> df1.to_sql('users', con=engine, if_exists='append') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'), (0, 'User 4'), (1, 'User 5')] Overwrite the table with just ``df1``. >>> df1.to_sql('users', con=engine, if_exists='replace', ... index_label='id') >>> engine.execute(\"SELECT * FROM users\").fetchall() [(0, 'User 4'), (1, 'User 5')] Specify the dtype (especially useful for integers with missing values). Notice that while pandas is forced to store the data as floating point, the database supports nullable integers. When fetching the data with Python, we get back integer scalars. >>> df = pd.DataFrame({\"A\": [1, None, 2]}) >>> df A 0 1.0 1 NaN 2 2.0 >>> from sqlalchemy.types import Integer >>> df.to_sql('integers', con=engine, index=False, ... dtype={\"A\": Integer()}) >>> engine.execute(\"SELECT * FROM integers\").fetchall() [(1,), (None,), (2,)] File: /opt/conda/lib/python3.7/site-packages/pandas/core/generic.py Type: method import asyncio async def coro ( int ): print ( f \"running { int } \" ) await asyncio . sleep ( 1 ) print ( f \"continuing { int } \" ) return int asyncio . run ( coro ) --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) <ipython-input-109-550412da50e5> in <module> ----> 1 asyncio . run ( coro ) /opt/conda/lib/python3.7/asyncio/runners.py in run (main, debug) 32 if events . _get_running_loop ( ) is not None : 33 raise RuntimeError( ---> 34 \"asyncio.run() cannot be called from a running event loop\") 35 36 if not coroutines . iscoroutine ( main ) : RuntimeError : asyncio.run() cannot be called from a running event loop","title":"%%sql"},{"location":"_nb/%3DPy/02_SQL/03_Postgres_tutorial/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % load_ext sql % env DATABASE_URL = postgresql + psycopg2 : // postgres : postgres @db . postgres . app . com uri = % env DATABASE_URL env: DATABASE_URL=postgresql+psycopg2://postgres:postgres@db.postgres.app.com or uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com\" Create tables \u00b6 %% sql \\ d 6 rows affected. Schema Name Type Owner public accounts table postgres public flat table postgres public t_cities table postgres public t_cities_id_seq sequence postgres public t_weather_observations table postgres public t_weather_observations_id_seq sequence postgres %% sql DROP TABLE IF EXISTS t_weather_observations , t_cities ; CREATE TABLE t_cities ( name varchar ( 80 ) PRIMARY KEY , location point ); CREATE TABLE t_weather_observations ( id SERIAL PRIMARY KEY , city varchar ( 80 ), temp_lo int , -- low temperature temp_hi int , -- high temperature prcp real , -- precipitation date date , FOREIGN KEY ( city ) REFERENCES t_cities ( name ) -- or city varchar ( 80 ) REFERENCES cities ( name ), ); Done. Done. Done. [] Populate a table with a row \u00b6 %% sql INSERT INTO t_cities ( name , location ) VALUES ( 'San Francisco' , '(-194.2, 53.0)' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com 1 rows affected. [] % sql SELECT * from Cities ; * postgresql+psycopg2://postgres:***@db.postgres.app.com 1 rows affected. name location San Francisco (-194.2,53) %% sql INSERT INTO weather ( city , temp_lo , temp_hi , prcp , date ) VALUES ( 'San Francisco' , 43 , 57 , 0.0 , '1994-11-29' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com 1 rows affected. [] % sql SELECT * from weather ; * postgresql+psycopg2://postgres:***@db.postgres.app.com 2 rows affected. id city temp_lo temp_hi prcp date 1 San Francisco 43 57 0.0 1994-11-29 3 San Francisco 43 57 0.0 1994-11-29 %% sql INSERT INTO weather ( date , city , temp_hi , temp_lo ) VALUES ( '1994-11-29' , 'Hayward' , 54 , 37 ); * postgresql+psycopg2://postgres:***@db.postgres.app.com --------------------------------------------------------------------------- ForeignKeyViolation Traceback (most recent call last) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1243 self.dialect.do_execute( -> 1244 cursor , statement , parameters , context 1245 ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py in do_execute (self, cursor, statement, parameters, context) 549 def do_execute ( self , cursor , statement , parameters , context = None ) : --> 550 cursor . execute ( statement , parameters ) 551 ForeignKeyViolation : insert or update on table \"weather\" violates foreign key constraint \"weather_city_fkey\" DETAIL: Key (city)=(Hayward) is not present in table \"cities\". The above exception was the direct cause of the following exception: IntegrityError Traceback (most recent call last) <ipython-input-93-3bccff404bf3> in <module> ----> 1 get_ipython ( ) . run_cell_magic ( 'sql' , '' , \"\\nINSERT INTO weather (date, city, temp_hi, temp_lo)\\nVALUES ('1994-11-29', 'Hayward', 54, 37);\\n\" ) /opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell_magic (self, magic_name, line, cell) 2356 with self . builtin_trap : 2357 args = ( magic_arg_s , cell ) -> 2358 result = fn ( * args , ** kwargs ) 2359 return result 2360 </opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-157> in execute (self, line, cell, local_ns) /opt/conda/lib/python3.7/site-packages/IPython/core/magic.py in <lambda> (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : </opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-156> in execute (self, line, cell, local_ns) /opt/conda/lib/python3.7/site-packages/IPython/core/magic.py in <lambda> (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : /opt/conda/lib/python3.7/site-packages/sql/magic.py in execute (self, line, cell, local_ns) 93 94 try : ---> 95 result = sql . run . run ( conn , parsed [ 'sql' ] , self , user_ns ) 96 97 if result is not None and not isinstance ( result , str ) and self . column_local_vars : /opt/conda/lib/python3.7/site-packages/sql/run.py in run (conn, sql, config, user_namespace) 338 else : 339 txt = sqlalchemy . sql . text ( statement ) --> 340 result = conn . session . execute ( txt , user_namespace ) 341 _commit ( conn = conn , config = config ) 342 if result and config . feedback : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in execute (self, object_, *multiparams, **params) 986 raise exc . ObjectNotExecutableError ( object_ ) 987 else : --> 988 return meth ( self , multiparams , params ) 989 990 def _execute_function ( self , func , multiparams , params ) : /opt/conda/lib/python3.7/site-packages/sqlalchemy/sql/elements.py in _execute_on_connection (self, connection, multiparams, params) 285 def _execute_on_connection ( self , connection , multiparams , params ) : 286 if self . supports_execution : --> 287 return connection . _execute_clauseelement ( self , multiparams , params ) 288 else : 289 raise exc . ObjectNotExecutableError ( self ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_clauseelement (self, elem, multiparams, params) 1105 distilled_params , 1106 compiled_sql , -> 1107 distilled_params , 1108 ) 1109 if self . _has_events or self . engine . _has_events : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1246 except BaseException as e : 1247 self._handle_dbapi_exception( -> 1248 e , statement , parameters , cursor , context 1249 ) 1250 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _handle_dbapi_exception (self, e, statement, parameters, cursor, context) 1464 util . raise_from_cause ( newraise , exc_info ) 1465 elif should_wrap : -> 1466 util . raise_from_cause ( sqlalchemy_exception , exc_info ) 1467 else : 1468 util . reraise ( * exc_info ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in raise_from_cause (exception, exc_info) 397 exc_type , exc_value , exc_tb = exc_info 398 cause = exc_value if exc_value is not exception else None --> 399 reraise ( type ( exception ) , exception , tb = exc_tb , cause = cause ) 400 401 /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in reraise (tp, value, tb, cause) 151 value . __cause__ = cause 152 if value . __traceback__ is not tb : --> 153 raise value . with_traceback ( tb ) 154 raise value 155 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1242 if not evt_handled : 1243 self.dialect.do_execute( -> 1244 cursor , statement , parameters , context 1245 ) 1246 except BaseException as e : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py in do_execute (self, cursor, statement, parameters, context) 548 549 def do_execute ( self , cursor , statement , parameters , context = None ) : --> 550 cursor . execute ( statement , parameters ) 551 552 def do_execute_no_params ( self , cursor , statement , context = None ) : IntegrityError : (psycopg2.errors.ForeignKeyViolation) insert or update on table \"weather\" violates foreign key constraint \"weather_city_fkey\" DETAIL: Key (city)=(Hayward) is not present in table \"cities\". [SQL: INSERT INTO weather (date, city, temp_hi, temp_lo) VALUES ('1994-11-29', 'Hayward', 54, 37);] (Background on this error at: http://sqlalche.me/e/gkpj)","title":"03 Postgres tutorial"},{"location":"_nb/%3DPy/02_SQL/03_Postgres_tutorial/#create-tables","text":"%% sql \\ d 6 rows affected. Schema Name Type Owner public accounts table postgres public flat table postgres public t_cities table postgres public t_cities_id_seq sequence postgres public t_weather_observations table postgres public t_weather_observations_id_seq sequence postgres %% sql DROP TABLE IF EXISTS t_weather_observations , t_cities ; CREATE TABLE t_cities ( name varchar ( 80 ) PRIMARY KEY , location point ); CREATE TABLE t_weather_observations ( id SERIAL PRIMARY KEY , city varchar ( 80 ), temp_lo int , -- low temperature temp_hi int , -- high temperature prcp real , -- precipitation date date , FOREIGN KEY ( city ) REFERENCES t_cities ( name ) -- or city varchar ( 80 ) REFERENCES cities ( name ), ); Done. Done. Done. []","title":"Create tables"},{"location":"_nb/%3DPy/02_SQL/03_Postgres_tutorial/#populate-a-table-with-a-row","text":"%% sql INSERT INTO t_cities ( name , location ) VALUES ( 'San Francisco' , '(-194.2, 53.0)' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com 1 rows affected. [] % sql SELECT * from Cities ; * postgresql+psycopg2://postgres:***@db.postgres.app.com 1 rows affected. name location San Francisco (-194.2,53) %% sql INSERT INTO weather ( city , temp_lo , temp_hi , prcp , date ) VALUES ( 'San Francisco' , 43 , 57 , 0.0 , '1994-11-29' ); * postgresql+psycopg2://postgres:***@db.postgres.app.com 1 rows affected. [] % sql SELECT * from weather ; * postgresql+psycopg2://postgres:***@db.postgres.app.com 2 rows affected. id city temp_lo temp_hi prcp date 1 San Francisco 43 57 0.0 1994-11-29 3 San Francisco 43 57 0.0 1994-11-29 %% sql INSERT INTO weather ( date , city , temp_hi , temp_lo ) VALUES ( '1994-11-29' , 'Hayward' , 54 , 37 ); * postgresql+psycopg2://postgres:***@db.postgres.app.com --------------------------------------------------------------------------- ForeignKeyViolation Traceback (most recent call last) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1243 self.dialect.do_execute( -> 1244 cursor , statement , parameters , context 1245 ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py in do_execute (self, cursor, statement, parameters, context) 549 def do_execute ( self , cursor , statement , parameters , context = None ) : --> 550 cursor . execute ( statement , parameters ) 551 ForeignKeyViolation : insert or update on table \"weather\" violates foreign key constraint \"weather_city_fkey\" DETAIL: Key (city)=(Hayward) is not present in table \"cities\". The above exception was the direct cause of the following exception: IntegrityError Traceback (most recent call last) <ipython-input-93-3bccff404bf3> in <module> ----> 1 get_ipython ( ) . run_cell_magic ( 'sql' , '' , \"\\nINSERT INTO weather (date, city, temp_hi, temp_lo)\\nVALUES ('1994-11-29', 'Hayward', 54, 37);\\n\" ) /opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_cell_magic (self, magic_name, line, cell) 2356 with self . builtin_trap : 2357 args = ( magic_arg_s , cell ) -> 2358 result = fn ( * args , ** kwargs ) 2359 return result 2360 </opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-157> in execute (self, line, cell, local_ns) /opt/conda/lib/python3.7/site-packages/IPython/core/magic.py in <lambda> (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : </opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-156> in execute (self, line, cell, local_ns) /opt/conda/lib/python3.7/site-packages/IPython/core/magic.py in <lambda> (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : /opt/conda/lib/python3.7/site-packages/sql/magic.py in execute (self, line, cell, local_ns) 93 94 try : ---> 95 result = sql . run . run ( conn , parsed [ 'sql' ] , self , user_ns ) 96 97 if result is not None and not isinstance ( result , str ) and self . column_local_vars : /opt/conda/lib/python3.7/site-packages/sql/run.py in run (conn, sql, config, user_namespace) 338 else : 339 txt = sqlalchemy . sql . text ( statement ) --> 340 result = conn . session . execute ( txt , user_namespace ) 341 _commit ( conn = conn , config = config ) 342 if result and config . feedback : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in execute (self, object_, *multiparams, **params) 986 raise exc . ObjectNotExecutableError ( object_ ) 987 else : --> 988 return meth ( self , multiparams , params ) 989 990 def _execute_function ( self , func , multiparams , params ) : /opt/conda/lib/python3.7/site-packages/sqlalchemy/sql/elements.py in _execute_on_connection (self, connection, multiparams, params) 285 def _execute_on_connection ( self , connection , multiparams , params ) : 286 if self . supports_execution : --> 287 return connection . _execute_clauseelement ( self , multiparams , params ) 288 else : 289 raise exc . ObjectNotExecutableError ( self ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_clauseelement (self, elem, multiparams, params) 1105 distilled_params , 1106 compiled_sql , -> 1107 distilled_params , 1108 ) 1109 if self . _has_events or self . engine . _has_events : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1246 except BaseException as e : 1247 self._handle_dbapi_exception( -> 1248 e , statement , parameters , cursor , context 1249 ) 1250 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _handle_dbapi_exception (self, e, statement, parameters, cursor, context) 1464 util . raise_from_cause ( newraise , exc_info ) 1465 elif should_wrap : -> 1466 util . raise_from_cause ( sqlalchemy_exception , exc_info ) 1467 else : 1468 util . reraise ( * exc_info ) /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in raise_from_cause (exception, exc_info) 397 exc_type , exc_value , exc_tb = exc_info 398 cause = exc_value if exc_value is not exception else None --> 399 reraise ( type ( exception ) , exception , tb = exc_tb , cause = cause ) 400 401 /opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py in reraise (tp, value, tb, cause) 151 value . __cause__ = cause 152 if value . __traceback__ is not tb : --> 153 raise value . with_traceback ( tb ) 154 raise value 155 /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context (self, dialect, constructor, statement, parameters, *args) 1242 if not evt_handled : 1243 self.dialect.do_execute( -> 1244 cursor , statement , parameters , context 1245 ) 1246 except BaseException as e : /opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py in do_execute (self, cursor, statement, parameters, context) 548 549 def do_execute ( self , cursor , statement , parameters , context = None ) : --> 550 cursor . execute ( statement , parameters ) 551 552 def do_execute_no_params ( self , cursor , statement , context = None ) : IntegrityError : (psycopg2.errors.ForeignKeyViolation) insert or update on table \"weather\" violates foreign key constraint \"weather_city_fkey\" DETAIL: Key (city)=(Hayward) is not present in table \"cities\". [SQL: INSERT INTO weather (date, city, temp_hi, temp_lo) VALUES ('1994-11-29', 'Hayward', 54, 37);] (Background on this error at: http://sqlalche.me/e/gkpj)","title":"Populate a table with a row"},{"location":"_nb/%3DPy/02_SQL/04_ibis/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Initialisation \u00b6 import ibis uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com/postgres\" con = ibis . postgres . connect ( url = uri ) con . list_tables () ['country'] ibis . options {'bigquery': {'partition_col': 'PARTITIONTIME'}, 'clickhouse': {'temp_db': '__ibis_tmp'}, 'default_backend': None, 'graphviz_repr': True, 'impala': {'temp_db': '__ibis_tmp', 'temp_hdfs_path': '/tmp/ibis'}, 'interactive': False, 'sql': {'default_limit': 10000}, 'verbose': False, 'verbose_log': None} ibis . options . interactive = False sql = lambda proj : print ( ibis . postgres . compile ( proj )) Table operations \u00b6 t = con . table ( \"accounts\" ) sql ( t . head ( 10 )) SELECT t0.id, t0.names, t0.amount FROM accounts AS t0 LIMIT %(param_1)s t . head () . execute () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount 0 59 Tim -330 1 43 Yvonne 2731 2 58 Hannah 888 3 65 Wendy 1670 4 82 Zelda -1114 t . namesdistinct () ref_0 PostgreSQLTable[table] name: accounts schema: id : int32 names : string amount : int64 names = Column[string*] 'names' from table ref_0 t . mutate ( new = t . names ) . execute () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount new 0 59 Tim -330 Tim 1 43 Yvonne 2731 Yvonne 2 58 Hannah 888 Hannah 3 65 Wendy 1670 Wendy 4 82 Zelda -1114 Zelda 5 -108 Ray 2221 Ray 6 122 Victor 1068 Victor 7 96 Charlie 373 Charlie 8 2 Ray 45 Ray 9 -85 Ingrid 1684 Ingrid 10 104 Yvonne 454 Yvonne 11 28 Quinn 559 Quinn 12 -84 Hannah 583 Hannah 13 -104 Tim 0 Tim 14 -72 Ray 1836 Ray 15 87 Jerry -16 Jerry 16 71 George 50 George 17 -61 Patricia 675 Patricia 18 94 Yvonne 1581 Yvonne 19 94 Laura 669 Laura 20 -39 Quinn 1938 Quinn 21 -9 Frank 117 Frank 22 -24 Ursula 479 Ursula 23 110 Xavier 24 Xavier 24 72 Laura 3620 Laura 25 85 Kevin 274 Kevin 26 25 Edith 125 Edith 27 28 Quinn 606 Quinn 28 -56 Charlie 1565 Charlie 29 -120 Dan 1560 Dan ... ... ... ... ... 9970 -99 Sarah 988 Sarah 9971 -116 Jerry 734 Jerry 9972 50 Quinn 1824 Quinn 9973 25 Edith 126 Edith 9974 -56 Charlie 1754 Charlie 9975 -77 Patricia 73 Patricia 9976 -36 Ursula 43 Ursula 9977 -14 Sarah -1 Sarah 9978 14 Laura 4770 Laura 9979 -66 George 32 George 9980 60 Ursula 967 Ursula 9981 -66 George 38 George 9982 -91 Patricia 188 Patricia 9983 -112 Alice -333 Alice 9984 96 Charlie 823 Charlie 9985 17 Victor 269 Victor 9986 16 Victor 232 Victor 9987 83 Michael 3144 Michael 9988 82 Ursula 3251 Ursula 9989 54 Norbert 63 Norbert 9990 -55 Zelda 893 Zelda 9991 35 Patricia -23 Patricia 9992 66 Ray 3333 Ray 9993 42 George -481 George 9994 111 Xavier 3164 Xavier 9995 -41 Oliver 26082 Oliver 9996 96 Wendy -6534 Wendy 9997 96 Charlie 1014 Charlie 9998 22 George 2196 George 9999 -2 Xavier 112 Xavier 10000 rows \u00d7 4 columns t . head () . execute () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount 0 -57 Xavier 251 1 -113 Michael 1082 2 45 Michael 1642 3 -61 Patricia 583 4 -89 Frank 445 Type \u00b6 Ibis uses its own type aliases that map onto database types. See, for example, the correspondence between Ibis type names and Impala type names: Ibis type Impala Type ~~~~~~~~~ ~~~~~~~~~~~ int8 TINYINT int16 SMALLINT int32 INT int64 BIGINT float FLOAT double DOUBLE boolean BOOLEAN string STRING timestamp TIMESTAMP decimal(p, s) DECIMAL(p,s) interval(u) INTERVAL(u)","title":"04 ibis"},{"location":"_nb/%3DPy/02_SQL/04_ibis/#initialisation","text":"import ibis uri = \"postgresql+psycopg2://postgres:postgres@db.postgres.app.com/postgres\" con = ibis . postgres . connect ( url = uri ) con . list_tables () ['country'] ibis . options {'bigquery': {'partition_col': 'PARTITIONTIME'}, 'clickhouse': {'temp_db': '__ibis_tmp'}, 'default_backend': None, 'graphviz_repr': True, 'impala': {'temp_db': '__ibis_tmp', 'temp_hdfs_path': '/tmp/ibis'}, 'interactive': False, 'sql': {'default_limit': 10000}, 'verbose': False, 'verbose_log': None} ibis . options . interactive = False sql = lambda proj : print ( ibis . postgres . compile ( proj ))","title":"Initialisation"},{"location":"_nb/%3DPy/02_SQL/04_ibis/#table-operations","text":"t = con . table ( \"accounts\" ) sql ( t . head ( 10 )) SELECT t0.id, t0.names, t0.amount FROM accounts AS t0 LIMIT %(param_1)s t . head () . execute () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount 0 59 Tim -330 1 43 Yvonne 2731 2 58 Hannah 888 3 65 Wendy 1670 4 82 Zelda -1114 t . namesdistinct () ref_0 PostgreSQLTable[table] name: accounts schema: id : int32 names : string amount : int64 names = Column[string*] 'names' from table ref_0 t . mutate ( new = t . names ) . execute () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount new 0 59 Tim -330 Tim 1 43 Yvonne 2731 Yvonne 2 58 Hannah 888 Hannah 3 65 Wendy 1670 Wendy 4 82 Zelda -1114 Zelda 5 -108 Ray 2221 Ray 6 122 Victor 1068 Victor 7 96 Charlie 373 Charlie 8 2 Ray 45 Ray 9 -85 Ingrid 1684 Ingrid 10 104 Yvonne 454 Yvonne 11 28 Quinn 559 Quinn 12 -84 Hannah 583 Hannah 13 -104 Tim 0 Tim 14 -72 Ray 1836 Ray 15 87 Jerry -16 Jerry 16 71 George 50 George 17 -61 Patricia 675 Patricia 18 94 Yvonne 1581 Yvonne 19 94 Laura 669 Laura 20 -39 Quinn 1938 Quinn 21 -9 Frank 117 Frank 22 -24 Ursula 479 Ursula 23 110 Xavier 24 Xavier 24 72 Laura 3620 Laura 25 85 Kevin 274 Kevin 26 25 Edith 125 Edith 27 28 Quinn 606 Quinn 28 -56 Charlie 1565 Charlie 29 -120 Dan 1560 Dan ... ... ... ... ... 9970 -99 Sarah 988 Sarah 9971 -116 Jerry 734 Jerry 9972 50 Quinn 1824 Quinn 9973 25 Edith 126 Edith 9974 -56 Charlie 1754 Charlie 9975 -77 Patricia 73 Patricia 9976 -36 Ursula 43 Ursula 9977 -14 Sarah -1 Sarah 9978 14 Laura 4770 Laura 9979 -66 George 32 George 9980 60 Ursula 967 Ursula 9981 -66 George 38 George 9982 -91 Patricia 188 Patricia 9983 -112 Alice -333 Alice 9984 96 Charlie 823 Charlie 9985 17 Victor 269 Victor 9986 16 Victor 232 Victor 9987 83 Michael 3144 Michael 9988 82 Ursula 3251 Ursula 9989 54 Norbert 63 Norbert 9990 -55 Zelda 893 Zelda 9991 35 Patricia -23 Patricia 9992 66 Ray 3333 Ray 9993 42 George -481 George 9994 111 Xavier 3164 Xavier 9995 -41 Oliver 26082 Oliver 9996 96 Wendy -6534 Wendy 9997 96 Charlie 1014 Charlie 9998 22 George 2196 George 9999 -2 Xavier 112 Xavier 10000 rows \u00d7 4 columns t . head () . execute () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id names amount 0 -57 Xavier 251 1 -113 Michael 1082 2 45 Michael 1642 3 -61 Patricia 583 4 -89 Frank 445","title":"Table operations"},{"location":"_nb/%3DPy/02_SQL/04_ibis/#type","text":"Ibis uses its own type aliases that map onto database types. See, for example, the correspondence between Ibis type names and Impala type names: Ibis type Impala Type ~~~~~~~~~ ~~~~~~~~~~~ int8 TINYINT int16 SMALLINT int32 INT int64 BIGINT float FLOAT double DOUBLE boolean BOOLEAN string STRING timestamp TIMESTAMP decimal(p, s) DECIMAL(p,s) interval(u) INTERVAL(u)","title":"Type"},{"location":"_nb/%3DPy/02_SQL/05_postgreSQL%20kernel/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); -- connection: postgresql://postgres:postgres@db.postgres.app.com Failed to connect to a database at postgresql://postgres:postgres@db.postgres.app.com -- connection: postgresql://johnny:password@192.168.32.3:5432/grafana Create tables \u00b6 DROP TABLE IF EXISTS t_weather_observations , t_cities ; -- data from https://simplemaps.com/data/world-cities -- fields are limited in free version -- https://simplemaps.com/data/world-cities#fields CREATE TABLE t_cities ( id SERIAL PRIMARY KEY , name VARCHAR ( 120 ) NOT NULL , name_ascii VARCHAR ( 120 ), location POINT , country VARCHAR ( 120 ), iso2 VARCHAR ( 2 ), iso3 VARCHAR ( 3 ), admin_name VARCHAR ( 120 ), capital VARCHAR ( 7 ), population VARCHAR ( 120 ) ); CREATE TABLE t_weather_observations ( id SERIAL PRIMARY KEY , city VARCHAR ( 80 ), temp_lo INT , -- low temperature temp_hi INT , -- high temperature prcp REAL , -- precipitation date DATE -- FOREIGN KEY (city) REFERENCES t_cities(name) -- or city varchar(80) REFERENCES cities(name), ); DESCRIBE TABLE using information_schema SELECT COLUMN_NAME , DATA_TYPE FROM information_schema . COLUMNS WHERE TABLE_NAME = 't_cities' ; 10 row(s) returned. column_name data_type id integer name character varying name_ascii character varying location point country character varying iso2 character varying iso3 character varying admin_name character varying capital character varying population character varying Populate a table with a row \u00b6 Simple insertion \u00b6 INSERT INTO t_cities ( name , location , capital ) VALUES ( 'San Francisco' , '-194.2, 53.0' , NULL ); SELECT * FROM t_cities LIMIT 10 ; 2 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 2 San Francisco (-194.2,53) 3 San Francisco (-194.2,53) Delete all the entries in table with optionall RETURNING (returns deletions) DELETE FROM t_cities RETURNING * ; 2 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 2 San Francisco (-194.2,53) 3 San Francisco (-194.2,53) SELECT * FROM t_cities ; 0 row(s) returned. Populate a table using FROM \u00b6 Copy the csv data from simplemaps.com with the COPY ... FROM command http://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/ First, remove unused fields with cut in a terminal cut -d, -f11 --complement worldcities.csv > worldcities_modified.csv COPY t_cities ( name , name_ascii , location , country , iso2 , iso3 , admin_name , capital , population ) FROM '/tmp/worldcities_modified.csv' NULL 'NULL' CSV HEADER DELIMITER ';' ; SELECT count ( * ) FROM t_cities ; 1 row(s) returned. count 12958 SELECT * FROM t_cities LIMIT 10 ; 10 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 4 Prizren Prizren (42.2139,20.7397) Kosovo XK XKS Prizren admin 5 Zubin Potok Zubin Potok (42.9144,20.6897) Kosovo XK XKS Zubin Potok admin 6 Kamenic\u00eb Kamenice (42.5781,21.5803) Kosovo XK XKS Kamenic\u00eb admin 7 Viti Viti (42.3214,21.3583) Kosovo XK XKS Viti admin 8 Sht\u00ebrpc\u00eb Shterpce (42.2394,21.0272) Kosovo XK XKS Sht\u00ebrpc\u00eb admin 9 Shtime Shtime (42.4331,21.0397) Kosovo XK XKS Shtime admin 10 Vushtrri Vushtrri (42.8231,20.9675) Kosovo XK XKS Vushtrri admin 11 Dragash Dragash (42.0265,20.6533) Kosovo XK XKS Dragash admin 12 Podujev\u00eb Podujeve (42.9111,21.1899) Kosovo XK XKS Podujev\u00eb admin 13 Fush\u00eb Kosov\u00eb Fushe Kosove (42.6639,21.0961) Kosovo XK XKS Fush\u00eb Kosov\u00eb admin SELECT * FROM t_cities WHERE iso3 = 'USA' LIMIT 10 ; 10 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 8098 Renton Renton (47.4758,-122.1905) United States US USA Washington 101379 8099 Chehalis Chehalis (46.6637,-122.9647) United States US USA Washington 7533 8100 Mercer Island Mercer Island (47.5625,-122.2265) United States US USA Washington 25261 8101 Lynnwood Lynnwood (47.8285,-122.3034) United States US USA Washington 38273 8102 Centralia Centralia (46.7226,-122.9695) United States US USA Washington 41643 8103 Mountlake Terrace Mountlake Terrace (47.792,-122.3076) United States US USA Washington 21337 8104 Seattle Seattle (47.6211,-122.3244) United States US USA Washington 3.64376e+06 8105 Liberty Lake Liberty Lake (47.6687,-117.1032) United States US USA Washington 9893 8106 Airway Heights Airway Heights (47.6459,-117.5792) United States US USA Washington 8166 8107 Brier Brier (47.7922,-122.2734) United States US USA Washington 6884 SELECT DISTINCT capital FROM t_cities LIMIT 10 ; 4 row(s) returned. capital primary minor admin SELECT DISTINCT name , admin_name , capital FROM t_cities WHERE iso3 = 'USA' AND capital <> NULL ORDER BY capital DESC ; 0 row(s) returned. DO $$ DECLARE counter INTEGER := 1 ; first_name VARCHAR ( 50 ) := 'John' ; last_name VARCHAR ( 50 ) := 'Doe' ; payment NUMERIC ( 11 , 2 ) := 20.5 ; BEGIN RAISE NOTICE '% % % has been paid % USD' , counter , first_name , last_name , payment ; END $$ ; NOTICE: 1 John Doe has been paid 20.50 USD INSERT INTO t_weather_observations ( city , temp_lo , temp_hi , prcp , date ) VALUES ( 'San Francisco' , 43 , 57 , 0.0 , '1994-11-29' ); INSERT INTO t_weather_observations ( date , city , temp_hi , temp_lo ) VALUES ( '1994-11-29' , 'Hayward' , 54 , 37 ); insert or update on table \"t_weather_observations\" violates foreign key constraint \"t_weather_observations_city_fkey\" DETAIL: Key (city)=(Hayward) is not present in table \"t_cities\".","title":"05 postgreSQL kernel"},{"location":"_nb/%3DPy/02_SQL/05_postgreSQL%20kernel/#create-tables","text":"DROP TABLE IF EXISTS t_weather_observations , t_cities ; -- data from https://simplemaps.com/data/world-cities -- fields are limited in free version -- https://simplemaps.com/data/world-cities#fields CREATE TABLE t_cities ( id SERIAL PRIMARY KEY , name VARCHAR ( 120 ) NOT NULL , name_ascii VARCHAR ( 120 ), location POINT , country VARCHAR ( 120 ), iso2 VARCHAR ( 2 ), iso3 VARCHAR ( 3 ), admin_name VARCHAR ( 120 ), capital VARCHAR ( 7 ), population VARCHAR ( 120 ) ); CREATE TABLE t_weather_observations ( id SERIAL PRIMARY KEY , city VARCHAR ( 80 ), temp_lo INT , -- low temperature temp_hi INT , -- high temperature prcp REAL , -- precipitation date DATE -- FOREIGN KEY (city) REFERENCES t_cities(name) -- or city varchar(80) REFERENCES cities(name), ); DESCRIBE TABLE using information_schema SELECT COLUMN_NAME , DATA_TYPE FROM information_schema . COLUMNS WHERE TABLE_NAME = 't_cities' ; 10 row(s) returned. column_name data_type id integer name character varying name_ascii character varying location point country character varying iso2 character varying iso3 character varying admin_name character varying capital character varying population character varying","title":"Create tables"},{"location":"_nb/%3DPy/02_SQL/05_postgreSQL%20kernel/#populate-a-table-with-a-row","text":"","title":"Populate a table with a row"},{"location":"_nb/%3DPy/02_SQL/05_postgreSQL%20kernel/#simple-insertion","text":"INSERT INTO t_cities ( name , location , capital ) VALUES ( 'San Francisco' , '-194.2, 53.0' , NULL ); SELECT * FROM t_cities LIMIT 10 ; 2 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 2 San Francisco (-194.2,53) 3 San Francisco (-194.2,53) Delete all the entries in table with optionall RETURNING (returns deletions) DELETE FROM t_cities RETURNING * ; 2 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 2 San Francisco (-194.2,53) 3 San Francisco (-194.2,53) SELECT * FROM t_cities ; 0 row(s) returned.","title":"Simple insertion"},{"location":"_nb/%3DPy/02_SQL/05_postgreSQL%20kernel/#populate-a-table-using-from","text":"Copy the csv data from simplemaps.com with the COPY ... FROM command http://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/ First, remove unused fields with cut in a terminal cut -d, -f11 --complement worldcities.csv > worldcities_modified.csv COPY t_cities ( name , name_ascii , location , country , iso2 , iso3 , admin_name , capital , population ) FROM '/tmp/worldcities_modified.csv' NULL 'NULL' CSV HEADER DELIMITER ';' ; SELECT count ( * ) FROM t_cities ; 1 row(s) returned. count 12958 SELECT * FROM t_cities LIMIT 10 ; 10 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 4 Prizren Prizren (42.2139,20.7397) Kosovo XK XKS Prizren admin 5 Zubin Potok Zubin Potok (42.9144,20.6897) Kosovo XK XKS Zubin Potok admin 6 Kamenic\u00eb Kamenice (42.5781,21.5803) Kosovo XK XKS Kamenic\u00eb admin 7 Viti Viti (42.3214,21.3583) Kosovo XK XKS Viti admin 8 Sht\u00ebrpc\u00eb Shterpce (42.2394,21.0272) Kosovo XK XKS Sht\u00ebrpc\u00eb admin 9 Shtime Shtime (42.4331,21.0397) Kosovo XK XKS Shtime admin 10 Vushtrri Vushtrri (42.8231,20.9675) Kosovo XK XKS Vushtrri admin 11 Dragash Dragash (42.0265,20.6533) Kosovo XK XKS Dragash admin 12 Podujev\u00eb Podujeve (42.9111,21.1899) Kosovo XK XKS Podujev\u00eb admin 13 Fush\u00eb Kosov\u00eb Fushe Kosove (42.6639,21.0961) Kosovo XK XKS Fush\u00eb Kosov\u00eb admin SELECT * FROM t_cities WHERE iso3 = 'USA' LIMIT 10 ; 10 row(s) returned. id name name_ascii location country iso2 iso3 admin_name capital population 8098 Renton Renton (47.4758,-122.1905) United States US USA Washington 101379 8099 Chehalis Chehalis (46.6637,-122.9647) United States US USA Washington 7533 8100 Mercer Island Mercer Island (47.5625,-122.2265) United States US USA Washington 25261 8101 Lynnwood Lynnwood (47.8285,-122.3034) United States US USA Washington 38273 8102 Centralia Centralia (46.7226,-122.9695) United States US USA Washington 41643 8103 Mountlake Terrace Mountlake Terrace (47.792,-122.3076) United States US USA Washington 21337 8104 Seattle Seattle (47.6211,-122.3244) United States US USA Washington 3.64376e+06 8105 Liberty Lake Liberty Lake (47.6687,-117.1032) United States US USA Washington 9893 8106 Airway Heights Airway Heights (47.6459,-117.5792) United States US USA Washington 8166 8107 Brier Brier (47.7922,-122.2734) United States US USA Washington 6884 SELECT DISTINCT capital FROM t_cities LIMIT 10 ; 4 row(s) returned. capital primary minor admin SELECT DISTINCT name , admin_name , capital FROM t_cities WHERE iso3 = 'USA' AND capital <> NULL ORDER BY capital DESC ; 0 row(s) returned. DO $$ DECLARE counter INTEGER := 1 ; first_name VARCHAR ( 50 ) := 'John' ; last_name VARCHAR ( 50 ) := 'Doe' ; payment NUMERIC ( 11 , 2 ) := 20.5 ; BEGIN RAISE NOTICE '% % % has been paid % USD' , counter , first_name , last_name , payment ; END $$ ; NOTICE: 1 John Doe has been paid 20.50 USD INSERT INTO t_weather_observations ( city , temp_lo , temp_hi , prcp , date ) VALUES ( 'San Francisco' , 43 , 57 , 0.0 , '1994-11-29' ); INSERT INTO t_weather_observations ( date , city , temp_hi , temp_lo ) VALUES ( '1994-11-29' , 'Hayward' , 54 , 37 ); insert or update on table \"t_weather_observations\" violates foreign key constraint \"t_weather_observations_city_fkey\" DETAIL: Key (city)=(Hayward) is not present in table \"t_cities\".","title":"Populate a table using FROM"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); OLTP - Online transaction processing OLEP - OLAP - Online analytical processing OLAP cube Cube multidimensionnel OLAP vs OLTP OLAP operations Apache Kylin OLAP \u00b6 Star/snowflake schemas \u00b6 The star schema separates business process data into facts, which hold the measurable, quantitative data about a business, and dimensions which are descriptive attributes related to fact data: - Fact tables record measurements or metrics for a specific event, generally consist of numeric values, and foreign keys to dimensional data where descriptive information is kept - Dimension tables usually have a relatively small number of records compared to fact tables, but each record may have a very large number of attributes to describe the fact data. \"Snowflaking\" is a method of normalizing the dimension tables in a star schema. Operations \u00b6 slice \u00b6 Dice \u00b6 Drill Down/Up \u00b6 Roll-up \u00b6 Pivot \u00b6","title":"OLEP   OLAP"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#olap","text":"","title":"OLAP"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#starsnowflake-schemas","text":"The star schema separates business process data into facts, which hold the measurable, quantitative data about a business, and dimensions which are descriptive attributes related to fact data: - Fact tables record measurements or metrics for a specific event, generally consist of numeric values, and foreign keys to dimensional data where descriptive information is kept - Dimension tables usually have a relatively small number of records compared to fact tables, but each record may have a very large number of attributes to describe the fact data. \"Snowflaking\" is a method of normalizing the dimension tables in a star schema.","title":"Star/snowflake schemas"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#operations","text":"","title":"Operations"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#slice","text":"","title":"slice"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#dice","text":"","title":"Dice"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#drill-downup","text":"","title":"Drill Down/Up"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#roll-up","text":"","title":"Roll-up"},{"location":"_nb/%3DPy/02_SQL/OLEP%20-%20OLAP/#pivot","text":"","title":"Pivot"},{"location":"_nb/%3DPy/02_SQL/Untitled/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); -- connection: postgresql://johnny:password@192.168.32.3:5432/grafana DROP TABLE IF EXISTS g_3p ; CREATE TABLE g_3p ( id SERIAL PRIMARY KEY , name VARCHAR ( 120 ) NOT NULL , ts TIMESTAMP , capital INTEGER , population INTEGER ); INSERT INTO g_3p ( name , ts , capital , population ) VALUES ( 'johnny' , '2019-11-08 11:10:25-07' , 2000 , 3000 ), ( 'thunder' , '2019-11-08 10:10:25-07' , 2500 , 3900 ) ; SELECT * from g_3p ; 2 row(s) returned. id name ts capital population 1 johnny 2019-11-08 11:10:25 2000 3000 2 thunder 2019-11-08 10:10:25 2500 3900 SELECT ts AS \"time\" , population , capital FROM g_3p ORDER BY ts 4 row(s) returned. time population capital 2019-11-08 10:10:25 3900 2500 2019-11-08 11:10:25 3000 2000 2019-11-08 14:10:25 390 2570 2019-11-08 15:10:25 300 2400 INSERT INTO g_3p ( name , ts , capital , population ) VALUES ( 'johnny' , '2019-11-08 15:10:25-07' , 2400 , 300 ), ( 'thunder' , '2019-11-08 14:10:25-07' , 2570 , 390 ) ;","title":"Untitled"},{"location":"_nb/%3DPy/03_MongoDB/MongoDB/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); % load_ext watermark % watermark - dvmp pymongo , pyarrow 2019-11-02 CPython 3.7.3 IPython 7.8.0 pymongo 3.8.0 pyarrow not installed compiler : GCC 7.3.0 system : Linux release : 5.0.0-31-generic machine : x86_64 processor : x86_64 CPU cores : 8 interpreter: 64bit from pymongo import MongoClient mongo_local = dict ( user = 'root' , password = 'secret' , port = 27017 , host = '172.22.0.3' , database = \"starwars\" , collection = \"people\" ) mongo_atlas = dict ( user = 'm220student' , password = 'm220password' , port = 27017 , host = 'baobab-crx55.mongodb.net' ) import datetime post = { \"author\" : \"Mike\" , \"text\" : \"My first blog post!\" , \"tags\" : [ \"mongodb\" , \"python\" , \"pymongo\" ], \"date\" : datetime . datetime . utcnow ()} uri = f\"mongodb://{user}:{password}@{host}\" conn = mongo_local uri = f \"mongodb:// { conn [ 'user' ] } : { conn [ 'password' ] } @ { conn [ 'host' ] } : { conn . get ( 'port' , 27017 ) } \" print ( uri ) database = \"starwars\" collection = \"people\" client = MongoClient ( uri ) mongodb://root:secret@172.22.0.3:27017 \"mongodb://root:secret@172.22.0.3:27017/starwars\" . rsplit ( \"/\" , maxsplit = 1 )[ 0 ] 'mongodb://root:secret@172.22.0.3:27017' m = MongoClient ( \"mongodb://mongo:password@mongo\" ) . list_database_names () m . list_database_names () --------------------------------------------------------------------------- OperationFailure Traceback (most recent call last) <ipython-input-71-a100b7e4b26f> in <module> ----> 1 m . list_database_names ( ) /opt/conda/lib/python3.7/site-packages/pymongo/mongo_client.py in list_database_names (self, session) 1697 \"\"\" 1698 return [doc[\"name\"] -> 1699 for doc in self.list_databases(session, nameOnly=True)] 1700 1701 def database_names ( self , session = None ) : /opt/conda/lib/python3.7/site-packages/pymongo/mongo_client.py in list_databases (self, session, **kwargs) 1678 cmd . update ( kwargs ) 1679 admin = self . _database_default_options ( \"admin\" ) -> 1680 res = admin . command ( cmd , session = session ) 1681 # listDatabases doesn't return a cursor (yet). Fake one. 1682 cursor = { /opt/conda/lib/python3.7/site-packages/pymongo/database.py in command (self, command, value, check, allowable_errors, read_preference, codec_options, session, **kwargs) 653 or ReadPreference.PRIMARY) 654 with self.__client._socket_for_reads( --> 655 read_preference) as (sock_info, slave_ok): 656 return self._command(sock_info, command, slave_ok, value, 657 check , allowable_errors , read_preference , /opt/conda/lib/python3.7/contextlib.py in __enter__ (self) 110 del self . args , self . kwds , self . func 111 try : --> 112 return next ( self . gen ) 113 except StopIteration : 114 raise RuntimeError ( \"generator didn't yield\" ) from None /opt/conda/lib/python3.7/site-packages/pymongo/mongo_client.py in _socket_for_reads (self, read_preference) 1135 server = topology . select_server ( read_preference ) 1136 -> 1137 with self . _get_socket ( server ) as sock_info : 1138 slave_ok = (single and not sock_info.is_mongos) or ( 1139 read_preference != ReadPreference.PRIMARY) /opt/conda/lib/python3.7/contextlib.py in __enter__ (self) 110 del self . args , self . kwds , self . func 111 try : --> 112 return next ( self . gen ) 113 except StopIteration : 114 raise RuntimeError ( \"generator didn't yield\" ) from None /opt/conda/lib/python3.7/site-packages/pymongo/mongo_client.py in _get_socket (self, server) 1092 def _get_socket ( self , server ) : 1093 try : -> 1094 with server . get_socket ( self . __all_credentials ) as sock_info : 1095 yield sock_info 1096 except NetworkTimeout : /opt/conda/lib/python3.7/contextlib.py in __enter__ (self) 110 del self . args , self . kwds , self . func 111 try : --> 112 return next ( self . gen ) 113 except StopIteration : 114 raise RuntimeError ( \"generator didn't yield\" ) from None /opt/conda/lib/python3.7/site-packages/pymongo/pool.py in get_socket (self, all_credentials, checkout) 1009 sock_info = self . _get_socket_no_auth ( ) 1010 try : -> 1011 sock_info . check_auth ( all_credentials ) 1012 yield sock_info 1013 except : /opt/conda/lib/python3.7/site-packages/pymongo/pool.py in check_auth (self, all_credentials) 680 681 for credentials in cached - authset : --> 682 auth . authenticate ( credentials , self ) 683 self . authset . add ( credentials ) 684 /opt/conda/lib/python3.7/site-packages/pymongo/auth.py in authenticate (credentials, sock_info) 563 mechanism = credentials . mechanism 564 auth_func = _AUTH_MAP . get ( mechanism ) --> 565 auth_func ( credentials , sock_info ) 566 567 /opt/conda/lib/python3.7/site-packages/pymongo/auth.py in _authenticate_default (credentials, sock_info) 538 return _authenticate_scram ( credentials , sock_info , 'SCRAM-SHA-256' ) 539 else : --> 540 return _authenticate_scram ( credentials , sock_info , 'SCRAM-SHA-1' ) 541 elif sock_info . max_wire_version >= 3 : 542 return _authenticate_scram ( credentials , sock_info , 'SCRAM-SHA-1' ) /opt/conda/lib/python3.7/site-packages/pymongo/auth.py in _authenticate_scram (credentials, sock_info, mechanism) 262 ( 'payload' , Binary ( b\"n,,\" + first_bare ) ) , 263 ('autoAuthorize', 1)]) --> 264 res = sock_info . command ( source , cmd ) 265 266 server_first = res [ 'payload' ] /opt/conda/lib/python3.7/site-packages/pymongo/pool.py in command (self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields) 582 use_op_msg = self . op_msg_enabled , 583 unacknowledged = unacknowledged , --> 584 user_fields=user_fields) 585 except OperationFailure : 586 raise /opt/conda/lib/python3.7/site-packages/pymongo/network.py in command (sock, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields) 156 helpers._check_command_response( 157 response_doc , None , allowable_errors , --> 158 parse_write_concern_error=parse_write_concern_error) 159 except Exception as exc : 160 if publish : /opt/conda/lib/python3.7/site-packages/pymongo/helpers.py in _check_command_response (response, msg, allowable_errors, parse_write_concern_error) 153 154 msg = msg or \"%s\" --> 155 raise OperationFailure ( msg % errmsg , code , response ) 156 157 OperationFailure : Authentication failed. \"mongodb://root:secret@172.22.0.3:27017/starwars\" . split <function str.split(sep=None, maxsplit=-1)> aze = MongoClient ( \"mongodb://root:secret@172.22.0.3:27017\" ) aze . list_database_names () ['admin', 'config', 'local', 'people-bson', 'saildrone', 'sc', 'starwars', 'test'] aze.get_database('starwars').get_collection('people').find_one() % store uri Stored 'uri' (str) client . list_database_names () ['admin', 'config', 'local', 'people-bson', 'saildrone', 'sc', 'starwars', 'test'] res = client . get_database ( 'starwars' ) . get_collection ( 'people' ) res . find_one () {'_id': ObjectId('5d31e79f5decab6c5ac11358'), 'name': 'Luke Skywalker', 'height': 172, 'mass': 77, 'hair_color': 'blond', 'skin_color': 'fair', 'eye_color': 'blue', 'birth_year': '19BBY', 'gender': 'male', 'homeworld': {'name': 'Tatooine', 'rotation_period': 23, 'orbital_period': 304, 'diameter': 10465, 'climate': 'arid', 'gravity': '1 standard', 'terrain': 'desert', 'surface_water': 1, 'population': 200000, 'residents': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/2/', 'https://swapi.co/api/people/4/', 'https://swapi.co/api/people/6/', 'https://swapi.co/api/people/7/', 'https://swapi.co/api/people/8/', 'https://swapi.co/api/people/9/', 'https://swapi.co/api/people/11/', 'https://swapi.co/api/people/43/', 'https://swapi.co/api/people/62/'], 'films': ['https://swapi.co/api/films/5/', 'https://swapi.co/api/films/4/', 'https://swapi.co/api/films/6/', 'https://swapi.co/api/films/3/', 'https://swapi.co/api/films/1/'], 'created': '2014-12-09T13:50:49.641000Z', 'edited': '2014-12-21T20:48:04.175778Z', 'url': 'https://swapi.co/api/planets/1/'}, 'films': [{'title': 'The Empire Strikes Back', 'episode_id': 5, 'opening_crawl': 'It is a dark time for the\\r\\nRebellion. Although the Death\\r\\nStar has been destroyed,\\r\\nImperial troops have driven the\\r\\nRebel forces from their hidden\\r\\nbase and pursued them across\\r\\nthe galaxy.\\r\\n\\r\\nEvading the dreaded Imperial\\r\\nStarfleet, a group of freedom\\r\\nfighters led by Luke Skywalker\\r\\nhas established a new secret\\r\\nbase on the remote ice world\\r\\nof Hoth.\\r\\n\\r\\nThe evil lord Darth Vader,\\r\\nobsessed with finding young\\r\\nSkywalker, has dispatched\\r\\nthousands of remote probes into\\r\\nthe far reaches of space....', 'director': 'Irvin Kershner', 'producer': 'Gary Kurtz, Rick McCallum', 'release_date': '1980-05-17', 'characters': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/2/', 'https://swapi.co/api/people/3/', 'https://swapi.co/api/people/4/', 'https://swapi.co/api/people/5/', 'https://swapi.co/api/people/10/', 'https://swapi.co/api/people/13/', 'https://swapi.co/api/people/14/', 'https://swapi.co/api/people/18/', 'https://swapi.co/api/people/20/', 'https://swapi.co/api/people/21/', 'https://swapi.co/api/people/22/', 'https://swapi.co/api/people/23/', 'https://swapi.co/api/people/24/', 'https://swapi.co/api/people/25/', 'https://swapi.co/api/people/26/'], 'planets': ['https://swapi.co/api/planets/4/', 'https://swapi.co/api/planets/5/', 'https://swapi.co/api/planets/6/', 'https://swapi.co/api/planets/27/'], 'starships': ['https://swapi.co/api/starships/15/', 'https://swapi.co/api/starships/10/', 'https://swapi.co/api/starships/11/', 'https://swapi.co/api/starships/12/', 'https://swapi.co/api/starships/21/', 'https://swapi.co/api/starships/22/', 'https://swapi.co/api/starships/23/', 'https://swapi.co/api/starships/3/', 'https://swapi.co/api/starships/17/'], 'vehicles': ['https://swapi.co/api/vehicles/8/', 'https://swapi.co/api/vehicles/14/', 'https://swapi.co/api/vehicles/16/', 'https://swapi.co/api/vehicles/18/', 'https://swapi.co/api/vehicles/19/', 'https://swapi.co/api/vehicles/20/'], 'species': ['https://swapi.co/api/species/6/', 'https://swapi.co/api/species/7/', 'https://swapi.co/api/species/3/', 'https://swapi.co/api/species/2/', 'https://swapi.co/api/species/1/'], 'created': '2014-12-12T11:26:24.656000Z', 'edited': '2017-04-19T10:57:29.544256Z', 'url': 'https://swapi.co/api/films/2/'}, {'title': 'Revenge of the Sith', 'episode_id': 3, 'opening_crawl': 'War! The Republic is crumbling\\r\\nunder attacks by the ruthless\\r\\nSith Lord, Count Dooku.\\r\\nThere are heroes on both sides.\\r\\nEvil is everywhere.\\r\\n\\r\\nIn a stunning move, the\\r\\nfiendish droid leader, General\\r\\nGrievous, has swept into the\\r\\nRepublic capital and kidnapped\\r\\nChancellor Palpatine, leader of\\r\\nthe Galactic Senate.\\r\\n\\r\\nAs the Separatist Droid Army\\r\\nattempts to flee the besieged\\r\\ncapital with their valuable\\r\\nhostage, two Jedi Knights lead a\\r\\ndesperate mission to rescue the\\r\\ncaptive Chancellor....', 'director': 'George Lucas', 'producer': 'Rick McCallum', 'release_date': '2005-05-19', 'characters': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/2/', 'https://swapi.co/api/people/3/', 'https://swapi.co/api/people/4/', 'https://swapi.co/api/people/5/', 'https://swapi.co/api/people/6/', 'https://swapi.co/api/people/7/', 'https://swapi.co/api/people/10/', 'https://swapi.co/api/people/11/', 'https://swapi.co/api/people/12/', 'https://swapi.co/api/people/13/', 'https://swapi.co/api/people/20/', 'https://swapi.co/api/people/21/', 'https://swapi.co/api/people/33/', 'https://swapi.co/api/people/46/', 'https://swapi.co/api/people/51/', 'https://swapi.co/api/people/52/', 'https://swapi.co/api/people/53/', 'https://swapi.co/api/people/54/', 'https://swapi.co/api/people/55/', 'https://swapi.co/api/people/56/', 'https://swapi.co/api/people/58/', 'https://swapi.co/api/people/63/', 'https://swapi.co/api/people/64/', 'https://swapi.co/api/people/67/', 'https://swapi.co/api/people/68/', 'https://swapi.co/api/people/75/', 'https://swapi.co/api/people/78/', 'https://swapi.co/api/people/79/', 'https://swapi.co/api/people/80/', 'https://swapi.co/api/people/81/', 'https://swapi.co/api/people/82/', 'https://swapi.co/api/people/83/', 'https://swapi.co/api/people/35/'], 'planets': ['https://swapi.co/api/planets/2/', 'https://swapi.co/api/planets/5/', 'https://swapi.co/api/planets/8/', 'https://swapi.co/api/planets/9/', 'https://swapi.co/api/planets/12/', 'https://swapi.co/api/planets/13/', 'https://swapi.co/api/planets/14/', 'https://swapi.co/api/planets/15/', 'https://swapi.co/api/planets/16/', 'https://swapi.co/api/planets/17/', 'https://swapi.co/api/planets/18/', 'https://swapi.co/api/planets/19/', 'https://swapi.co/api/planets/1/'], 'starships': ['https://swapi.co/api/starships/48/', 'https://swapi.co/api/starships/59/', 'https://swapi.co/api/starships/61/', 'https://swapi.co/api/starships/32/', 'https://swapi.co/api/starships/63/', 'https://swapi.co/api/starships/64/', 'https://swapi.co/api/starships/65/', 'https://swapi.co/api/starships/66/', 'https://swapi.co/api/starships/74/', 'https://swapi.co/api/starships/75/', 'https://swapi.co/api/starships/2/', 'https://swapi.co/api/starships/68/'], 'vehicles': ['https://swapi.co/api/vehicles/33/', 'https://swapi.co/api/vehicles/50/', 'https://swapi.co/api/vehicles/53/', 'https://swapi.co/api/vehicles/56/', 'https://swapi.co/api/vehicles/60/', 'https://swapi.co/api/vehicles/62/', 'https://swapi.co/api/vehicles/67/', 'https://swapi.co/api/vehicles/69/', 'https://swapi.co/api/vehicles/70/', 'https://swapi.co/api/vehicles/71/', 'https://swapi.co/api/vehicles/72/', 'https://swapi.co/api/vehicles/73/', 'https://swapi.co/api/vehicles/76/'], 'species': ['https://swapi.co/api/species/19/', 'https://swapi.co/api/species/33/', 'https://swapi.co/api/species/2/', 'https://swapi.co/api/species/3/', 'https://swapi.co/api/species/36/', 'https://swapi.co/api/species/37/', 'https://swapi.co/api/species/6/', 'https://swapi.co/api/species/1/', 'https://swapi.co/api/species/34/', 'https://swapi.co/api/species/15/', 'https://swapi.co/api/species/35/', 'https://swapi.co/api/species/20/', 'https://swapi.co/api/species/23/', 'https://swapi.co/api/species/24/', 'https://swapi.co/api/species/25/', 'https://swapi.co/api/species/26/', 'https://swapi.co/api/species/27/', 'https://swapi.co/api/species/28/', 'https://swapi.co/api/species/29/', 'https://swapi.co/api/species/30/'], 'created': '2014-12-20T18:49:38.403000Z', 'edited': '2015-04-11T09:45:44.862122Z', 'url': 'https://swapi.co/api/films/6/'}, {'title': 'Return of the Jedi', 'episode_id': 6, 'opening_crawl': 'Luke Skywalker has returned to\\r\\nhis home planet of Tatooine in\\r\\nan attempt to rescue his\\r\\nfriend Han Solo from the\\r\\nclutches of the vile gangster\\r\\nJabba the Hutt.\\r\\n\\r\\nLittle does Luke know that the\\r\\nGALACTIC EMPIRE has secretly\\r\\nbegun construction on a new\\r\\narmored space station even\\r\\nmore powerful than the first\\r\\ndreaded Death Star.\\r\\n\\r\\nWhen completed, this ultimate\\r\\nweapon will spell certain doom\\r\\nfor the small band of rebels\\r\\nstruggling to restore freedom\\r\\nto the galaxy...', 'director': 'Richard Marquand', 'producer': 'Howard G. Kazanjian, George Lucas, Rick McCallum', 'release_date': '1983-05-25', 'characters': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/2/', 'https://swapi.co/api/people/3/', 'https://swapi.co/api/people/4/', 'https://swapi.co/api/people/5/', 'https://swapi.co/api/people/10/', 'https://swapi.co/api/people/13/', 'https://swapi.co/api/people/14/', 'https://swapi.co/api/people/16/', 'https://swapi.co/api/people/18/', 'https://swapi.co/api/people/20/', 'https://swapi.co/api/people/21/', 'https://swapi.co/api/people/22/', 'https://swapi.co/api/people/25/', 'https://swapi.co/api/people/27/', 'https://swapi.co/api/people/28/', 'https://swapi.co/api/people/29/', 'https://swapi.co/api/people/30/', 'https://swapi.co/api/people/31/', 'https://swapi.co/api/people/45/'], 'planets': ['https://swapi.co/api/planets/5/', 'https://swapi.co/api/planets/7/', 'https://swapi.co/api/planets/8/', 'https://swapi.co/api/planets/9/', 'https://swapi.co/api/planets/1/'], 'starships': ['https://swapi.co/api/starships/15/', 'https://swapi.co/api/starships/10/', 'https://swapi.co/api/starships/11/', 'https://swapi.co/api/starships/12/', 'https://swapi.co/api/starships/22/', 'https://swapi.co/api/starships/23/', 'https://swapi.co/api/starships/27/', 'https://swapi.co/api/starships/28/', 'https://swapi.co/api/starships/29/', 'https://swapi.co/api/starships/3/', 'https://swapi.co/api/starships/17/', 'https://swapi.co/api/starships/2/'], 'vehicles': ['https://swapi.co/api/vehicles/8/', 'https://swapi.co/api/vehicles/16/', 'https://swapi.co/api/vehicles/18/', 'https://swapi.co/api/vehicles/19/', 'https://swapi.co/api/vehicles/24/', 'https://swapi.co/api/vehicles/25/', 'https://swapi.co/api/vehicles/26/', 'https://swapi.co/api/vehicles/30/'], 'species': ['https://swapi.co/api/species/1/', 'https://swapi.co/api/species/2/', 'https://swapi.co/api/species/3/', 'https://swapi.co/api/species/5/', 'https://swapi.co/api/species/6/', 'https://swapi.co/api/species/8/', 'https://swapi.co/api/species/9/', 'https://swapi.co/api/species/10/', 'https://swapi.co/api/species/15/'], 'created': '2014-12-18T10:39:33.255000Z', 'edited': '2015-04-11T09:46:05.220365Z', 'url': 'https://swapi.co/api/films/3/'}, {'title': 'A New Hope', 'episode_id': 4, 'opening_crawl': \"It is a period of civil war.\\r\\nRebel spaceships, striking\\r\\nfrom a hidden base, have won\\r\\ntheir first victory against\\r\\nthe evil Galactic Empire.\\r\\n\\r\\nDuring the battle, Rebel\\r\\nspies managed to steal secret\\r\\nplans to the Empire's\\r\\nultimate weapon, the DEATH\\r\\nSTAR, an armored space\\r\\nstation with enough power\\r\\nto destroy an entire planet.\\r\\n\\r\\nPursued by the Empire's\\r\\nsinister agents, Princess\\r\\nLeia races home aboard her\\r\\nstarship, custodian of the\\r\\nstolen plans that can save her\\r\\npeople and restore\\r\\nfreedom to the galaxy....\", 'director': 'George Lucas', 'producer': 'Gary Kurtz, Rick McCallum', 'release_date': '1977-05-25', 'characters': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/2/', 'https://swapi.co/api/people/3/', 'https://swapi.co/api/people/4/', 'https://swapi.co/api/people/5/', 'https://swapi.co/api/people/6/', 'https://swapi.co/api/people/7/', 'https://swapi.co/api/people/8/', 'https://swapi.co/api/people/9/', 'https://swapi.co/api/people/10/', 'https://swapi.co/api/people/12/', 'https://swapi.co/api/people/13/', 'https://swapi.co/api/people/14/', 'https://swapi.co/api/people/15/', 'https://swapi.co/api/people/16/', 'https://swapi.co/api/people/18/', 'https://swapi.co/api/people/19/', 'https://swapi.co/api/people/81/'], 'planets': ['https://swapi.co/api/planets/2/', 'https://swapi.co/api/planets/3/', 'https://swapi.co/api/planets/1/'], 'starships': ['https://swapi.co/api/starships/2/', 'https://swapi.co/api/starships/3/', 'https://swapi.co/api/starships/5/', 'https://swapi.co/api/starships/9/', 'https://swapi.co/api/starships/10/', 'https://swapi.co/api/starships/11/', 'https://swapi.co/api/starships/12/', 'https://swapi.co/api/starships/13/'], 'vehicles': ['https://swapi.co/api/vehicles/4/', 'https://swapi.co/api/vehicles/6/', 'https://swapi.co/api/vehicles/7/', 'https://swapi.co/api/vehicles/8/'], 'species': ['https://swapi.co/api/species/5/', 'https://swapi.co/api/species/3/', 'https://swapi.co/api/species/2/', 'https://swapi.co/api/species/1/', 'https://swapi.co/api/species/4/'], 'created': '2014-12-10T14:23:31.880000Z', 'edited': '2015-04-11T09:46:52.774897Z', 'url': 'https://swapi.co/api/films/1/'}, {'title': 'The Force Awakens', 'episode_id': 7, 'opening_crawl': \"Luke Skywalker has vanished.\\r\\nIn his absence, the sinister\\r\\nFIRST ORDER has risen from\\r\\nthe ashes of the Empire\\r\\nand will not rest until\\r\\nSkywalker, the last Jedi,\\r\\nhas been destroyed.\\r\\n \\r\\nWith the support of the\\r\\nREPUBLIC, General Leia Organa\\r\\nleads a brave RESISTANCE.\\r\\nShe is desperate to find her\\r\\nbrother Luke and gain his\\r\\nhelp in restoring peace and\\r\\njustice to the galaxy.\\r\\n \\r\\nLeia has sent her most daring\\r\\npilot on a secret mission\\r\\nto Jakku, where an old ally\\r\\nhas discovered a clue to\\r\\nLuke's whereabouts....\", 'director': 'J. J. Abrams', 'producer': 'Kathleen Kennedy, J. J. Abrams, Bryan Burk', 'release_date': '2015-12-11', 'characters': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/3/', 'https://swapi.co/api/people/5/', 'https://swapi.co/api/people/13/', 'https://swapi.co/api/people/14/', 'https://swapi.co/api/people/27/', 'https://swapi.co/api/people/84/', 'https://swapi.co/api/people/85/', 'https://swapi.co/api/people/86/', 'https://swapi.co/api/people/87/', 'https://swapi.co/api/people/88/'], 'planets': ['https://swapi.co/api/planets/61/'], 'starships': ['https://swapi.co/api/starships/77/', 'https://swapi.co/api/starships/10/'], 'vehicles': [], 'species': ['https://swapi.co/api/species/3/', 'https://swapi.co/api/species/2/', 'https://swapi.co/api/species/1/'], 'created': '2015-04-17T06:51:30.504780Z', 'edited': '2015-12-17T14:31:47.617768Z', 'url': 'https://swapi.co/api/films/7/'}], 'species': [{'name': 'Human', 'classification': 'mammal', 'designation': 'sentient', 'average_height': 180, 'skin_colors': 'caucasian, black, asian, hispanic', 'hair_colors': 'blonde, brown, black, red', 'eye_colors': 'brown, blue, green, hazel, grey, amber', 'average_lifespan': 120, 'homeworld': 'https://swapi.co/api/planets/9/', 'language': 'Galactic Basic', 'people': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/4/', 'https://swapi.co/api/people/5/', 'https://swapi.co/api/people/6/', 'https://swapi.co/api/people/7/', 'https://swapi.co/api/people/9/', 'https://swapi.co/api/people/10/', 'https://swapi.co/api/people/11/', 'https://swapi.co/api/people/12/', 'https://swapi.co/api/people/14/', 'https://swapi.co/api/people/18/', 'https://swapi.co/api/people/19/', 'https://swapi.co/api/people/21/', 'https://swapi.co/api/people/22/', 'https://swapi.co/api/people/25/', 'https://swapi.co/api/people/26/', 'https://swapi.co/api/people/28/', 'https://swapi.co/api/people/29/', 'https://swapi.co/api/people/32/', 'https://swapi.co/api/people/34/', 'https://swapi.co/api/people/43/', 'https://swapi.co/api/people/51/', 'https://swapi.co/api/people/60/', 'https://swapi.co/api/people/61/', 'https://swapi.co/api/people/62/', 'https://swapi.co/api/people/66/', 'https://swapi.co/api/people/67/', 'https://swapi.co/api/people/68/', 'https://swapi.co/api/people/69/', 'https://swapi.co/api/people/74/', 'https://swapi.co/api/people/81/', 'https://swapi.co/api/people/84/', 'https://swapi.co/api/people/85/', 'https://swapi.co/api/people/86/', 'https://swapi.co/api/people/35/'], 'films': ['https://swapi.co/api/films/2/', 'https://swapi.co/api/films/7/', 'https://swapi.co/api/films/5/', 'https://swapi.co/api/films/4/', 'https://swapi.co/api/films/6/', 'https://swapi.co/api/films/3/', 'https://swapi.co/api/films/1/'], 'created': '2014-12-10T13:52:11.567000Z', 'edited': '2015-04-17T06:59:55.850671Z', 'url': 'https://swapi.co/api/species/1/'}], 'vehicles': [{'name': 'Snowspeeder', 'model': 't-47 airspeeder', 'manufacturer': 'Incom corporation', 'cost_in_credits': 'unknown', 'length': 4.5, 'max_atmosphering_speed': 650, 'crew': 2, 'passengers': 0, 'cargo_capacity': 10, 'consumables': 'none', 'vehicle_class': 'airspeeder', 'pilots': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/18/'], 'films': ['https://swapi.co/api/films/2/'], 'created': '2014-12-15T12:22:12Z', 'edited': '2014-12-22T18:21:15.623033Z', 'url': 'https://swapi.co/api/vehicles/14/'}, {'name': 'Imperial Speeder Bike', 'model': '74-Z speeder bike', 'manufacturer': 'Aratech Repulsor Company', 'cost_in_credits': 8000, 'length': 3, 'max_atmosphering_speed': 360, 'crew': 1, 'passengers': 1, 'cargo_capacity': 4, 'consumables': '1 day', 'vehicle_class': 'speeder', 'pilots': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/5/'], 'films': ['https://swapi.co/api/films/3/'], 'created': '2014-12-18T11:20:04.625000Z', 'edited': '2014-12-22T18:21:15.920537Z', 'url': 'https://swapi.co/api/vehicles/30/'}], 'starships': [{'name': 'X-wing', 'model': 'T-65 X-wing', 'manufacturer': 'Incom Corporation', 'cost_in_credits': 149999, 'length': 12.5, 'max_atmosphering_speed': 1050, 'crew': 1, 'passengers': 0, 'cargo_capacity': 110, 'consumables': '1 week', 'hyperdrive_rating': 1.0, 'MGLT': 100, 'starship_class': 'Starfighter', 'pilots': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/9/', 'https://swapi.co/api/people/18/', 'https://swapi.co/api/people/19/'], 'films': ['https://swapi.co/api/films/2/', 'https://swapi.co/api/films/3/', 'https://swapi.co/api/films/1/'], 'created': '2014-12-12T11:19:05.340000Z', 'edited': '2014-12-22T17:35:44.491233Z', 'url': 'https://swapi.co/api/starships/12/'}, {'name': 'Imperial shuttle', 'model': 'Lambda-class T-4a shuttle', 'manufacturer': 'Sienar Fleet Systems', 'cost_in_credits': 240000, 'length': 20, 'max_atmosphering_speed': 850, 'crew': 6, 'passengers': 20, 'cargo_capacity': 80000, 'consumables': '2 months', 'hyperdrive_rating': 1.0, 'MGLT': 50, 'starship_class': 'Armed government transport', 'pilots': ['https://swapi.co/api/people/1/', 'https://swapi.co/api/people/13/', 'https://swapi.co/api/people/14/'], 'films': ['https://swapi.co/api/films/2/', 'https://swapi.co/api/films/3/'], 'created': '2014-12-15T13:04:47.235000Z', 'edited': '2014-12-22T17:35:44.795405Z', 'url': 'https://swapi.co/api/starships/22/'}], 'created': '2014-12-09T13:50:51.644000Z', 'edited': '2014-12-20T21:17:56.891000Z', 'url': {'name': 'Luke Skywalker', 'height': 172, 'mass': 77, 'hair_color': 'blond', 'skin_color': 'fair', 'eye_color': 'blue', 'birth_year': '19BBY', 'gender': 'male', 'homeworld': 'https://swapi.co/api/planets/1/', 'films': ['https://swapi.co/api/films/2/', 'https://swapi.co/api/films/6/', 'https://swapi.co/api/films/3/', 'https://swapi.co/api/films/1/', 'https://swapi.co/api/films/7/'], 'species': ['https://swapi.co/api/species/1/'], 'vehicles': ['https://swapi.co/api/vehicles/14/', 'https://swapi.co/api/vehicles/30/'], 'starships': ['https://swapi.co/api/starships/12/', 'https://swapi.co/api/starships/22/'], 'created': '2014-12-09T13:50:51.644000Z', 'edited': '2014-12-20T21:17:56.891000Z', 'url': 'https://swapi.co/api/people/1/'}} db = client . saildrone antarctica = db . create_collection ( 'antarctica' ) pymongo . common . int validator = \"\"\"{ 'validator': { $jsonSchema: { bsonType: \"object\", required: [ \"name\", \"year\", \"major\", \"address\" ], properties: { name: { bsonType: \"string\", description: \"must be a string and is required\" }, year: { bsonType: \"int\", minimum: 2017, maximum: 3017, description: \"must be an integer in [ 2017, 3017 ] and is required\" }, major: { enum: [ \"Math\", \"English\", \"Computer Science\", \"History\", null ], description: \"can only be one of the enum values and is required\" }, gpa: { bsonType: [ \"double\" ], description: \"must be a double if the field exists\" }, address: { bsonType: \"object\", required: [ \"city\" ], properties: { street: { bsonType: \"string\", description: \"must be a string if the field exists\" }, city: { bsonType: \"string\", \"description\": \"must be a string and is required\" } } } } } } \"\"\" import json json . loads ( '{\"validator\": 1}' ) {'validator': 1} client . list_database_names () ['admin', 'config', 'local', 'saildrone', 'test'] db . list_collection_names () ['antarctica'] antarctica = db . antartica cursor = antarctica . aggregate ([{ \"$match\" : {} }]) from datetime import ( datetime , timedelta ) from random import ( choice , randint , random , uniform , lognormvariate ) def feed_db ( n ): json_body = ( { \"measurement\" : \"starfleet_01\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"speed\" : lognormvariate ( 10 , 3 ), \"consumption\" : uniform ( 0 , 300 ), \"pressure_a\" : 3 + random (), \"status_b\" : choice (( True , False )) } } for i in range ( n ) ) antarctica . insert_many ( json_body ) % timeit feed_db ( 100_000 ) 3.56 s \u00b1 26.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) antarctica . count_documents ({}) 2993003 antarctica . insert_one ( { \"item\" : \"canvas\" , \"qty\" : \"$myMul(100)\" , \"tags\" : [ \"cotton\" ], \"size\" : { \"h\" : 28 , \"w\" : 35.5 , \"uom\" : \"cm\" }}) <pymongo.results.InsertOneResult at 0x7f1d8c753c08> antarctica . aggregate ([{ \"$match\" : {}},{ \"$project\" : { \"qty\" : 1 } }]) . next () {'_id': ObjectId('5d5ef7a5e261536f4714057d'), 'qty': 100} cursor = antarctica . find ({}) list ( cursor ) [{'_id': ObjectId('5d5ef7a5e261536f4714057d'), 'item': 'canvas', 'qty': 100, 'tags': ['cotton'], 'size': {'h': 28, 'w': 35.5, 'uom': 'cm'}}, {'_id': ObjectId('5d5ef86be261536f4714057e'), 'item': 'canvas', 'qty': 'myMul(100)', 'tags': ['cotton'], 'size': {'h': 28, 'w': 35.5, 'uom': 'cm'}}, {'_id': ObjectId('5d5ef897e261536f4714057f'), 'item': 'canvas', 'qty': '$myMul(100)', 'tags': ['cotton'], 'size': {'h': 28, 'w': 35.5, 'uom': 'cm'}}] Replica set: A cluster of MongoDB servers that implements replication and automated failover. MongoDB\u2019s recommended replication strategy. See Replication. Sharded cluster","title":"MongoDB"},{"location":"_nb/%3DPy/04_influxDB/01%20-%20Intro%20InfluxDB/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); InfluxDB is a time series database designed to handle timestamped data, including DevOps monitoring, application metrics, IoT sensor data, and real-time analytics. Key features \u00b6 CLI/HTTP write and query API. Expressive SQL-like query language Schemas don't have to be defined up front and schema preferences may change over time. Tags allow series to be indexed for fast and efficient queries. Retention policies efficiently auto-expire stale data. Plugins support for other data ingestion protocols such as Graphite, collectd, and OpenTSDB. Continuous queries automatically compute aggregate data to make frequent queries more efficient. InfluxDB isn\u2019t fully CRUD The open source edition of InfluxDB runs on a single node, high availability is only available in the InfluxDB Enterprise Edition. Data structure \u00b6 Time series key concepts : - time - a timestamp - is similar to a SQL primary key, - tags , zero to many key-values, contain any metadata about the value, tags are indexed - at least one key-value field set ( `field key identifies the measured element while field value are the measured value itself, e.g. \u201cvalue=0.64\u201d, or \u201ctemperature=21.2\u201d). **fields are not indexed** It\u2019s important to note that fields are not indexed. Queries that use field values as filters must scan all values that match the other conditions in the query. As a result, those queries are not performant relative to queries on tags. In general, fields should not contain commonly-queried metadata. Further concepts: - a measurement acts as a container for tags , fields , and the time column. Assimilable to a SQL table, where the primary index is always time . tags and fields are effectively columns in the table. - a series is the collection of data that share the same retention policy, measurement, and tag set. - a point represents a single data record that has four components: a measurement, tag set, field set, and a timestamp. A point is uniquely identified by its series and timestamp (similar to a row in a SQL database table) Element Optional/Required Description Type (See data types for more information.) Measurement Required The measurement name. InfluxDB accepts one measurement per point. String Tag set Optional All tag key-value pairs for the point. Tag keys and tag values are both strings. Field set Required. Points must have at least one field. All field key-value pairs for the point. Field keys are strings. Field values can be floats, integers, strings, or Booleans. Timestamp Optional. InfluxDB uses the server\u2019s local nanosecond timestamp in UTC if the timestamp is not included with the point. The timestamp for the data point. InfluxDB accepts one timestamp per point. Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API . Data type \u00b6 Datatype Element(s) Description Float Field values IEEE-754 64-bit floating-point numbers. This is the default numerical type. Examples: 1 , 1.0 , 1.e+78 , 1.E+78 . Integer Field values Signed 64-bit integers (-9223372036854775808 to 9223372036854775807). Specify an integer with a trailing i on the number. Example: 1i . String Measurements, tag keys, tag values, field keys, field values Length limit 64KB. Boolean Field values Stores TRUE or FALSE values. TRUE write syntax: [t, T, true, True, TRUE] . FALSE write syntax: [f, F, false, False, FALSE] Timestamp Timestamps Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API . The minimum valid timestamp is -9223372036854775806 or 1677-09-21T00:12:43.145224194Z . The maximum valid timestamp is 9223372036854775806 or 2262-04-11T23:47:16.854775806Z . Python module documentation Example \u00b6 *census*: time butterflies honeybees location scientist 2015-08-18T00:00:00Z 12 23 1 langstroth 2015-08-18T00:00:00Z 1 30 1 perpetua 2015-08-18T00:06:00Z 11 28 1 langstroth 015-08-18T00:06:00Z 3 28 1 perpetua 2015-08-18T05:54:00Z 2 11 2 langstroth 2015-08-18T06:00:00Z 1 10 2 langstroth 2015-08-18T06:06:00Z 8 23 2 perpetua 2015-08-18T06:12:00Z 7 22 2 perpetua **8 field sets** butterflies = 12 honeybees = 23 butterflies = 1 honeybees = 30 butterflies = 11 honeybees = 28 butterflies = 3 honeybees = 28 butterflies = 2 honeybees = 11 butterflies = 1 honeybees = 10 butterflies = 8 honeybees = 23 butterflies = 7 honeybees = 22 **4 tag sets** (different combinations of all the tag key-value pairs) location = 1, scientist = langstroth location = 2, scientist = langstroth location = 1, scientist = perpetua location = 2, scientist = perpetua Arbitrary series number Retention policy Measurement Tag set series 1 autogen census location = 1 , scientist = langstroth series 2 autogen census location = 2 , scientist = langstroth series 3 autogen census location = 1 , scientist = perpetua series 4 autogen census location = 2 , scientist = perpetua from datetime import ( datetime , timedelta ) from random import ( choice , randint , random , uniform , lognormvariate ) from influxdb import ( InfluxDBClient , DataFrameClient ) INFLUXDB_USER = 'telegraf' INFLUXDB_USER_PASSWORD = 'secretpassword' host = 'db.influxdb.app.com' port = 8086 \"\"\"Instantiate a connection to the InfluxDB.\"\"\" user = 'admin' password = 'supersecretpassword' dbname = 'example' dbuser = 'telegraf' dbuser_password = 'secretpassword' client = InfluxDBClient ( host , port , user , password , dbname ) DB init \u00b6 For creating the DB client.create_database(dbname) Define a specific retention policy, drop after 30d, with replica factor of 3 and applied by default to new elements client . create_retention_policy ( 'custom_policy' , '30d' , 3 , default = True ) # For dropping the policy: client.drop_retention_policy('custom_policy', dbname) client . switch_user ( dbuser , dbuser_password ) def feed_db ( n ): json_body = [ { \"measurement\" : \"starfleet_01\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"speed\" : lognormvariate ( 10 , 3 ), \"consumption\" : uniform ( 0 , 300 ), \"pressure_a\" : 3 + random (), \"status_b\" : choice (( True , False )) } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) def feed_db_array ( n ): json_body = [ { \"measurement\" : \"starfleet_02\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"curve_b[0]\" : 10 + random (), \"curve_b[1]\" : choice (( 15 + random (), 4 + random ())), \"curve_b[2]\" : 20 + random (), } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) % timeit feed_db ( 100_000 ) 13.2 s \u00b1 202 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) feed_db_array(1_000_000) Series can be deleted client.delete_series(database=\"example\", measurement=\"starfleet_01\") client . query ( query = 'select count(*) from starfleet_01' ) ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count_consumption': 1866653, 'count_pressure_a': 1866653, 'count_speed': 1866653, 'count_status_b': 1866653}]}) from IPython.core.magic import ( register_line_cell_magic ) @register_line_cell_magic def influxql ( line , cell = None ): \"Magic that works both as %lc magic and as %% lcmagic\" if cell is None : sqlstr = line else : sqlstr = \";\" . join (( op . strip ( \";\" ) for op in cell . strip ( \" \\n \" ) . split ( \" \\n \" ))) + \";\" return client . query ( query = sqlstr ) % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:05Z', 'speed': 774750.9698706511}, {'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}]}) result = % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; result ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}, {'time': '2019-08-19T20:52:25Z', 'speed': 9.829304084029904}]}) % influxql SELECT COUNT ( DISTINCT ( pressure_a )) FROM starfleet_01 ; ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count': 1000000}]}) % influxql SELECT COUNT ( pressure_a ) FROM starfleet_01 GROUP BY time ( 28 d ), region LIMIT 1 ; ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118099}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118282}], '('starfleet_01', {'region': 'Earth'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117988}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117959}]}) % influxql SELECT MEAN ( pressure_a ) FROM starfleet_01 GROUP BY region ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.499534039730786}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.4999780335201867}], '('starfleet_01', {'region': 'Earth'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5005520567253616}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5013387093463155}]}) You can explain query % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE region = 'Andoria' LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 750'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 2160'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 2160'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 5992395'}]}) % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE pressure_a > 3.5 LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 3000'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 8640'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 8640'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 23943525'}]}) res = % influxql SELECT * FROM \"starfleet_01\" WHERE pressure_a > 3.5 LIMIT 50 points = res . get_points ( tags = { \"region\" : \"Andoria\" }) from pandas import DataFrame df = DataFrame ( points ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region spacecraft speed status_b time 0 Archer 80.868742 3.764769 Andoria NX-1707 4.540769e+06 False 2019-07-28T01:35:50Z 1 Archer 64.351610 3.784118 Andoria NX-1707 8.549125e+05 False 2019-07-28T01:36:00Z 2 Archer 60.765559 3.907481 Andoria NX-1702 1.679463e+05 False 2019-07-28T01:36:04Z 3 Archer 252.870551 3.800938 Andoria NX-1706 1.444727e+04 True 2019-07-28T01:36:06Z 4 Kruge 192.871755 3.930994 Andoria NX-1702 4.376490e+03 False 2019-07-28T01:36:08Z df . groupby ( 'spacecraft' ) . max () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region speed status_b time spacecraft NX-1701 Kirk 226.626952 3.518973 Andoria 6.987498e+05 False 2019-07-28T01:38:44Z NX-1702 Kruge 217.135955 3.952388 Andoria 6.735246e+05 True 2019-07-28T01:37:38Z NX-1704 Kruge 278.172741 3.976138 Andoria 2.770339e+01 True 2019-07-28T01:37:54Z NX-1705 Kirk 197.423732 3.964069 Andoria 4.300635e+04 True 2019-07-28T01:37:42Z NX-1706 Kruge 252.870551 3.800938 Andoria 1.444727e+04 True 2019-07-28T01:37:02Z NX-1707 Kruge 289.899273 3.913948 Andoria 4.540769e+06 True 2019-07-28T01:38:46Z NX-1709 Kruge 272.085362 3.734222 Andoria 1.653500e+05 True 2019-07-28T01:37:30Z NX-1710 Kruge 297.309907 3.875039 Andoria 5.887814e+04 True 2019-07-28T01:38:20Z % influxql SHOW QUERIES ; ResultSet({'('results', None)': [{'qid': 2821, 'query': 'SHOW QUERIES', 'database': 'example', 'duration': '171\u00b5s', 'status': 'running'}]}) % influxql SHOW TAG KEYS ; ResultSet({'('starfleet_01', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}], '('starfleet_02', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}]})","title":"01   Intro InfluxDB"},{"location":"_nb/%3DPy/04_influxDB/01%20-%20Intro%20InfluxDB/#key-features","text":"CLI/HTTP write and query API. Expressive SQL-like query language Schemas don't have to be defined up front and schema preferences may change over time. Tags allow series to be indexed for fast and efficient queries. Retention policies efficiently auto-expire stale data. Plugins support for other data ingestion protocols such as Graphite, collectd, and OpenTSDB. Continuous queries automatically compute aggregate data to make frequent queries more efficient. InfluxDB isn\u2019t fully CRUD The open source edition of InfluxDB runs on a single node, high availability is only available in the InfluxDB Enterprise Edition.","title":"Key features"},{"location":"_nb/%3DPy/04_influxDB/01%20-%20Intro%20InfluxDB/#data-structure","text":"Time series key concepts : - time - a timestamp - is similar to a SQL primary key, - tags , zero to many key-values, contain any metadata about the value, tags are indexed - at least one key-value field set ( `field key identifies the measured element while field value are the measured value itself, e.g. \u201cvalue=0.64\u201d, or \u201ctemperature=21.2\u201d). **fields are not indexed** It\u2019s important to note that fields are not indexed. Queries that use field values as filters must scan all values that match the other conditions in the query. As a result, those queries are not performant relative to queries on tags. In general, fields should not contain commonly-queried metadata. Further concepts: - a measurement acts as a container for tags , fields , and the time column. Assimilable to a SQL table, where the primary index is always time . tags and fields are effectively columns in the table. - a series is the collection of data that share the same retention policy, measurement, and tag set. - a point represents a single data record that has four components: a measurement, tag set, field set, and a timestamp. A point is uniquely identified by its series and timestamp (similar to a row in a SQL database table) Element Optional/Required Description Type (See data types for more information.) Measurement Required The measurement name. InfluxDB accepts one measurement per point. String Tag set Optional All tag key-value pairs for the point. Tag keys and tag values are both strings. Field set Required. Points must have at least one field. All field key-value pairs for the point. Field keys are strings. Field values can be floats, integers, strings, or Booleans. Timestamp Optional. InfluxDB uses the server\u2019s local nanosecond timestamp in UTC if the timestamp is not included with the point. The timestamp for the data point. InfluxDB accepts one timestamp per point. Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API .","title":"Data structure"},{"location":"_nb/%3DPy/04_influxDB/01%20-%20Intro%20InfluxDB/#data-type","text":"Datatype Element(s) Description Float Field values IEEE-754 64-bit floating-point numbers. This is the default numerical type. Examples: 1 , 1.0 , 1.e+78 , 1.E+78 . Integer Field values Signed 64-bit integers (-9223372036854775808 to 9223372036854775807). Specify an integer with a trailing i on the number. Example: 1i . String Measurements, tag keys, tag values, field keys, field values Length limit 64KB. Boolean Field values Stores TRUE or FALSE values. TRUE write syntax: [t, T, true, True, TRUE] . FALSE write syntax: [f, F, false, False, FALSE] Timestamp Timestamps Unix nanosecond timestamp. Specify alternative precisions with the InfluxDB API . The minimum valid timestamp is -9223372036854775806 or 1677-09-21T00:12:43.145224194Z . The maximum valid timestamp is 9223372036854775806 or 2262-04-11T23:47:16.854775806Z . Python module documentation","title":"Data type"},{"location":"_nb/%3DPy/04_influxDB/01%20-%20Intro%20InfluxDB/#example","text":"*census*: time butterflies honeybees location scientist 2015-08-18T00:00:00Z 12 23 1 langstroth 2015-08-18T00:00:00Z 1 30 1 perpetua 2015-08-18T00:06:00Z 11 28 1 langstroth 015-08-18T00:06:00Z 3 28 1 perpetua 2015-08-18T05:54:00Z 2 11 2 langstroth 2015-08-18T06:00:00Z 1 10 2 langstroth 2015-08-18T06:06:00Z 8 23 2 perpetua 2015-08-18T06:12:00Z 7 22 2 perpetua **8 field sets** butterflies = 12 honeybees = 23 butterflies = 1 honeybees = 30 butterflies = 11 honeybees = 28 butterflies = 3 honeybees = 28 butterflies = 2 honeybees = 11 butterflies = 1 honeybees = 10 butterflies = 8 honeybees = 23 butterflies = 7 honeybees = 22 **4 tag sets** (different combinations of all the tag key-value pairs) location = 1, scientist = langstroth location = 2, scientist = langstroth location = 1, scientist = perpetua location = 2, scientist = perpetua Arbitrary series number Retention policy Measurement Tag set series 1 autogen census location = 1 , scientist = langstroth series 2 autogen census location = 2 , scientist = langstroth series 3 autogen census location = 1 , scientist = perpetua series 4 autogen census location = 2 , scientist = perpetua from datetime import ( datetime , timedelta ) from random import ( choice , randint , random , uniform , lognormvariate ) from influxdb import ( InfluxDBClient , DataFrameClient ) INFLUXDB_USER = 'telegraf' INFLUXDB_USER_PASSWORD = 'secretpassword' host = 'db.influxdb.app.com' port = 8086 \"\"\"Instantiate a connection to the InfluxDB.\"\"\" user = 'admin' password = 'supersecretpassword' dbname = 'example' dbuser = 'telegraf' dbuser_password = 'secretpassword' client = InfluxDBClient ( host , port , user , password , dbname )","title":"Example"},{"location":"_nb/%3DPy/04_influxDB/01%20-%20Intro%20InfluxDB/#db-init","text":"For creating the DB client.create_database(dbname) Define a specific retention policy, drop after 30d, with replica factor of 3 and applied by default to new elements client . create_retention_policy ( 'custom_policy' , '30d' , 3 , default = True ) # For dropping the policy: client.drop_retention_policy('custom_policy', dbname) client . switch_user ( dbuser , dbuser_password ) def feed_db ( n ): json_body = [ { \"measurement\" : \"starfleet_01\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"speed\" : lognormvariate ( 10 , 3 ), \"consumption\" : uniform ( 0 , 300 ), \"pressure_a\" : 3 + random (), \"status_b\" : choice (( True , False )) } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) def feed_db_array ( n ): json_body = [ { \"measurement\" : \"starfleet_02\" , \"tags\" : { \"cmdt\" : choice (( \"Archer\" , \"Kirk\" , \"Kruge\" )), \"region\" : choice (( \"Andoria\" , \"Deep Space Nine\" , \"Earth\" , \"Genesis\" )), \"spacecraft\" : f \"NX-17 { randint ( 1 , 10 ) : 02d } \" }, \"time\" : ( datetime . now () - timedelta ( seconds = 2 * ( n - i ))) . strftime ( \"%Y-%m- %d T%H:%M:%S\" ), \"fields\" : { \"curve_b[0]\" : 10 + random (), \"curve_b[1]\" : choice (( 15 + random (), 4 + random ())), \"curve_b[2]\" : 20 + random (), } } for i in range ( n ) ] client . write_points ( json_body , batch_size = 100_000 ) % timeit feed_db ( 100_000 ) 13.2 s \u00b1 202 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) feed_db_array(1_000_000) Series can be deleted client.delete_series(database=\"example\", measurement=\"starfleet_01\") client . query ( query = 'select count(*) from starfleet_01' ) ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count_consumption': 1866653, 'count_pressure_a': 1866653, 'count_speed': 1866653, 'count_status_b': 1866653}]}) from IPython.core.magic import ( register_line_cell_magic ) @register_line_cell_magic def influxql ( line , cell = None ): \"Magic that works both as %lc magic and as %% lcmagic\" if cell is None : sqlstr = line else : sqlstr = \";\" . join (( op . strip ( \";\" ) for op in cell . strip ( \" \\n \" ) . split ( \" \\n \" ))) + \";\" return client . query ( query = sqlstr ) % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:05Z', 'speed': 774750.9698706511}, {'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}]}) result = % influxql SELECT speed FROM starfleet_01 WHERE time > now () - 1 d LIMIT 10 ; result ResultSet({'('starfleet_01', None)': [{'time': '2019-08-19T20:52:07Z', 'speed': 487121.20016297186}, {'time': '2019-08-19T20:52:09Z', 'speed': 18753.305850476325}, {'time': '2019-08-19T20:52:11Z', 'speed': 17151.44033960194}, {'time': '2019-08-19T20:52:13Z', 'speed': 34535.68231005546}, {'time': '2019-08-19T20:52:15Z', 'speed': 17274.816825933573}, {'time': '2019-08-19T20:52:17Z', 'speed': 31681.839234807274}, {'time': '2019-08-19T20:52:19Z', 'speed': 9354.756781762246}, {'time': '2019-08-19T20:52:21Z', 'speed': 6355.474730264167}, {'time': '2019-08-19T20:52:23Z', 'speed': 40375.16829113543}, {'time': '2019-08-19T20:52:25Z', 'speed': 9.829304084029904}]}) % influxql SELECT COUNT ( DISTINCT ( pressure_a )) FROM starfleet_01 ; ResultSet({'('starfleet_01', None)': [{'time': '1970-01-01T00:00:00Z', 'count': 1000000}]}) % influxql SELECT COUNT ( pressure_a ) FROM starfleet_01 GROUP BY time ( 28 d ), region LIMIT 1 ; ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118099}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '2019-07-11T00:00:00Z', 'count': 118282}], '('starfleet_01', {'region': 'Earth'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117988}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '2019-07-11T00:00:00Z', 'count': 117959}]}) % influxql SELECT MEAN ( pressure_a ) FROM starfleet_01 GROUP BY region ResultSet({'('starfleet_01', {'region': 'Andoria'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.499534039730786}], '('starfleet_01', {'region': 'Deep Space Nine'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.4999780335201867}], '('starfleet_01', {'region': 'Earth'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5005520567253616}], '('starfleet_01', {'region': 'Genesis'})': [{'time': '1970-01-01T00:00:00Z', 'mean': 3.5013387093463155}]}) You can explain query % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE region = 'Andoria' LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 750'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 2160'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 2160'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 5992395'}]}) % influxql EXPLAIN SELECT * FROM starfleet_02 WHERE pressure_a > 3.5 LIMIT 1 ResultSet({'('results', None)': [{'QUERY PLAN': 'EXPRESSION: <nil>'}, {'QUERY PLAN': 'AUXILIARY FIELDS: cmdt::tag, \"curve_b[0]\"::float, \"curve_b[1]\"::float, \"curve_b[2]\"::float, region::tag, spacecraft::tag'}, {'QUERY PLAN': 'NUMBER OF SHARDS: 25'}, {'QUERY PLAN': 'NUMBER OF SERIES: 3000'}, {'QUERY PLAN': 'CACHED VALUES: 0'}, {'QUERY PLAN': 'NUMBER OF FILES: 8640'}, {'QUERY PLAN': 'NUMBER OF BLOCKS: 8640'}, {'QUERY PLAN': 'SIZE OF BLOCKS: 23943525'}]}) res = % influxql SELECT * FROM \"starfleet_01\" WHERE pressure_a > 3.5 LIMIT 50 points = res . get_points ( tags = { \"region\" : \"Andoria\" }) from pandas import DataFrame df = DataFrame ( points ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region spacecraft speed status_b time 0 Archer 80.868742 3.764769 Andoria NX-1707 4.540769e+06 False 2019-07-28T01:35:50Z 1 Archer 64.351610 3.784118 Andoria NX-1707 8.549125e+05 False 2019-07-28T01:36:00Z 2 Archer 60.765559 3.907481 Andoria NX-1702 1.679463e+05 False 2019-07-28T01:36:04Z 3 Archer 252.870551 3.800938 Andoria NX-1706 1.444727e+04 True 2019-07-28T01:36:06Z 4 Kruge 192.871755 3.930994 Andoria NX-1702 4.376490e+03 False 2019-07-28T01:36:08Z df . groupby ( 'spacecraft' ) . max () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cmdt consumption pressure_a region speed status_b time spacecraft NX-1701 Kirk 226.626952 3.518973 Andoria 6.987498e+05 False 2019-07-28T01:38:44Z NX-1702 Kruge 217.135955 3.952388 Andoria 6.735246e+05 True 2019-07-28T01:37:38Z NX-1704 Kruge 278.172741 3.976138 Andoria 2.770339e+01 True 2019-07-28T01:37:54Z NX-1705 Kirk 197.423732 3.964069 Andoria 4.300635e+04 True 2019-07-28T01:37:42Z NX-1706 Kruge 252.870551 3.800938 Andoria 1.444727e+04 True 2019-07-28T01:37:02Z NX-1707 Kruge 289.899273 3.913948 Andoria 4.540769e+06 True 2019-07-28T01:38:46Z NX-1709 Kruge 272.085362 3.734222 Andoria 1.653500e+05 True 2019-07-28T01:37:30Z NX-1710 Kruge 297.309907 3.875039 Andoria 5.887814e+04 True 2019-07-28T01:38:20Z % influxql SHOW QUERIES ; ResultSet({'('results', None)': [{'qid': 2821, 'query': 'SHOW QUERIES', 'database': 'example', 'duration': '171\u00b5s', 'status': 'running'}]}) % influxql SHOW TAG KEYS ; ResultSet({'('starfleet_01', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}], '('starfleet_02', None)': [{'tagKey': 'cmdt'}, {'tagKey': 'region'}, {'tagKey': 'spacecraft'}]})","title":"DB init"},{"location":"_nb/%3DPy/05_pandas_xarray/00_fetch_data/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import numpy as np import pandas as pd from pandas import DataFrame pd . options . display . max_rows = 10 Create a HDF Store for serializing the data store = pd . HDFStore ( 'store.h5' ) ADAC - df0 mit Abgasnorm Euro 6d-Temp, Euro 6d \u00b6 ADAC - df0 mit Abgasnorm Euro 6d-Temp, Euro 6d url = \"https://www.adac.de/rund-ums-fahrzeug/auto-kaufen-verkaufen/neuwagenkauf/euro-6d-temp-modelle\" res = pd . read_html ( url , header = 0 ) Concatenate all tables and reindex df0 = pd . concat (( elt for elt in res ), ignore_index = True ) df0 . rename ({ 'Markt- einf\u00fchrung' : 'Markteinfuehrung' , 'Hubraum in ccm' : 'Hubraum' , 'Leistung in KW' : 'Leistung' }, axis = 1 , inplace = True ) Convert Markteinfuehrung col to datetime For date manipulation, see for ex.https://www.python-kurs.eu/python3_time_and_date.php import locale locale . setlocale ( locale . LC_ALL , 'de_DE.UTF-8' ) pat = r \"^(\\w {3} ).*(\\d {2} )$\" repl = lambda m : f \" { m . group ( 1 ) } { m . group ( 2 ) } \" df0 . Markteinfuehrung = df0 . Markteinfuehrung \\ . str . replace ( '^v' , 'Nov' ) \\ . str . replace ( '(Mrz|Mar)' , 'M\u00e4r' ) \\ . str . replace ( pat , repl ) df0 . Markteinfuehrung = pd . to_datetime ( df0 . Markteinfuehrung , format = '%b %y' , errors = 'coerce' ) df0 = df0 . astype ({ 'Hersteller' : 'category' , 'Modell' : str , 'Motorart' : 'category' , 'Abgasnorm' : 'category' }) df0 . dtypes Hersteller category Modell object Motorart category Hubraum int64 Leistung int64 Abgasnorm category Markteinfuehrung datetime64[ns] dtype: object df0 . sample ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Hersteller Modell Motorart Hubraum Leistung Abgasnorm Markteinfuehrung 2677 VW Caddy Maxi Kombi 2.0 TDI SCR Diesel 1968 75 Euro 6d-TEMP-EVAP 2018-10-01 690 Dacia Dokker Blue dCi 75 Diesel 1461 55 Euro 6d-TEMP-EVAP 2018-09-01 1226 Lamborghini Hurac\u00e1n LP580-2 Otto 5204 426 Euro 6d-TEMP 2018-09-01 df0 . memory_usage () Index 128 Hersteller 4506 Modell 22992 Motorart 3082 Hubraum 22992 Leistung 22992 Abgasnorm 3250 Markteinfuehrung 22992 dtype: int64 Save to the store store . put ( 'ADAC' , df0 , format = 'table' ) print ( store . info ()) <class 'pandas.io.pytables.HDFStore'> File path: store.h5 /ADAC frame_table (typ->appendable,nrows->2874,ncols->7,indexers->[index],dc->[]) /ADAC/meta/values_block_0/meta series_table (typ->appendable,nrows->44,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_1/meta series_table (typ->appendable,nrows->6,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_2/meta series_table (typ->appendable,nrows->7,ncols->1,indexers->[index],dc->[values]) store . get ( '/ADAC' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Hersteller Modell Motorart Hubraum Leistung Abgasnorm Markteinfuehrung 0 Abarth 595 Otto 1368 107 Euro 6d-TEMP-EVAP 2018-09-01 1 Abarth 595 Pista Otto 1368 118 Euro 6d-TEMP-EVAP 2018-09-01 2 Abarth 595 Turismo Otto 1368 121 Euro 6d-TEMP-EVAP 2018-09-01 3 Abarth 595 Competizione Otto 1368 132 Euro 6d-TEMP-EVAP 2018-09-01 4 Abarth 595C Otto 1368 107 Euro 6d-TEMP-EVAP 2018-09-01 ... ... ... ... ... ... ... ... 2869 VW Touran 2.0 TDI SCR Diesel 1968 140 Euro 6d-TEMP 2019-01-01 2870 VW up! 1.0 Otto 999 44 Euro 6d-TEMP 2018-08-01 2871 VW up! 1.0 Otto 999 55 Euro 6d-TEMP 2018-08-01 2872 VW up! 1.0 TSI Otto 999 66 Euro 6d-TEMP 2018-09-01 2873 VW up! GTI Otto 999 85 Euro 6d-TEMP 2018-01-01 2874 rows \u00d7 7 columns Umweltdaten N\u00fcrnberg \u00b6 Messstation Jakobsplatz - Stadt N\u00fcrnberg from datetime import datetime today = datetime.today() from string import Template url = Template((\"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/\" \"archiv/csv-export/SUN/ {where}/ {where}/ /\" \"individuell/ {first}/ {first}/ /export.csv\")) make_url = lambda where, what, year: url.substitute( where=where, what=what, first=f\"01.01.{year}\", until=f'31.12.{year}') def get_air_data_in_nuremberg ( where : str , what : str , year : int ): opts = { 'skiprows' : range ( 0 , 10 ), 'encoding' : 'ISO-8859-1' , 'sep' : ';' , 'parse_dates' : [ 0 ], 'index_col' : 0 , 'na_values' : [ '-' ] } url = ( f \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/\" f \"archiv/csv-export/SUN/ { where } / { what } /\" f \"individuell/01.01. { year } /31.12. { year } /export.csv\" ) return pd . read_csv ( url , ** opts ) df = pd . concat ([ get_air_data_in_nuremberg ( where = \"nuernberg-jakobsplatz\" , what = \"stickstoffdioxid\" , year = y ) for y in range ( 2005 , 2020 )]) http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / messstation - jakobsplatz / feinstaub - pm10 / csv - export / SUN / nuernberg - jakobsplatz / staubpartikel - pm10 / 7 - Tages - Ansicht / export . csv Nu2HD5 = { 'nuernberg-jakobsplatz' : 'JAKOBSPALTZ' , 'nuernberg-flugfeld' : 'FLUGFELD' , 'stickstoffmonoxid' : 'NO' , 'stickstoffdioxid' : 'NO2' , 'ozon' : 'O3' , 'staubpartikel-pm10' : 'PM10' , 'staub-pm-25' : 'PM25' } from itertools import product for what , where in product ([ k for k in Nu2HD5 . keys () if 'nuernberg' not in k ], [ k for k in Nu2HD5 . keys () if 'nuernberg' in k ]): try : df = pd . concat ([ get_air_data_in_nuremberg ( where = where , what = what , year = y ) for y in range ( 2005 , 2020 )]) tableName = f \"AIR/ { Nu2HD5 [ where ] } / { Nu2HD5 [ what ] } \" store . put ( tableName , df , format = 'table' ) except Exception as e : print ( e ) print ( store . info ()) <class 'pandas.io.pytables.HDFStore'> File path: store.h5 /ADAC frame_table (typ->appendable,nrows->2874,ncols->7,indexers->[index],dc->[]) /ADAC/meta/values_block_0/meta series_table (typ->appendable,nrows->44,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_1/meta series_table (typ->appendable,nrows->6,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_2/meta series_table (typ->appendable,nrows->7,ncols->1,indexers->[index],dc->[values]) /AIR/FLUGFELD/NO frame_table (typ->appendable,nrows->127817,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/NO2 frame_table (typ->appendable,nrows->127779,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/O3 frame_table (typ->appendable,nrows->129541,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/PM10 frame_table (typ->appendable,nrows->130374,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/PM25 frame_table (typ->appendable,nrows->103667,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/NO frame_table (typ->appendable,nrows->123168,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/NO2 frame_table (typ->appendable,nrows->123353,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/O3 frame_table (typ->appendable,nrows->125972,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/PM10 frame_table (typ->appendable,nrows->126952,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/PM25 frame_table (typ->appendable,nrows->87343,ncols->1,indexers->[index],dc->[]) df1 = store . get ( '/AIR/JAKOBSPALTZ/O3' ) df1 . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) Datum/Zeit 2005-05-24 21:00:00 59.0 2005-01-06 00:00:00 57.0 2005-01-06 01:00:00 49.0 2005-01-06 02:00:00 51.0 2005-01-06 03:00:00 34.0 df1 . groupby ( df1 . index . weekday ) . boxplot ( layout = ( 1 , 7 ), figsize = ( 16 , 6 )); with pandas \u00b6 dfk = pd . read_csv ( make_url ( where = \"nuernberg-jakobsplatz\" , what = \"stickstoffdioxid\" , year = 2019 ), ** opts ) The data will be retrieved year for year, see no \" Da bei den Abfragen m\u00f6glicherweise gro\u00dfe Datenmengen entstehen, wird empfohlen maximal 12 Monate als Bezugszeitraum anzugeben und bei Bedarf mehrere Abfragen durchzuf\u00fchren. \" with pyarrow \u00b6 from pyarrow import csv from pyarrow.csv import ( ReadOptions , ParseOptions , ConvertOptions ) read_opts = ReadOptions ( skip_rows = 13 , column_names = [ \"Date\" , \"NO2\" ]) parse_opts = ParseOptions ( delimiter = ';' ) conv_opts = ConvertOptions ( column_types = { 'NO2' : pa . int32 ()}, null_values = [ \"-\" ]) # Date are not an # 'Date': pa.timestamp('s'), from io import ( BytesIO , StringIO ) bio = BytesIO ( r . content . decode ( encoding = 'ISO-8859-1' ) . encode ()) table = csv . read_csv ( bio , read_options = read_opts , parse_options = parse_opts , convert_options = conv_opts ) table . schema Date: string NO2: int32 dfk . boxplot () <matplotlib.axes._subplots.AxesSubplot at 0x7f6fe5bd2710> import pyarrow as pa from pyarrow import csv from requests import Session year = 1 u1 = url . substitute ( what = \"stickstoffdioxid\" , first = today . strftime ( ' %d .%m.' ) + str ( today . year - year - 1 ), until = today . strftime ( ' %d .%m.' ) + str ( today . year - year )) s = Session () r = s . get ( u1 ) table . schema Date: string NO2: int32 table . to_pandas () Date object NO2 float64 dtype: object df1 = pd . concat (( pd . read_csv ( url . substitute ( what = \"stickstoffdioxid\" , first = today . strftime ( ' %d .%m.' ) + str ( today . year - year - 1 ), until = today . strftime ( ' %d .%m.' ) + str ( today . year - year )), ** opts ) for year in range ( 15 ))) df1 . info () <class 'pandas.core.frame.DataFrame'> DatetimeIndex: 112269 entries, 2019-01-01 01:00:00 to 2005-11-27 23:00:00 Data columns (total 1 columns): Wert (\u00b5g/m\u00b3) 111358 non-null float64 dtypes: float64(1) memory usage: 1.7 MB df1 [ 'Wert (\u00b5g/m\u00b3)' ] . metadata = {} df1 [ 'Wert (\u00b5g/m\u00b3)' ] . iloc [: 30 ] Datum/Zeit 2019-01-01 01:00:00 30.0 2019-01-01 02:00:00 29.0 2019-01-01 03:00:00 24.0 2019-01-01 04:00:00 22.0 2019-01-01 05:00:00 20.0 ... 2019-02-01 02:00:00 8.0 2019-02-01 03:00:00 6.0 2019-02-01 04:00:00 7.0 2019-02-01 05:00:00 6.0 2019-02-01 06:00:00 8.0 Name: Wert (\u00b5g/m\u00b3), Length: 30, dtype: float64 week_df = df1 . groupby ( df1 . index . weekday ) . mean () df1 . groupby ( df1 . index . weekday ) . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Wert (\u00b5g/m\u00b3) count mean std min 25% 50% 75% max Datum/Zeit 0 15849.0 30.795003 17.231654 1.0 18.0 27.0 40.0 133.0 1 15949.0 31.919744 17.604728 0.0 19.0 28.0 41.0 129.0 2 15943.0 32.267578 17.488338 0.0 19.0 29.0 42.0 148.0 3 15954.0 32.525385 17.798968 1.0 19.0 29.0 42.0 135.0 4 15959.0 31.770725 17.249226 -1.0 19.0 28.0 41.0 135.0 5 15816.0 28.693349 15.996195 0.0 17.0 25.0 37.0 129.0 6 15888.0 25.967082 16.686306 0.0 14.0 22.0 34.0 128.0 \" Although fine particle OC concentrations did not correlate with day of the week, EC concentrations showed a significant weekly pattern, with the highest concentration during the middle of the workweek and the lowest concentration on Sundays. \" https://www.ncbi.nlm.nih.gov/pubmed/15303295 df1 . groupby ( df1 . index . weekday ) . boxplot ( layout = ( 1 , 7 ), figsize = ( 16 , 6 )); gp = df1 . groupby ( df1 . index . weekday ) % timeit df1 [ df1 . index . weekday == 2 ] 7.61 ms \u00b1 75.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) % timeit df1 . groupby ( df1 . index . weekday ) . get_group ( 2 ) 10.2 ms \u00b1 73.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) df_wend = df1 [ df1 . index . weekday == 2 ] df_wend . groupby ( df_wend . index . hour ) . mean () . plot () <matplotlib.axes._subplots.AxesSubplot at 0x7f6ff53afc88> import seaborn as sns df_wend_h = df_wend . groupby ( df_wend . index . hour ) df_wend_h . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Wert (\u00b5g/m\u00b3) count mean std min 25% 50% 75% max Datum/Zeit 0 667.0 35.112444 19.408852 0.0 20.0 30.0 46.00 117.0 1 665.0 32.306767 18.458983 0.0 18.0 28.0 44.00 105.0 2 665.0 29.712782 17.153460 0.0 16.0 25.0 40.00 94.0 3 666.0 28.234234 15.617778 0.0 16.0 25.0 37.00 92.0 4 667.0 28.008996 14.758310 1.0 16.0 25.0 37.00 86.0 ... ... ... ... ... ... ... ... ... 19 667.0 35.962519 18.899770 6.0 21.0 32.0 46.00 144.0 20 668.0 38.938623 19.969410 6.0 25.0 36.0 48.25 148.0 21 666.0 39.978979 20.332119 4.0 25.0 36.0 50.00 125.0 22 665.0 40.756391 20.704699 6.0 26.0 37.0 52.00 124.0 23 665.0 39.533835 20.385202 5.0 24.0 36.0 51.00 118.0 24 rows \u00d7 8 columns sns . pointplot ( x = \"day\" , y = \"tip\" , data = tips , ci = 68 ) df_wend_h . boxplot ( subplots = False , figsize = ( 16 , 6 ), column = list ( df_wend_h . groups . keys ())) <matplotlib.axes._subplots.AxesSubplot at 0x7f6fe55677b8> df_wend_h . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Wert (\u00b5g/m\u00b3) count mean std min 25% 50% 75% max Datum/Zeit 0 667.0 35.112444 19.408852 0.0 20.0 30.0 46.00 117.0 1 665.0 32.306767 18.458983 0.0 18.0 28.0 44.00 105.0 2 665.0 29.712782 17.153460 0.0 16.0 25.0 40.00 94.0 3 666.0 28.234234 15.617778 0.0 16.0 25.0 37.00 92.0 4 667.0 28.008996 14.758310 1.0 16.0 25.0 37.00 86.0 ... ... ... ... ... ... ... ... ... 19 667.0 35.962519 18.899770 6.0 21.0 32.0 46.00 144.0 20 668.0 38.938623 19.969410 6.0 25.0 36.0 48.25 148.0 21 666.0 39.978979 20.332119 4.0 25.0 36.0 50.00 125.0 22 665.0 40.756391 20.704699 6.0 26.0 37.0 52.00 124.0 23 665.0 39.533835 20.385202 5.0 24.0 36.0 51.00 118.0 24 rows \u00d7 8 columns df_wend_h . boxplot ( by = 'Datum/Zeit' , figsize = ( 16 , 10 )); --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-204-ee7cf848b6f4> in <module> ----> 1 df_wend_h . boxplot ( by = 'Datum/Zeit' , figsize = ( 16 , 10 ) ) ; /opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py in boxplot_frame_groupby (grouped, subplots, column, fontsize, rot, grid, ax, figsize, layout, sharex, sharey, **kwds) 498 sharex = sharex , 499 sharey = sharey , --> 500 ** kwds 501 ) 502 /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in boxplot_frame_groupby (grouped, subplots, column, fontsize, rot, grid, ax, figsize, layout, sharex, sharey, **kwds) 390 for ( key , group ) , ax in zip ( grouped , axes ) : 391 d = group.boxplot( --> 392 ax = ax , column = column , fontsize = fontsize , rot = rot , grid = grid , ** kwds 393 ) 394 ax . set_title ( pprint_thing ( key ) ) /opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py in boxplot_frame (self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds) 418 layout = layout , 419 return_type = return_type , --> 420 ** kwds 421 ) 422 /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in boxplot_frame (self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds) 353 layout = layout , 354 return_type = return_type , --> 355 ** kwds 356 ) 357 plt . draw_if_interactive ( ) /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in boxplot (data, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds) 300 ax = ax , 301 layout = layout , --> 302 return_type = return_type , 303 ) 304 else : /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in _grouped_plot_by_column (plotf, data, columns, by, numeric_only, grid, figsize, ax, layout, return_type, **kwargs) 205 gp_col = grouped [ col ] 206 keys , values = zip ( * gp_col ) --> 207 re_plotf = plotf ( keys , values , ax , ** kwargs ) 208 ax . set_title ( col ) 209 ax . set_xlabel ( pprint_thing ( by ) ) /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in plot_group (keys, values, ax) 262 keys = [ pprint_thing ( x ) for x in keys ] 263 values = [ np . asarray ( remove_na_arraylike ( v ) ) for v in values ] --> 264 bp = ax . boxplot ( values , ** kwds ) 265 if fontsize is not None : 266 ax . tick_params ( axis = \"both\" , labelsize = fontsize ) /opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper (*args, **kwargs) 305 f\"for the old name will be dropped %(removal)s.\") 306 kwargs [ new ] = kwargs . pop ( old ) --> 307 return func ( * args , ** kwargs ) 308 309 # wrapper() must keep the same documented signature as func(): if we /opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner (ax, data, *args, **kwargs) 1599 def inner ( ax , * args , data = None , ** kwargs ) : 1600 if data is None : -> 1601 return func ( ax , * map ( sanitize_sequence , args ) , ** kwargs ) 1602 1603 bound = new_sig . bind ( ax , * args , ** kwargs ) /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in boxplot (self, x, notch, sym, vert, whis, positions, widths, patch_artist, bootstrap, usermedians, conf_intervals, meanline, showmeans, showcaps, showbox, showfliers, boxprops, labels, flierprops, medianprops, meanprops, capprops, whiskerprops, manage_ticks, autorange, zorder) 3770 meanline = meanline , showfliers = showfliers , 3771 capprops = capprops , whiskerprops = whiskerprops , -> 3772 manage_ticks=manage_ticks, zorder=zorder) 3773 return artists 3774 /opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper (*args, **kwargs) 305 f\"for the old name will be dropped %(removal)s.\") 306 kwargs [ new ] = kwargs . pop ( old ) --> 307 return func ( * args , ** kwargs ) 308 309 # wrapper() must keep the same documented signature as func(): if we /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in bxp (self, bxpstats, positions, widths, vert, patch_artist, shownotches, showmeans, showcaps, showbox, showfliers, boxprops, whiskerprops, flierprops, medianprops, capprops, meanprops, meanline, manage_ticks, zorder) 4094 4095 # draw the medians -> 4096 medians . extend ( doplot ( med_x , med_y , ** final_medianprops ) ) 4097 4098 # maybe draw the means /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in doplot (*args, **kwargs) 3996 if vert : 3997 def doplot ( * args , ** kwargs ) : -> 3998 return self . plot ( * args , ** kwargs ) 3999 4000 def dopatch ( xs , ys , ** kwargs ) : /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in plot (self, scalex, scaley, data, *args, **kwargs) 1667 for line in lines : 1668 self . add_line ( line ) -> 1669 self . autoscale_view ( scalex = scalex , scaley = scaley ) 1670 return lines 1671 /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py in autoscale_view (self, tight, scalex, scaley) 2493 handle_single_axis( 2494 scalex , self . _autoscaleXon , self . _shared_x_axes , 'intervalx' , -> 2495 'minposx', self.xaxis, self._xmargin, x_stickies, self.set_xbound) 2496 handle_single_axis( 2497 scaley , self . _autoscaleYon , self . _shared_y_axes , 'intervaly' , /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py in handle_single_axis (scale, autoscaleon, shared_axes, interval, minpos, axis, margin, stickies, set_bound) 2460 x0 , x1 = getattr ( bb , interval ) 2461 locator = axis . get_major_locator ( ) -> 2462 x0 , x1 = locator . nonsingular ( x0 , x1 ) 2463 2464 # Add the margin in figure space and then transform back, to handle /opt/conda/lib/python3.7/site-packages/matplotlib/ticker.py in nonsingular (self, v0, v1) 1523 def nonsingular ( self , v0 , v1 ) : 1524 \"\"\"Expand a range as needed to avoid singularities.\"\"\" -> 1525 return mtransforms . nonsingular ( v0 , v1 , expander = .05 ) 1526 1527 def view_limits ( self , vmin , vmax ) : /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in nonsingular (vmin, vmax, expander, tiny, increasing) 2825 swapped = True 2826 -> 2827 maxabsvalue = max ( abs ( vmin ) , abs ( vmax ) ) 2828 if maxabsvalue < ( 1e6 / tiny ) * np . finfo ( float ) . tiny : 2829 vmin = - expander KeyboardInterrupt : Error in callback <function flush_figures at 0x7f6ff8de0d90> (for post_execute): --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) /opt/conda/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py in flush_figures () 115 # ignore the tracking, just draw and close all figures 116 try : --> 117 return show ( True ) 118 except Exception as e : 119 # safely show traceback if in IPython, else raise /opt/conda/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py in show (close, block) 37 display( 38 figure_manager . canvas . figure , ---> 39 metadata = _fetch_figure_metadata ( figure_manager . canvas . figure ) 40 ) 41 finally : /opt/conda/lib/python3.7/site-packages/IPython/core/display.py in display (include, exclude, metadata, transient, display_id, *objs, **kwargs) 311 publish_display_data ( data = obj , metadata = metadata , ** kwargs ) 312 else : --> 313 format_dict , md_dict = format ( obj , include = include , exclude = exclude ) 314 if not format_dict : 315 # nothing to display (e.g. _ipython_display_ took over) /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in format (self, obj, include, exclude) 178 md = None 179 try : --> 180 data = formatter ( obj ) 181 except : 182 # FIXME: log the exception </opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-9> in __call__ (self, obj) /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in catch_format_error (method, self, *args, **kwargs) 222 \"\"\"show traceback on failed format call\"\"\" 223 try : --> 224 r = method ( self , * args , ** kwargs ) 225 except NotImplementedError : 226 # don't warn on NotImplementedErrors /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) /opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) /opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : /opt/conda/lib/python3.7/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) 2059 bbox_inches = self.figure.get_tightbbox(renderer, -> 2060 bbox_extra_artists=bbox_artists) 2061 pad = kwargs . pop ( \"pad_inches\" , None ) 2062 if pad is None : /opt/conda/lib/python3.7/site-packages/matplotlib/figure.py in get_tightbbox (self, renderer, bbox_extra_artists) 2386 return self . bbox_inches 2387 -> 2388 _bbox = Bbox . union ( bb ) 2389 2390 bbox_inches = TransformedBbox(_bbox, /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in union (bboxes) 702 x0 = np . min ( [ bbox . xmin for bbox in bboxes ] ) 703 x1 = np . max ( [ bbox . xmax for bbox in bboxes ] ) --> 704 y0 = np . min ( [ bbox . ymin for bbox in bboxes ] ) 705 y1 = np . max ( [ bbox . ymax for bbox in bboxes ] ) 706 return Bbox ( [ [ x0 , y0 ] , [ x1 , y1 ] ] ) /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in <listcomp> (.0) 702 x0 = np . min ( [ bbox . xmin for bbox in bboxes ] ) 703 x1 = np . max ( [ bbox . xmax for bbox in bboxes ] ) --> 704 y0 = np . min ( [ bbox . ymin for bbox in bboxes ] ) 705 y1 = np . max ( [ bbox . ymax for bbox in bboxes ] ) 706 return Bbox ( [ [ x0 , y0 ] , [ x1 , y1 ] ] ) /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in ymin (self) 353 def ymin ( self ) : 354 \"\"\"The bottom edge of the bounding box.\"\"\" --> 355 return np . min ( self . get_points ( ) [ : , 1 ] ) 356 357 @ property <__array_function__ internals> in amin (*args, **kwargs) /opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in amin (a, axis, out, keepdims, initial, where) 2744 \"\"\" 2745 return _wrapreduction(a, np.minimum, 'min', axis, None, out, -> 2746 keepdims=keepdims, initial=initial, where=where) 2747 2748 /opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapreduction (obj, ufunc, method, axis, dtype, out, **kwargs) 88 return reduction ( axis = axis , out = out , ** passkwargs ) 89 ---> 90 return ufunc . reduce ( obj , axis , dtype , out , ** passkwargs ) 91 92 KeyboardInterrupt : df1 . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) count 111358.000000 mean 30.567341 std 17.305318 min -1.000000 25% 18.000000 50% 27.000000 75% 40.000000 max 148.000000 np . arange ( - 1 , 150 , 20 ) . reshape ( 1 , 8 ) . shape (1, 8) df1 . iloc [:, 0 ] . to_numpy () array([30., 29., 24., ..., 38., 33., 39.]) cut = pd . qcut ( df1 . iloc [:, 0 ] . to_numpy (), q = 10 ) df1 . groupby ( cut ) . mean () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) (-1.001, 12.0] 9.379547 (12.0, 16.0] 14.562010 (16.0, 19.0] 17.998225 (19.0, 23.0] 21.479578 (23.0, 27.0] 25.477695 (27.0, 31.0] 29.440277 (31.0, 37.0] 34.399984 (37.0, 44.0] 40.804197 (44.0, 54.0] 49.080055 (54.0, 148.0] 67.818124 week_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) Datum/Zeit 0 30.795003 1 31.919744 2 32.267578 3 32.525385 4 31.770725 5 28.693349 6 25.967082 df1 . plot () <matplotlib.axes._subplots.AxesSubplot at 0x7feedcd0e780> http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / stickstoffmonoxid / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / lufttemperatur - aussen / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / stickstoffdioxid / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / staub - pm - 25 / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / staubpartikel - pm10 / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / staubpartikel - pm10 / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv urls = { 'stickstoffmonoxid' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/stickstoffmonoxid/csv-export/SUN/nuernberg-jakobsplatz/stickstoffmonoxid/7-Tages-Ansicht/export.csv\" , 'stickstoffdioxid' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/stickstoffdioxid/csv-export/SUN/nuernberg-jakobsplatz/stickstoffdioxid/7-Tages-Ansicht/export.csv\" , 'ozon' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/ozon/csv-export/SUN/nuernberg-jakobsplatz/ozon/7-Tages-Ansicht/export.csv\" , 'pm10' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/feinstaub-pm10/csv-export/SUN/nuernberg-jakobsplatz/staubpartikel-pm10/7-Tages-Ansicht/export.csv\" , 'pm25' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/feinstaub-pm25/csv-export/SUN/nuernberg-jakobsplatz/staub-pm-25/7-Tages-Ansicht/export.csv\" } opts = { 'skiprows' : range ( 10 ), 'encoding' : 'ISO-8859-1' , 'sep' : \";\" , 'index_col' : 0 } res = { comp : pd . read_csv ( url , ** opts ) for comp , url in urls . items ()} http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / stickstoffdioxid / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv [ df . shape for df in res . values ()] [(187, 1), (187, 1), (187, 1), (187, 1), (187, 1)] res [ 'ozon' ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) Datum/Zeit 20.11.2019 01:00 23 20.11.2019 02:00 31 20.11.2019 03:00 32 20.11.2019 04:00 25 20.11.2019 05:00 27 ... ... 27.11.2019 15:00 12 27.11.2019 16:00 8 27.11.2019 17:00 6 27.11.2019 18:00 3 27.11.2019 19:00 - 187 rows \u00d7 1 columns import stumpy val = dfk . dropna () . to_numpy () . ravel () st = stumpy . stump ( val , val . size // 330 ) import matplotlib.pyplot as plt fig , axs = plt . subplots ( 2 , sharex = True , figsize = ( 16 , 9 ), gridspec_kw = { 'hspace' : 0 }) plt . suptitle ( 'Discord (Anomaly/Novelty) Discovery' , fontsize = '30' ) axs [ 0 ] . plot ( val ) axs [ 1 ] . set_xlabel ( 'Time' , fontsize = '20' ) axs [ 1 ] . set_ylabel ( 'Matrix Profile' , fontsize = '20' ) #axs[1].axvline(x=3864, linestyle=\"dashed\") axs [ 1 ] . plot ( st [:, 0 ]) [<matplotlib.lines.Line2D at 0x7f03c4501860>]","title":"00 fetch data"},{"location":"_nb/%3DPy/05_pandas_xarray/00_fetch_data/#adac-df0-mit-abgasnorm-euro-6d-temp-euro-6d","text":"ADAC - df0 mit Abgasnorm Euro 6d-Temp, Euro 6d url = \"https://www.adac.de/rund-ums-fahrzeug/auto-kaufen-verkaufen/neuwagenkauf/euro-6d-temp-modelle\" res = pd . read_html ( url , header = 0 ) Concatenate all tables and reindex df0 = pd . concat (( elt for elt in res ), ignore_index = True ) df0 . rename ({ 'Markt- einf\u00fchrung' : 'Markteinfuehrung' , 'Hubraum in ccm' : 'Hubraum' , 'Leistung in KW' : 'Leistung' }, axis = 1 , inplace = True ) Convert Markteinfuehrung col to datetime For date manipulation, see for ex.https://www.python-kurs.eu/python3_time_and_date.php import locale locale . setlocale ( locale . LC_ALL , 'de_DE.UTF-8' ) pat = r \"^(\\w {3} ).*(\\d {2} )$\" repl = lambda m : f \" { m . group ( 1 ) } { m . group ( 2 ) } \" df0 . Markteinfuehrung = df0 . Markteinfuehrung \\ . str . replace ( '^v' , 'Nov' ) \\ . str . replace ( '(Mrz|Mar)' , 'M\u00e4r' ) \\ . str . replace ( pat , repl ) df0 . Markteinfuehrung = pd . to_datetime ( df0 . Markteinfuehrung , format = '%b %y' , errors = 'coerce' ) df0 = df0 . astype ({ 'Hersteller' : 'category' , 'Modell' : str , 'Motorart' : 'category' , 'Abgasnorm' : 'category' }) df0 . dtypes Hersteller category Modell object Motorart category Hubraum int64 Leistung int64 Abgasnorm category Markteinfuehrung datetime64[ns] dtype: object df0 . sample ( 3 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Hersteller Modell Motorart Hubraum Leistung Abgasnorm Markteinfuehrung 2677 VW Caddy Maxi Kombi 2.0 TDI SCR Diesel 1968 75 Euro 6d-TEMP-EVAP 2018-10-01 690 Dacia Dokker Blue dCi 75 Diesel 1461 55 Euro 6d-TEMP-EVAP 2018-09-01 1226 Lamborghini Hurac\u00e1n LP580-2 Otto 5204 426 Euro 6d-TEMP 2018-09-01 df0 . memory_usage () Index 128 Hersteller 4506 Modell 22992 Motorart 3082 Hubraum 22992 Leistung 22992 Abgasnorm 3250 Markteinfuehrung 22992 dtype: int64 Save to the store store . put ( 'ADAC' , df0 , format = 'table' ) print ( store . info ()) <class 'pandas.io.pytables.HDFStore'> File path: store.h5 /ADAC frame_table (typ->appendable,nrows->2874,ncols->7,indexers->[index],dc->[]) /ADAC/meta/values_block_0/meta series_table (typ->appendable,nrows->44,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_1/meta series_table (typ->appendable,nrows->6,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_2/meta series_table (typ->appendable,nrows->7,ncols->1,indexers->[index],dc->[values]) store . get ( '/ADAC' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Hersteller Modell Motorart Hubraum Leistung Abgasnorm Markteinfuehrung 0 Abarth 595 Otto 1368 107 Euro 6d-TEMP-EVAP 2018-09-01 1 Abarth 595 Pista Otto 1368 118 Euro 6d-TEMP-EVAP 2018-09-01 2 Abarth 595 Turismo Otto 1368 121 Euro 6d-TEMP-EVAP 2018-09-01 3 Abarth 595 Competizione Otto 1368 132 Euro 6d-TEMP-EVAP 2018-09-01 4 Abarth 595C Otto 1368 107 Euro 6d-TEMP-EVAP 2018-09-01 ... ... ... ... ... ... ... ... 2869 VW Touran 2.0 TDI SCR Diesel 1968 140 Euro 6d-TEMP 2019-01-01 2870 VW up! 1.0 Otto 999 44 Euro 6d-TEMP 2018-08-01 2871 VW up! 1.0 Otto 999 55 Euro 6d-TEMP 2018-08-01 2872 VW up! 1.0 TSI Otto 999 66 Euro 6d-TEMP 2018-09-01 2873 VW up! GTI Otto 999 85 Euro 6d-TEMP 2018-01-01 2874 rows \u00d7 7 columns","title":"ADAC - df0 mit Abgasnorm Euro 6d-Temp, Euro 6d"},{"location":"_nb/%3DPy/05_pandas_xarray/00_fetch_data/#umweltdaten-nurnberg","text":"Messstation Jakobsplatz - Stadt N\u00fcrnberg from datetime import datetime today = datetime.today() from string import Template url = Template((\"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/\" \"archiv/csv-export/SUN/ {where}/ {where}/ /\" \"individuell/ {first}/ {first}/ /export.csv\")) make_url = lambda where, what, year: url.substitute( where=where, what=what, first=f\"01.01.{year}\", until=f'31.12.{year}') def get_air_data_in_nuremberg ( where : str , what : str , year : int ): opts = { 'skiprows' : range ( 0 , 10 ), 'encoding' : 'ISO-8859-1' , 'sep' : ';' , 'parse_dates' : [ 0 ], 'index_col' : 0 , 'na_values' : [ '-' ] } url = ( f \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/\" f \"archiv/csv-export/SUN/ { where } / { what } /\" f \"individuell/01.01. { year } /31.12. { year } /export.csv\" ) return pd . read_csv ( url , ** opts ) df = pd . concat ([ get_air_data_in_nuremberg ( where = \"nuernberg-jakobsplatz\" , what = \"stickstoffdioxid\" , year = y ) for y in range ( 2005 , 2020 )]) http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / messstation - jakobsplatz / feinstaub - pm10 / csv - export / SUN / nuernberg - jakobsplatz / staubpartikel - pm10 / 7 - Tages - Ansicht / export . csv Nu2HD5 = { 'nuernberg-jakobsplatz' : 'JAKOBSPALTZ' , 'nuernberg-flugfeld' : 'FLUGFELD' , 'stickstoffmonoxid' : 'NO' , 'stickstoffdioxid' : 'NO2' , 'ozon' : 'O3' , 'staubpartikel-pm10' : 'PM10' , 'staub-pm-25' : 'PM25' } from itertools import product for what , where in product ([ k for k in Nu2HD5 . keys () if 'nuernberg' not in k ], [ k for k in Nu2HD5 . keys () if 'nuernberg' in k ]): try : df = pd . concat ([ get_air_data_in_nuremberg ( where = where , what = what , year = y ) for y in range ( 2005 , 2020 )]) tableName = f \"AIR/ { Nu2HD5 [ where ] } / { Nu2HD5 [ what ] } \" store . put ( tableName , df , format = 'table' ) except Exception as e : print ( e ) print ( store . info ()) <class 'pandas.io.pytables.HDFStore'> File path: store.h5 /ADAC frame_table (typ->appendable,nrows->2874,ncols->7,indexers->[index],dc->[]) /ADAC/meta/values_block_0/meta series_table (typ->appendable,nrows->44,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_1/meta series_table (typ->appendable,nrows->6,ncols->1,indexers->[index],dc->[values]) /ADAC/meta/values_block_2/meta series_table (typ->appendable,nrows->7,ncols->1,indexers->[index],dc->[values]) /AIR/FLUGFELD/NO frame_table (typ->appendable,nrows->127817,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/NO2 frame_table (typ->appendable,nrows->127779,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/O3 frame_table (typ->appendable,nrows->129541,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/PM10 frame_table (typ->appendable,nrows->130374,ncols->1,indexers->[index],dc->[]) /AIR/FLUGFELD/PM25 frame_table (typ->appendable,nrows->103667,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/NO frame_table (typ->appendable,nrows->123168,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/NO2 frame_table (typ->appendable,nrows->123353,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/O3 frame_table (typ->appendable,nrows->125972,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/PM10 frame_table (typ->appendable,nrows->126952,ncols->1,indexers->[index],dc->[]) /AIR/JAKOBSPALTZ/PM25 frame_table (typ->appendable,nrows->87343,ncols->1,indexers->[index],dc->[]) df1 = store . get ( '/AIR/JAKOBSPALTZ/O3' ) df1 . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) Datum/Zeit 2005-05-24 21:00:00 59.0 2005-01-06 00:00:00 57.0 2005-01-06 01:00:00 49.0 2005-01-06 02:00:00 51.0 2005-01-06 03:00:00 34.0 df1 . groupby ( df1 . index . weekday ) . boxplot ( layout = ( 1 , 7 ), figsize = ( 16 , 6 ));","title":"Umweltdaten N\u00fcrnberg"},{"location":"_nb/%3DPy/05_pandas_xarray/00_fetch_data/#with-pandas","text":"dfk = pd . read_csv ( make_url ( where = \"nuernberg-jakobsplatz\" , what = \"stickstoffdioxid\" , year = 2019 ), ** opts ) The data will be retrieved year for year, see no \" Da bei den Abfragen m\u00f6glicherweise gro\u00dfe Datenmengen entstehen, wird empfohlen maximal 12 Monate als Bezugszeitraum anzugeben und bei Bedarf mehrere Abfragen durchzuf\u00fchren. \"","title":"with pandas"},{"location":"_nb/%3DPy/05_pandas_xarray/00_fetch_data/#with-pyarrow","text":"from pyarrow import csv from pyarrow.csv import ( ReadOptions , ParseOptions , ConvertOptions ) read_opts = ReadOptions ( skip_rows = 13 , column_names = [ \"Date\" , \"NO2\" ]) parse_opts = ParseOptions ( delimiter = ';' ) conv_opts = ConvertOptions ( column_types = { 'NO2' : pa . int32 ()}, null_values = [ \"-\" ]) # Date are not an # 'Date': pa.timestamp('s'), from io import ( BytesIO , StringIO ) bio = BytesIO ( r . content . decode ( encoding = 'ISO-8859-1' ) . encode ()) table = csv . read_csv ( bio , read_options = read_opts , parse_options = parse_opts , convert_options = conv_opts ) table . schema Date: string NO2: int32 dfk . boxplot () <matplotlib.axes._subplots.AxesSubplot at 0x7f6fe5bd2710> import pyarrow as pa from pyarrow import csv from requests import Session year = 1 u1 = url . substitute ( what = \"stickstoffdioxid\" , first = today . strftime ( ' %d .%m.' ) + str ( today . year - year - 1 ), until = today . strftime ( ' %d .%m.' ) + str ( today . year - year )) s = Session () r = s . get ( u1 ) table . schema Date: string NO2: int32 table . to_pandas () Date object NO2 float64 dtype: object df1 = pd . concat (( pd . read_csv ( url . substitute ( what = \"stickstoffdioxid\" , first = today . strftime ( ' %d .%m.' ) + str ( today . year - year - 1 ), until = today . strftime ( ' %d .%m.' ) + str ( today . year - year )), ** opts ) for year in range ( 15 ))) df1 . info () <class 'pandas.core.frame.DataFrame'> DatetimeIndex: 112269 entries, 2019-01-01 01:00:00 to 2005-11-27 23:00:00 Data columns (total 1 columns): Wert (\u00b5g/m\u00b3) 111358 non-null float64 dtypes: float64(1) memory usage: 1.7 MB df1 [ 'Wert (\u00b5g/m\u00b3)' ] . metadata = {} df1 [ 'Wert (\u00b5g/m\u00b3)' ] . iloc [: 30 ] Datum/Zeit 2019-01-01 01:00:00 30.0 2019-01-01 02:00:00 29.0 2019-01-01 03:00:00 24.0 2019-01-01 04:00:00 22.0 2019-01-01 05:00:00 20.0 ... 2019-02-01 02:00:00 8.0 2019-02-01 03:00:00 6.0 2019-02-01 04:00:00 7.0 2019-02-01 05:00:00 6.0 2019-02-01 06:00:00 8.0 Name: Wert (\u00b5g/m\u00b3), Length: 30, dtype: float64 week_df = df1 . groupby ( df1 . index . weekday ) . mean () df1 . groupby ( df1 . index . weekday ) . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Wert (\u00b5g/m\u00b3) count mean std min 25% 50% 75% max Datum/Zeit 0 15849.0 30.795003 17.231654 1.0 18.0 27.0 40.0 133.0 1 15949.0 31.919744 17.604728 0.0 19.0 28.0 41.0 129.0 2 15943.0 32.267578 17.488338 0.0 19.0 29.0 42.0 148.0 3 15954.0 32.525385 17.798968 1.0 19.0 29.0 42.0 135.0 4 15959.0 31.770725 17.249226 -1.0 19.0 28.0 41.0 135.0 5 15816.0 28.693349 15.996195 0.0 17.0 25.0 37.0 129.0 6 15888.0 25.967082 16.686306 0.0 14.0 22.0 34.0 128.0 \" Although fine particle OC concentrations did not correlate with day of the week, EC concentrations showed a significant weekly pattern, with the highest concentration during the middle of the workweek and the lowest concentration on Sundays. \" https://www.ncbi.nlm.nih.gov/pubmed/15303295 df1 . groupby ( df1 . index . weekday ) . boxplot ( layout = ( 1 , 7 ), figsize = ( 16 , 6 )); gp = df1 . groupby ( df1 . index . weekday ) % timeit df1 [ df1 . index . weekday == 2 ] 7.61 ms \u00b1 75.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) % timeit df1 . groupby ( df1 . index . weekday ) . get_group ( 2 ) 10.2 ms \u00b1 73.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each) df_wend = df1 [ df1 . index . weekday == 2 ] df_wend . groupby ( df_wend . index . hour ) . mean () . plot () <matplotlib.axes._subplots.AxesSubplot at 0x7f6ff53afc88> import seaborn as sns df_wend_h = df_wend . groupby ( df_wend . index . hour ) df_wend_h . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Wert (\u00b5g/m\u00b3) count mean std min 25% 50% 75% max Datum/Zeit 0 667.0 35.112444 19.408852 0.0 20.0 30.0 46.00 117.0 1 665.0 32.306767 18.458983 0.0 18.0 28.0 44.00 105.0 2 665.0 29.712782 17.153460 0.0 16.0 25.0 40.00 94.0 3 666.0 28.234234 15.617778 0.0 16.0 25.0 37.00 92.0 4 667.0 28.008996 14.758310 1.0 16.0 25.0 37.00 86.0 ... ... ... ... ... ... ... ... ... 19 667.0 35.962519 18.899770 6.0 21.0 32.0 46.00 144.0 20 668.0 38.938623 19.969410 6.0 25.0 36.0 48.25 148.0 21 666.0 39.978979 20.332119 4.0 25.0 36.0 50.00 125.0 22 665.0 40.756391 20.704699 6.0 26.0 37.0 52.00 124.0 23 665.0 39.533835 20.385202 5.0 24.0 36.0 51.00 118.0 24 rows \u00d7 8 columns sns . pointplot ( x = \"day\" , y = \"tip\" , data = tips , ci = 68 ) df_wend_h . boxplot ( subplots = False , figsize = ( 16 , 6 ), column = list ( df_wend_h . groups . keys ())) <matplotlib.axes._subplots.AxesSubplot at 0x7f6fe55677b8> df_wend_h . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } Wert (\u00b5g/m\u00b3) count mean std min 25% 50% 75% max Datum/Zeit 0 667.0 35.112444 19.408852 0.0 20.0 30.0 46.00 117.0 1 665.0 32.306767 18.458983 0.0 18.0 28.0 44.00 105.0 2 665.0 29.712782 17.153460 0.0 16.0 25.0 40.00 94.0 3 666.0 28.234234 15.617778 0.0 16.0 25.0 37.00 92.0 4 667.0 28.008996 14.758310 1.0 16.0 25.0 37.00 86.0 ... ... ... ... ... ... ... ... ... 19 667.0 35.962519 18.899770 6.0 21.0 32.0 46.00 144.0 20 668.0 38.938623 19.969410 6.0 25.0 36.0 48.25 148.0 21 666.0 39.978979 20.332119 4.0 25.0 36.0 50.00 125.0 22 665.0 40.756391 20.704699 6.0 26.0 37.0 52.00 124.0 23 665.0 39.533835 20.385202 5.0 24.0 36.0 51.00 118.0 24 rows \u00d7 8 columns df_wend_h . boxplot ( by = 'Datum/Zeit' , figsize = ( 16 , 10 )); --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) <ipython-input-204-ee7cf848b6f4> in <module> ----> 1 df_wend_h . boxplot ( by = 'Datum/Zeit' , figsize = ( 16 , 10 ) ) ; /opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py in boxplot_frame_groupby (grouped, subplots, column, fontsize, rot, grid, ax, figsize, layout, sharex, sharey, **kwds) 498 sharex = sharex , 499 sharey = sharey , --> 500 ** kwds 501 ) 502 /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in boxplot_frame_groupby (grouped, subplots, column, fontsize, rot, grid, ax, figsize, layout, sharex, sharey, **kwds) 390 for ( key , group ) , ax in zip ( grouped , axes ) : 391 d = group.boxplot( --> 392 ax = ax , column = column , fontsize = fontsize , rot = rot , grid = grid , ** kwds 393 ) 394 ax . set_title ( pprint_thing ( key ) ) /opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py in boxplot_frame (self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds) 418 layout = layout , 419 return_type = return_type , --> 420 ** kwds 421 ) 422 /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in boxplot_frame (self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds) 353 layout = layout , 354 return_type = return_type , --> 355 ** kwds 356 ) 357 plt . draw_if_interactive ( ) /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in boxplot (data, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds) 300 ax = ax , 301 layout = layout , --> 302 return_type = return_type , 303 ) 304 else : /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in _grouped_plot_by_column (plotf, data, columns, by, numeric_only, grid, figsize, ax, layout, return_type, **kwargs) 205 gp_col = grouped [ col ] 206 keys , values = zip ( * gp_col ) --> 207 re_plotf = plotf ( keys , values , ax , ** kwargs ) 208 ax . set_title ( col ) 209 ax . set_xlabel ( pprint_thing ( by ) ) /opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/boxplot.py in plot_group (keys, values, ax) 262 keys = [ pprint_thing ( x ) for x in keys ] 263 values = [ np . asarray ( remove_na_arraylike ( v ) ) for v in values ] --> 264 bp = ax . boxplot ( values , ** kwds ) 265 if fontsize is not None : 266 ax . tick_params ( axis = \"both\" , labelsize = fontsize ) /opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper (*args, **kwargs) 305 f\"for the old name will be dropped %(removal)s.\") 306 kwargs [ new ] = kwargs . pop ( old ) --> 307 return func ( * args , ** kwargs ) 308 309 # wrapper() must keep the same documented signature as func(): if we /opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner (ax, data, *args, **kwargs) 1599 def inner ( ax , * args , data = None , ** kwargs ) : 1600 if data is None : -> 1601 return func ( ax , * map ( sanitize_sequence , args ) , ** kwargs ) 1602 1603 bound = new_sig . bind ( ax , * args , ** kwargs ) /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in boxplot (self, x, notch, sym, vert, whis, positions, widths, patch_artist, bootstrap, usermedians, conf_intervals, meanline, showmeans, showcaps, showbox, showfliers, boxprops, labels, flierprops, medianprops, meanprops, capprops, whiskerprops, manage_ticks, autorange, zorder) 3770 meanline = meanline , showfliers = showfliers , 3771 capprops = capprops , whiskerprops = whiskerprops , -> 3772 manage_ticks=manage_ticks, zorder=zorder) 3773 return artists 3774 /opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper (*args, **kwargs) 305 f\"for the old name will be dropped %(removal)s.\") 306 kwargs [ new ] = kwargs . pop ( old ) --> 307 return func ( * args , ** kwargs ) 308 309 # wrapper() must keep the same documented signature as func(): if we /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in bxp (self, bxpstats, positions, widths, vert, patch_artist, shownotches, showmeans, showcaps, showbox, showfliers, boxprops, whiskerprops, flierprops, medianprops, capprops, meanprops, meanline, manage_ticks, zorder) 4094 4095 # draw the medians -> 4096 medians . extend ( doplot ( med_x , med_y , ** final_medianprops ) ) 4097 4098 # maybe draw the means /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in doplot (*args, **kwargs) 3996 if vert : 3997 def doplot ( * args , ** kwargs ) : -> 3998 return self . plot ( * args , ** kwargs ) 3999 4000 def dopatch ( xs , ys , ** kwargs ) : /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in plot (self, scalex, scaley, data, *args, **kwargs) 1667 for line in lines : 1668 self . add_line ( line ) -> 1669 self . autoscale_view ( scalex = scalex , scaley = scaley ) 1670 return lines 1671 /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py in autoscale_view (self, tight, scalex, scaley) 2493 handle_single_axis( 2494 scalex , self . _autoscaleXon , self . _shared_x_axes , 'intervalx' , -> 2495 'minposx', self.xaxis, self._xmargin, x_stickies, self.set_xbound) 2496 handle_single_axis( 2497 scaley , self . _autoscaleYon , self . _shared_y_axes , 'intervaly' , /opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py in handle_single_axis (scale, autoscaleon, shared_axes, interval, minpos, axis, margin, stickies, set_bound) 2460 x0 , x1 = getattr ( bb , interval ) 2461 locator = axis . get_major_locator ( ) -> 2462 x0 , x1 = locator . nonsingular ( x0 , x1 ) 2463 2464 # Add the margin in figure space and then transform back, to handle /opt/conda/lib/python3.7/site-packages/matplotlib/ticker.py in nonsingular (self, v0, v1) 1523 def nonsingular ( self , v0 , v1 ) : 1524 \"\"\"Expand a range as needed to avoid singularities.\"\"\" -> 1525 return mtransforms . nonsingular ( v0 , v1 , expander = .05 ) 1526 1527 def view_limits ( self , vmin , vmax ) : /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in nonsingular (vmin, vmax, expander, tiny, increasing) 2825 swapped = True 2826 -> 2827 maxabsvalue = max ( abs ( vmin ) , abs ( vmax ) ) 2828 if maxabsvalue < ( 1e6 / tiny ) * np . finfo ( float ) . tiny : 2829 vmin = - expander KeyboardInterrupt : Error in callback <function flush_figures at 0x7f6ff8de0d90> (for post_execute): --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) /opt/conda/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py in flush_figures () 115 # ignore the tracking, just draw and close all figures 116 try : --> 117 return show ( True ) 118 except Exception as e : 119 # safely show traceback if in IPython, else raise /opt/conda/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py in show (close, block) 37 display( 38 figure_manager . canvas . figure , ---> 39 metadata = _fetch_figure_metadata ( figure_manager . canvas . figure ) 40 ) 41 finally : /opt/conda/lib/python3.7/site-packages/IPython/core/display.py in display (include, exclude, metadata, transient, display_id, *objs, **kwargs) 311 publish_display_data ( data = obj , metadata = metadata , ** kwargs ) 312 else : --> 313 format_dict , md_dict = format ( obj , include = include , exclude = exclude ) 314 if not format_dict : 315 # nothing to display (e.g. _ipython_display_ took over) /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in format (self, obj, include, exclude) 178 md = None 179 try : --> 180 data = formatter ( obj ) 181 except : 182 # FIXME: log the exception </opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-9> in __call__ (self, obj) /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in catch_format_error (method, self, *args, **kwargs) 222 \"\"\"show traceback on failed format call\"\"\" 223 try : --> 224 r = method ( self , * args , ** kwargs ) 225 except NotImplementedError : 226 # don't warn on NotImplementedErrors /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in __call__ (self, obj) 339 pass 340 else : --> 341 return printer ( obj ) 342 # Finally look for special method names 343 method = get_real_method ( obj , self . print_method ) /opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py in <lambda> (fig) 242 243 if 'png' in formats : --> 244 png_formatter . for_type ( Figure , lambda fig : print_figure ( fig , 'png' , ** kwargs ) ) 245 if 'retina' in formats or 'png2x' in formats : 246 png_formatter . for_type ( Figure , lambda fig : retina_figure ( fig , ** kwargs ) ) /opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py in print_figure (fig, fmt, bbox_inches, **kwargs) 126 127 bytes_io = BytesIO ( ) --> 128 fig . canvas . print_figure ( bytes_io , ** kw ) 129 data = bytes_io . getvalue ( ) 130 if fmt == 'svg' : /opt/conda/lib/python3.7/site-packages/matplotlib/backend_bases.py in print_figure (self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2058 bbox_artists = kwargs . pop ( \"bbox_extra_artists\" , None ) 2059 bbox_inches = self.figure.get_tightbbox(renderer, -> 2060 bbox_extra_artists=bbox_artists) 2061 pad = kwargs . pop ( \"pad_inches\" , None ) 2062 if pad is None : /opt/conda/lib/python3.7/site-packages/matplotlib/figure.py in get_tightbbox (self, renderer, bbox_extra_artists) 2386 return self . bbox_inches 2387 -> 2388 _bbox = Bbox . union ( bb ) 2389 2390 bbox_inches = TransformedBbox(_bbox, /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in union (bboxes) 702 x0 = np . min ( [ bbox . xmin for bbox in bboxes ] ) 703 x1 = np . max ( [ bbox . xmax for bbox in bboxes ] ) --> 704 y0 = np . min ( [ bbox . ymin for bbox in bboxes ] ) 705 y1 = np . max ( [ bbox . ymax for bbox in bboxes ] ) 706 return Bbox ( [ [ x0 , y0 ] , [ x1 , y1 ] ] ) /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in <listcomp> (.0) 702 x0 = np . min ( [ bbox . xmin for bbox in bboxes ] ) 703 x1 = np . max ( [ bbox . xmax for bbox in bboxes ] ) --> 704 y0 = np . min ( [ bbox . ymin for bbox in bboxes ] ) 705 y1 = np . max ( [ bbox . ymax for bbox in bboxes ] ) 706 return Bbox ( [ [ x0 , y0 ] , [ x1 , y1 ] ] ) /opt/conda/lib/python3.7/site-packages/matplotlib/transforms.py in ymin (self) 353 def ymin ( self ) : 354 \"\"\"The bottom edge of the bounding box.\"\"\" --> 355 return np . min ( self . get_points ( ) [ : , 1 ] ) 356 357 @ property <__array_function__ internals> in amin (*args, **kwargs) /opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in amin (a, axis, out, keepdims, initial, where) 2744 \"\"\" 2745 return _wrapreduction(a, np.minimum, 'min', axis, None, out, -> 2746 keepdims=keepdims, initial=initial, where=where) 2747 2748 /opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapreduction (obj, ufunc, method, axis, dtype, out, **kwargs) 88 return reduction ( axis = axis , out = out , ** passkwargs ) 89 ---> 90 return ufunc . reduce ( obj , axis , dtype , out , ** passkwargs ) 91 92 KeyboardInterrupt : df1 . describe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) count 111358.000000 mean 30.567341 std 17.305318 min -1.000000 25% 18.000000 50% 27.000000 75% 40.000000 max 148.000000 np . arange ( - 1 , 150 , 20 ) . reshape ( 1 , 8 ) . shape (1, 8) df1 . iloc [:, 0 ] . to_numpy () array([30., 29., 24., ..., 38., 33., 39.]) cut = pd . qcut ( df1 . iloc [:, 0 ] . to_numpy (), q = 10 ) df1 . groupby ( cut ) . mean () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) (-1.001, 12.0] 9.379547 (12.0, 16.0] 14.562010 (16.0, 19.0] 17.998225 (19.0, 23.0] 21.479578 (23.0, 27.0] 25.477695 (27.0, 31.0] 29.440277 (31.0, 37.0] 34.399984 (37.0, 44.0] 40.804197 (44.0, 54.0] 49.080055 (54.0, 148.0] 67.818124 week_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) Datum/Zeit 0 30.795003 1 31.919744 2 32.267578 3 32.525385 4 31.770725 5 28.693349 6 25.967082 df1 . plot () <matplotlib.axes._subplots.AxesSubplot at 0x7feedcd0e780> http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / stickstoffmonoxid / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / lufttemperatur - aussen / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / stickstoffdioxid / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / staub - pm - 25 / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / staubpartikel - pm10 / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / staubpartikel - pm10 / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv urls = { 'stickstoffmonoxid' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/stickstoffmonoxid/csv-export/SUN/nuernberg-jakobsplatz/stickstoffmonoxid/7-Tages-Ansicht/export.csv\" , 'stickstoffdioxid' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/stickstoffdioxid/csv-export/SUN/nuernberg-jakobsplatz/stickstoffdioxid/7-Tages-Ansicht/export.csv\" , 'ozon' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/ozon/csv-export/SUN/nuernberg-jakobsplatz/ozon/7-Tages-Ansicht/export.csv\" , 'pm10' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/feinstaub-pm10/csv-export/SUN/nuernberg-jakobsplatz/staubpartikel-pm10/7-Tages-Ansicht/export.csv\" , 'pm25' : \"http://umweltdaten.nuernberg.de/csv/aussenluft/stadt-nuernberg/messstation-jakobsplatz/feinstaub-pm25/csv-export/SUN/nuernberg-jakobsplatz/staub-pm-25/7-Tages-Ansicht/export.csv\" } opts = { 'skiprows' : range ( 10 ), 'encoding' : 'ISO-8859-1' , 'sep' : \";\" , 'index_col' : 0 } res = { comp : pd . read_csv ( url , ** opts ) for comp , url in urls . items ()} http : // umweltdaten . nuernberg . de / csv / aussenluft / stadt - nuernberg / archiv / csv - export / SUN / nuernberg - jakobsplatz / stickstoffdioxid / individuell / 01.06 . 2005 / 27.11 . 2019 / export . csv [ df . shape for df in res . values ()] [(187, 1), (187, 1), (187, 1), (187, 1), (187, 1)] res [ 'ozon' ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Wert (\u00b5g/m\u00b3) Datum/Zeit 20.11.2019 01:00 23 20.11.2019 02:00 31 20.11.2019 03:00 32 20.11.2019 04:00 25 20.11.2019 05:00 27 ... ... 27.11.2019 15:00 12 27.11.2019 16:00 8 27.11.2019 17:00 6 27.11.2019 18:00 3 27.11.2019 19:00 - 187 rows \u00d7 1 columns import stumpy val = dfk . dropna () . to_numpy () . ravel () st = stumpy . stump ( val , val . size // 330 ) import matplotlib.pyplot as plt fig , axs = plt . subplots ( 2 , sharex = True , figsize = ( 16 , 9 ), gridspec_kw = { 'hspace' : 0 }) plt . suptitle ( 'Discord (Anomaly/Novelty) Discovery' , fontsize = '30' ) axs [ 0 ] . plot ( val ) axs [ 1 ] . set_xlabel ( 'Time' , fontsize = '20' ) axs [ 1 ] . set_ylabel ( 'Matrix Profile' , fontsize = '20' ) #axs[1].axvline(x=3864, linestyle=\"dashed\") axs [ 1 ] . plot ( st [:, 0 ]) [<matplotlib.lines.Line2D at 0x7f03c4501860>]","title":"with pyarrow"},{"location":"_nb/%3DPy/05_pandas_xarray/Interval%20and%20IntervalArray/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import xarray xarray . set_options ( display_style = \"html\" ) import numpy as np import pandas as pd from pandas import ( DataFrame , Series , Interval ) from pandas.arrays import IntervalArray from xarray import DataArray % load_ext watermark % watermark - vdmp xarray The watermark extension is already loaded. To reload it, use: %reload_ext watermark 2019-11-27 CPython 3.7.3 IPython 7.9.0 xarray 0.14.1 compiler : GCC 7.3.0 system : Linux release : 5.0.0-36-generic machine : x86_64 processor : x86_64 CPU cores : 8 interpreter: 64bit Interval \u00b6 Pandas IntervalDtype extends Numpy ndarray type . This is not an actual numpy dtype , but a duck type. An Interval is an immutable object implementing a bounded slice-like interval. Parameters: - left: scalar - right: scalar - closed: string , default to right s = Series ( np . random . randint ( 1 , 100 , size = 100 )) r = pd . cut ( s , np . arange ( 0 , 101 , 20 )) r . sample ( 3 ) 14 (20, 40] 92 (0, 20] 97 (0, 20] dtype: category Categories (5, interval[int64]): [(0, 20] < (20, 40] < (40, 60] < (60, 80] < (80, 100]] IntervalArray \u00b6 IntervalArray . from_arrays ([ 0 , 1 , 2 ], [ 1 , 2 , 3 ]) IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') IntervalArray . from_tuples ((( 0 , 1 ), ( 1 , 2 ), ( 2 , 3 ))) IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') IntervalArray . from_breaks ([ 0 , 1 , 2 , 3 ]) IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') intervals = IntervalArray . from_breaks ([ 0 , 1 , 2 , 3 ]) from sys import getsizeof getsizeof ( intervals ) 56 intervals . take ([ 1 ]) IntervalArray([(1, 2]], closed='right', dtype='interval[int64]') intervals IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') a = np . array ([( 1 , 2 ), ( 2 , 3 )], dtype = [( 'lb' , np . int32 ), ( 'ub' , np . int32 )]) da = DataArray ( range ( 2 ), coords = [( 'x' , IntervalArray ([ Interval ( * v ) for v in a ]))]) da + da Show/Hide data repr Show/Hide attributes /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } .xr-wrap { min-width: 300px; max-width: 700px; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u25ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u25bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } xarray.DataArray x : 2 0 2 array([0, 2]) Coordinates: (1) x (x) object (1, 2] (2, 3] array([Interval(1, 2, closed='right'), Interval(2, 3, closed='right')], dtype=object) Attributes: (0) da . plot . hist () (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), <a list of 10 Patch objects>) i = Interval ( left = 0 , right = 5 ) i . length 5 da . to_dict () {'dims': ('x',), 'attrs': {}, 'data': [0, 1], 'coords': {'x': {'dims': ('x',), 'attrs': {}, 'data': [Interval(1, 2, closed='right'), Interval(2, 3, closed='right')]}}, 'name': None} da . to_masked_array () masked_array(data=[0, 1], mask=[False, False], fill_value=999999)","title":"Interval and IntervalArray"},{"location":"_nb/%3DPy/05_pandas_xarray/Interval%20and%20IntervalArray/#interval","text":"Pandas IntervalDtype extends Numpy ndarray type . This is not an actual numpy dtype , but a duck type. An Interval is an immutable object implementing a bounded slice-like interval. Parameters: - left: scalar - right: scalar - closed: string , default to right s = Series ( np . random . randint ( 1 , 100 , size = 100 )) r = pd . cut ( s , np . arange ( 0 , 101 , 20 )) r . sample ( 3 ) 14 (20, 40] 92 (0, 20] 97 (0, 20] dtype: category Categories (5, interval[int64]): [(0, 20] < (20, 40] < (40, 60] < (60, 80] < (80, 100]]","title":"Interval"},{"location":"_nb/%3DPy/05_pandas_xarray/Interval%20and%20IntervalArray/#intervalarray","text":"IntervalArray . from_arrays ([ 0 , 1 , 2 ], [ 1 , 2 , 3 ]) IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') IntervalArray . from_tuples ((( 0 , 1 ), ( 1 , 2 ), ( 2 , 3 ))) IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') IntervalArray . from_breaks ([ 0 , 1 , 2 , 3 ]) IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') intervals = IntervalArray . from_breaks ([ 0 , 1 , 2 , 3 ]) from sys import getsizeof getsizeof ( intervals ) 56 intervals . take ([ 1 ]) IntervalArray([(1, 2]], closed='right', dtype='interval[int64]') intervals IntervalArray([(0, 1], (1, 2], (2, 3]], closed='right', dtype='interval[int64]') a = np . array ([( 1 , 2 ), ( 2 , 3 )], dtype = [( 'lb' , np . int32 ), ( 'ub' , np . int32 )]) da = DataArray ( range ( 2 ), coords = [( 'x' , IntervalArray ([ Interval ( * v ) for v in a ]))]) da + da Show/Hide data repr Show/Hide attributes /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1)); --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54)); --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38)); --xr-border-color: var(--jp-border-color2, #e0e0e0); --xr-disabled-color: var(--jp-layout-color3, #bdbdbd); --xr-background-color: var(--jp-layout-color0, white); --xr-background-color-row-even: var(--jp-layout-color1, white); --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee); } .xr-wrap { min-width: 300px; max-width: 700px; } .xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(--xr-border-color); } .xr-header > div, .xr-header > ul { display: inline; margin-top: 0; margin-bottom: 0; } .xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; } .xr-obj-type { color: var(--xr-font-color2); } .xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; } .xr-section-item { display: contents; } .xr-section-item input { display: none; } .xr-section-item input + label { color: var(--xr-disabled-color); } .xr-section-item input:enabled + label { cursor: pointer; color: var(--xr-font-color2); } .xr-section-item input:enabled + label:hover { color: var(--xr-font-color0); } .xr-section-summary { grid-column: 1; color: var(--xr-font-color2); font-weight: 500; } .xr-section-summary > span { display: inline-block; padding-left: 0.5em; } .xr-section-summary-in:disabled + label { color: var(--xr-font-color2); } .xr-section-summary-in + label:before { display: inline-block; content: '\u25ba'; font-size: 11px; width: 15px; text-align: center; } .xr-section-summary-in:disabled + label:before { color: var(--xr-disabled-color); } .xr-section-summary-in:checked + label:before { content: '\u25bc'; } .xr-section-summary-in:checked + label > span { display: none; } .xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; } .xr-section-inline-details { grid-column: 2 / -1; } .xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; } .xr-section-summary-in:checked ~ .xr-section-details { display: contents; } .xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; } .xr-array-wrap > label { grid-column: 1; vertical-align: top; } .xr-preview { color: var(--xr-font-color3); } .xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; } .xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; } .xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; } .xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; } .xr-dim-list li { display: inline-block; padding: 0; margin: 0; } .xr-dim-list:before { content: '('; } .xr-dim-list:after { content: ')'; } .xr-dim-list li:not(:last-child):after { content: ','; padding-right: 5px; } .xr-has-index { font-weight: bold; } .xr-var-list, .xr-var-item { display: contents; } .xr-var-item > div, .xr-var-item label, .xr-var-item > .xr-var-name span { background-color: var(--xr-background-color-row-even); margin-bottom: 0; } .xr-var-item > .xr-var-name:hover span { padding-right: 5px; } .xr-var-list > li:nth-child(odd) > div, .xr-var-list > li:nth-child(odd) > label, .xr-var-list > li:nth-child(odd) > .xr-var-name span { background-color: var(--xr-background-color-row-odd); } .xr-var-name { grid-column: 1; } .xr-var-dims { grid-column: 2; } .xr-var-dtype { grid-column: 3; text-align: right; color: var(--xr-font-color2); } .xr-var-preview { grid-column: 4; } .xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; } .xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; } .xr-var-attrs, .xr-var-data { display: none; background-color: var(--xr-background-color) !important; padding-bottom: 5px !important; } .xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; } .xr-var-data > table { float: right; } .xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; } .xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; } dl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; } .xr-attrs dt, dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; } .xr-attrs dt { font-weight: normal; grid-column: 1; } .xr-attrs dt:hover span { display: inline-block; background: var(--xr-background-color); padding-right: 10px; } .xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; } .xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } xarray.DataArray x : 2 0 2 array([0, 2]) Coordinates: (1) x (x) object (1, 2] (2, 3] array([Interval(1, 2, closed='right'), Interval(2, 3, closed='right')], dtype=object) Attributes: (0) da . plot . hist () (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), <a list of 10 Patch objects>) i = Interval ( left = 0 , right = 5 ) i . length 5 da . to_dict () {'dims': ('x',), 'attrs': {}, 'data': [0, 1], 'coords': {'x': {'dims': ('x',), 'attrs': {}, 'data': [Interval(1, 2, closed='right'), Interval(2, 3, closed='right')]}}, 'name': None} da . to_masked_array () masked_array(data=[0, 1], mask=[False, False], fill_value=999999)","title":"IntervalArray"},{"location":"data/_intro/","text":"Apache Arrow \u00b6","title":"Intro"},{"location":"data/_intro/#apache-arrow","text":"","title":"Apache Arrow"},{"location":"data/windowing/","text":"Windowing \u00b6 Machine learning and data exploring: the potential of windowing","title":"Windowing"},{"location":"data/windowing/#windowing","text":"Machine learning and data exploring: the potential of windowing","title":"Windowing"},{"location":"data/timeseries/_intro/","text":"Time series \u00b6 http://www.timeseriesclassification.com","title":"Intro"},{"location":"data/timeseries/_intro/#time-series","text":"http://www.timeseriesclassification.com","title":"Time series"},{"location":"data/timeseries/features/","text":"Time series features extraction \u00b6 https://towardsdatascience.com/time-series-feature-extraction-for-industrial-big-data-iiot-applications-5243c84aaf0e http://fastml.com/classifying-time-series-using-feature-extraction/","title":"Features selection"},{"location":"data/timeseries/features/#time-series-features-extraction","text":"https://towardsdatascience.com/time-series-feature-extraction-for-industrial-big-data-iiot-applications-5243c84aaf0e http://fastml.com/classifying-time-series-using-feature-extraction/","title":"Time series features extraction"},{"location":"data/timeseries/matrixprofile/","text":"Matrix profile \u00b6 Papers: Efficient Matrix Profile Computation Using DifferentDistance Functions Matrix Profile I: All Pairs Similarity Joins for Time Series:A Unifying View that Includes Motifs, Discords and Shapelets Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred MillionBarrierfor Time Series Motifs and Joins Stumpy \u00b6 Quote At its core, the STUMPY library efficiently computes something called a matrix profile , a vector that stores the z-normalized Euclidean distance between any subsequence within a time series and its nearest neigbor.","title":"Matrix profile"},{"location":"data/timeseries/matrixprofile/#matrix-profile","text":"Papers: Efficient Matrix Profile Computation Using DifferentDistance Functions Matrix Profile I: All Pairs Similarity Joins for Time Series:A Unifying View that Includes Motifs, Discords and Shapelets Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred MillionBarrierfor Time Series Motifs and Joins","title":"Matrix profile"},{"location":"data/timeseries/matrixprofile/#stumpy","text":"Quote At its core, the STUMPY library efficiently computes something called a matrix profile , a vector that stores the z-normalized Euclidean distance between any subsequence within a time series and its nearest neigbor.","title":"Stumpy "},{"location":"devops/ansible/","text":"Ansible \u00b6 Mac setup and configuration from Jeff Gerling github repo < Cowsay and Ansible > \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || || Testing \u00b6 Molecule \u00b6","title":"Ansible"},{"location":"devops/ansible/#ansible","text":"Mac setup and configuration from Jeff Gerling github repo < Cowsay and Ansible > \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || ||","title":"Ansible"},{"location":"devops/ansible/#testing","text":"","title":"Testing"},{"location":"devops/ansible/#molecule","text":"","title":"Molecule"},{"location":"devops/cicd/","text":"","title":"CI/CD"},{"location":"devops/cloudlandscape/","text":"","title":"Cloud landscape"},{"location":"devops/cloudnative/","text":"CNCF Coud Native Definition v1.0 English Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach. These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil. The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone. Fran\u00e7ais Les technologies nativement cloud permettent aux entreprises de construire et d'exploiter des applications \u00e9lastiques dans des environnements modernes et dynamiques comme des clouds publics, priv\u00e9s ou bien hybrides. Les conteneurs, les services maill\u00e9s, les micro services, les infrastructures immuables et les API d\u00e9claratives illustrent cette approche. Ces techniques permettent la mise en \u0153uvre de syst\u00e8mes faiblement coupl\u00e9s, \u00e0 la fois r\u00e9sistants, pilotables et observables. Combin\u00e9s \u00e0 un robuste syst\u00e8me d'automatisation, ils permettent aux ing\u00e9nieurs de proc\u00e9der \u00e0 des modifications impactantes, fr\u00e9quemment et de fa\u00e7on pr\u00e9visible avec un minimum de travail. La Cloud Native Computing Foundation cherche \u00e0 favoriser l'adoption de ce paradigme en encourageant et en soutenant un \u00e9cosyst\u00e8me de projets \"opensource\" et ind\u00e9pendants. Nous d\u00e9mocratisons l'\u00e9tat de l'art des pratiques afin de rendre l'innovation accessible \u00e0 tous. Deutsch Cloud native Technologien erm\u00f6glichen es Unternehmen, skalierbare Anwendungen in modernen, dynamischen Umgebungen zu implementieren und zu betreiben. Dies k\u00f6nnen \u00f6ffentliche, private und Hybrid-Clouds sein. Best-Practises, wie Container, Service-Meshs, Microservices, immutable Infrastruktur und deklarative APIs, unterst\u00fctzen diesen Ansatz. Die zugrundeliegenden Techniken erm\u00f6glichen die Umsetzung von entkoppelten Systemen, die belastbar, handhabbar und beobachtbar sind. Kombiniert mit einer robusten Automatisierung k\u00f6nnen Softwareentwickler mit geringem Aufwand flexibel und schnell auf \u00c4nderungen reagieren. Die Cloud Native Computing Foundation f\u00f6rdert die Akzeptanz dieser Paradigmen durch die Ausgestaltung eines Open Source \u00d6kosystems aus herstellerneutralen Projekten. Wir demokratisieren modernste und innovative Softwareentwicklungs-Patterns, um diese Innovationen f\u00fcr alle zug\u00e4nglich zu machen. Work at scale \u00b6 vertical scaling k horizontal scaling involves service instances, e.g. load balancer in K8s","title":"Cloud native"},{"location":"devops/cloudnative/#work-at-scale","text":"vertical scaling k horizontal scaling involves service instances, e.g. load balancer in K8s","title":"Work at scale"},{"location":"devops/codecov/","text":"Code coverage \u00b6 In computer science, test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs. Coverage criteria \u00b6 There are a number of coverage criteria, the main ones being: Function coverage has each function (or subroutine) in the program been called? Statement coverage has each statement in the program been executed? Edge coverage has every edge in the Control flow graph been executed? Branch coverage has each branch (also called DD-path) of each control structure (such as in if and case statements) been executed? For example, given an if statement, have both the true and false branches been executed? This is a subset of edge coverage. Condition coverage (or predicate coverage) has each Boolean sub-expression evaluated both to true and false? https://codecov.io/","title":"Code coverage"},{"location":"devops/codecov/#code-coverage","text":"In computer science, test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs.","title":"Code coverage"},{"location":"devops/codecov/#coverage-criteria","text":"There are a number of coverage criteria, the main ones being: Function coverage has each function (or subroutine) in the program been called? Statement coverage has each statement in the program been executed? Edge coverage has every edge in the Control flow graph been executed? Branch coverage has each branch (also called DD-path) of each control structure (such as in if and case statements) been executed? For example, given an if statement, have both the true and false branches been executed? This is a subset of edge coverage. Condition coverage (or predicate coverage) has each Boolean sub-expression evaluated both to true and false? https://codecov.io/","title":"Coverage criteria"},{"location":"devops/containerization/cli/","text":"","title":"CLI usage"},{"location":"devops/containerization/intro/","text":"Docker \u00b6","title":"Intro"},{"location":"devops/containerization/intro/#docker","text":"","title":"Docker"},{"location":"devops/orchestration/cli/","text":"","title":"CLI usage"},{"location":"devops/orchestration/intro/","text":"K8S components \u00b6 Control Plane Components \u00b6 kube-apiserver exposes K8S API. etcd is used as Kubernetes' store for all cluster data. kube-scheduler watches and decide on why node to run newly created pods. kube-controller-manager Node controller : notices and responds when nodes go down. Replication controller : maintains the correct number of pods for every replication controller object Endpoints controller : populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : creates default accounts and API access tokens. cloud-controller-manager embeds cloud-specific control logic, e.g.: Node controller : checks the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : sets up routes Service controller : creates, updates and deletes cloud provider load balancers Node Components \u00b6 kubelet is an agent running on each node that starts and monitor the container runtime workloads. kube-proxy routes inter-pod and internet requests. Container runtime is responsible for running containers (usually Docker).","title":"Intro"},{"location":"devops/orchestration/intro/#k8s-components","text":"","title":"K8S components"},{"location":"devops/orchestration/intro/#control-plane-components","text":"kube-apiserver exposes K8S API. etcd is used as Kubernetes' store for all cluster data. kube-scheduler watches and decide on why node to run newly created pods. kube-controller-manager Node controller : notices and responds when nodes go down. Replication controller : maintains the correct number of pods for every replication controller object Endpoints controller : populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : creates default accounts and API access tokens. cloud-controller-manager embeds cloud-specific control logic, e.g.: Node controller : checks the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : sets up routes Service controller : creates, updates and deletes cloud provider load balancers","title":"Control Plane Components"},{"location":"devops/orchestration/intro/#node-components","text":"kubelet is an agent running on each node that starts and monitor the container runtime workloads. kube-proxy routes inter-pod and internet requests. Container runtime is responsible for running containers (usually Docker).","title":"Node Components"},{"location":"devops/orchestration/minikube/","text":"Minikube \u00b6 Installation: local cluster with minikkube \u00b6 Direct download via: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube Driver: The vmware driver supports virtualization across all VMware based hypervisors. https://minikube.sigs.k8s.io/docs/drivers/vmware/ r=https://api.github.com/repos/machine-drivers/docker-machine-driver-vmware curl -LO $(curl -s $r/releases/latest | grep -o 'http.*darwin_amd64' | head -n1) \\ && install docker-machine-driver-vmware_darwin_amd64 \\ /usr/local/bin/docker-machine-driver-vmware Install minikube \u21a9","title":"Minikube"},{"location":"devops/orchestration/minikube/#minikube","text":"","title":"Minikube  "},{"location":"devops/orchestration/minikube/#installation-local-cluster-with-minikkube","text":"Direct download via: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\ && chmod +x minikube Driver: The vmware driver supports virtualization across all VMware based hypervisors. https://minikube.sigs.k8s.io/docs/drivers/vmware/ r=https://api.github.com/repos/machine-drivers/docker-machine-driver-vmware curl -LO $(curl -s $r/releases/latest | grep -o 'http.*darwin_amd64' | head -n1) \\ && install docker-machine-driver-vmware_darwin_amd64 \\ /usr/local/bin/docker-machine-driver-vmware Install minikube \u21a9","title":"Installation: local cluster with minikkube"},{"location":"doc/md/","text":"usage and plugins \u00b6 mkdocs mkdocs-material Github guide Comments \u00b6 [comment]: <> (This is a comment, it will not be included) [//]: <> (This is also a comment.) [//]: # (This may be the most platform independent comment) Source: Stack Overflow 4823469 Extensions \u00b6 PyMdown extensions \u00b6 Collection of extensions for Python Markdown. Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with MathJax. p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} . Admonition \u00b6 Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content Note !!! note For fixed block Note ??? note For collapsible block Supported types: note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error Bug Example quote, cite Content tab \u00b6 Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Keys \u00b6 ++ctrl+alt+del++ ++ctrl+C++","title":"Help"},{"location":"doc/md/#usage-and-plugins","text":"mkdocs mkdocs-material Github guide","title":"usage and plugins"},{"location":"doc/md/#comments","text":"[comment]: <> (This is a comment, it will not be included) [//]: <> (This is also a comment.) [//]: # (This may be the most platform independent comment) Source: Stack Overflow 4823469","title":"Comments"},{"location":"doc/md/#extensions","text":"","title":"Extensions"},{"location":"doc/md/#pymdown-extensions","text":"Collection of extensions for Python Markdown. Arithmatex is an extension that preserves LaTeX math equations during the Markdown conversion process so that they can be used with MathJax. p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} .","title":"PyMdown extensions  "},{"location":"doc/md/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content Note !!! note For fixed block Note ??? note For collapsible block Supported types: note, seealso abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq warning, caution, attention failure, fail, missing danger, error Bug Example quote, cite","title":"Admonition"},{"location":"doc/md/#content-tab","text":"Unordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci C++ #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Content tab"},{"location":"doc/md/#keys","text":"++ctrl+alt+del++ ++ctrl+C++","title":"Keys"},{"location":"extern/md-guide/","text":"Markdown Guide \u00b6 The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both. Contributing \u00b6 Contributions are welcome. Feel free to open a pull request with changes. Running it Locally \u00b6 It can be helpful to preview changes on your computer before opening a pull request. The Markdown Guide uses the Jekyll static site generator . After forking or cloning the repository, perform the following steps to generate the site and preview it: Make sure you have ruby installed on your computer. See https://www.ruby-lang.org/en/downloads/ bundle install bundle exec jekyll serve Point your browser at http://127.0.0.1:4000/ Adding tools \u00b6 See this page for information about adding applications to the Markdown tools directory . Deployment \u00b6 Pull requests merged to the master branch are automatically deployed to the production website. License \u00b6 The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"Markdown Guide"},{"location":"extern/md-guide/#markdown-guide","text":"The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both.","title":"Markdown Guide"},{"location":"extern/md-guide/#contributing","text":"Contributions are welcome. Feel free to open a pull request with changes.","title":"Contributing"},{"location":"extern/md-guide/#running-it-locally","text":"It can be helpful to preview changes on your computer before opening a pull request. The Markdown Guide uses the Jekyll static site generator . After forking or cloning the repository, perform the following steps to generate the site and preview it: Make sure you have ruby installed on your computer. See https://www.ruby-lang.org/en/downloads/ bundle install bundle exec jekyll serve Point your browser at http://127.0.0.1:4000/","title":"Running it Locally"},{"location":"extern/md-guide/#adding-tools","text":"See this page for information about adding applications to the Markdown tools directory .","title":"Adding tools"},{"location":"extern/md-guide/#deployment","text":"Pull requests merged to the master branch are automatically deployed to the production website.","title":"Deployment"},{"location":"extern/md-guide/#license","text":"The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"License"},{"location":"extern/md-guide/about/","text":"Purpose \u00b6 The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both. Contributing \u00b6 This is an open-source project, and your contributions are welcome. The repository is hosted on GitHub . See the README for instructions and guidelines. Reporting Issues \u00b6 Find a typo or inaccurate statement? Please create an issue in our GitHub project. Contacting \u00b6 Use the contact form to send a message to the maintainer of The Markdown Guide . Acknowledgements \u00b6 The Markdown Guide is made possible by the support of several individuals and organizations. Thanks to all who have contributed to this project, and thanks to Netlify for graciously hosting this website. License \u00b6 The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"About"},{"location":"extern/md-guide/about/#purpose","text":"The Markdown Guide is a comprehensive Markdown reference designed for both novices and experts. It was born out of frustration with existing Markdown references that are incomplete, inadequate, or both.","title":"Purpose"},{"location":"extern/md-guide/about/#contributing","text":"This is an open-source project, and your contributions are welcome. The repository is hosted on GitHub . See the README for instructions and guidelines.","title":"Contributing"},{"location":"extern/md-guide/about/#reporting-issues","text":"Find a typo or inaccurate statement? Please create an issue in our GitHub project.","title":"Reporting Issues"},{"location":"extern/md-guide/about/#contacting","text":"Use the contact form to send a message to the maintainer of The Markdown Guide .","title":"Contacting"},{"location":"extern/md-guide/about/#acknowledgements","text":"The Markdown Guide is made possible by the support of several individuals and organizations. Thanks to all who have contributed to this project, and thanks to Netlify for graciously hosting this website.","title":"Acknowledgements"},{"location":"extern/md-guide/about/#license","text":"The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license , and the underlying source code used to format and display that content is licensed under the MIT license .","title":"License"},{"location":"extern/md-guide/basic-syntax/","text":"{% include syntax.html type=\"basic\" syntax-id=\"overview\" %} {% include syntax.html type=\"basic\" syntax-id=\"headings\" %} {% include syntax.html type=\"basic\" syntax-id=\"paragraphs\" %} {% include syntax.html type=\"basic\" syntax-id=\"line-breaks\" %} {% include syntax.html type=\"basic\" syntax-id=\"emphasis\" %} {% include syntax.html type=\"basic\" syntax-id=\"blockquotes\" %} {% include syntax.html type=\"basic\" syntax-id=\"lists\" %} {% include syntax.html type=\"basic\" syntax-id=\"code\" %} {% include syntax.html type=\"basic\" syntax-id=\"horizontal-rules\" %} {% include syntax.html type=\"basic\" syntax-id=\"links\" %} {% include syntax.html type=\"basic\" syntax-id=\"images\" %} {% include syntax.html type=\"basic\" syntax-id=\"escaping-characters\" %} {% include syntax.html type=\"basic\" syntax-id=\"html\" %}","title":"MD: basic"},{"location":"extern/md-guide/book/","text":"The Markdown Guide By Matt Cone Learn Markdown in 60 pages. The Markdown Guide book includes everything you need to get started and master Markdown syntax. \u2714\ufe0f Professional quality PDF, MOBI, and EPUB files (DRM-free) \u2714\ufe0f Unlimited free lifetime updates \u2714\ufe0f 100% satisfaction guaranteed Buy now for $9.99 Read free sample The Markdown Guide is also available on Leanpub and Amazon . Take your Markdown skills to the next level. Learn the power of Markdown and take full control of the syntax. \ud83d\udcda See how Markdown works and dive in using an online editor. \ud83d\udcdd Practice using basic and extended Markdown syntax elements. \ud83d\udcaa Learn how to use Markdown for just about everything. What's inside. Detailed descriptions. Clear and concise examples. Beautifully formatted pages. What readers are saying. The Markdown Guide is hands-down the best Markdown reference. Michael Hartl, Founder of Learn Enough and author of the Ruby on Rails Tutorial Well done! This is an incredibly valuable and well-done resource. It does a great job of educating without becoming too overwhelming or too narrowly focused on one application of Markdown. nxprefect, via Reddit The Markdown Guide is awesome. I keep it open in a browser tab for reference while working on my guides. Rob Reeder, Documentation Specialist, Software Engineering Institute, CMU This book provides the right amount of information to learn Markdown and I highly recommend it! Mohamad Kalaaji, via Goodreads If you\u2019re working with Markdown, then do yourself a favour and check out The Markdown Guide ... It\u2019s excellent. Matthew Setter, via Twitter I've found this very simple guide to Markdown syntax very useful in a pinch. Morgan Thompson, via Twitter 100% satisfaction guaranteed. If you're not completely satisfied with The Markdown Guide , I'll refund your money, no questions asked. Buy now for $9.99 About the Author Matt Cone is a technical writer at Fastly . He has experience creating documentation for organizations like Linode and the U.S. Department of Health and Human Services. Matt's first book, Master Your Mac , was published by No Starch Press. To get in touch with Matt, visit https://www.mattcone.com .","title":"The Markdown Guide Book"},{"location":"extern/md-guide/cheat-sheet/","text":"Overview \u00b6 This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can't cover every edge case, so if you need more information about any of these elements, refer to our reference guides for basic syntax and extended syntax . Basic Syntax \u00b6 These are the elements outlined in John Gruber's original design document. All Markdown applications support these elements. Element Markdown Syntax Heading # H1 ## H2 ### H3 Bold **bold text** Italic *italicized text* Blockquote > blockquote Ordered List 1. First item 2. Second item 3. Third item Unordered List - First item - Second item - Third item Code `code` Horizontal Rule --- Link [title](https://www.example.com) Image ![alt text](image.jpg) Extended Syntax \u00b6 These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Element Markdown Syntax Table | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | Fenced Code Block ``` { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` Footnote Here's a sentence with a footnote. [^1] [^1]: This is the footnote. Heading ID ### My Great Heading {#custom-id} Definition List term : definition Strikethrough ~~The world is flat.~~ Task List - [x] Write the press release - [ ] Update the website - [ ] Contact the media Downloads \u00b6 You can download this cheat sheet as a Markdown file for use in your Markdown application.","title":"Markdown Cheat Sheet"},{"location":"extern/md-guide/cheat-sheet/#overview","text":"This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can't cover every edge case, so if you need more information about any of these elements, refer to our reference guides for basic syntax and extended syntax .","title":"Overview"},{"location":"extern/md-guide/cheat-sheet/#basic-syntax","text":"These are the elements outlined in John Gruber's original design document. All Markdown applications support these elements. Element Markdown Syntax Heading # H1 ## H2 ### H3 Bold **bold text** Italic *italicized text* Blockquote > blockquote Ordered List 1. First item 2. Second item 3. Third item Unordered List - First item - Second item - Third item Code `code` Horizontal Rule --- Link [title](https://www.example.com) Image ![alt text](image.jpg)","title":"Basic Syntax"},{"location":"extern/md-guide/cheat-sheet/#extended-syntax","text":"These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Element Markdown Syntax Table | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | Fenced Code Block ``` { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` Footnote Here's a sentence with a footnote. [^1] [^1]: This is the footnote. Heading ID ### My Great Heading {#custom-id} Definition List term : definition Strikethrough ~~The world is flat.~~ Task List - [x] Write the press release - [ ] Update the website - [ ] Contact the media","title":"Extended Syntax"},{"location":"extern/md-guide/cheat-sheet/#downloads","text":"You can download this cheat sheet as a Markdown file for use in your Markdown application.","title":"Downloads"},{"location":"extern/md-guide/contact/","text":"Email address We'll never share your email with anyone else. Message Submit","title":"Contact"},{"location":"extern/md-guide/extended-syntax/","text":"{% include syntax.html type=\"extended\" syntax-id=\"overview\" %} {% include syntax.html type=\"extended\" syntax-id=\"availability\" %} {% include syntax.html type=\"extended\" syntax-id=\"tables\" %} {% include syntax.html type=\"extended\" syntax-id=\"fenced-code-blocks\" %} {% include syntax.html type=\"extended\" syntax-id=\"footnotes\" %} {% include syntax.html type=\"extended\" syntax-id=\"heading-ids\" %} {% include syntax.html type=\"extended\" syntax-id=\"definition-lists\" %} {% include syntax.html type=\"extended\" syntax-id=\"strikethrough\" %} {% include syntax.html type=\"extended\" syntax-id=\"task-lists\" %} {% include syntax.html type=\"extended\" syntax-id=\"emoji\" %} {% include syntax.html type=\"extended\" syntax-id=\"automatic-url-linking\" %}","title":"MD: extended"},{"location":"extern/md-guide/getting-started/","text":"{% include_relative _getting-started/whats-markdown.md %} {% include_relative _getting-started/why-use-markdown.md %} {% include_relative _getting-started/kicking-the-tires.md %} {% include_relative _getting-started/how-does-it-work.md %} {% include_relative _getting-started/whats-markdown-good-for.md %} {% include_relative _getting-started/flavors-of-markdown.md %} {% include_relative _getting-started/additional-resources.md %}","title":"Getting Started"},{"location":"extern/md-guide/tools/","text":"\ud83d\udc4b Howdy! This is the start of a comprehensive Markdown tool directory. Compiling all this will take some time! Learn how to contribute. {% for tool in site.tools %} {{ tool.title }} {{ tool.description }} Learn more {% endfor %}","title":"Tools"},{"location":"extern/md-guide/_basic-syntax/blockquotes/","text":"To create a blockquote, add a > in front of a paragraph. > Dorothy followed her through many of the beautiful rooms in her castle. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. Blockquotes with Multiple Paragraphs \u00b6 Blockquotes can contain multiple paragraphs. Add a > on the blank lines between the paragraphs. > Dorothy followed her through many of the beautiful rooms in her castle. > > The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Nested Blockquotes \u00b6 Blockquotes can be nested. Add a >> in front of the paragraph you want to nest. > Dorothy followed her through many of the beautiful rooms in her castle. > >> The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. Blockquotes with Other Elements \u00b6 Blockquotes can contain other Markdown formatted elements. Not all elements can be used \u2014 you'll need to experiment to see which ones work. > #### The quarterly results look great! > > - Revenue was off the chart. > - Profits were higher than ever. > > *Everything* is going according to **plan**. The rendered output looks like this: The quarterly results look great! Revenue was off the chart. Profits were higher than ever. Everything is going according to plan .","title":"Blockquotes"},{"location":"extern/md-guide/_basic-syntax/blockquotes/#blockquotes-with-multiple-paragraphs","text":"Blockquotes can contain multiple paragraphs. Add a > on the blank lines between the paragraphs. > Dorothy followed her through many of the beautiful rooms in her castle. > > The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.","title":"Blockquotes with Multiple Paragraphs"},{"location":"extern/md-guide/_basic-syntax/blockquotes/#nested-blockquotes","text":"Blockquotes can be nested. Add a >> in front of the paragraph you want to nest. > Dorothy followed her through many of the beautiful rooms in her castle. > >> The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. The rendered output looks like this: Dorothy followed her through many of the beautiful rooms in her castle. The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.","title":"Nested Blockquotes"},{"location":"extern/md-guide/_basic-syntax/blockquotes/#blockquotes-with-other-elements","text":"Blockquotes can contain other Markdown formatted elements. Not all elements can be used \u2014 you'll need to experiment to see which ones work. > #### The quarterly results look great! > > - Revenue was off the chart. > - Profits were higher than ever. > > *Everything* is going according to **plan**. The rendered output looks like this:","title":"Blockquotes with Other Elements"},{"location":"extern/md-guide/_basic-syntax/bold/","text":"To bold text, add two asterisks or underscores before and after a word or phrase. To bold the middle of a word for emphasis, add two asterisks without spaces around the letters. Markdown HTML Rendered Output I just love **bold text**. I just love <strong>bold text</strong>. I just love bold text . I just love __bold text__. I just love <strong>bold text</strong>. I just love bold text . Love**is**bold Love<strong>is</strong>bold Love is bold Bold Best Practices \u00b6 Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to bold the middle of a word for emphasis. \u2705 Do this \u274c Don't do this Love**is**bold Love__is__bold","title":"Bold"},{"location":"extern/md-guide/_basic-syntax/bold/#bold-best-practices","text":"Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to bold the middle of a word for emphasis. \u2705 Do this \u274c Don't do this Love**is**bold Love__is__bold","title":"Bold Best Practices"},{"location":"extern/md-guide/_basic-syntax/code/","text":"To denote a word or phrase as code, enclose it in backticks ( ` ). Markdown HTML Rendered Output At the command prompt, type `nano`. At the command prompt, type <code>nano</code>. At the command prompt, type nano . Escaping Backticks \u00b6 If the word or phrase you want to denote as code includes one or more backticks, you can escape it by enclosing the word or phrase in double backticks ( `` ). Markdown HTML Rendered Output ``Use `code` in your Markdown file.`` <code>Use `code` in your Markdown file.</code> Use `code` in your Markdown file. Code Blocks \u00b6 To create code blocks, indent every line of the block by at least four spaces or one tab. <html> <head> </head> </html> The rendered output looks like this: <html> <head> </head> </html> Note: To create code blocks without indenting lines, use fenced code blocks .","title":"Code"},{"location":"extern/md-guide/_basic-syntax/code/#escaping-backticks","text":"If the word or phrase you want to denote as code includes one or more backticks, you can escape it by enclosing the word or phrase in double backticks ( `` ). Markdown HTML Rendered Output ``Use `code` in your Markdown file.`` <code>Use `code` in your Markdown file.</code> Use `code` in your Markdown file.","title":"Escaping Backticks"},{"location":"extern/md-guide/_basic-syntax/code/#code-blocks","text":"To create code blocks, indent every line of the block by at least four spaces or one tab. <html> <head> </head> </html> The rendered output looks like this: <html> <head> </head> </html> Note: To create code blocks without indenting lines, use fenced code blocks .","title":"Code Blocks"},{"location":"extern/md-guide/_basic-syntax/emphasis/","text":"You can add emphasis by making text bold or italic. {% include syntax.html type=\"basic-sub\" syntax-id=\"bold\" %} {% include syntax.html type=\"basic-sub\" syntax-id=\"italic\" %} Bold and Italic \u00b6 To emphasize text with bold and italics at the same time, add three asterisks or underscores before and after a word or phrase. To bold and italicize the middle of a word for emphasis, add three asterisks without spaces around the letters. Markdown HTML Rendered Output This text is ***really important***. This text is <strong><em>really important</em></strong>. This text is really important . This text is ___really important___. This text is <strong><em>really important</em></strong>. This text is really important . This text is __*really important*__. This text is <strong><em>really important</em></strong>. This text is really important . This text is **_really important_**. This text is <strong><em>really important</em></strong>. This text is really important . This is really***very***important text. This is really<strong><em>very</em></strong>important text. This is really very important text. Bold and Italic Best Practices \u00b6 Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to bold and italicize the middle of a word for emphasis. \u2705 Do this \u274c Don't do this This is really***very***important text. This is really___very___important text.","title":"Emphasis"},{"location":"extern/md-guide/_basic-syntax/emphasis/#bold-and-italic","text":"To emphasize text with bold and italics at the same time, add three asterisks or underscores before and after a word or phrase. To bold and italicize the middle of a word for emphasis, add three asterisks without spaces around the letters. Markdown HTML Rendered Output This text is ***really important***. This text is <strong><em>really important</em></strong>. This text is really important . This text is ___really important___. This text is <strong><em>really important</em></strong>. This text is really important . This text is __*really important*__. This text is <strong><em>really important</em></strong>. This text is really important . This text is **_really important_**. This text is <strong><em>really important</em></strong>. This text is really important . This is really***very***important text. This is really<strong><em>very</em></strong>important text. This is really very important text.","title":"Bold and Italic"},{"location":"extern/md-guide/_basic-syntax/emphasis/#bold-and-italic-best-practices","text":"Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to bold and italicize the middle of a word for emphasis. \u2705 Do this \u274c Don't do this This is really***very***important text. This is really___very___important text.","title":"Bold and Italic Best Practices"},{"location":"extern/md-guide/_basic-syntax/escaping-characters/","text":"To display a literal character that would otherwise be used to format text in a Markdown document, add a backslash ( \\ ) in front of the character. \\* Without the backslash, this would be a bullet in an unordered list. The rendered output looks like this: * Without the backslash, this would be a bullet in an unordered list. Characters You Can Escape \u00b6 You can use a backslash to escape the following characters. Character Name \\ backslash ` backtick (see also escaping backticks in code ) * asterisk _ underscore { } curly braces [ ] brackets ( ) parentheses # pound sign + plus sign - minus sign (hyphen) . dot ! exclamation mark | pipe (see also escaping pipe in tables )","title":"Escaping Characters"},{"location":"extern/md-guide/_basic-syntax/escaping-characters/#characters-you-can-escape","text":"You can use a backslash to escape the following characters. Character Name \\ backslash ` backtick (see also escaping backticks in code ) * asterisk _ underscore { } curly braces [ ] brackets ( ) parentheses # pound sign + plus sign - minus sign (hyphen) . dot ! exclamation mark | pipe (see also escaping pipe in tables )","title":"Characters You Can Escape"},{"location":"extern/md-guide/_basic-syntax/headings/","text":"To create a heading, add number signs ( # ) in front of a word or phrase. The number of number signs you use should correspond to the heading level. For example, to create a heading level three ( <h3> ), use three number signs (e.g., ### My Header ). Markdown HTML Rendered Output # Heading level 1 <h1>Heading level 1</h1> Heading level 1 ## Heading level 2 <h2>Heading level 2</h2> Heading level 2 ### Heading level 3 <h3>Heading level 3</h3> Heading level 3 #### Heading level 4 <h4>Heading level 4</h4> Heading level 4 ##### Heading level 5 <h5>Heading level 5</h5> Heading level 5 ###### Heading level 6 <h6>Heading level 6</h6> Heading level 6 Alternate Syntax \u00b6 Alternatively, on the line below the text, add any number of == characters for heading level 1 or -- characters for heading level 2. Markdown HTML Rendered Output Heading level 1 =============== <h1>Heading level 1</h1> Heading level 1 Heading level 2 --------------- <h2>Heading level 2</h2> Heading level 2 Heading Best Practices \u00b6 Markdown applications don't agree on how to handle a missing space between the number signs ( # ) and the heading name. For compatibility, always put a space between the number signs and the heading name. \u2705 Do this \u274c Don't do this # Here's a Heading #Here's a Heading","title":"Headings"},{"location":"extern/md-guide/_basic-syntax/headings/#alternate-syntax","text":"Alternatively, on the line below the text, add any number of == characters for heading level 1 or -- characters for heading level 2. Markdown HTML Rendered Output Heading level 1 =============== <h1>Heading level 1</h1>","title":"Alternate Syntax"},{"location":"extern/md-guide/_basic-syntax/headings/#heading-best-practices","text":"Markdown applications don't agree on how to handle a missing space between the number signs ( # ) and the heading name. For compatibility, always put a space between the number signs and the heading name. \u2705 Do this \u274c Don't do this # Here's a Heading #Here's a Heading","title":"Heading Best Practices"},{"location":"extern/md-guide/_basic-syntax/horizontal-rules/","text":"To create a horizontal rule, use three or more asterisks ( *** ), dashes ( --- ), or underscores ( ___ ) on a line by themselves. *** --- _________________ The rendered output of all three looks identical: Horizontal Rule Best Practices \u00b6 For compatibility, put blank lines before and after horizontal rules. \u2705 Do this \u274c Don't do this Try to put a blank line before... --- ...and after a horizontal rule. Without blank lines, this would be a heading. --- Don't do this!","title":"Horizontal Rules"},{"location":"extern/md-guide/_basic-syntax/horizontal-rules/#horizontal-rule-best-practices","text":"For compatibility, put blank lines before and after horizontal rules. \u2705 Do this \u274c Don't do this Try to put a blank line before... --- ...and after a horizontal rule. Without blank lines, this would be a heading. --- Don't do this!","title":"Horizontal Rule Best Practices"},{"location":"extern/md-guide/_basic-syntax/html/","text":"Many Markdown applications allow you to use HTML tags in Markdown-formatted text. This is helpful if you prefer certain HTML tags to Markdown syntax. For example, some people find it easier to use HTML tags for images. Using HTML is also helpful when you need to change the attributes of an element, like specifying the color of text or changing the width of an image. To use HTML, place the tags in the text of your Markdown-formatted file. This **word** is bold. This <em>word</em> is italic. The rendered output looks like this: This word is bold. This word is italic. HTML Best Practices \u00b6 For security reasons, not all Markdown applications support HTML in Markdown documents. When in doubt, check your Markdown application's documentation. Some applications support only a subset of HTML tags. Use blank lines to separate block-level HTML elements\u2009like <div> , <table> , <pre> , and <p> from the surrounding content. Try not to indent the tags with tabs or spaces \u2014 that can interfere with the formatting. You can't use Markdown syntax inside block-level HTML tags. For example, <p>italic and **bold**</p> won't work.","title":"HTML"},{"location":"extern/md-guide/_basic-syntax/html/#html-best-practices","text":"For security reasons, not all Markdown applications support HTML in Markdown documents. When in doubt, check your Markdown application's documentation. Some applications support only a subset of HTML tags. Use blank lines to separate block-level HTML elements\u2009like <div> , <table> , <pre> , and <p> from the surrounding content. Try not to indent the tags with tabs or spaces \u2014 that can interfere with the formatting. You can't use Markdown syntax inside block-level HTML tags. For example, <p>italic and **bold**</p> won't work.","title":"HTML Best Practices"},{"location":"extern/md-guide/_basic-syntax/images/","text":"To add an image, add an exclamation mark ( ! ), followed by alt text in brackets, and the path or URL to the image asset in parentheses. You can optionally add a title after the URL in the parentheses. ![Philadelphia's Magic Gardens. This place was so cool!](/assets/images/philly-magic-gardens.jpg \"Philadelphia's Magic Gardens\") The rendered output looks like this: Linking Images \u00b6 To add a link to an image, enclose the Markdown for the image in brackets, and then add the link in parentheses. [![An old rock in the desert](/assets/images/shiprock.jpg \"Shiprock, New Mexico by Beau Rogers\")](https://www.flickr.com/photos/beaurogers/31833779864/in/photolist-Qv3rFw-34mt9F-a9Cmfy-5Ha3Zi-9msKdv-o3hgjr-hWpUte-4WMsJ1-KUQ8N-deshUb-vssBD-6CQci6-8AFCiD-zsJWT-nNfsgB-dPDwZJ-bn9JGn-5HtSXY-6CUhAL-a4UTXB-ugPum-KUPSo-fBLNm-6CUmpy-4WMsc9-8a7D3T-83KJev-6CQ2bK-nNusHJ-a78rQH-nw3NvT-7aq2qf-8wwBso-3nNceh-ugSKP-4mh4kh-bbeeqH-a7biME-q3PtTf-brFpgb-cg38zw-bXMZc-nJPELD-f58Lmo-bXMYG-bz8AAi-bxNtNT-bXMYi-bXMY6-bXMYv) The rendered output looks like this:","title":"Images"},{"location":"extern/md-guide/_basic-syntax/images/#linking-images","text":"To add a link to an image, enclose the Markdown for the image in brackets, and then add the link in parentheses. [![An old rock in the desert](/assets/images/shiprock.jpg \"Shiprock, New Mexico by Beau Rogers\")](https://www.flickr.com/photos/beaurogers/31833779864/in/photolist-Qv3rFw-34mt9F-a9Cmfy-5Ha3Zi-9msKdv-o3hgjr-hWpUte-4WMsJ1-KUQ8N-deshUb-vssBD-6CQci6-8AFCiD-zsJWT-nNfsgB-dPDwZJ-bn9JGn-5HtSXY-6CUhAL-a4UTXB-ugPum-KUPSo-fBLNm-6CUmpy-4WMsc9-8a7D3T-83KJev-6CQ2bK-nNusHJ-a78rQH-nw3NvT-7aq2qf-8wwBso-3nNceh-ugSKP-4mh4kh-bbeeqH-a7biME-q3PtTf-brFpgb-cg38zw-bXMZc-nJPELD-f58Lmo-bXMYG-bz8AAi-bxNtNT-bXMYi-bXMY6-bXMYv) The rendered output looks like this:","title":"Linking Images"},{"location":"extern/md-guide/_basic-syntax/italic/","text":"To italicize text, add one asterisk or underscore before and after a word or phrase. To italicize the middle of a word for emphasis, add one asterisk without spaces around the letters. Markdown HTML Rendered Output Italicized text is the *cat's meow*. Italicized text is the <em>cat's meow</em>. Italicized text is the cat\u2019s meow . Italicized text is the _cat's meow_. Italicized text is the <em>cat's meow</em>. Italicized text is the cat\u2019s meow . A*cat*meow A<em>cat</em>meow A cat meow Italic Best Practices \u00b6 Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to italicize the middle of a word for emphasis. \u2705 Do this \u274c Don't do this A*cat*meow A_cat_meow","title":"Italic"},{"location":"extern/md-guide/_basic-syntax/italic/#italic-best-practices","text":"Markdown applications don't agree on how to handle underscores in the middle of a word. For compatibility, use asterisks to italicize the middle of a word for emphasis. \u2705 Do this \u274c Don't do this A*cat*meow A_cat_meow","title":"Italic Best Practices"},{"location":"extern/md-guide/_basic-syntax/line-breaks/","text":"To create a line break ( <br> ), end a line with two or more spaces, and then type return. Markdown HTML Rendered Output This is the first line. And this is the second line. <p>This is the first line.<br> And this is the second line.</p> This is the first line. And this is the second line. Line Break Best Practices \u00b6 You can use two or more spaces (commonly referred to as \"trailing whitespace\") for line breaks in nearly every Markdown application, but it's controversial. It's hard to see trailing whitespace in an editor, and many people accidentally or intentionally put two spaces after every sentence. For this reason, you may want to use something other than trailing whitespace for line breaks. Fortunately, there is another option supported by nearly every Markdown application: the <br> HTML tag. For compatibility, use trailing white space or the <br> HTML tag at the end of the line. There are two other options I don't recommend using. CommonMark and a few other lightweight markup languages let you type a backslash ( \\ ) at the end of the line, but not all Markdown applications support this, so it isn't a great option from a compatibility perspective. And at least a couple lightweight markup languages don't require anything at the end of the line \u2014 just type return and they'll create a line break. \u2705 Do this \u274c Don't do this First line with two spaces after. And the next line. First line with the HTML tag after.<br> And the next line. First line with a backslash after.\\ And the next line. First line with nothing after. And the next line.","title":"Line Breaks"},{"location":"extern/md-guide/_basic-syntax/line-breaks/#line-break-best-practices","text":"You can use two or more spaces (commonly referred to as \"trailing whitespace\") for line breaks in nearly every Markdown application, but it's controversial. It's hard to see trailing whitespace in an editor, and many people accidentally or intentionally put two spaces after every sentence. For this reason, you may want to use something other than trailing whitespace for line breaks. Fortunately, there is another option supported by nearly every Markdown application: the <br> HTML tag. For compatibility, use trailing white space or the <br> HTML tag at the end of the line. There are two other options I don't recommend using. CommonMark and a few other lightweight markup languages let you type a backslash ( \\ ) at the end of the line, but not all Markdown applications support this, so it isn't a great option from a compatibility perspective. And at least a couple lightweight markup languages don't require anything at the end of the line \u2014 just type return and they'll create a line break. \u2705 Do this \u274c Don't do this First line with two spaces after. And the next line. First line with the HTML tag after.<br> And the next line. First line with a backslash after.\\ And the next line. First line with nothing after. And the next line.","title":"Line Break Best Practices"},{"location":"extern/md-guide/_basic-syntax/links/","text":"To create a link, enclose the link text in brackets (e.g., [Duck Duck Go] ) and then follow it immediately with the URL in parentheses (e.g., (https://duckduckgo.com) ). My favorite search engine is [Duck Duck Go](https://duckduckgo.com). The rendered output looks like this: My favorite search engine is Duck Duck Go . Adding Titles \u00b6 You can optionally add a title for a link. This will appear as a tooltip when the user hovers over the link. To add a title, enclose it in parentheses after the URL. My favorite search engine is [Duck Duck Go](https://duckduckgo.com \"The best search engine for privacy\"). The rendered output looks like this: My favorite search engine is Duck Duck Go . URLs and Email Addresses \u00b6 To quickly turn a URL or email address into a link, enclose it in angle brackets. <https://www.markdownguide.org> <fake@example.com> The rendered output looks like this: https://www.markdownguide.org fake@example.com Formatting Links \u00b6 To emphasize links, add asterisks before and after the brackets and parentheses. To denote links as code , add backticks in the brackets. I love supporting the **[EFF](https://eff.org)**. This is the *[Markdown Guide](https://www.markdownguide.org)*. See the section on [`code`](#code). The rendered output looks like this: I love supporting the EFF . This is the Markdown Guide . See the section on code . Reference-style Links \u00b6 Reference-style links are a special kind of link that make URLs easier to display and read in Markdown. Reference-style links are constructed in two parts: the part you keep inline with your text and the part you store somewhere else in the file to keep the text easy to read. Formatting the First Part of the Link \u00b6 The first part of a reference-style link is formatted with two sets of brackets. The first set of brackets surrounds the text that should appear linked. The second set of brackets displays a label used to point to the link you're storing elsewhere in your document. Although not required, you can include a space between the first and second set of brackets. The label in the second set of brackets is not case sensitive and can include letters, numbers, spaces, or punctuation. This means the following example formats are roughly equivalent for the first part of the link: [hobbit-hole][1] [hobbit-hole] [1] Formatting the Second Part of the Link \u00b6 The second part of a reference-style link is formatted with the following attributes: The label, in brackets, followed immediately by a colon and at least one space (e.g., [label]: ). The URL for the link, which you can optionally enclose in angle brackets. The optional title for the link, which you can enclose in double quotes, single quotes, or parentheses. This means the following example formats are all roughly equivalent for the second part of the link: [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\" [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle 'Hobbit lifestyles' [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle (Hobbit lifestyles) [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> 'Hobbit lifestyles' [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> (Hobbit lifestyles) You can place this second part of the link anywhere in your Markdown document. Some people place them immediately after the paragraph in which they appear while other people place them at the end of the document (like endnotes or footnotes). An Example Putting the Parts Together \u00b6 Say you add a URL as a standard URL link to a paragraph and it looks like this in Markdown: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [hobbit-hole](https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\"), and that means comfort. Though it may point to interesting additional information, the URL as displayed really doesn't add much to the existing raw text other than making it harder to read. To fix that, you could format the URL like this instead: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [hobbit-hole][1], and that means comfort. [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" In both instances above, the rendered output would be identical: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole , and that means comfort. and the HTML for the link would be: <a href=\"https://en.wikipedia.org/wiki/Hobbit#Lifestyle\" title=\"Hobbit lifestyles\">hobbit-hole</a> Link Best Practices \u00b6 Markdown applications don't agree on how to handle spaces in the middle of a URL. For compatibility, try to URL encode any spaces with %20 . \u2705 Do this \u274c Don't do this [link](https://www.example.com/my%20great%20page) [link](https://www.example.com/my great page)","title":"Links"},{"location":"extern/md-guide/_basic-syntax/links/#adding-titles","text":"You can optionally add a title for a link. This will appear as a tooltip when the user hovers over the link. To add a title, enclose it in parentheses after the URL. My favorite search engine is [Duck Duck Go](https://duckduckgo.com \"The best search engine for privacy\"). The rendered output looks like this: My favorite search engine is Duck Duck Go .","title":"Adding Titles"},{"location":"extern/md-guide/_basic-syntax/links/#urls-and-email-addresses","text":"To quickly turn a URL or email address into a link, enclose it in angle brackets. <https://www.markdownguide.org> <fake@example.com> The rendered output looks like this: https://www.markdownguide.org fake@example.com","title":"URLs and Email Addresses"},{"location":"extern/md-guide/_basic-syntax/links/#formatting-links","text":"To emphasize links, add asterisks before and after the brackets and parentheses. To denote links as code , add backticks in the brackets. I love supporting the **[EFF](https://eff.org)**. This is the *[Markdown Guide](https://www.markdownguide.org)*. See the section on [`code`](#code). The rendered output looks like this: I love supporting the EFF . This is the Markdown Guide . See the section on code .","title":"Formatting Links"},{"location":"extern/md-guide/_basic-syntax/links/#reference-style-links","text":"Reference-style links are a special kind of link that make URLs easier to display and read in Markdown. Reference-style links are constructed in two parts: the part you keep inline with your text and the part you store somewhere else in the file to keep the text easy to read.","title":"Reference-style Links"},{"location":"extern/md-guide/_basic-syntax/links/#formatting-the-first-part-of-the-link","text":"The first part of a reference-style link is formatted with two sets of brackets. The first set of brackets surrounds the text that should appear linked. The second set of brackets displays a label used to point to the link you're storing elsewhere in your document. Although not required, you can include a space between the first and second set of brackets. The label in the second set of brackets is not case sensitive and can include letters, numbers, spaces, or punctuation. This means the following example formats are roughly equivalent for the first part of the link: [hobbit-hole][1] [hobbit-hole] [1]","title":"Formatting the First Part of the Link"},{"location":"extern/md-guide/_basic-syntax/links/#formatting-the-second-part-of-the-link","text":"The second part of a reference-style link is formatted with the following attributes: The label, in brackets, followed immediately by a colon and at least one space (e.g., [label]: ). The URL for the link, which you can optionally enclose in angle brackets. The optional title for the link, which you can enclose in double quotes, single quotes, or parentheses. This means the following example formats are all roughly equivalent for the second part of the link: [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\" [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle 'Hobbit lifestyles' [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle (Hobbit lifestyles) [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> 'Hobbit lifestyles' [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> (Hobbit lifestyles) You can place this second part of the link anywhere in your Markdown document. Some people place them immediately after the paragraph in which they appear while other people place them at the end of the document (like endnotes or footnotes).","title":"Formatting the Second Part of the Link"},{"location":"extern/md-guide/_basic-syntax/links/#an-example-putting-the-parts-together","text":"Say you add a URL as a standard URL link to a paragraph and it looks like this in Markdown: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [hobbit-hole](https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\"), and that means comfort. Though it may point to interesting additional information, the URL as displayed really doesn't add much to the existing raw text other than making it harder to read. To fix that, you could format the URL like this instead: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a [hobbit-hole][1], and that means comfort. [1]: <https://en.wikipedia.org/wiki/Hobbit#Lifestyle> \"Hobbit lifestyles\" In both instances above, the rendered output would be identical: In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole , and that means comfort. and the HTML for the link would be: <a href=\"https://en.wikipedia.org/wiki/Hobbit#Lifestyle\" title=\"Hobbit lifestyles\">hobbit-hole</a>","title":"An Example Putting the Parts Together"},{"location":"extern/md-guide/_basic-syntax/links/#link-best-practices","text":"Markdown applications don't agree on how to handle spaces in the middle of a URL. For compatibility, try to URL encode any spaces with %20 . \u2705 Do this \u274c Don't do this [link](https://www.example.com/my%20great%20page) [link](https://www.example.com/my great page)","title":"Link Best Practices"},{"location":"extern/md-guide/_basic-syntax/lists/","text":"You can organize items into ordered and unordered lists. {% include syntax.html type=\"basic-sub\" syntax-id=\"ordered-lists\" %} {% include syntax.html type=\"basic-sub\" syntax-id=\"unordered-lists\" %} Adding Elements in Lists \u00b6 To add another element in a list while preserving the continuity of the list, indent the element four spaces or one tab, as shown in the following examples. Paragraphs \u00b6 * This is the first list item. * Here's the second list item. I need to add another paragraph below the second list item. * And here's the third list item. The rendered output looks like this: This is the first list item. Here's the second list item. I need to add another paragraph below the second list item. And here's the third list item. Blockquotes \u00b6 * This is the first list item. * Here's the second list item. > A blockquote would look great below the second list item. * And here's the third list item. The rendered output looks like this: This is the first list item. Here's the second list item. A blockquote would look great below the second list item. And here's the third list item. Code Blocks \u00b6 Code blocks are normally indented four spaces or one tab. When they're in a list, indent them eight spaces or two tabs. 1. Open the file. 2. Find the following code block on line 21: <html> <head> <title>Test</title> </head> 3. Update the title to match the name of your website. The rendered output looks like this: Open the file. Find the following code block on line 21: <html> <head> <title>Test</title> </head> Update the title to match the name of your website. Images \u00b6 1. Open the file containing the Linux mascot. 2. Marvel at its beauty. ![Tux, the Linux mascot](/assets/images/tux.png) 3. Close the file. The rendered output looks like this: Open the file containing the Linux mascot. Marvel at its beauty. Close the file.","title":"Lists"},{"location":"extern/md-guide/_basic-syntax/lists/#adding-elements-in-lists","text":"To add another element in a list while preserving the continuity of the list, indent the element four spaces or one tab, as shown in the following examples.","title":"Adding Elements in Lists"},{"location":"extern/md-guide/_basic-syntax/lists/#paragraphs","text":"* This is the first list item. * Here's the second list item. I need to add another paragraph below the second list item. * And here's the third list item. The rendered output looks like this: This is the first list item. Here's the second list item. I need to add another paragraph below the second list item. And here's the third list item.","title":"Paragraphs"},{"location":"extern/md-guide/_basic-syntax/lists/#blockquotes","text":"* This is the first list item. * Here's the second list item. > A blockquote would look great below the second list item. * And here's the third list item. The rendered output looks like this: This is the first list item. Here's the second list item. A blockquote would look great below the second list item. And here's the third list item.","title":"Blockquotes"},{"location":"extern/md-guide/_basic-syntax/lists/#code-blocks-1","text":"Code blocks are normally indented four spaces or one tab. When they're in a list, indent them eight spaces or two tabs. 1. Open the file. 2. Find the following code block on line 21: <html> <head> <title>Test</title> </head> 3. Update the title to match the name of your website. The rendered output looks like this: Open the file. Find the following code block on line 21: <html> <head> <title>Test</title> </head> Update the title to match the name of your website.","title":"Code Blocks"},{"location":"extern/md-guide/_basic-syntax/lists/#images","text":"1. Open the file containing the Linux mascot. 2. Marvel at its beauty. ![Tux, the Linux mascot](/assets/images/tux.png) 3. Close the file. The rendered output looks like this: Open the file containing the Linux mascot. Marvel at its beauty. Close the file.","title":"Images"},{"location":"extern/md-guide/_basic-syntax/ordered-lists/","text":"To create an ordered list, add line items with numbers followed by periods. The numbers don't have to be in numerical order, but the list should start with the number one. Markdown HTML Rendered Output 1. First item 2. Second item 3. Third item 4. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ol> First item Second item Third item Fourth item 1. First item 1. Second item 1. Third item 1. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ol> First item Second item Third item Fourth item 1. First item 8. Second item 3. Third item 5. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ol> First item Second item Third item Fourth item 1. First item 2. Second item 3. Third item 1. Indented item 2. Indented item 4. Fourth item <ol> <li>First item</li> <li>Second item</li> <li>Third item <ol> <li>Indented item</li> <li>Indented item</li> </ol> </li> <li>Fourth item</li> </ol> First item Second item Third item Indented item Indented item Fourth item","title":"Ordered Lists"},{"location":"extern/md-guide/_basic-syntax/overview/","text":"Nearly all Markdown applications support the basic syntax outlined in John Gruber's original design document. There are minor variations and discrepancies between Markdown processors \u2014 those are noted inline wherever possible.","title":"Overview"},{"location":"extern/md-guide/_basic-syntax/paragraphs/","text":"To create paragraphs, use a blank line to separate one or more lines of text. Markdown HTML Rendered Output I really like using Markdown. I think I'll use it to format all of my documents from now on. <p>I really like using Markdown.</p> <p>I think I'll use it to format all of my documents from now on.</p> I really like using Markdown. I think I'll use it to format all of my documents from now on. Paragraph Best Practices \u00b6 Unless the paragraph is in a list , don't indent paragraphs with spaces or tabs. \u2705 Do this \u274c Don't do this Don't put tabs or spaces in front of your paragraphs. Keep lines left-aligned like this. This can result in unexpected formatting problems. Don't add tabs or spaces in front of paragraphs.","title":"Paragraphs"},{"location":"extern/md-guide/_basic-syntax/paragraphs/#paragraph-best-practices","text":"Unless the paragraph is in a list , don't indent paragraphs with spaces or tabs. \u2705 Do this \u274c Don't do this Don't put tabs or spaces in front of your paragraphs. Keep lines left-aligned like this. This can result in unexpected formatting problems. Don't add tabs or spaces in front of paragraphs.","title":"Paragraph Best Practices"},{"location":"extern/md-guide/_basic-syntax/unordered-lists/","text":"To create an unordered list, add dashes ( - ), asterisks ( * ), or plus signs ( + ) in front of line items. Indent one or more items to create a nested list. Markdown HTML Rendered Output - First item - Second item - Third item - Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ul> First item Second item Third item Fourth item * First item * Second item * Third item * Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ul> First item Second item Third item Fourth item + First item * Second item - Third item + Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item</li> <li>Fourth item</li> </ul> First item Second item Third item Fourth item - First item - Second item - Third item - Indented item - Indented item - Fourth item <ul> <li>First item</li> <li>Second item</li> <li>Third item <ul> <li>Indented item</li> <li>Indented item</li> </ul> </li> <li>Fourth item</li> </ul> First item Second item Third item Indented item Indented item Fourth item","title":"Unordered Lists"},{"location":"extern/md-guide/_extended-syntax/automatic-url-linking/","text":"Many Markdown processors automatically turn URLs into links. That means if you type http://www.example.com, your Markdown processor will automatically turn it into a link even though you haven\u2019t used brackets . http://www.example.com The rendered output looks like this: http://www.example.com Disabling Automatic URL Linking \u00b6 If you don't want a URL to be automatically linked, you can remove the link by denoting the URL as code with backticks. `http://www.example.com` The rendered output looks like this: http://www.example.com","title":"Automatic URL Linking"},{"location":"extern/md-guide/_extended-syntax/automatic-url-linking/#disabling-automatic-url-linking","text":"If you don't want a URL to be automatically linked, you can remove the link by denoting the URL as code with backticks. `http://www.example.com` The rendered output looks like this: http://www.example.com","title":"Disabling Automatic URL Linking"},{"location":"extern/md-guide/_extended-syntax/availability/","text":"Not all Markdown applications support extended syntax elements. You'll need to check whether or not the lightweight markup language your application is using supports the extended syntax elements you want to use. If it doesn't, it may still be possible to enable extensions in your Markdown processor. Lightweight Markup Languages \u00b6 There are several lightweight markup languages that are supersets of Markdown. They include Gruber's basic syntax and build upon it by adding additional elements like tables, code blocks, syntax highlighting, URL auto-linking, and footnotes. Many of the most popular Markdown applications use one of the following lightweight markup languages: CommonMark GitHub Flavored Markdown (GFM) Markdown Extra MultiMarkdown R Markdown Markdown Processors \u00b6 There are dozens of Markdown processors available. Many of them allow you to add extensions that enable extended syntax elements. Check your processor's documentation for more information.","title":"Availability"},{"location":"extern/md-guide/_extended-syntax/availability/#lightweight-markup-languages","text":"There are several lightweight markup languages that are supersets of Markdown. They include Gruber's basic syntax and build upon it by adding additional elements like tables, code blocks, syntax highlighting, URL auto-linking, and footnotes. Many of the most popular Markdown applications use one of the following lightweight markup languages: CommonMark GitHub Flavored Markdown (GFM) Markdown Extra MultiMarkdown R Markdown","title":"Lightweight Markup Languages"},{"location":"extern/md-guide/_extended-syntax/availability/#markdown-processors","text":"There are dozens of Markdown processors available. Many of them allow you to add extensions that enable extended syntax elements. Check your processor's documentation for more information.","title":"Markdown Processors"},{"location":"extern/md-guide/_extended-syntax/definition-lists/","text":"Some Markdown processors allow you to create definition lists of terms and their corresponding definitions. To create a definition list, type the term on the first line. On the next line, type a colon followed by a space and the definition. First Term : This is the definition of the first term. Second Term : This is one definition of the second term. : This is another definition of the second term. The HTML looks like this: < dl > < dt > First Term </ dt > < dd > This is the definition of the first term. </ dd > < dt > Second Term </ dt > < dd > This is one definition of the second term. </ dd > < dd > This is another definition of the second term. </ dd > </ dl > The rendered output looks like this: First Term This is the definition of the first term. Second Term This is one definition of the second term. This is another definition of the second term.","title":"Definition Lists"},{"location":"extern/md-guide/_extended-syntax/emoji/","text":"There are two ways to add emoji to Markdown files: copy and paste the emoji into your Markdown-formatted text, or type emoji shortcodes . Copying and Pasting Emoji \u00b6 In most cases, you can simply copy an emoji from a source like Emojipedia and paste it into your document. Many Markdown applications will automatically display the emoji in the Markdown-formatted text. The HTML and PDF files you export from your Markdown application should display the emoji. Tip: If you're using a static site generator, make sure you encode HTML pages as UTF-8 . Using Emoji Shortcodes \u00b6 Some Markdown applications allow you to insert emoji by typing emoji shortcodes. These begin and end with a colon and include the name of an emoji. Gone camping! :tent: Be back soon. That is so funny! :joy: The rendered output looks like this: Gone camping! \u26fa Be back soon. That is so funny! \ud83d\ude02 Note: You can use this list of emoji shortcodes , but keep in mind that emoji shortcodes vary from application to application. Refer to your Markdown application's documentation for more information.","title":"Emoji"},{"location":"extern/md-guide/_extended-syntax/emoji/#copying-and-pasting-emoji","text":"In most cases, you can simply copy an emoji from a source like Emojipedia and paste it into your document. Many Markdown applications will automatically display the emoji in the Markdown-formatted text. The HTML and PDF files you export from your Markdown application should display the emoji. Tip: If you're using a static site generator, make sure you encode HTML pages as UTF-8 .","title":"Copying and Pasting Emoji"},{"location":"extern/md-guide/_extended-syntax/emoji/#using-emoji-shortcodes","text":"Some Markdown applications allow you to insert emoji by typing emoji shortcodes. These begin and end with a colon and include the name of an emoji. Gone camping! :tent: Be back soon. That is so funny! :joy: The rendered output looks like this: Gone camping! \u26fa Be back soon. That is so funny! \ud83d\ude02 Note: You can use this list of emoji shortcodes , but keep in mind that emoji shortcodes vary from application to application. Refer to your Markdown application's documentation for more information.","title":"Using Emoji Shortcodes"},{"location":"extern/md-guide/_extended-syntax/fenced-code-blocks/","text":"The basic Markdown syntax allows you to create code blocks by indenting lines by four spaces or one tab. If you find that inconvenient, try using fenced code blocks. Depending on your Markdown processor or editor, you'll use three backticks ( ``</code>) or three tildes ( ~ `) on the lines before and after the code block. The best part? You don't have to indent any lines! ``` { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` The rendered output looks like this: { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } Tip: Need to display backticks inside a code block? See this section to learn how to escape them. Syntax Highlighting \u00b6 Many Markdown processors support syntax highlighting for fenced code blocks. This feature allows you to add color highlighting for whatever language your code was written in. To add syntax highlighting, specify a language next to the backticks before the fenced code block. ```json { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` The rendered output looks like this: { \"firstName\" : \"John\" , \"lastName\" : \"Smith\" , \"age\" : 25 }","title":"Fenced Code Blocks"},{"location":"extern/md-guide/_extended-syntax/fenced-code-blocks/#syntax-highlighting","text":"Many Markdown processors support syntax highlighting for fenced code blocks. This feature allows you to add color highlighting for whatever language your code was written in. To add syntax highlighting, specify a language next to the backticks before the fenced code block. ```json { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } ``` The rendered output looks like this: { \"firstName\" : \"John\" , \"lastName\" : \"Smith\" , \"age\" : 25 }","title":"Syntax Highlighting"},{"location":"extern/md-guide/_extended-syntax/footnotes/","text":"Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ( [^1] ). Identifiers can be numbers or words, but they can't contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself \u2014 in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ( [^1]: My footnote. ). You don't have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. Here's a simple footnote,[^1] and here's a longer one.[^bignote] [^1]: This is the first footnote. [^bignote]: Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. `{ my code }` Add as many paragraphs as you like. The rendered output looks like this: Here's a simple footnote, 1 and here's a longer one. 2 This is the first footnote. \u21a9 Here's one with multiple paragraphs and code. Indent paragraphs to include them in the footnote. { my code } Add as many paragraphs as you like. \u21a9","title":"Footnotes"},{"location":"extern/md-guide/_extended-syntax/heading-ids/","text":"Many Markdown processors support custom IDs for headings \u2014 some Markdown processors automatically add them. Adding custom IDs allows you to link directly to headings and modify them with CSS. To add a custom heading ID, enclose the custom ID in curly braces on the same line as the heading. ### My Great Heading {#custom-id} The HTML looks like this: < h3 id = \"custom-id\" > My Great Heading </ h3 > Linking to Heading IDs \u00b6 You can link to headings with custom IDs in the file by creating a standard link with a number sign ( # ) followed by the custom heading ID. Markdown HTML Rendered Output [Heading IDs](#heading-ids) <a href=\"#heading-ids\">Heading IDs</a> Heading IDs Other websites can link to the heading by adding the custom heading ID to the full URL of the webpage (e.g, [Heading IDs](https://www.markdownguide.org/extended-syntax#heading-ids) ).","title":"Heading IDs"},{"location":"extern/md-guide/_extended-syntax/heading-ids/#linking-to-heading-ids","text":"You can link to headings with custom IDs in the file by creating a standard link with a number sign ( # ) followed by the custom heading ID. Markdown HTML Rendered Output [Heading IDs](#heading-ids) <a href=\"#heading-ids\">Heading IDs</a> Heading IDs Other websites can link to the heading by adding the custom heading ID to the full URL of the webpage (e.g, [Heading IDs](https://www.markdownguide.org/extended-syntax#heading-ids) ).","title":"Linking to Heading IDs"},{"location":"extern/md-guide/_extended-syntax/overview/","text":"The basic syntax outlined in John Gruber's original design document added many of the elements needed on a day-to-day basis, but it wasn't enough for some people. That's where extended syntax comes in. Several individuals and organizations took it upon themselves to extend the basic syntax by adding additional elements like tables, code blocks, syntax highlighting, URL auto-linking, and footnotes. These elements can be enabled by using a lightweight markup language that builds upon the basic Markdown syntax, or by adding an extension to a compatible Markdown processor.","title":"Overview"},{"location":"extern/md-guide/_extended-syntax/strikethrough/","text":"You can strikethrough words by putting a horizontal line through the center of them. The result looks like this . This feature allows you to indicate that certain words are a mistake not meant for inclusion in the document. To strikethrough words, use two tilde symbols ( ~~ ) before and after the words. ~~The world is flat.~~ We now know that the world is round. The rendered output looks like this: The world is flat. We now know that the world is round.","title":"Strikethrough"},{"location":"extern/md-guide/_extended-syntax/tables/","text":"To add a table, use three or more hyphens ( --- ) to create each column's header, and use pipes ( | ) to separate each column. You can optionally add pipes on either end of the table. | Syntax | Description | | ----------- | ----------- | | Header | Title | | Paragraph | Text | The rendered output looks like this: Syntax Description Header Title Paragraph Text Cell widths can vary, as shown below. The rendered output will look the same. | Syntax | Description | | --- | ----------- | | Header | Title | | Paragraph | Text | Tip: Creating tables with hyphens and pipes can be tedious. To speed up the process, try using the Markdown Tables Generator . Build a table using the graphical interface, and then copy the generated Markdown-formatted text into your file. Alignment \u00b6 You can align text in the columns to the left, right, or center by adding a colon ( : ) to the left, right, or on both side of the hyphens within the header row. | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | The rendered output looks like this: Syntax Description Test Text Header Title Here\u2019s this Paragraph Text And more Formatting Text in Tables \u00b6 You can format the text within tables. For example, you can add links , code (words or phrases in backticks ( ` ) only, not code blocks ), and emphasis . You can't add headings, blockquotes, lists, horizontal rules, images, or HTML tags. Escaping Pipe Characters in Tables \u00b6 You can display a pipe ( | ) character in a table by using its HTML character code ( &#124; ).","title":"Tables"},{"location":"extern/md-guide/_extended-syntax/tables/#alignment","text":"You can align text in the columns to the left, right, or center by adding a colon ( : ) to the left, right, or on both side of the hyphens within the header row. | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | The rendered output looks like this: Syntax Description Test Text Header Title Here\u2019s this Paragraph Text And more","title":"Alignment"},{"location":"extern/md-guide/_extended-syntax/tables/#formatting-text-in-tables","text":"You can format the text within tables. For example, you can add links , code (words or phrases in backticks ( ` ) only, not code blocks ), and emphasis . You can't add headings, blockquotes, lists, horizontal rules, images, or HTML tags.","title":"Formatting Text in Tables"},{"location":"extern/md-guide/_extended-syntax/tables/#escaping-pipe-characters-in-tables","text":"You can display a pipe ( | ) character in a table by using its HTML character code ( &#124; ).","title":"Escaping Pipe Characters in Tables"},{"location":"extern/md-guide/_extended-syntax/task-lists/","text":"Task lists allow you to create a list of items with checkboxes. In Markdown applications that support task lists, checkboxes will be displayed next to the content. To create a task list, add dashes ( - ) and brackets with a space ( [ ] ) in front of task list items. To select a checkbox, add an x in between the brackets ( [x] ). - [x] Write the press release - [ ] Update the website - [ ] Contact the media The rendered output looks like this:","title":"Task Lists"},{"location":"extern/md-guide/_getting-started/additional-resources/","text":"Additional Resources \u00b6 There are lots of resources you can use to learn Markdown. Here are some other introductory resources: John Gruber's Markdown documentation . The original guide written by the creator of Markdown. Markdown Tutorial . An open source website that allows you to try Markdown in your web browser. Awesome Markdown . A list of Markdown tools and learning resources. Typesetting Markdown . A multi-part series that describes an ecosystem for typesetting Markdown documents using pandoc and ConTeXt .","title":"Additional resources"},{"location":"extern/md-guide/_getting-started/additional-resources/#additional-resources","text":"There are lots of resources you can use to learn Markdown. Here are some other introductory resources: John Gruber's Markdown documentation . The original guide written by the creator of Markdown. Markdown Tutorial . An open source website that allows you to try Markdown in your web browser. Awesome Markdown . A list of Markdown tools and learning resources. Typesetting Markdown . A multi-part series that describes an ecosystem for typesetting Markdown documents using pandoc and ConTeXt .","title":"Additional Resources"},{"location":"extern/md-guide/_getting-started/flavors-of-markdown/","text":"Flavors of Markdown \u00b6 One of the most confusing aspects of using Markdown is that practically every Markdown application implements a slightly different version of Markdown. These variants of Markdown are commonly referred to as flavors . It's your job to master whatever flavor of Markdown your application has implemented. To wrap your head around the concept of Markdown flavors, it might help to think of them as language dialects. People in Ciudad Ju\u00e1rez speak Spanish just like the people in Barcelona, but there are substantial differences between the dialects used in both cities. The same is true for people using different Markdown applications. Using Dillinger to write with Markdown is a vastly different experience than using Ulysses . Practically speaking, this means you never know exactly what a company means when they say they support \"Markdown.\" Are they talking about only the basic syntax elements , or all of the basic and extended syntax elements combined, or some arbitrary combination of syntax elements? You won't know until you read the documentation or start using the application. If you're just starting out, the best advice I can give you is to pick a Markdown application with good Markdown support. That'll go a long way towards maintaining the portability of your Markdown files. You might want to store and use your Markdown files in other applications, and to do that you need to start with an application that provides good support. You can use the tool directory to find an application that fits the bill.","title":"Flavors of markdown"},{"location":"extern/md-guide/_getting-started/flavors-of-markdown/#flavors-of-markdown","text":"One of the most confusing aspects of using Markdown is that practically every Markdown application implements a slightly different version of Markdown. These variants of Markdown are commonly referred to as flavors . It's your job to master whatever flavor of Markdown your application has implemented. To wrap your head around the concept of Markdown flavors, it might help to think of them as language dialects. People in Ciudad Ju\u00e1rez speak Spanish just like the people in Barcelona, but there are substantial differences between the dialects used in both cities. The same is true for people using different Markdown applications. Using Dillinger to write with Markdown is a vastly different experience than using Ulysses . Practically speaking, this means you never know exactly what a company means when they say they support \"Markdown.\" Are they talking about only the basic syntax elements , or all of the basic and extended syntax elements combined, or some arbitrary combination of syntax elements? You won't know until you read the documentation or start using the application. If you're just starting out, the best advice I can give you is to pick a Markdown application with good Markdown support. That'll go a long way towards maintaining the portability of your Markdown files. You might want to store and use your Markdown files in other applications, and to do that you need to start with an application that provides good support. You can use the tool directory to find an application that fits the bill.","title":"Flavors of Markdown"},{"location":"extern/md-guide/_getting-started/how-does-it-work/","text":"How Does it Work? \u00b6 Dillinger makes writing in Markdown easy because it hides the stuff happening behind the scenes, but it's worth exploring how the process works in general. When you write in Markdown, the text is stored in a plaintext file that has an .md or .markdown extension. But then what? How is your Markdown-formatted file converted into HTML or a print-ready document? The short answer is that you need a Markdown application capable of processing the Markdown file. There are lots of applications available \u2014 everything from simple scripts to desktop applications that look like Microsoft Word. Despite their visual differences, all of the applications do the same thing. Like Dillinger, they all convert Markdown-formatted text to HTML so it can be displayed in web browsers. Markdown applications use something called a Markdown processor (also commonly referred to as a \"parser\" or an \"implementation\") to take the Markdown-formatted text and output it to HTML format. At that point, your document can be viewed in a web browser or combined with a style sheet and printed. You can see a visual representation of this process below. Note: The Markdown application and processor are two separate components. For the sake of brevity, I've combined them into one element (\"Markdown App\") in the figure below. To summarize, this is a four-part process: Create a Markdown file using a text editor or a dedicated Markdown application. The file should have an .md or .markdown extension. Open the Markdown file in a Markdown application. Use the Markdown application to convert the Markdown file to an HTML document. View the HTML file in a web browser or use the Markdown application to convert it to another file format, like PDF. From your perspective, the process will vary somewhat depending on the application you use. For example, Dillinger essentially combines steps 1-3 into a single, seamless interface \u2014 all you have to do is type in the left pane and the rendered output magically appears in the right pane. But if you use other tools, like a text editor with a static website generator, you'll find that the process is much more visible.","title":"How does it work"},{"location":"extern/md-guide/_getting-started/how-does-it-work/#how-does-it-work","text":"Dillinger makes writing in Markdown easy because it hides the stuff happening behind the scenes, but it's worth exploring how the process works in general. When you write in Markdown, the text is stored in a plaintext file that has an .md or .markdown extension. But then what? How is your Markdown-formatted file converted into HTML or a print-ready document? The short answer is that you need a Markdown application capable of processing the Markdown file. There are lots of applications available \u2014 everything from simple scripts to desktop applications that look like Microsoft Word. Despite their visual differences, all of the applications do the same thing. Like Dillinger, they all convert Markdown-formatted text to HTML so it can be displayed in web browsers. Markdown applications use something called a Markdown processor (also commonly referred to as a \"parser\" or an \"implementation\") to take the Markdown-formatted text and output it to HTML format. At that point, your document can be viewed in a web browser or combined with a style sheet and printed. You can see a visual representation of this process below. Note: The Markdown application and processor are two separate components. For the sake of brevity, I've combined them into one element (\"Markdown App\") in the figure below. To summarize, this is a four-part process: Create a Markdown file using a text editor or a dedicated Markdown application. The file should have an .md or .markdown extension. Open the Markdown file in a Markdown application. Use the Markdown application to convert the Markdown file to an HTML document. View the HTML file in a web browser or use the Markdown application to convert it to another file format, like PDF. From your perspective, the process will vary somewhat depending on the application you use. For example, Dillinger essentially combines steps 1-3 into a single, seamless interface \u2014 all you have to do is type in the left pane and the rendered output magically appears in the right pane. But if you use other tools, like a text editor with a static website generator, you'll find that the process is much more visible.","title":"How Does it Work?"},{"location":"extern/md-guide/_getting-started/kicking-the-tires/","text":"Kicking the Tires \u00b6 The best way to get started with Markdown is to use it. That's easier than ever before thanks to a variety of free tools. You don't even need to download anything. There are several online Markdown editors that you can use to try writing in Markdown. Dillinger is one of the best online Markdown editors. Just open the site and start typing in the left pane. A preview of the rendered document appears in the right pane. You'll probably want to keep the Dillinger website open as you read through this guide. That way you can try the syntax as you learn about it. After you've become familiar with Markdown, you may want to use a Markdown application that can be installed on your desktop computer or mobile device.","title":"Kicking the tires"},{"location":"extern/md-guide/_getting-started/kicking-the-tires/#kicking-the-tires","text":"The best way to get started with Markdown is to use it. That's easier than ever before thanks to a variety of free tools. You don't even need to download anything. There are several online Markdown editors that you can use to try writing in Markdown. Dillinger is one of the best online Markdown editors. Just open the site and start typing in the left pane. A preview of the rendered document appears in the right pane. You'll probably want to keep the Dillinger website open as you read through this guide. That way you can try the syntax as you learn about it. After you've become familiar with Markdown, you may want to use a Markdown application that can be installed on your desktop computer or mobile device.","title":"Kicking the Tires"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/","text":"What's Markdown Good For? \u00b6 Markdown is a fast and easy way to take notes, create content for a website, and produce print-ready documents. It doesn't take long to learn the Markdown syntax, and once you know how to use it, you can write using Markdown just about everywhere. Most people use Markdown to create content for the web, but Markdown is good for formatting everything from email messages to grocery lists. Here are some examples of what you can do with Markdown. Websites \u00b6 Markdown was designed for the web, so it should come as no surprise that there are plenty of applications specifically designed for creating website content. If you're looking for the simplest possible way to create a website with Markdown files, check out blot.im and smallvictori.es . After you sign up for one of these services, they create a Dropbox folder on your computer. Just drag and drop your Markdown files into the folder and \u2014 poof! \u2014 they're on your website. It couldn't be easier. If you're familiar with HTML, CSS, and version control, check out Jekyll , a popular static site generator that takes Markdown files and builds an HTML website. One advantage to this approach is that GitHub Pages provides free hosting for Jekyll-generated websites. If Jekyll isn't your cup of tea, just pick one of the many other static site generators available . Note: I used Jekyll to create the Markdown Guide . You can view the source code on GitHub . If you'd like to use a content management system (CMS) to power your website, take a look at Ghost . It's a free and open-source blogging platform with a nice Markdown editor. If you're a WordPress user, you'll be happy to know there's Markdown support for websites hosted on WordPress.com. Self-hosted WordPress sites can use the Jetpack plugin . Documents \u00b6 Markdown doesn't have all the bells and whistles of word processors like Microsoft Word, but it's good enough for creating basic documents like assignments and letters. You can use a Markdown document authoring application to create and export Markdown-formatted documents to PDF or HTML file format. The PDF part is key, because once you have a PDF document, you can do anything with it \u2014 print it, email it, or upload it to a website. Here are some Markdown document authoring applications I recommend: Mac: MacDown , iA Writer , or Marked iOS / Android: iA Writer Windows: ghostwriter or Markdown Monster Linux: ReText or ghostwriter Web: Dillinger or StackEdit Tip: iA Writer provides templates for previewing, printing, and exporting Markdown-formatted documents. For example, the \"Academic \u2013 MLA Style\" template indents paragraphs and adds double sentence spacing. Notes \u00b6 In nearly every way, Markdown is the ideal syntax for taking notes. Sadly, Evernote and OneNote , two of the most popular note applications, don't currently support Markdown. The good news is that several other note applications do support Markdown: Simplenote is a free, barebones note-taking application available for every platform. Notable is a note-taking application that runs on a variety of platforms. Bear is an Evernote-like application available for Mac and iOS devices. It doesn't exclusively use Markdown by default, but you can enable Markdown compatibility mode. Boostnote bills itself as an \"open source note-taking app designed for programmers.\" If you can't part with Evernote, check out Marxico , a subscription-based Markdown editor for Evernote, or use Markdown Here with the Evernote website. Books \u00b6 Looking to self-publish a novel? Try Leanpub , a service that takes your Markdown-formatted files and turns them into an electronic book. Leanpub outputs your book in PDF, EPUB, and MOBI file format. If you'd like to create paperback copies of your book, you can upload the PDF file to another service such as Kindle Direct Publishing . To learn more about writing and self-publishing a book using Markdown, read this blog post . Presentations \u00b6 Believe it or not, you can generate presentations from Markdown-formatted files. Creating presentations in Markdown takes a little getting used to, but once you get the hang of it, it's a lot faster and easier than using an application like PowerPoint or Keynote. Remark ( GitHub project ) is a popular browser-based Markdown slideshow tool, as is Cleaver ( GitHub project ). If you use a Mac and would prefer to use an application, check out Deckset or Marked . Email \u00b6 If you send a lot of email and you're tired of the formatting controls available on most email provider websites, you'll be happy to learn there's an easy way to write email messages using Markdown. Markdown Here is a free and open-source browser extension that converts Markdown-formatted text into HTML that's ready to send. Documentation \u00b6 Markdown is a natural fit for technical documentation. Companies like GitHub are increasingly switching to Markdown for their documentation \u2014 check out their blog post about how they migrated their Markdown-formatted documentation to Jekyll . If you write documentation for a product or service, take a look at these handy tools: Read the Docs can generate a documentation website from your open source Markdown files. Just connect your GitHub repository to their service and push \u2014 Read the Docs does the rest. They also have a service for commercial entities . MkDocs is a fast and simple static site generator that's geared towards building project documentation. Documentation source files are written in Markdown and configured with a single YAML configuration file. MkDocs has several built in themes , including a port of the Read the Docs documentation theme for use with MkDocs. One of the newest themes is MkDocs Material . Docusaurus is a static site generator designed exclusively for creating documentation websites. It supports translations, search, and versioning. VuePress is a static site generator powered by Vue and optimized for writing technical documentation. Jekyll was mentioned earlier in the section on websites, but it's also a good option for generating a documentation website from Markdown files. If you go this route, be sure to check out the Jekyll documentation theme .","title":"Whats markdown good for"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#whats-markdown-good-for","text":"Markdown is a fast and easy way to take notes, create content for a website, and produce print-ready documents. It doesn't take long to learn the Markdown syntax, and once you know how to use it, you can write using Markdown just about everywhere. Most people use Markdown to create content for the web, but Markdown is good for formatting everything from email messages to grocery lists. Here are some examples of what you can do with Markdown.","title":"What's Markdown Good For?"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#websites","text":"Markdown was designed for the web, so it should come as no surprise that there are plenty of applications specifically designed for creating website content. If you're looking for the simplest possible way to create a website with Markdown files, check out blot.im and smallvictori.es . After you sign up for one of these services, they create a Dropbox folder on your computer. Just drag and drop your Markdown files into the folder and \u2014 poof! \u2014 they're on your website. It couldn't be easier. If you're familiar with HTML, CSS, and version control, check out Jekyll , a popular static site generator that takes Markdown files and builds an HTML website. One advantage to this approach is that GitHub Pages provides free hosting for Jekyll-generated websites. If Jekyll isn't your cup of tea, just pick one of the many other static site generators available . Note: I used Jekyll to create the Markdown Guide . You can view the source code on GitHub . If you'd like to use a content management system (CMS) to power your website, take a look at Ghost . It's a free and open-source blogging platform with a nice Markdown editor. If you're a WordPress user, you'll be happy to know there's Markdown support for websites hosted on WordPress.com. Self-hosted WordPress sites can use the Jetpack plugin .","title":"Websites"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#documents","text":"Markdown doesn't have all the bells and whistles of word processors like Microsoft Word, but it's good enough for creating basic documents like assignments and letters. You can use a Markdown document authoring application to create and export Markdown-formatted documents to PDF or HTML file format. The PDF part is key, because once you have a PDF document, you can do anything with it \u2014 print it, email it, or upload it to a website. Here are some Markdown document authoring applications I recommend: Mac: MacDown , iA Writer , or Marked iOS / Android: iA Writer Windows: ghostwriter or Markdown Monster Linux: ReText or ghostwriter Web: Dillinger or StackEdit Tip: iA Writer provides templates for previewing, printing, and exporting Markdown-formatted documents. For example, the \"Academic \u2013 MLA Style\" template indents paragraphs and adds double sentence spacing.","title":"Documents"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#notes","text":"In nearly every way, Markdown is the ideal syntax for taking notes. Sadly, Evernote and OneNote , two of the most popular note applications, don't currently support Markdown. The good news is that several other note applications do support Markdown: Simplenote is a free, barebones note-taking application available for every platform. Notable is a note-taking application that runs on a variety of platforms. Bear is an Evernote-like application available for Mac and iOS devices. It doesn't exclusively use Markdown by default, but you can enable Markdown compatibility mode. Boostnote bills itself as an \"open source note-taking app designed for programmers.\" If you can't part with Evernote, check out Marxico , a subscription-based Markdown editor for Evernote, or use Markdown Here with the Evernote website.","title":"Notes"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#books","text":"Looking to self-publish a novel? Try Leanpub , a service that takes your Markdown-formatted files and turns them into an electronic book. Leanpub outputs your book in PDF, EPUB, and MOBI file format. If you'd like to create paperback copies of your book, you can upload the PDF file to another service such as Kindle Direct Publishing . To learn more about writing and self-publishing a book using Markdown, read this blog post .","title":"Books"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#presentations","text":"Believe it or not, you can generate presentations from Markdown-formatted files. Creating presentations in Markdown takes a little getting used to, but once you get the hang of it, it's a lot faster and easier than using an application like PowerPoint or Keynote. Remark ( GitHub project ) is a popular browser-based Markdown slideshow tool, as is Cleaver ( GitHub project ). If you use a Mac and would prefer to use an application, check out Deckset or Marked .","title":"Presentations"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#email","text":"If you send a lot of email and you're tired of the formatting controls available on most email provider websites, you'll be happy to learn there's an easy way to write email messages using Markdown. Markdown Here is a free and open-source browser extension that converts Markdown-formatted text into HTML that's ready to send.","title":"Email"},{"location":"extern/md-guide/_getting-started/whats-markdown-good-for/#documentation","text":"Markdown is a natural fit for technical documentation. Companies like GitHub are increasingly switching to Markdown for their documentation \u2014 check out their blog post about how they migrated their Markdown-formatted documentation to Jekyll . If you write documentation for a product or service, take a look at these handy tools: Read the Docs can generate a documentation website from your open source Markdown files. Just connect your GitHub repository to their service and push \u2014 Read the Docs does the rest. They also have a service for commercial entities . MkDocs is a fast and simple static site generator that's geared towards building project documentation. Documentation source files are written in Markdown and configured with a single YAML configuration file. MkDocs has several built in themes , including a port of the Read the Docs documentation theme for use with MkDocs. One of the newest themes is MkDocs Material . Docusaurus is a static site generator designed exclusively for creating documentation websites. It supports translations, search, and versioning. VuePress is a static site generator powered by Vue and optimized for writing technical documentation. Jekyll was mentioned earlier in the section on websites, but it's also a good option for generating a documentation website from Markdown files. If you go this route, be sure to check out the Jekyll documentation theme .","title":"Documentation"},{"location":"extern/md-guide/_getting-started/whats-markdown/","text":"What's Markdown? \u00b6 Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Created by John Gruber in 2004, Markdown is now one of the world's most popular markup languages. Using Markdown is different than using a WYSIWYG editor. In an application like Microsoft Word, you click buttons to format words and phrases, and the changes are visible immediately. Markdown isn't like that. When you create a Markdown-formatted file, you add Markdown syntax to the text to indicate which words and phrases should look different. For instance, to denote a heading, you add a number sign before it (e.g., # Heading One ). Or to make a phrase bold, you add two asterisks before and after it (e.g., **this text is bold** ). It may take a while to get used to seeing Markdown syntax in your text, especially if you're accustomed to WYSIWYG applications. The screenshot below shows a Markdown file displayed in the Atom text editor . You can add Markdown formatting elements to a plaintext file using a text editor application. Or you can use one of the many Markdown applications for macOS, Windows, Linux, iOS, and Android operating systems. There are also several web-based applications specifically designed for writing in Markdown. Depending on the application you use, you may not be able to preview the formatted document in real time. But that's okay. According to Gruber , Markdown syntax is designed to be readable and unobtrusive, so the text in Markdown files can be read even if it isn't rendered. The overriding design goal for Markdown\u2019s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it\u2019s been marked up with tags or formatting instructions.","title":"Whats markdown"},{"location":"extern/md-guide/_getting-started/whats-markdown/#whats-markdown","text":"Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Created by John Gruber in 2004, Markdown is now one of the world's most popular markup languages. Using Markdown is different than using a WYSIWYG editor. In an application like Microsoft Word, you click buttons to format words and phrases, and the changes are visible immediately. Markdown isn't like that. When you create a Markdown-formatted file, you add Markdown syntax to the text to indicate which words and phrases should look different. For instance, to denote a heading, you add a number sign before it (e.g., # Heading One ). Or to make a phrase bold, you add two asterisks before and after it (e.g., **this text is bold** ). It may take a while to get used to seeing Markdown syntax in your text, especially if you're accustomed to WYSIWYG applications. The screenshot below shows a Markdown file displayed in the Atom text editor . You can add Markdown formatting elements to a plaintext file using a text editor application. Or you can use one of the many Markdown applications for macOS, Windows, Linux, iOS, and Android operating systems. There are also several web-based applications specifically designed for writing in Markdown. Depending on the application you use, you may not be able to preview the formatted document in real time. But that's okay. According to Gruber , Markdown syntax is designed to be readable and unobtrusive, so the text in Markdown files can be read even if it isn't rendered. The overriding design goal for Markdown\u2019s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it\u2019s been marked up with tags or formatting instructions.","title":"What's Markdown?"},{"location":"extern/md-guide/_getting-started/why-use-markdown/","text":"Why Use Markdown? \u00b6 You might be wondering why people use Markdown instead of a WYSIWYG editor. Why write with Markdown when you can press buttons in an interface to format your text? As it turns out, there are a couple different reasons why people use Markdown instead of WYSIWYG editors. Markdown can be used for everything. People use it to create websites , documents , notes , books , presentations , email messages , and technical documentation . Markdown is portable. Files containing Markdown-formatted text can be opened using virtually any application. If you decide you don't like the Markdown application you're currently using, you can import your Markdown files into another Markdown application. That's in stark contrast to word processing applications like Microsoft Word that lock your content into a proprietary file format. Markdown is platform independent. You can create Markdown-formatted text on any device running any operating system. Markdown is future proof. Even if the application you're using stops working at some point in the future, you'll still be able to read your Markdown-formatted text using a text editing application. This is an important consideration when it comes to books, university theses, and other milestone documents that need to be preserved indefinitely. Markdown is everywhere. Websites like Reddit and GitHub support Markdown, and lots of desktop and web-based applications support it.","title":"Why use markdown"},{"location":"extern/md-guide/_getting-started/why-use-markdown/#why-use-markdown","text":"You might be wondering why people use Markdown instead of a WYSIWYG editor. Why write with Markdown when you can press buttons in an interface to format your text? As it turns out, there are a couple different reasons why people use Markdown instead of WYSIWYG editors. Markdown can be used for everything. People use it to create websites , documents , notes , books , presentations , email messages , and technical documentation . Markdown is portable. Files containing Markdown-formatted text can be opened using virtually any application. If you decide you don't like the Markdown application you're currently using, you can import your Markdown files into another Markdown application. That's in stark contrast to word processing applications like Microsoft Word that lock your content into a proprietary file format. Markdown is platform independent. You can create Markdown-formatted text on any device running any operating system. Markdown is future proof. Even if the application you're using stops working at some point in the future, you'll still be able to read your Markdown-formatted text using a text editing application. This is an important consideration when it comes to books, university theses, and other milestone documents that need to be preserved indefinitely. Markdown is everywhere. Websites like Reddit and GitHub support Markdown, and lots of desktop and web-based applications support it.","title":"Why Use Markdown?"},{"location":"extern/md-guide/_tools/bear/","text":"Bear is a macOS and iOS application designed for one thing: note taking. It's like Evernote , but without the bloat. There aren't a lot of whizbang features in Bear. Instead, Bear consistently delivers on all of its promises. Tags, search, and syncing all work flawlessly. The application is intuitive, and that's exactly what you want when you're taking notes. Bear doesn't automatically enable support Markdown by default, but you can enable it in the preferences . The application has a hybrid live editor and text editor \u2014 you can see both the Markdown syntax and the way the formatting changes the text. It takes a while to get used to, but it's useful if you're just getting started with Markdown. Enabling Markdown Support \u00b6 To enable Markdown support in Bear, open the Preferences window. On the General tab, turn on the setting for Markdown compatibility mode . Tip: If you're using Bear on more than one device, you'll need to enable the Markdown compatibility mode setting on all of your devices. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Bear provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase Underline ~word or phrase~ word or phrase","title":"Bear"},{"location":"extern/md-guide/_tools/bear/#enabling-markdown-support","text":"To enable Markdown support in Bear, open the Preferences window. On the General tab, turn on the setting for Markdown compatibility mode . Tip: If you're using Bear on more than one device, you'll need to enable the Markdown compatibility mode setting on all of your devices. {% include tool-syntax-table.html %}","title":"Enabling Markdown Support"},{"location":"extern/md-guide/_tools/bear/#support-for-additional-syntax-elements","text":"As an added bonus, Bear provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase Underline ~word or phrase~ word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/boostnote/","text":"Boostnote bills itself as a note taking application for developers, but anyone in need of a Markdown application for notes would be happy with this application. Markdown support is excellent. The application's interface is polished and intuitive, and open source clients are freely available for macOS, Windows, and Linux operating systems. Boostnote allows you create folders, tag notes, and export Markdown files to HTML and PDF file format. {% include tool-syntax-table.html %}","title":"Boostnote"},{"location":"extern/md-guide/_tools/byword/","text":"Byword is no-frills Markdown editor for macOS and iOS. You type Markdown-formatted text, use a menu option to invoke the preview, and export to one of several available file formats including HTML, PDF, Microsoft Word, and LaTeX. You can publish to several blogging services, and the iCloud sync feature lets you author and access the files from all of your Apple devices. Byword isn't fancy by any means \u2014 some people might even be put off by the application's insubstantial look and feel \u2014 but it gets the job done. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Byword provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Byword"},{"location":"extern/md-guide/_tools/byword/#support-for-additional-syntax-elements","text":"As an added bonus, Byword provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/codimd/","text":"CodiMD is an open-source real-time collaborative Markdown editor. You can easily deploy CodiMD with Docker following this tutorial . CodiMD supports CommonMark and other markup syntax, such as: MathJax for formulas Mermaid and Graphviz for UML diagrams Vega-lite for data visualizations CodiMD is the open-source version of HackMD . {% include tool-syntax-table.html %}","title":"CodiMD"},{"location":"extern/md-guide/_tools/collected-notes/","text":"Collected Notes is a note-taking platform that can publish your Markdown notes on the internet. Your notes can be kept private or published on a public webpage. You can author notes using the Collected Notes website or the macOS and iOS applications. This is a new application that debuted in the middle of 2020. Some of the kinks are still being worked out, but there's a lot of potential here! See the feature roadmap for a list of stuff that's slated to be implemented. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Collected Notes provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase","title":"Collected Notes"},{"location":"extern/md-guide/_tools/collected-notes/#support-for-additional-syntax-elements","text":"As an added bonus, Collected Notes provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/dillinger/","text":"Dillinger is an online Markdown editor. Like StackEdit , it loads right in your web browser, so there's no need to download and install an application on your computer. Dillinger has two panes: the editor on the left, and the live preview on the right. The split panes make it easy to see what Markdown-formatted text looks like. Dillinger provides excellent Markdown support. Unfortunately, the export options are not customizable and the file saving features are a bit flaky. And since Dillinger loads in your web browser, it's entirely dependent on a consistent internet connection. If your internet connection goes down or your web browser crashes, you could lose your work. For those reasons, Dillinger is best used for experimentation and quick note taking. The application uses the markdown-it Markdown processor. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Dillinger provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Dillinger"},{"location":"extern/md-guide/_tools/dillinger/#support-for-additional-syntax-elements","text":"As an added bonus, Dillinger provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/docusaurus/","text":"Docusaurus is an open-source static site generator that converts Markdown files to a documentation website. Created by Facebook, Docusaurus is written in the Node.js programming language. Thousands of organizations use Docusaurus to power their documentation websites. An example of a website generated by Docusaurus is shown below. Docusaurus uses the remarkable Markdown processor. {% include tool-syntax-table.html %}","title":"Docusaurus"},{"location":"extern/md-guide/_tools/ghost/","text":"Ghost is a relatively new content management system (CMS) for blogging that competes with older, established CMS products like WordPress and Drupal. Ghost is an open source project renowned for its speed, simplicity, and ease of use. Markdown support is standard and available out-of-the-box. There are a couple minor compatibility issues noted below but, generally speaking, Ghost has solid Markdown support. The live editor is fairly intuitive and seems like a good choice for bloggers. Copying and pasting Markdown-formatted text into the editor works the way you'd expect it to. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Ghost provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^super^ X super","title":"Ghost"},{"location":"extern/md-guide/_tools/ghost/#support-for-additional-syntax-elements","text":"As an added bonus, Ghost provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^super^ X super","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/gitbook/","text":"GitBook is a hosted solution for documentation websites and knowledge bases. In a nutshell, you sign in to GitBook's website and use their web-based editor to write your documentation. Or, if you'd rather maintain control over your content, you can keep it in a GitHub repository that is integrated with GitBook . Either way, you can create different webpages and organize them in a logical order. When everything looks the way you want it, you can publish it on a custom domain. Like so many projects, GitBook started as an open source toolchain with a commercial offering, but eventually dropped the open source project in favor of a new proprietary and closed-source offering that's hosted exclusively on their website. The open source toolchain is still available , but as that option is now unsupported, this article only documents the new hosted option. The advantage of GitBook over a tool like Docusaurus is that GitBook takes care of building and hosting the site, and the WYSIWYG controls are intuitive enough to be used by Markdown novices. On the GitBook website, the live editor hides the Markdown formatting syntax after you type it. The editor is a bit flaky, but weird little bugs aside, the website generally works for both Markdown experts and people who don't have any experience with Markdown. You can also simply copy and paste Markdown-formatted text into the GitBook interface. {% include tool-syntax-table.html %}","title":"GitBook"},{"location":"extern/md-guide/_tools/github-pages/","text":"GitHub Pages is a service that turns Markdown files into a website and hosts them for free on the internet. If you know how to use GitHub and you need to create a simple webpage, you can't do better than GitHub Pages. Just create a new repository on GitHub, commit the Markdown files, and enable the GitHub Pages feature. GitHub Pages uses the Jekyll static site generator to create your website, and the Markdown support is excellent. You can pick one of GitHub's pre-made themes for your website, use a Jekyll theme , or use your own custom CSS. Shown below is a sample webpage using one of GitHub's pre-made themes. Confusingly, GitHub Pages renders Markdown differently than GitHub does. GitHub uses its own Markdown processor; GitHub Pages uses jekyll-commonmark . This means your README.md file will look different on GitHub's website than on your GitHub Pages website. For example, emoji are rendered on GitHub's website, but not on websites generated using GitHub Pages. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, GitHub Pages provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"GitHub Pages"},{"location":"extern/md-guide/_tools/github-pages/#support-for-additional-syntax-elements","text":"As an added bonus, GitHub Pages provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/hackmd/","text":"HackMD is a real-time, multi-platform collaborative Markdown editor. You can use HackMD to write notes with other people on your computer, tablet, or phone. HackMD provides a variety of document templates and allows users to push documents to GitHub. You can import and export documents from Dropbox, Google Drive, and GitHub gists. HackMD supports CommonMark and other markup syntax, such as: MathJax for formulas Mermaid and Graphviz for UML diagrams Vega-lite for data visualizations HackMD is the commercial version of CodiMD . {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, HackMD provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"HackMD"},{"location":"extern/md-guide/_tools/hackmd/#support-for-additional-syntax-elements","text":"As an added bonus, HackMD provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/hugo/","text":"Hugo is a popular static site generator written in the Go programming language. Hugo is jam-packed with features, but one of its main selling points is speed \u2014 Hugo takes mere seconds to generate a site with thousands of pages. Smashing Magazine recently switched to Hugo from WordPress. Hugo has excellent Markdown support out of the box. By default, Hugo uses the Goldmark Markdown processor which is fully CommonMark-compliant. See the configuration instructions to learn more about the extensions you can configure. You can change Hugo's Goldmark settings in the config.toml file, as shown below. baseURL = \"http://mysite.org/\" languageCode = \"en-us\" title = \"My Site\" theme = \"ananke\" [markup] taskLists = false {% include tool-syntax-table.html %}","title":"Hugo"},{"location":"extern/md-guide/_tools/ia-writer/","text":"iA Writer is one of the most established and widely-acclaimed Markdown editors. Considered to be a \"gold standard\" Markdown editor, iA Writer is available for devices running macOS, Windows, iOS, and Android operating systems. The application allows you to export Markdown files to HTML, PDF, and Microsoft Word file format using custom templates . One of the hallmarks of the application is focus mode . When enabled, that feature keeps the sentence you're currently working on horizontally centered, as shown in the screenshot below. It feels a little like using a typewriter. There are a couple of quirks you should be aware of. iA Writer doesn't save new files with the Markdown extension ( .md ) by default. If you plan to exclusively create Markdown files using iA Writer, you should change the default extension to .md in Preferences > Files . The Preview button is the little triangle button in the top-right corner of the window. You can click that to preview the output, and then click it again to return to the source. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, iA Writer provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"iA Writer"},{"location":"extern/md-guide/_tools/ia-writer/#support-for-additional-syntax-elements","text":"As an added bonus, iA Writer provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/imdone/","text":"Imdone is a simple and powerful kanban board for people who work with Markdown and code. Markdown blocks in your notes, docs, and code are represented as cards on your kanban boards. You can add and edit cards using the built-in card editor or your favorite text editor, making it convenient to update your tasks while you're working on a Markdown document or code. {% include tool-syntax-table.html %}","title":"Imdone"},{"location":"extern/md-guide/_tools/jekyll/","text":"Jekyll is a static site generator that takes Markdown files and converts them to a website. Jekyll is a free and open-source application written in the Ruby programming language. Thousands of websites, including the Markdown Guide , rely on Jekyll to convert Markdown source files to HTML output. GitHub Pages uses Jekyll as the backend for its free website creation service. By default, Jekyll uses the kramdown Markdown processor with stock settings, but you can enable other kramdown options or even switch Jekyll to another Markdown processor. See the Jekyll Markdown configuration options documentation for more information. You can change Jekyll's kramdown settings in the _config.yml file. The settings for the Markdown Guide are shown below. kramdown : syntax_highlighter : rouge input : GFM auto_ids : true toc_levels : 1..3 {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Jekyll provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"Jekyll"},{"location":"extern/md-guide/_tools/jekyll/#support-for-additional-syntax-elements","text":"As an added bonus, Jekyll provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C.","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/joplin/","text":"Joplin is a free and open-source note taking application that works on every platform. Joplin's user interface isn't as polished as some of its competitors \u2014 it feels more geeky, if that makes any sense \u2014 but the application is a favorite among privacy advocates and is recommended by privacytools.io . Joplin stores notes on your local file system, provides end-to-end encryption, and allows you to synchronize files across devices by storing them on a service like Dropbox or Nextcloud. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Joplin provides support for several obscure elements. Tip: Most of these elements are disabled by default. You can enable them in Preferences > Plugins . Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Joplin"},{"location":"extern/md-guide/_tools/joplin/#support-for-additional-syntax-elements","text":"As an added bonus, Joplin provides support for several obscure elements. Tip: Most of these elements are disabled by default. You can enable them in Preferences > Plugins . Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Insert ++This text has been inserted++ This text has been inserted Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/macdown/","text":"MacDown is one of the best Markdown editors available for macOS. The application is free and open source, and it strikes a good balance between power and simplicity. MacDown provides excellent Markdown support. MacDown sports two panes \u2014 you type on the left and preview the formatted text on the right. Basic export options for HTML and PDF file format are provided. You can enable and disable support for many syntax elements, a nice feature for people who simply don't want or need all of the bells and whistles. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, MacDown provides support for several obscure elements. These are disabled by default, but you can enable them in Preferences > Markdown . Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript X^2 X 2 Underline _word or phrase_ word or phrase","title":"MacDown"},{"location":"extern/md-guide/_tools/macdown/#support-for-additional-syntax-elements","text":"As an added bonus, MacDown provides support for several obscure elements. These are disabled by default, but you can enable them in Preferences > Markdown . Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript X^2 X 2 Underline _word or phrase_ word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/mark-text/","text":"Mark Text is a popular free and open-source document editor designed exclusively for writing in Markdown. Like Typora , Mark Text has a polished interface and a live editor that hides the Markdown formatting after you type it. The PDF and HTML export options are handy, as is the feature that allows you to copy text out of the editor as Markdown, HTML, or plaintext. There are some minor annoyances. In several instances (noted below in the table), the appearance of the text in the application didn't match the rendered output of the exported HTML and PDF. And as with Notion , it can be difficult to edit Markdown-formatted text after the live editor has converted it. {% include tool-syntax-table.html %}","title":"Mark Text"},{"location":"extern/md-guide/_tools/markdeep/","text":"Markdeep is a free and simple tool that turns any Markdown file into a self-contained HTML file that can be viewed in a web browser. There's nothing to install and there's no service to register for \u2014 you simply add one line of code to the bottom of your Markdown file. This is a great option if you need to quickly view a Markdown file in a web browser or share a Markdown file with someone who needs to view the rendered output. Using Markdeep is a three-part process: Add the following tag for Markdeep on a single line at the bottom of a Markdown file. <!-- Markdeep: --><style class=\"fallback\">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src=\"markdeep.min.js\" charset=\"utf-8\"></script><script src=\"https://casual-effects.com/markdeep/latest/markdeep.min.js\" charset=\"utf-8\"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility=\"visible\")</script> Rename the Markdown file to add the .md.html extension (i.e., myfile.md.html ). Open the file in a web browser to see the rendered output. This tool has a lot of features beyond what's described here. For instance, you can choose from a variety of templates to customize the look of your page. Markdeep also supports diagrams, LaTeX typesetting for equations, and much more. Check out the excellent documentation for the full details. {% include tool-syntax-table.html %}","title":"Markdeep"},{"location":"extern/md-guide/_tools/markdown-here/","text":"Markdown Here is a free and open-source browser extension that converts Markdown text in website forms to properly-formatted rich text. This a good way to start using Markdown everywhere you type, whether you're drafting email messages in Gmail or writing blog posts in WordPress. The marketing material positions Markdown Here as a solution for email, but the extension can be used with virtually any website that supports rich text, including Evernote. See the list of compatible websites and services for more information. To use Markdown Here after installing it, start typing Markdown-formatted text in a form, like a new email message in Gmail. When you're finished writing the message, right click in the form and select Markdown Toggle , as shown in the screenshot below. Markdown Here will convert your Markdown-formatted text to properly-formatted rich text. One source of frustration is the inconsistency in rendered output. Since Markdown Here relies on the features provided by whatever rich text editor you happen to be working in, the rendered output varies from website to website. This probably goes without saying, but you should be careful to examine the output before sending your email message or saving your file. {% include tool-syntax-table.html %}","title":"Markdown Here"},{"location":"extern/md-guide/_tools/mattermost/","text":"Mattermost is an open source enterprise messaging and team collaboration application. It's like Slack , but with excellent Markdown support. In fact, Mattermost provides exactly the type of Markdown support you want to see in a messaging application. You can type messages in Markdown or copy and paste Markdown-formatted text into the message field \u2014 it works exactly the way you'd expect it to. The application uses a fork of the marked Markdown processor . {% include tool-syntax-table.html %}","title":"Mattermost"},{"location":"extern/md-guide/_tools/mkdocs/","text":"MkDocs is a static site generator designed for building documentation websites. Written in the Python programming language, MkDocs is an open-source project with a lot of community support. A variety of themes are available. In terms of Markdown support, MkDocs does an excellent job supporting the basic syntax elements, but it lacks support for some extended syntax elements. The application uses the Python-Markdown Markdown processor. You can enable additional extensions . {% include tool-syntax-table.html %} Using Admonitions \u00b6 Here's a handy feature: You can enable an extension to use admonitions in MkDocs. This is a quick and easy way to start using notes, warnings, and tips on your MkDocs site. See this GitHub issue for more information and examples.","title":"MkDocs"},{"location":"extern/md-guide/_tools/mkdocs/#using-admonitions","text":"Here's a handy feature: You can enable an extension to use admonitions in MkDocs. This is a quick and easy way to start using notes, warnings, and tips on your MkDocs site. See this GitHub issue for more information and examples.","title":"Using Admonitions"},{"location":"extern/md-guide/_tools/modako/","text":"Modako is a fast Markdown processor for writing professional articles, books, manuals, webpages and presentations, with a focus on simplicity and plain text readability. You can use Modako to write complex documents in Markdown and get beautiful PDF and HTML output. Madoko is a Javascript Markdown processor written in Koka. It started out as a demo program for the new, strongly typed, Koka language and the name comes from \"Markdown in Koka.\" Madoko can both be run locally as a command-line program or on Madoko.net to take advantage of storage and collaboration features. Madoko integrates seamlessly with Dropbox, Github, and OneDrive. It automatically synchronizes all changes in the cloud. This way, your document is always available from any device. The online editor can also edit files on the local disk, or run LaTeX locally, using the Madoko local program. Madoko implements extensions like Github Flavored Markdown, pandoc , Markdown Extra , and multi-markdown , and it adds other useful features for writing academic and industrial documents. In Madoko, tabs are considered to be equivalent to 4 spaces. It's best to configure your editor to view tabs as 4 spaces wide or documents may look off. {% include tool-syntax-table.html %}","title":"Modako"},{"location":"extern/md-guide/_tools/notable/","text":"Notable is a bare-bones note taking application with excellent Markdown support. Free for desktop use, Notable is designed for people who like to see Markdown-formatted text while they're tying. There's no live editor here. It's just you and raw text. You can click the Edit button to switch between the editor and preview screen \u2014 a handy feature when you're reading through your notes. One of Notable's best features, if you can call it that, is the lack of features. There's no need to create an account, and there's no synchronization feature. Some might see that as a limitation, but it does eliminate the possibility of your files being compromised on a third-party server. But without a doubt, Notable's best feature is that it doesn't manipulate your Markdown files in any way \u2014 they're stored on your computer in the same format you see in Notable. If you decide later that you don't like Notable, you can take your Markdown files and do anything with them. The application uses the markdown-it Markdown processor. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Notable provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Notable"},{"location":"extern/md-guide/_tools/notable/#support-for-additional-syntax-elements","text":"As an added bonus, Notable provides support for several obscure elements. Element Markdown Rendered Output Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/notion/","text":"Notion is an innovative application that bills itself as an all-in-one knowledge management solution for individuals and teams. You could think of it as a note-taking app or a wiki, but those descriptions don't really do it justice. You really have to try it to get a sense of what it's capable of. Some organizations use Notion for project management and task tracking, among other things. The application can even function as a database of sorts. Notion has desktop and mobile apps available, as well as a web-based interface. You create an account for yourself and your organization \u2014 the accounts are used to sync everything with Notion's servers. Notion's Markdown support is hit or miss. Copying and pasting Markdown-formatted text into Notion generally works the way you'd expect, but using Notion's live editor to write using Markdown doesn't always work. You can, for instance, use asterisks to make text bold, but trying to use brackets to create a link or pipes to create a table doesn't work \u2014 which is strange considering that those syntax elements do work when you copy and paste them in. It's also difficult to edit Markdown-formatted text that you've copied and pasted in Notion. {% include tool-syntax-table.html %}","title":"Notion"},{"location":"extern/md-guide/_tools/reddit/","text":"With Markdown, Reddit text formatting is a breeze. All Reddit users have the option of writing comments and posts in Markdown. The popular news website has developed its own Markdown processor called \"snoomark\" which is based on GitHub-Flavored Markdown. Some have started referring to this as \"Reddit-flavored Markdown.\" For a deep dive into Reddit's Markdown support, see this wiki article . Enabling Markdown Support \u00b6 By default, Reddit disables Markdown support for new posts and comments. You can switch from the rich text editor to Markdown by clicking the Switch to markdown link, as shown below. To permanently save this setting, you can enable the Default to Markdown setting in User Settings > Feed Settings . Enabling that setting will automatically enable Markdown for new posts or comments. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Reddit provides support for several obscure elements. Element Markdown Rendered Output Spoilers This text will be hidden: >!spoilers! < Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return.","title":"Reddit"},{"location":"extern/md-guide/_tools/reddit/#enabling-markdown-support","text":"By default, Reddit disables Markdown support for new posts and comments. You can switch from the rich text editor to Markdown by clicking the Switch to markdown link, as shown below. To permanently save this setting, you can enable the Default to Markdown setting in User Settings > Feed Settings . Enabling that setting will automatically enable Markdown for new posts or comments. {% include tool-syntax-table.html %}","title":"Enabling Markdown Support"},{"location":"extern/md-guide/_tools/reddit/#support-for-additional-syntax-elements","text":"As an added bonus, Reddit provides support for several obscure elements. Element Markdown Rendered Output Spoilers This text will be hidden: >!spoilers! < Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return.","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/simplenote/","text":"Simplenote is a basic note-taking application developed by Automattic, the same company that created WordPress. The application is free and available on every platform, including Linux. It's also open source . You can use Simplenote in your web browser. After you download the application, you'll be prompted to create an account. That account is used to back up your notes to Automattic's servers and synchronize your notes across all of your other devices. Note that Automattic doesn't encrypt your content on their servers. You can't disable the synchronizing feature. Export options are limited, but the Publish to Web feature allows you to share your notes on the internet with a public URL. Enabling Markdown Support \u00b6 To enable Markdown support in Simplenote, create a note, click the Info icon, and then select Markdown Formatted . The currently selected note and any new notes you create in the future will have this setting enabled automatically. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Simplenote provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return. Underline _word or phrase_ word or phrase Previewing Markdown Documents \u00b6 Simplenote doesn't use a live editor. You'll continue to see the Markdown-formatted text after you've typed it. To preview Markdown documents in Simplenote, click the Preview Markdown icon \u2014 it looks like an eye.","title":"Simplenote"},{"location":"extern/md-guide/_tools/simplenote/#enabling-markdown-support","text":"To enable Markdown support in Simplenote, create a note, click the Info icon, and then select Markdown Formatted . The currently selected note and any new notes you create in the future will have this setting enabled automatically. {% include tool-syntax-table.html %}","title":"Enabling Markdown Support"},{"location":"extern/md-guide/_tools/simplenote/#support-for-additional-syntax-elements","text":"As an added bonus, Simplenote provides support for several obscure elements. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Superscript The greatest thing you'll ever learn is just to ^reddit and be ^(reddited here) in return. The greatest thing you'll ever learn is just to reddit and be reddited here in return. Underline _word or phrase_ word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/simplenote/#previewing-markdown-documents","text":"Simplenote doesn't use a live editor. You'll continue to see the Markdown-formatted text after you've typed it. To preview Markdown documents in Simplenote, click the Preview Markdown icon \u2014 it looks like an eye.","title":"Previewing Markdown Documents"},{"location":"extern/md-guide/_tools/slack/","text":"Slack is a popular team messaging and collaboration application that supports a subset of the Markdown syntax. Different parts of the interface provide different levels of Markdown support. Messages \u00b6 Slack's message interface is the one people use most. Support for some basic syntax is provided, although support for many elements is notably absent. In November 2019, Slack introduced a new WYSIWYG interface, as shown below. This feature is enabled for all users by default. The most obvious change is the addition of formatting buttons in the interface controls, but there's also a live editor that hides the Markdown formatting after you type it. You don't have to use the interface controls to format your text \u2014 you can still use the Markdown syntax elements described in the next section. You can disable the WYSIWYG interface in Preferences > Advanced . Select the Format messages with markup setting, as shown below. Enabling this setting will hide the WYSIWYG formatting buttons and disable the live editor so you can see the Markdown formatting as you type it. Tip: If you have multiple workplaces open in Slack, you'll need to enable this setting for each workplace. Slack Markdown Support in Messages \u00b6 The Slack message interface provides support for the following the Markdown elements. Element Support Notes Headings No Paragraphs No Line Breaks No The Markdown syntax is not supported, but you can press the Shift and Return keys to go to the next line. Bold No The Markdown syntax is not supported, but you can add bold styling with single asterisks, which is the standard Markdown syntax for italic. Very confusing! Italic Partial Only underscores are supported. Blockquotes Yes Ordered Lists No Unordered Lists No Code Partial Code blocks are not supported. Horizontal Rules No Links No Images No The Markdown syntax is not supported, but you can drag and drop images to share them. Tables No Fenced Code Blocks Yes Syntax Highlighting No Footnotes No Heading IDs No Definition Lists No Strikethrough Partial Use only one tilde symbol before and after the phrase. Task Lists No Emoji (copy and paste) Yes Emoji (shortcodes) Yes Automatic URL Linking Yes Disabling Automatic URL Linking No HTML No Tip: This information relates to the message interface in Slack's user interface. The Slack API for messages supports additional syntax elements that aren't supported in Slack's user interface. See Slack's API documentation for more information. Posts \u00b6 The Slack post interface is editor that allows you to create a document for sharing in Slack. This is a live editor, which means you will see the actual formatting immediately after you type Markdown formatted text. For example, if you type _test_ , the underscores will disappear and you'll see the word \"test\" in italics. To create a post, click the shortcuts icon and select Create a Post as shown below. Slack Markdown Support in Posts \u00b6 The Slack post interface provides support for the following Markdown elements. Element Support Notes Headings Partial Only heading levels one and two are supported. Only number signs are supported. Paragraphs Yes Line Breaks No Bold No The Markdown syntax is not supported, but you can add bold styling with single asterisks, which is the standard Markdown syntax for italic. Very confusing! Italic Partial Only underscores are supported. Blockquotes Yes Ordered Lists Yes Unordered Lists Yes Code Yes Horizontal Rules No Links No Images No Tables No Fenced Code Blocks Yes Syntax Highlighting No Footnotes No Heading IDs No Definition Lists No Strikethrough Partial Use only one tilde symbol before and after the phrase. Task Lists No Emoji (copy and paste) Yes Emoji (shortcodes) Yes Automatic URL Linking Yes Disabling Automatic URL Linking Yes HTML No See Also \u00b6 Formatting Slack messages in the interface Formatting Slack posts in the interface API documentation for formatting Slack messages slack_markdown ruby gem","title":"Slack"},{"location":"extern/md-guide/_tools/slack/#messages","text":"Slack's message interface is the one people use most. Support for some basic syntax is provided, although support for many elements is notably absent. In November 2019, Slack introduced a new WYSIWYG interface, as shown below. This feature is enabled for all users by default. The most obvious change is the addition of formatting buttons in the interface controls, but there's also a live editor that hides the Markdown formatting after you type it. You don't have to use the interface controls to format your text \u2014 you can still use the Markdown syntax elements described in the next section. You can disable the WYSIWYG interface in Preferences > Advanced . Select the Format messages with markup setting, as shown below. Enabling this setting will hide the WYSIWYG formatting buttons and disable the live editor so you can see the Markdown formatting as you type it. Tip: If you have multiple workplaces open in Slack, you'll need to enable this setting for each workplace.","title":"Messages"},{"location":"extern/md-guide/_tools/slack/#slack-markdown-support-in-messages","text":"The Slack message interface provides support for the following the Markdown elements. Element Support Notes Headings No Paragraphs No Line Breaks No The Markdown syntax is not supported, but you can press the Shift and Return keys to go to the next line. Bold No The Markdown syntax is not supported, but you can add bold styling with single asterisks, which is the standard Markdown syntax for italic. Very confusing! Italic Partial Only underscores are supported. Blockquotes Yes Ordered Lists No Unordered Lists No Code Partial Code blocks are not supported. Horizontal Rules No Links No Images No The Markdown syntax is not supported, but you can drag and drop images to share them. Tables No Fenced Code Blocks Yes Syntax Highlighting No Footnotes No Heading IDs No Definition Lists No Strikethrough Partial Use only one tilde symbol before and after the phrase. Task Lists No Emoji (copy and paste) Yes Emoji (shortcodes) Yes Automatic URL Linking Yes Disabling Automatic URL Linking No HTML No Tip: This information relates to the message interface in Slack's user interface. The Slack API for messages supports additional syntax elements that aren't supported in Slack's user interface. See Slack's API documentation for more information.","title":"Slack Markdown Support in Messages"},{"location":"extern/md-guide/_tools/slack/#posts","text":"The Slack post interface is editor that allows you to create a document for sharing in Slack. This is a live editor, which means you will see the actual formatting immediately after you type Markdown formatted text. For example, if you type _test_ , the underscores will disappear and you'll see the word \"test\" in italics. To create a post, click the shortcuts icon and select Create a Post as shown below.","title":"Posts"},{"location":"extern/md-guide/_tools/slack/#slack-markdown-support-in-posts","text":"The Slack post interface provides support for the following Markdown elements. Element Support Notes Headings Partial Only heading levels one and two are supported. Only number signs are supported. Paragraphs Yes Line Breaks No Bold No The Markdown syntax is not supported, but you can add bold styling with single asterisks, which is the standard Markdown syntax for italic. Very confusing! Italic Partial Only underscores are supported. Blockquotes Yes Ordered Lists Yes Unordered Lists Yes Code Yes Horizontal Rules No Links No Images No Tables No Fenced Code Blocks Yes Syntax Highlighting No Footnotes No Heading IDs No Definition Lists No Strikethrough Partial Use only one tilde symbol before and after the phrase. Task Lists No Emoji (copy and paste) Yes Emoji (shortcodes) Yes Automatic URL Linking Yes Disabling Automatic URL Linking Yes HTML No","title":"Slack Markdown Support in Posts"},{"location":"extern/md-guide/_tools/slack/#see-also","text":"Formatting Slack messages in the interface Formatting Slack posts in the interface API documentation for formatting Slack messages slack_markdown ruby gem","title":"See Also"},{"location":"extern/md-guide/_tools/squarespace/","text":"id: headings available: y id: paragraphs available: y id: line-breaks available: y id: bold available: y id: italic available: y id: blockquotes available: y id: ordered-lists available: y id: unordered-lists available: y id: code available: y id: horizontal-rules available: y id: links available: p notes: \"Using angle brackets for URLs and email addresses is not supported.\" id: images available: y id: tables available: y id: fenced-code-blocks available: y id: syntax-highlighting available: n id: footnotes available: n id: heading-ids available: n id: definition-lists available: n id: strikethrough available: y id: task-lists available: n id: emoji-cp available: y id: emoji-sc available: n id: auto-url-linking available: y id: disabling-auto-url available: y id: html available: y see-also: name: Markdown cheat sheet link: https://support.squarespace.com/hc/en-us/articles/206543587-Markdown-cheat-sheet name: Markdown blocks link: https://support.squarespace.com/hc/en-us/articles/205813788-Markdown-Blocks Squarespace is a popular subscription service for building websites. The service features a drag-and-drop interface that lets you build websites right in your web browser. One of the components available for webpages is a Markdown block \u2014 a content area that supports Markdown. You'll see the option when you click the Add Block icon, as shown below. Squarespace supports most basic Markdown syntax elements, but support for a number of extended syntax elements is lacking. One disadvantage is that the editor for the Markdown block is a tiny box and the text is displayed in a minuscule (and non-adjustable) font size. You're probably better off copying and pasting the text in from another application. {% include tool-syntax-table.html %}","title":"Squarespace"},{"location":"extern/md-guide/_tools/stackedit/","text":"StackEdit is a powerful online Markdown editor. Like Dillinger , it loads right in your web browser, so there's no need to download and install an application on your computer. StackEdit has a wide variety of features and configurable options for power users, making it in many ways a better all-around option than comparable desktop applications. StackEdit's Markdown support is excellent. Features include the ability to sync and save files to third-party services, output to various file formats using custom templates, and configure metadata properties for files. (Note that you must subscribe to StackEdit to output to some of the file formats, like PDF.) LaTeX and UML diagrams are also supported. You can apparently use StackEdit without an internet connection. StackEdit is limited by a lack of documentation. Users are left to discover and toy around with many of the application's features on their own. That's a shame, because the undocumented features are essentially unusable by all but the most advanced users. For example, you can create your own templates for exported files, but there's no information about what templating language is used, and no guidance on how to create your own templates. There is a community support forum , but users shouldn't have to read through questions and answers to figure out how to do something simple. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, StackEdit provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"StackEdit"},{"location":"extern/md-guide/_tools/stackedit/#support-for-additional-syntax-elements","text":"As an added bonus, StackEdit provides support for several obscure elements. Element Markdown Rendered Output Abbreviation *[HTML]: Hyper Text Markup Language The HTML specification is maintained by the W3C. The HTML specification is maintained by the W3C. Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/standard-notes/","text":"Standard Notes is an elegant, open-source note taking application with an excellent feature set. Markdown support is not provided by default, but by paying for the optional subscription , you can enable one of several Markdown extensions available to subscribers. I used the Advanced Markdown extension , which is what's documented below. Admittedly, the category for Markdown note taking applications is a crowded one. Standard Notes stands out by offering a great user experience, outstanding privacy and synchronization features, and a strong commitment to open source software. The application and the overall experience feels professional-grade. Standard Notes works on every platform. {% include tool-syntax-table.html %}","title":"Standard Notes"},{"location":"extern/md-guide/_tools/todoist/","text":"Todoist is a to-do list application that helps you record and track tasks to completion. Todoist provides surprisingly good Markdown support for an application of this type. You can use Markdown syntax to format the task names and comments you create in the Todoist website and mobile applications (unfortunately, you can't use Markdown in the names for projects, labels, or filters). {% include tool-syntax-table.html %}","title":"Todoist"},{"location":"extern/md-guide/_tools/trello/","text":"Trello is a popular kanban-style project management application that can be used for everything from project management to making grocery shopping lists. You create a board, add columns (called \"lists\"), and then add cards to lists. The interactive drag-and-drop interface allows you to easily reorder cards and move them between lists as you work on tasks. Trello has excellent support for basic Markdown syntax. You can use Markdown in the card descriptions, checklists, and comments. You can also use Markdown for your Trello bio. Not all formatting is properly displayed when viewed in the iOS and Andriod applications. {% include tool-syntax-table.html %} See Also \u00b6 How To Format Your Text in Trello","title":"Trello"},{"location":"extern/md-guide/_tools/trello/#see-also","text":"How To Format Your Text in Trello","title":"See Also"},{"location":"extern/md-guide/_tools/typora/","text":"Typora is a simple and configurable document editor that provides excellent Markdown support. This application is ideal for students and professionals who need to write essays and reports. It might be difficult using Typora for multi-file projects or for website publishing. Typora stands out by offering a variety of settings without sacrificing the simplicity of a barebones interface. Newcomers to Markdown may appreciate the keyboard shortcuts for formatting options as well as the intuitive live editor that hides the Markdown formatting syntax after you type it. See the Typora Markdown reference for the official documentation. The Typora documentation indicates that the application generally uses GitHub Flavored Markdown (GFM) . {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Typora provides support for several obscure elements, including diagrams and inline math. Most of these elements are disabled by default. To enable them, open the Preferences window and modify the settings under Markdown > Syntax Support . See the Typora Markdown reference for additional information. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2 Themes \u00b6 Typora provides a variety of themes for when you export your documents. If you know CSS, you can customize these themes. Open the Preferences window and see the settings under Appearance > Themes . Strict Mode \u00b6 Typora provides strict mode settings for users who want to enforce syntax limitations on headings, ordered lists, and unordered lists. For example, you could configure unordered lists to only use hyphens and not asterisks. Configure these settings in the Preferences window under Markdown > Syntax Preference . See the Typora documentation for additional information. Source Code Mode \u00b6 You can disable Typora's live editor by selecting View > Source Code Mode . This will reveal all of the Markdown formatting that's hidden by the live editor. Export Options \u00b6 Typora provides a wide variety of export options under File > Export for when you're ready to publish your Markdown document. Some of the export options, like Microsoft Word and LaTeX format, require Pandoc .","title":"Typora"},{"location":"extern/md-guide/_tools/typora/#support-for-additional-syntax-elements","text":"As an added bonus, Typora provides support for several obscure elements, including diagrams and inline math. Most of these elements are disabled by default. To enable them, open the Preferences window and modify the settings under Markdown > Syntax Support . See the Typora Markdown reference for additional information. Element Markdown Rendered Output Highlight ==word or phrase== word or phrase Subscript H~2~O H 2 O Superscript X^2^ X 2","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/typora/#themes","text":"Typora provides a variety of themes for when you export your documents. If you know CSS, you can customize these themes. Open the Preferences window and see the settings under Appearance > Themes .","title":"Themes"},{"location":"extern/md-guide/_tools/typora/#strict-mode","text":"Typora provides strict mode settings for users who want to enforce syntax limitations on headings, ordered lists, and unordered lists. For example, you could configure unordered lists to only use hyphens and not asterisks. Configure these settings in the Preferences window under Markdown > Syntax Preference . See the Typora documentation for additional information.","title":"Strict Mode"},{"location":"extern/md-guide/_tools/typora/#source-code-mode","text":"You can disable Typora's live editor by selecting View > Source Code Mode . This will reveal all of the Markdown formatting that's hidden by the live editor.","title":"Source Code Mode"},{"location":"extern/md-guide/_tools/typora/#export-options","text":"Typora provides a wide variety of export options under File > Export for when you're ready to publish your Markdown document. Some of the export options, like Microsoft Word and LaTeX format, require Pandoc .","title":"Export Options"},{"location":"extern/md-guide/_tools/ulysses/","text":"Ulysses is a popular writing application for macOS and iOS devices. Lauded by journalists and reviewers, Ulysses provides lots of useful features and nice touches for people who write professionally. The theming and export options are second to none. Unfortunately, using Ulysses to write in Markdown is an exercise in frustration. The application supports a subset of the Markdown syntax, but support for many syntax elements is notably absent. Even worse, support for some elements is provided using non-standard notation. Ulysses might not be your first choice if you're wanting to write exclusively in Markdown. {% include tool-syntax-table.html %} Support for Additional Syntax Elements \u00b6 As an added bonus, Ulysses provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase","title":"Ulysses"},{"location":"extern/md-guide/_tools/ulysses/#support-for-additional-syntax-elements","text":"As an added bonus, Ulysses provides support for several obscure elements. Element Markdown Rendered Output Highlight ::word or phrase:: word or phrase","title":"Support for Additional Syntax Elements"},{"location":"extern/md-guide/_tools/zettlr/","text":"Zettlr is free and open source Markdown application designed for academic writing. It provides a lot of powerful tools to help you write academic texts right out of the box. The application's stated goal is simple: \"Enabling researchers of arts and humanities, e.g. those people without any knowledge of coding, to finally free themselves from software that costs hundreds of dollars and pave the way into an Open Source era. This would be only fitting, given the fact that especially in political science and sociology, cries for Open Access journals are on the rise. So here\u2019s what Zettlr is all about: It wants to be serious competition for word processors.\" Zettlr Markdown Support \u00b6 Zettlr provides support for the following Markdown elements. See the Zettlr Documentation for the official documentation. Zettlr itself implements a mixture of different dialects. The editor itself highlights only GitHub Flavored Markdown plus some extra elements which extends Markdown syntax with Zettelkasten elements. You can also add LaTeX-commands. {% include tool-syntax-table.html %}","title":"Zettlr"},{"location":"extern/md-guide/_tools/zettlr/#zettlr-markdown-support","text":"Zettlr provides support for the following Markdown elements. See the Zettlr Documentation for the official documentation. Zettlr itself implements a mixture of different dialects. The editor itself highlights only GitHub Flavored Markdown plus some extra elements which extends Markdown syntax with Zettelkasten elements. You can also add LaTeX-commands. {% include tool-syntax-table.html %}","title":"Zettlr Markdown Support"},{"location":"extern/md-guide/_tools/znote/","text":"Znote is a free application designed to help you write organized Markdown documents. You can quickly edit your texts, notes, and files using the simplistic left-side widget organizer for smoothly navigating different files. The dark mode and code highlighter features are designed for developers. Available for macOS, Windows and Linux. {% include tool-syntax-table.html %}","title":"Znote"},{"location":"extern/md-guide/api/v1/","text":"Introduction \u00b6 The Markdown Guide API provides a subset of documentation from the Markdown Guide in JSON format. We hope that software developers and organizations use this API to programmatically consume our documentation and display it in applications and on websites. Why? \u00b6 Why create an API for Markdown documentation? Because there's so much duplicated Markdown documentation on the web! It seems like everybody has their own version of Markdown documentation for their application or website. That's a shame since most of it is exactly the same. Then came the epiphany. \ud83d\udca1 We realized we could create a JSON API using documentation from the Markdown Guide . That way, software developers could start using the API to include our documentation in their applications, and organizations like universities and libraries could use the API to include our documentation on their websites. We'd love to see the Markdown Guide become the central documentation repository for the thousands of Markdown instructions sprinkled around the internet. Will it work? Who knows! One thing's for sure though: We can't wait to see what you do with it. \ud83e\udd18 Limitations \u00b6 The Markdown Guide API is designed to provide only essential Markdown documentation. As a result, the API doesn't include all of the documentation available on the Markdown Guide website. For example, the Adding Elements in Lists section is not available through the basic syntax endpoint. Basic Syntax Endpoint \u00b6 The basic syntax endpoint contains documentation about the Markdown elements outlined in John Gruber's design document and described on the Basic Syntax page . API Endpoint /api/v1/basic-syntax.json Request \u00b6 curl https://www.markdownguide.org/api/v1/basic-syntax.json Response \u00b6 Cheat Sheet Endpoint \u00b6 The cheat sheet endpoint provides an overview of the most popular basic and extended Markdown syntax elements, as described on the Cheat Sheet page . API Endpoint /api/v1/cheat-sheet.json Request \u00b6 curl https://www.markdownguide.org/api/v1/cheat-sheet.json Response \u00b6 Changelog Here's a list of all the changes we've made to the Markdown Guide API. 2018-10-18 - Updated cheat sheet endpoint to include information about definition lists 2018-07-12 - Updated links description to include information about adding titles 2017-11-10 - Added cheat sheet endpoint 2017-11-04 - Added section about escaping backticks in code 2017-10-24 - Released API v1 - Published docs","title":"API"},{"location":"extern/md-guide/api/v1/#introduction","text":"The Markdown Guide API provides a subset of documentation from the Markdown Guide in JSON format. We hope that software developers and organizations use this API to programmatically consume our documentation and display it in applications and on websites.","title":"Introduction"},{"location":"extern/md-guide/api/v1/#why","text":"Why create an API for Markdown documentation? Because there's so much duplicated Markdown documentation on the web! It seems like everybody has their own version of Markdown documentation for their application or website. That's a shame since most of it is exactly the same. Then came the epiphany. \ud83d\udca1 We realized we could create a JSON API using documentation from the Markdown Guide . That way, software developers could start using the API to include our documentation in their applications, and organizations like universities and libraries could use the API to include our documentation on their websites. We'd love to see the Markdown Guide become the central documentation repository for the thousands of Markdown instructions sprinkled around the internet. Will it work? Who knows! One thing's for sure though: We can't wait to see what you do with it. \ud83e\udd18","title":"Why?"},{"location":"extern/md-guide/api/v1/#limitations","text":"The Markdown Guide API is designed to provide only essential Markdown documentation. As a result, the API doesn't include all of the documentation available on the Markdown Guide website. For example, the Adding Elements in Lists section is not available through the basic syntax endpoint.","title":"Limitations"},{"location":"extern/md-guide/api/v1/#basic-syntax-endpoint","text":"The basic syntax endpoint contains documentation about the Markdown elements outlined in John Gruber's design document and described on the Basic Syntax page .","title":"Basic Syntax Endpoint"},{"location":"extern/md-guide/api/v1/#request","text":"curl https://www.markdownguide.org/api/v1/basic-syntax.json","title":"Request"},{"location":"extern/md-guide/api/v1/#response","text":"","title":"Response"},{"location":"extern/md-guide/api/v1/#cheat-sheet-endpoint","text":"The cheat sheet endpoint provides an overview of the most popular basic and extended Markdown syntax elements, as described on the Cheat Sheet page .","title":"Cheat Sheet Endpoint"},{"location":"extern/md-guide/api/v1/#request_1","text":"curl https://www.markdownguide.org/api/v1/cheat-sheet.json","title":"Request"},{"location":"extern/md-guide/api/v1/#response_1","text":"","title":"Response"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/","text":"Markdown Cheat Sheet \u00b6 Thanks for visiting The Markdown Guide ! This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can\u2019t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax . Basic Syntax \u00b6 These are the elements outlined in John Gruber\u2019s original design document. All Markdown applications support these elements. Heading \u00b6 H1 \u00b6 H2 \u00b6 H3 \u00b6 Bold \u00b6 bold text Italic \u00b6 italicized text Blockquote \u00b6 blockquote Ordered List \u00b6 First item Second item Third item Unordered List \u00b6 First item Second item Third item Code \u00b6 code Horizontal Rule \u00b6 Link \u00b6 title Image \u00b6 Extended Syntax \u00b6 These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Table \u00b6 Syntax Description Header Title Paragraph Text Fenced Code Block \u00b6 { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } Footnote \u00b6 Here's a sentence with a footnote. 1 Heading ID \u00b6 My Great Heading \u00b6 Definition List \u00b6 term definition Strikethrough \u00b6 The world is flat. Task List \u00b6 [x] Write the press release [ ] Update the website [ ] Contact the media This is the footnote. \u21a9","title":"Markdown Cheat Sheet"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#markdown-cheat-sheet","text":"Thanks for visiting The Markdown Guide ! This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can\u2019t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax .","title":"Markdown Cheat Sheet"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#basic-syntax","text":"These are the elements outlined in John Gruber\u2019s original design document. All Markdown applications support these elements.","title":"Basic Syntax"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#heading","text":"","title":"Heading"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#h1","text":"","title":"H1"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#h2","text":"","title":"H2"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#h3","text":"","title":"H3"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#bold","text":"bold text","title":"Bold"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#italic","text":"italicized text","title":"Italic"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#blockquote","text":"blockquote","title":"Blockquote"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#ordered-list","text":"First item Second item Third item","title":"Ordered List"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#unordered-list","text":"First item Second item Third item","title":"Unordered List"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#code","text":"code","title":"Code"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#horizontal-rule","text":"","title":"Horizontal Rule"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#link","text":"title","title":"Link"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#image","text":"","title":"Image"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#extended-syntax","text":"These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements.","title":"Extended Syntax"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#table","text":"Syntax Description Header Title Paragraph Text","title":"Table"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#fenced-code-block","text":"{ \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 }","title":"Fenced Code Block"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#footnote","text":"Here's a sentence with a footnote. 1","title":"Footnote"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#heading-id","text":"","title":"Heading ID"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#custom-id","text":"","title":"My Great Heading"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#definition-list","text":"term definition","title":"Definition List"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#strikethrough","text":"The world is flat.","title":"Strikethrough"},{"location":"extern/md-guide/assets/markdown-cheat-sheet/#task-list","text":"[x] Write the press release [ ] Update the website [ ] Contact the media This is the footnote. \u21a9","title":"Task List"},{"location":"go/concurency/","text":"Do not communicate by sharing memory; instead, share memory by communicating. 1 Notes: \u00b6 https://golang.org/doc/effective_go.html#concurrency \u21a9","title":"Concurency"},{"location":"go/concurency/#notes","text":"https://golang.org/doc/effective_go.html#concurrency \u21a9","title":"Notes:"},{"location":"linux/network/","text":"Network \u00b6 Basics \u00b6 The OSI (Open Systems Interconnection) uses seven layers, - physical layer (layer 1) - network layer (layer 3) - transport layer (layer 4) - application layer (layer 7) Resources \u00b6 18 commands to monitor network bandwith on Linux server","title":"network"},{"location":"linux/network/#network","text":"","title":"Network"},{"location":"linux/network/#basics","text":"The OSI (Open Systems Interconnection) uses seven layers, - physical layer (layer 1) - network layer (layer 3) - transport layer (layer 4) - application layer (layer 7)","title":"Basics"},{"location":"linux/network/#resources","text":"18 commands to monitor network bandwith on Linux server","title":"Resources"},{"location":"ml/dl/","text":"Time series \u00b6 tsfresh \u00b6 Quote tsfresh is a python package. It automatically calculates a large number of time series characteristics, the so called features. Further the package contains methods to evaluate the explaining power and importance of such characteristics for regression or classification tasks. 1D convolutional neural network \u00b6 Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences A Visual Introduction to Machine Learning and AI 1D ConvolutionalNeural Networks andApplications\u2013A Survey Signal Status Recognition Based on 1DCNN and Its Feature Extraction Mechanism Analysis Working with 1D convonlutional neural network in Keras \u00b6 https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/ Example \u00b6","title":"Time series"},{"location":"ml/dl/#time-series","text":"","title":"Time series"},{"location":"ml/dl/#tsfresh","text":"Quote tsfresh is a python package. It automatically calculates a large number of time series characteristics, the so called features. Further the package contains methods to evaluate the explaining power and importance of such characteristics for regression or classification tasks.","title":"tsfresh"},{"location":"ml/dl/#1d-convolutional-neural-network","text":"Introduction to 1D Convolutional Neural Networks in Keras for Time Sequences A Visual Introduction to Machine Learning and AI 1D ConvolutionalNeural Networks andApplications\u2013A Survey Signal Status Recognition Based on 1DCNN and Its Feature Extraction Mechanism Analysis","title":"1D convolutional neural network"},{"location":"ml/dl/#working-with-1d-convonlutional-neural-network-in-keras","text":"https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/","title":"Working with 1D convonlutional neural network in Keras"},{"location":"ml/dl/#example","text":"","title":"Example"},{"location":"ml/regression/","text":"Multi linear regression: identify the strength of the effect that the independent variables have on the dependent variable predict the impact of changes, that is, to understand how the dependent variable changes when we change the independent variables","title":"Regression"},{"location":"ndarray/intro/","text":"ND-array \u00b6 The N-dimensional array (ndarray) \u00b6 contiguous one-dimensional segment of computer memory NumPy ndarray internals can be read in source code typedef struct tagPyArrayObject_fields { PyObject_HEAD /* Pointer to the raw data buffer */ char * data ; /* The number of dimensions, also called 'ndim' */ int nd ; /* The size in each dimension, also called 'shape' */ npy_intp * dimensions ; /* * Number of bytes to jump to get to the * next element in each dimension */ npy_intp * strides ; /* * This object is decref'd upon * deletion of array. Except in the * case of WRITEBACKIFCOPY which has * special handling. * * For views it points to the original * array, collapsed so no chains of * views occur. * * For creation from buffer object it * points to an object that should be * decref'd on deletion * * For WRITEBACKIFCOPY flag this is an * array to-be-updated upon calling * PyArray_ResolveWritebackIfCopy */ PyObject * base ; /* Pointer to type structure */ PyArray_Descr * descr ; /* Flags describing array -- see below */ int flags ; /* For weak references */ PyObject * weakreflist ; } PyArrayObject_fields ; Papers: https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html NumPy documentation https://github.com/numpy/numpy/blob/b7c27bd2a3817f59c84b004b87bba5db57d9a9b0/numpy/core/include/numpy/ndarraytypes.h#L1343 ndarray.flags Information about the memory layout of the array. ndarray.shape Tuple of array dimensions. ndarray.strides Tuple of bytes to step in each dimension when traversing an array. ndarray.ndim Number of array dimensions. ndarray.data Python buffer object pointing to the start of the array\u2019s data. ndarray.size Number of elements in the array. ndarray.itemsize Length of one array element in bytes. ndarray.nbytes Total bytes consumed by the elements of the array. ndarray.base Base object if memory is from some other object.","title":"Intro"},{"location":"ndarray/intro/#nd-array","text":"","title":"ND-array"},{"location":"ndarray/intro/#the-n-dimensional-array-ndarray","text":"contiguous one-dimensional segment of computer memory NumPy ndarray internals can be read in source code typedef struct tagPyArrayObject_fields { PyObject_HEAD /* Pointer to the raw data buffer */ char * data ; /* The number of dimensions, also called 'ndim' */ int nd ; /* The size in each dimension, also called 'shape' */ npy_intp * dimensions ; /* * Number of bytes to jump to get to the * next element in each dimension */ npy_intp * strides ; /* * This object is decref'd upon * deletion of array. Except in the * case of WRITEBACKIFCOPY which has * special handling. * * For views it points to the original * array, collapsed so no chains of * views occur. * * For creation from buffer object it * points to an object that should be * decref'd on deletion * * For WRITEBACKIFCOPY flag this is an * array to-be-updated upon calling * PyArray_ResolveWritebackIfCopy */ PyObject * base ; /* Pointer to type structure */ PyArray_Descr * descr ; /* Flags describing array -- see below */ int flags ; /* For weak references */ PyObject * weakreflist ; } PyArrayObject_fields ; Papers: https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html NumPy documentation https://github.com/numpy/numpy/blob/b7c27bd2a3817f59c84b004b87bba5db57d9a9b0/numpy/core/include/numpy/ndarraytypes.h#L1343 ndarray.flags Information about the memory layout of the array. ndarray.shape Tuple of array dimensions. ndarray.strides Tuple of bytes to step in each dimension when traversing an array. ndarray.ndim Number of array dimensions. ndarray.data Python buffer object pointing to the start of the array\u2019s data. ndarray.size Number of elements in the array. ndarray.itemsize Length of one array element in bytes. ndarray.nbytes Total bytes consumed by the elements of the array. ndarray.base Base object if memory is from some other object.","title":"The N-dimensional array (ndarray)"},{"location":"shell/fzf/","text":"fzf (fuzzy finder) \u00b6 Search syntax \u00b6 Token Match type Description sbtrkt fuzzy-match Items that match sbtrkt 'wild exact-match (quoted) Items that include wild ^music prefix-exact-match Items that start with music .mp3$ suffix-exact-match Items that end with .mp3 !fire inverse-exact-match Items that do not include fire !^music inverse-prefix-exact-match Items that do not start with music !.mp3$ inverse-suffix-exact-match Items that do not end with .mp3","title":"fzf"},{"location":"shell/fzf/#fzf-fuzzy-finder","text":"","title":"fzf (fuzzy finder)   "},{"location":"shell/fzf/#search-syntax","text":"Token Match type Description sbtrkt fuzzy-match Items that match sbtrkt 'wild exact-match (quoted) Items that include wild ^music prefix-exact-match Items that start with music .mp3$ suffix-exact-match Items that end with .mp3 !fire inverse-exact-match Items that do not include fire !^music inverse-prefix-exact-match Items that do not start with music !.mp3$ inverse-suffix-exact-match Items that do not end with .mp3","title":"Search syntax"},{"location":"shell/git/","text":"GIT \u00b6 Configuration \u00b6 The configuration is made out of four files : $(prefix)/etc/gitconfig $XDG_CONFIG_HOME/git/config ~/.gitconfig $GIT_DIR/config Pull request \u00b6 Write a pull request \u00b6 https://github.blog/2015-01-21-how-to-write-the-perfect-pull-request/ https://stackoverflow.com/questions/14680711 https://stackoverflow.com/questions/29049650 Switch branches or restore working tree files git checkout master git checkout -b mybranch git remote manage the set of repositories (\"remotes\") whose branches you track. git remote -v # If upstream is not configured, add the upstream route git remote add upstream /url/original/repo git fetch upstream # reset master to upstream/master git checkout master git reset --hard upstream/master git push --force y--y--y (mybranch) / z--z--z (master, upstream/master, origin/master) # replay the patches (even they are rejected for now) on top of master git checkout mybranch git rebase master git push -u origin mybranch y'--y'--y' (mybranch, origin/mybranch) / z--z--z (master, upstream/master, origin/master) Submodules \u00b6 Commands \u00b6 status prints the SHA1 status of checked submodules. Prefixed with: - if the submodule is not initialized + in case of conflicts between current subdmodule and the index of the containing directory U in case of merge conflicts Remove a submodule \u00b6 A submodule can be deleted by running git rm <submodule path> && git commit . $GIT_DIR/modules/<name> delete the submodule completly. Util then, deletion can be undone using git revert . Alternative method: Remove the submodule entry from .git/config git submodule deinit -f path/to/submodule Remove the submodule directory from the superproject's .git/modules directory rm -rf .git/modules/path/to/submodule Commit the changes git commit-m \"Removed submodule \" Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule git rm -f path/to/submodule Cherry pick from another repository \u00b6 First the other repository source must be added to the remote list git remote add other https://other.url/repository.git git fetch other Then use git cherry-pick","title":"git"},{"location":"shell/git/#git","text":"","title":"GIT"},{"location":"shell/git/#configuration","text":"The configuration is made out of four files : $(prefix)/etc/gitconfig $XDG_CONFIG_HOME/git/config ~/.gitconfig $GIT_DIR/config","title":"Configuration"},{"location":"shell/git/#pull-request","text":"","title":"Pull request"},{"location":"shell/git/#write-a-pull-request","text":"https://github.blog/2015-01-21-how-to-write-the-perfect-pull-request/ https://stackoverflow.com/questions/14680711 https://stackoverflow.com/questions/29049650 Switch branches or restore working tree files git checkout master git checkout -b mybranch git remote manage the set of repositories (\"remotes\") whose branches you track. git remote -v # If upstream is not configured, add the upstream route git remote add upstream /url/original/repo git fetch upstream # reset master to upstream/master git checkout master git reset --hard upstream/master git push --force y--y--y (mybranch) / z--z--z (master, upstream/master, origin/master) # replay the patches (even they are rejected for now) on top of master git checkout mybranch git rebase master git push -u origin mybranch y'--y'--y' (mybranch, origin/mybranch) / z--z--z (master, upstream/master, origin/master)","title":"Write a pull request"},{"location":"shell/git/#submodules","text":"","title":"Submodules"},{"location":"shell/git/#commands","text":"status prints the SHA1 status of checked submodules. Prefixed with: - if the submodule is not initialized + in case of conflicts between current subdmodule and the index of the containing directory U in case of merge conflicts","title":"Commands"},{"location":"shell/git/#remove-a-submodule","text":"A submodule can be deleted by running git rm <submodule path> && git commit . $GIT_DIR/modules/<name> delete the submodule completly. Util then, deletion can be undone using git revert . Alternative method: Remove the submodule entry from .git/config git submodule deinit -f path/to/submodule Remove the submodule directory from the superproject's .git/modules directory rm -rf .git/modules/path/to/submodule Commit the changes git commit-m \"Removed submodule \" Remove the entry in .gitmodules and remove the submodule directory located at path/to/submodule git rm -f path/to/submodule","title":"Remove a submodule"},{"location":"shell/git/#cherry-pick-from-another-repository","text":"First the other repository source must be added to the remote list git remote add other https://other.url/repository.git git fetch other Then use git cherry-pick","title":"Cherry pick from another repository"},{"location":"shell/intro/","text":"Linux \u00b6 Finding files \u00b6 Ranger \u00b6 A VIM-inspired filemanager for the console JQ exa \u00b6 exa is a replacement for ls written in Rust. Makefile \u00b6 Splitting Recipe Lines https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html Makefile tutorial https://makefiletutorial.com/ Introduction \u00e0 Makefile https://gl.developpez.com/tutoriel/outil/makefile/","title":"shell"},{"location":"shell/intro/#linux","text":"","title":"Linux"},{"location":"shell/intro/#finding-files","text":"","title":"Finding files"},{"location":"shell/intro/#ranger","text":"A VIM-inspired filemanager for the console JQ","title":"Ranger  "},{"location":"shell/intro/#exa","text":"exa is a replacement for ls written in Rust.","title":"exa  "},{"location":"shell/intro/#makefile","text":"Splitting Recipe Lines https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html Makefile tutorial https://makefiletutorial.com/ Introduction \u00e0 Makefile https://gl.developpez.com/tutoriel/outil/makefile/","title":"Makefile"},{"location":"shell/sys/","text":"Helpers \u00b6 Displaying IP address on eth0 interface ifconfig eth0 | grep \"inet ad\" | cut -d ':' -f 2 | cut -d ' ' -f 1","title":"helpers"},{"location":"shell/sys/#helpers","text":"Displaying IP address on eth0 interface ifconfig eth0 | grep \"inet ad\" | cut -d ':' -f 2 | cut -d ' ' -f 1","title":"Helpers"},{"location":"shell/vim/","text":"Vim \u00b6 :h terminal or Configuration \u00b6 ~/.vim/syntax contains","title":"Intro"},{"location":"shell/vim/#vim","text":":h terminal or","title":"Vim"},{"location":"shell/vim/#configuration","text":"~/.vim/syntax contains","title":"Configuration"},{"location":"shell/vm/","text":"Wikipedia Vagrant \u00b6 Installation on Debian based systems \u00b6 deb package can be found at download curl -LO https://releases.hashicorp.com/vagrant/2.2.9/vagrant_2.2.9_x86_64.deb sudo apt install ./vagrant_2.2.9_x86_64.deb # or dpkg -i Customizing Vagrant VMware Fusion Virtual Machines with VMX Parameters How to create a Vagrant Box running Red Hat Enterprise Linux","title":"Virtualization"},{"location":"shell/vm/#vagrant","text":"","title":"Vagrant"},{"location":"shell/vm/#installation-on-debian-based-systems","text":"deb package can be found at download curl -LO https://releases.hashicorp.com/vagrant/2.2.9/vagrant_2.2.9_x86_64.deb sudo apt install ./vagrant_2.2.9_x86_64.deb # or dpkg -i Customizing Vagrant VMware Fusion Virtual Machines with VMX Parameters How to create a Vagrant Box running Red Hat Enterprise Linux","title":"Installation on Debian based systems"},{"location":"shell/zsh/","text":"Zsh \u00b6 The Z-shell Glob qualifiers \u00b6 http://zsh.sourceforge.net/Doc/Release/Expansion.html#Glob-Qualifiers Qualifiers Scope / directories Plugins \u00b6 zsh-z Jump quickly to directories that you have visited \"frecently.\" zsh-autosuggestions Fish-like autosuggestions for zsh Other links \u00b6 Adding Vi to your Zsh","title":"zsh"},{"location":"shell/zsh/#zsh","text":"The Z-shell","title":"Zsh    "},{"location":"shell/zsh/#glob-qualifiers","text":"http://zsh.sourceforge.net/Doc/Release/Expansion.html#Glob-Qualifiers Qualifiers Scope / directories","title":"Glob qualifiers"},{"location":"shell/zsh/#plugins","text":"zsh-z Jump quickly to directories that you have visited \"frecently.\" zsh-autosuggestions Fish-like autosuggestions for zsh","title":"Plugins"},{"location":"shell/zsh/#other-links","text":"Adding Vi to your Zsh","title":"Other links"},{"location":"shell/Ubuntu/configuration/","text":"Configuration \u00b6 LVM \u00b6 https://doc.ubuntu-fr.org/lvm Partitioning: https://www.cyberciti.biz/tips/fdisk-unable-to-create-partition-greater-2tb.html Touchpad \u00b6 libinput \u00b6 See https://wayland.freedesktop.org/libinput/doc/latest/index.html libinput-gesture fusuma","title":"Configuration"},{"location":"shell/Ubuntu/configuration/#configuration","text":"","title":"Configuration"},{"location":"shell/Ubuntu/configuration/#lvm","text":"https://doc.ubuntu-fr.org/lvm Partitioning: https://www.cyberciti.biz/tips/fdisk-unable-to-create-partition-greater-2tb.html","title":"LVM"},{"location":"shell/Ubuntu/configuration/#touchpad","text":"","title":"Touchpad"},{"location":"shell/Ubuntu/configuration/#libinput","text":"See https://wayland.freedesktop.org/libinput/doc/latest/index.html libinput-gesture fusuma","title":"libinput"},{"location":"shell/Ubuntu/python/","text":"Tagen tenditur missos pectus viam vocavit fama \u00b6 Cereri est tamquam et flammas solvit et \u00b6 Ubuntu pyhton's distribution patches various modules, especialy site.py Lorem markdownum tubas; ore manesque prior lacrimae femina convertunt tamen concessa ait tecta das. Hyperborea timent et fontana , defuit illo nati secura, ero. Tamquam arduus qua : in inputet habemus ventis pendens quicquam Minervae, puro pavido his vastius. Acta omnia pectus cui balistave maxima narrare medicamine coepere? Danger Bash #!/bin/bash STR = \"Hello World!\" echo $STR C #include int main(void) { printf ( \"hello, world \\n \" ); } C++ #include <iostream> int main () { std :: cout << \"Hello, world! \\n \" ; return 0 ; } C# using System ; class Program { static void Main ( string [] args ) { Console . WriteLine ( \"Hello, world!\" ); } } S\u00e9paration python #!/usr/bin/python import tensorflow as tf python #!/usr/bin/python import tensorflow as tf < b > aze </ b > ! [ ndarray ]( https : // docs . scipy . org / doc / numpy / _images / threefundamental . png ) config = { container: \"#tree-simple\" }; parent_node = { text: { name: \"Parent node\" } }; first_child = { parent: parent_node, text: { name: \"First child\" } }; second_child = { parent: parent_node, text: { name: \"Second child\" } }; simple_chart_config = [ config, parent_node, first_child, second_child ]; Un essai st=>start: Start:>http://www.google.com[blank] e=>end:>http://www.google.com op1=>operation: My Operation op2=>operation: My Operation 2 sub1=>subroutine: My Subroutine cond=>condition: Yes or No?:>http://www.google.com io=>inputoutput: catch something... st->op1->op2->cond cond(yes)->io->e cond(no)->sub1(right)->op1 Title: Here is a title A->B: Ligne line B-->C: Dashed line C->>D: Open arrow D-->>A: Dashed open arrow Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tela illa litus quot Graia rediit dexteriore Quaesita loquaci Herbas nec volentem finierat congreditur quibus vestibus Puellae factum Lapillos minores ait admovit apertos me hunc Rapidas spectat cornua Et maior \u00b6 Meritis collumque regale terrae dictum mollitaque natura collumque aliquemque vetus speculabar totque, eam in. Binominis silvestre purpura mercibus, Achivos fata cognoscendus Alpes tremebunda litus carpit . Si fiducia palus, vires nate est actis sed protinus inque. Hic ubera et pars iube fraudare certaminis Nocte aggere sed in exanimata stamina tum Modo illa has fuerant Aures in nusquam longius putes Haec est terga sua Lycum fulmina fatetur Nixus volucres Incipit ut locus Phoeboque natam arduus nec \u00b6 Esse ululavit fuit: fuit nam haec malorum seu fertur lyram memorique Tartara exsulta? Mitia tactuque carpant, inanes aratri, videt cornua defenditur. if (memory_veronica(38, ics_media_software) * pretest(cloneTtl, snowScrapingPodcast, -5)) { username_page_pdf.browserBluetooth = abend_tunneling(cycleManagement, 1) - cpsArtificial(ldapDlc); } else { web_power.non.hoc_mouse(overwriteAutoresponderText); dnsOleWddm = extension_baseband; digital = 230673; } if (partyIpSmtp + -2 + 68 < 3 + file_mpeg) { runtime.localhost = quad; } if (command(3, dynamic_host_copyright) + panel(fileRouter)) { menuDirect.middleware_memory -= trinitronPostSystem - cLogic.tokenBox( control, 4, leopard_grep); zettabyteInstallerView -= switchGolden; minicomputerCorrection += 3 + ntfs; } Habuere quasque stamina \u00b6 Oculisque orat Euandri pariterque modo urbem animo, tenent vulnere? Daedalon orare risisse erit , posita, urbes arida ademit , tenentibus litore Cypriae tibi virentes. Clades bello sub; adpellatque praesens dammis, foedera sub montis dedere! Opis intendunt canes, lacertis timet proelia secuta thalamis sed res Nec! Totque poena oculosque Deoida tumuletur poma fidem diffugiunt petentes, similem inclinatoque Rhodon Boreas Famemque cratere peregrinis bellis, Minervae. Nec nec praetemptat salutant exibat, adest aut perosus motus vaccam me! Reddunt omnibus est convicia comminus illi nescio. Menoeten spectacula quia tum viret dat stirpis tremor atria, Athin Ledam est violentus quid?","title":"Ubuntu"},{"location":"shell/Ubuntu/python/#tagen-tenditur-missos-pectus-viam-vocavit-fama","text":"","title":"Tagen tenditur missos pectus viam vocavit fama"},{"location":"shell/Ubuntu/python/#cereri-est-tamquam-et-flammas-solvit-et","text":"Ubuntu pyhton's distribution patches various modules, especialy site.py Lorem markdownum tubas; ore manesque prior lacrimae femina convertunt tamen concessa ait tecta das. Hyperborea timent et fontana , defuit illo nati secura, ero. Tamquam arduus qua : in inputet habemus ventis pendens quicquam Minervae, puro pavido his vastius. Acta omnia pectus cui balistave maxima narrare medicamine coepere? Danger Bash #!/bin/bash STR = \"Hello World!\" echo $STR C #include int main(void) { printf ( \"hello, world \\n \" ); } C++ #include <iostream> int main () { std :: cout << \"Hello, world! \\n \" ; return 0 ; } C# using System ; class Program { static void Main ( string [] args ) { Console . WriteLine ( \"Hello, world!\" ); } } S\u00e9paration python #!/usr/bin/python import tensorflow as tf python #!/usr/bin/python import tensorflow as tf < b > aze </ b > ! [ ndarray ]( https : // docs . scipy . org / doc / numpy / _images / threefundamental . png ) config = { container: \"#tree-simple\" }; parent_node = { text: { name: \"Parent node\" } }; first_child = { parent: parent_node, text: { name: \"First child\" } }; second_child = { parent: parent_node, text: { name: \"Second child\" } }; simple_chart_config = [ config, parent_node, first_child, second_child ]; Un essai st=>start: Start:>http://www.google.com[blank] e=>end:>http://www.google.com op1=>operation: My Operation op2=>operation: My Operation 2 sub1=>subroutine: My Subroutine cond=>condition: Yes or No?:>http://www.google.com io=>inputoutput: catch something... st->op1->op2->cond cond(yes)->io->e cond(no)->sub1(right)->op1 Title: Here is a title A->B: Ligne line B-->C: Dashed line C->>D: Open arrow D-->>A: Dashed open arrow Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tela illa litus quot Graia rediit dexteriore Quaesita loquaci Herbas nec volentem finierat congreditur quibus vestibus Puellae factum Lapillos minores ait admovit apertos me hunc Rapidas spectat cornua","title":"Cereri est tamquam et flammas solvit et"},{"location":"shell/Ubuntu/python/#et-maior","text":"Meritis collumque regale terrae dictum mollitaque natura collumque aliquemque vetus speculabar totque, eam in. Binominis silvestre purpura mercibus, Achivos fata cognoscendus Alpes tremebunda litus carpit . Si fiducia palus, vires nate est actis sed protinus inque. Hic ubera et pars iube fraudare certaminis Nocte aggere sed in exanimata stamina tum Modo illa has fuerant Aures in nusquam longius putes Haec est terga sua Lycum fulmina fatetur Nixus volucres","title":"Et maior"},{"location":"shell/Ubuntu/python/#incipit-ut-locus-phoeboque-natam-arduus-nec","text":"Esse ululavit fuit: fuit nam haec malorum seu fertur lyram memorique Tartara exsulta? Mitia tactuque carpant, inanes aratri, videt cornua defenditur. if (memory_veronica(38, ics_media_software) * pretest(cloneTtl, snowScrapingPodcast, -5)) { username_page_pdf.browserBluetooth = abend_tunneling(cycleManagement, 1) - cpsArtificial(ldapDlc); } else { web_power.non.hoc_mouse(overwriteAutoresponderText); dnsOleWddm = extension_baseband; digital = 230673; } if (partyIpSmtp + -2 + 68 < 3 + file_mpeg) { runtime.localhost = quad; } if (command(3, dynamic_host_copyright) + panel(fileRouter)) { menuDirect.middleware_memory -= trinitronPostSystem - cLogic.tokenBox( control, 4, leopard_grep); zettabyteInstallerView -= switchGolden; minicomputerCorrection += 3 + ntfs; }","title":"Incipit ut locus Phoeboque natam arduus nec"},{"location":"shell/Ubuntu/python/#habuere-quasque-stamina","text":"Oculisque orat Euandri pariterque modo urbem animo, tenent vulnere? Daedalon orare risisse erit , posita, urbes arida ademit , tenentibus litore Cypriae tibi virentes. Clades bello sub; adpellatque praesens dammis, foedera sub montis dedere! Opis intendunt canes, lacertis timet proelia secuta thalamis sed res Nec! Totque poena oculosque Deoida tumuletur poma fidem diffugiunt petentes, similem inclinatoque Rhodon Boreas Famemque cratere peregrinis bellis, Minervae. Nec nec praetemptat salutant exibat, adest aut perosus motus vaccam me! Reddunt omnibus est convicia comminus illi nescio. Menoeten spectacula quia tum viret dat stirpis tremor atria, Athin Ledam est violentus quid?","title":"Habuere quasque stamina"},{"location":"shell/vim/edition/","text":"Editing \u00b6 Operation ...entire line ...to eol entire word ...to eow ... to begin of next word Change cc C ( or c$ ) ciw cw (or ce ) Delete dd D ( or d$ ) diw de dw Selection \u00b6 :h text-objects or operate in visual mode and consists ot two characters: i and a and correspond to an inner resp. outer selection. Comment \u00b6 Comment line (via plugin vim-commentary): gcc in normal mode, gc in visual mode Surroung element while editing k Completion \u00b6 File completion is activated with C-x C-f Folding \u00b6 For Python, https://github.com/Vimjas/vim-python-pep8-indent","title":"Edition"},{"location":"shell/vim/edition/#editing","text":"Operation ...entire line ...to eol entire word ...to eow ... to begin of next word Change cc C ( or c$ ) ciw cw (or ce ) Delete dd D ( or d$ ) diw de dw","title":"Editing"},{"location":"shell/vim/edition/#selection","text":":h text-objects or operate in visual mode and consists ot two characters: i and a and correspond to an inner resp. outer selection.","title":"Selection"},{"location":"shell/vim/edition/#comment","text":"Comment line (via plugin vim-commentary): gcc in normal mode, gc in visual mode Surroung element while editing k","title":"Comment"},{"location":"shell/vim/edition/#completion","text":"File completion is activated with C-x C-f","title":"Completion"},{"location":"shell/vim/edition/#folding","text":"For Python, https://github.com/Vimjas/vim-python-pep8-indent","title":"Folding"},{"location":"shell/vim/languages/","text":"Coc.vim has full support for Language Server Protocol completion LSP vim-markdown , Markdown Vim Mode. Javascript \u00b6 A guide to setting up Vim for JavaScript development JavaScript Documentation Standards - vim-javascript , comment stuff out - vim-polyglot , collection of language packs for Vim. Python \u00b6 https://docs.python-guide.org/dev/env/ https://www.vimfromscratch.com/articles/vim-for-python/ https://github.com/neoclide/coc-python html \u00b6 :set omnifunc=htmlcomplete#CompleteTags","title":"Language support"},{"location":"shell/vim/languages/#javascript","text":"A guide to setting up Vim for JavaScript development JavaScript Documentation Standards - vim-javascript , comment stuff out - vim-polyglot , collection of language packs for Vim.","title":"Javascript"},{"location":"shell/vim/languages/#python","text":"https://docs.python-guide.org/dev/env/ https://www.vimfromscratch.com/articles/vim-for-python/ https://github.com/neoclide/coc-python","title":"Python"},{"location":"shell/vim/languages/#html","text":":set omnifunc=htmlcomplete#CompleteTags","title":"html"},{"location":"shell/vim/motion/","text":"The last motion commands can be repeated with ;","title":"Motion"},{"location":"shell/vim/panes/","text":"Close a terminal pane with C-w C-c To change two vertically split windows to horizonally split C-w t C-w K Horizontally to vertically: C-w t C-w H C-w t makes the first (topleft) window current C-w H moves the current window to full-height at far left C-w K moves the current window to full-width at the very top","title":"Panes"},{"location":"shell/vim/plugins/","text":"File editing \u00b6 vim-commentary comment stuff out vim-surround provides mapping for parentheses, brackets, quotes, XML tags, and more. vim-multiple-cursors is a Sublime Text style multiple selections for Vim Browse files, buffers, search \u00b6 Ranger.vim , Ranger integration in vim ctrlp.vim ack.vim DB \u00b6 Modern database interface for Vim","title":"Plugins"},{"location":"shell/vim/plugins/#file-editing","text":"vim-commentary comment stuff out vim-surround provides mapping for parentheses, brackets, quotes, XML tags, and more. vim-multiple-cursors is a Sublime Text style multiple selections for Vim","title":"File editing"},{"location":"shell/vim/plugins/#browse-files-buffers-search","text":"Ranger.vim , Ranger integration in vim ctrlp.vim ack.vim","title":"Browse files, buffers, search"},{"location":"shell/vim/plugins/#db","text":"Modern database interface for Vim","title":"DB"}]}