# Bayesian inference

## Basics

 
!!! summary "Short def. (Wikipedia)"

    The [ **marginal probability** ](https://en.wikipedia.org/wiki/Marginal_distribution) is the probability of a single event occurring, independent of other events.

    $$\displaystyle p_{X}(x)=\operatorname {E} _{Y}[p_{X\mid Y}(x\mid y)]$$

    The [ **conditional probability** ](https://en.wikipedia.org/wiki/Conditional_probability) is a measure of the probability of an event occurring given that another event has (by assumption, presumption, assertion or evidence) occurred.

    $$\displaystyle p_{Y|X}(y|x)=P(Y=y|X=x)={\frac {P(X=x,Y=y)}{P_{X}(x)}}$$

    Given random variables $\displaystyle X,Y,\ldots$, that are defined on a probability space, the [**joint probability**](https://en.wikipedia.org/wiki/Joint_probability_distribution) for $\displaystyle X,Y,\ldots$ is a probability distribution that gives the probability that each of $\displaystyle X,Y,\ldots$ falls in any particular range or discrete set of values specified for that variable.

    $$∀ A ∈ C \quad P(A/B) = \frac{P(A ∩ B)}{P(B)}$$

